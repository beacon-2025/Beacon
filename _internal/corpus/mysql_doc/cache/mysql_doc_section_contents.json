{
    "15.1 Data Definition Statements": "15.1 Data Definition Statements",
    "15.1.1 Atomic Data Definition Statement Support": "15.1.1 Atomic Data Definition Statement Support\nMySQL 9.1 supports atomic Data Definition Language (DDL) statements. This feature is referred\nto as atomic DDL. An atomic DDL statement combines the data dictionary updates, storage engine\noperations, and binary log writes associated with a DDL operation into a single, atomic operation. The\noperation is either committed, with applicable changes persisted to the data dictionary, storage engine,\nand binary log, or is rolled back, even if the server halts during the operation.\nNote\nAtomic DDL is not transactional DDL. DDL statements, atomic or otherwise,\nimplicitly end any transaction that is active in the current session, as if you\nhad done a COMMIT before executing the statement. This means that DDL\nstatements cannot be performed within another transaction, within transaction\ncontrol statements such as START TRANSACTION ... COMMIT, or combined\nwith other statements within the same transaction.\nAtomic DDL is made possible by the MySQL data dictionary, which provides centralized, transactional\nmetadata storage.\nThe atomic DDL feature is described under the following topics in this section:\n• Supported DDL Statements\n• Atomic DDL Characteristics\n• DDL Statement Behavior\n• Storage Engine Support\n• Viewing DDL Logs\nSupported DDL Statements\nThe atomic DDL feature supports both table and non-table DDL statements. Table-related DDL\noperations require storage engine support, whereas non-table DDL operations do not. Currently, only\nthe InnoDB storage engine supports atomic DDL.\n• Supported table DDL statements include CREATE, ALTER, and DROP statements for databases,\ntablespaces, tables, and indexes, and the TRUNCATE TABLE statement.\n• Supported non-table DDL statements include:\n• CREATE and DROP statements, and, if applicable, ALTER statements for stored programs, triggers,\nviews, and loadable functions.\n• Account management statements: CREATE, ALTER, DROP, and, if applicable, RENAME statements\nfor users and roles, as well as GRANT and REVOKE statements.\nThe following statements are not supported by the atomic DDL feature:\n• Table-related DDL statements that involve a storage engine other than InnoDB.\n• INSTALL PLUGIN and UNINSTALL PLUGIN statements.\n• INSTALL COMPONENT and UNINSTALL COMPONENT statements.\n• CREATE SERVER, ALTER SERVER, and DROP SERVER statements.\nAtomic DDL Characteristics\nThe characteristics of atomic DDL statements include the following:\n• Metadata updates, binary log writes, and storage engine operations, where applicable, are combined\ninto a single atomic operation.\n• There are no intermediate commits at the SQL layer during the DDL operation.\n• Where applicable:\n• The state of data dictionary, routine, event, and loadable function caches is consistent with the\nstatus of the DDL operation, meaning that caches are updated to reflect whether or not the DDL\noperation was completed successfully or rolled back.\n• The storage engine methods involved in a DDL operation do not perform intermediate commits,\nand the storage engine registers itself as part of the DDL operation.\n• The storage engine supports redo and rollback of DDL operations, which is performed in the Post-\nDDL phase of the DDL operation.\n• The visible behaviour of DDL operations is atomic.\nDDL Statement Behavior\nThis section describes some important aspects of DDL statement behavior when using a storage\nengine that support atomic DDL, such as InnoDB.\n• DROP TABLE operations are fully atomic if all named tables use a storage engine which supports\natomic DDL. The statement either drops all tables successfully or is rolled back.\nDROP TABLE fails with an error if a named table does not exist, and no changes are made,\nregardless of the storage engine.\n• CREATE DATABASE and DROP DATABASE are fully atomic and crash-safe, provided that all tables in\nthe named database use a storage engine which supports atomic DDL, in which case the statement\neither adds or drops all objects successfully, or is rolled back.\nIn previous versions of MySQL:\n• When CREATE DATABASE created the database directory but the statement was not subsequently\ncommitted, the directory had to be removed manually.\n• When removal of the database directory failed due to a file system error or a server halt, DROP\nDATABASE was not rolled back.\nThese are no longer issues in MySQL 9.1.\n• For tables that do not use a storage engine which supports atomic DDL, table deletion occurs\noutside of the atomic DROP TABLE or DROP DATABASE transaction. Such table deletions are\nwritten to the binary log individually, which limits the discrepancy between the storage engine, data\ndictionary, and binary log to one table at most in the case of an interrupted DROP TABLE or DROP\nDATABASE operation. For operations that drop multiple tables, any tables that do not use a storage\nengine which supports atomic DDL are dropped before tables that do so.\n• CREATE TABLE, ALTER TABLE, RENAME TABLE, TRUNCATE TABLE, CREATE TABLESPACE, and\nDROP TABLESPACE operations for tables that use a storage engine which supports atomic DDL\nare either fully committed or rolled back if the server halts during their operation. RENAME TABLE\noperations are atomic only if all named tables use a storage engine which supports atomic DDL.\n• For storage engines that support atomic DDL, the CREATE TABLE ... SELECT statement is\nlogged as one transaction in the binary log when row-based replication is in use.\nOn storage engines that support both atomic DDL and foreign key constraints, creation of foreign\nkeys is not permitted in CREATE TABLE ... SELECT statements when row-based replication is in\nuse. Foreign key constraints can be added later using ALTER TABLE.\nWhen CREATE TABLE ... SELECT is applied as an atomic operation, a metadata lock is held on\nthe table while data is inserted, which prevents concurrent access to the table for the duration of the\noperation.\n• DROP VIEW fails if a named view does not exist, and no changes are made.\n• Account management statements either succeed for all named users or roll back and have no effect\nif an error occurs.\nStorage Engine Support\nCurrently, only the InnoDB storage engine supports atomic DDL. Storage engines that do not support\natomic DDL are exempted from DDL atomicity. DDL operations involving exempted storage engines\nremain capable of introducing inconsistencies that can occur when operations are interrupted or only\npartially completed.\nTo support redo and rollback of DDL operations, InnoDB writes DDL logs to the\nmysql.innodb_ddl_log table, which is a hidden data dictionary table that resides in the\nmysql.ibd data dictionary tablespace.\nTo view DDL logs that are written to the mysql.innodb_ddl_log table during a DDL operation,\nenable the innodb_print_ddl_logs configuration option. For more information, see Viewing DDL\nLogs.\nNote\nThe redo logs for changes to the mysql.innodb_ddl_log table are flushed\nto disk immediately regardless of the innodb_flush_log_at_trx_commit\nsetting. Flushing the redo logs immediately avoids situations where data\nfiles are modified by DDL operations but the redo logs for changes to the\nmysql.innodb_ddl_log table resulting from those operations are not\npersisted to disk. Such a situation could cause errors during rollback or\nrecovery.\nThe InnoDB storage engine executes DDL operations in phases. DDL operations such as ALTER\nTABLE may perform the Prepare and Perform phases multiple times prior to the Commit phase.\n1. Prepare: Create the required objects and write the DDL logs to the mysql.innodb_ddl_log\ntable. The DDL logs define how to roll forward and roll back the DDL operation.\n2. Perform: Perform the DDL operation. For example, perform a create routine for a CREATE TABLE\noperation.\n3. Commit: Update the data dictionary and commit the data dictionary transaction.\n4. Post-DDL: Replay and remove DDL logs from the mysql.innodb_ddl_log table. To ensure\nthat rollback can be performed safely without introducing inconsistencies, file operations such\nas renaming or removing data files are performed in this final phase. This phase also removes\ndynamic metadata from the mysql.innodb_dynamic_metadata data dictionary table for DROP\nTABLE, TRUNCATE TABLE, and other DDL operations that rebuild the table.\nDDL logs are replayed and removed from the mysql.innodb_ddl_log table during the Post-DDL\nphase, regardless of whether the DDL operation is committed or rolled back. DDL logs should only\nremain in the mysql.innodb_ddl_log table if the server is halted during a DDL operation. In this\ncase, the DDL logs are replayed and removed after recovery.\nIn a recovery situation, a DDL operation may be committed or rolled back when the server is restarted.\nIf the data dictionary transaction that was performed during the Commit phase of a DDL operation is\npresent in the redo log and binary log, the operation is considered successful and is rolled forward.\nOtherwise, the incomplete data dictionary transaction is rolled back when InnoDB replays data\ndictionary redo logs, and the DDL operation is rolled back.\nViewing DDL Logs\nTo view DDL logs that are written to the mysql.innodb_ddl_log data dictionary table during atomic\nDDL operations that involve the InnoDB storage engine, enable innodb_print_ddl_logs to\nhave MySQL write the DDL logs to stderr. Depending on the host operating system and MySQL\nconfiguration, stderr may be the error log, terminal, or console window. See Section 7.4.2.2, “Default\nError Log Destination Configuration”.\nInnoDB writes DDL logs to the mysql.innodb_ddl_log table to support redo and rollback\nof DDL operations. The mysql.innodb_ddl_log table is a hidden data dictionary table that\nresides in the mysql.ibd data dictionary tablespace. Like other hidden data dictionary tables, the\nmysql.innodb_ddl_log table cannot be accessed directly in non-debug versions of MySQL.\n(See Section 16.1, “Data Dictionary Schema”.) The structure of the mysql.innodb_ddl_log table\ncorresponds to this definition:\nCREATE TABLE mysql.innodb_ddl_log (\n  id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  thread_id BIGINT UNSIGNED NOT NULL,\n  type INT UNSIGNED NOT NULL,\n  space_id INT UNSIGNED,\n  page_no INT UNSIGNED,\n  index_id BIGINT UNSIGNED,\n  table_id BIGINT UNSIGNED,\n  old_file_path VARCHAR(512) COLLATE utf8mb4_bin,\n  new_file_path VARCHAR(512) COLLATE utf8mb4_bin,\n  KEY(thread_id)\n);\n• id: A unique identifier for a DDL log record.\n• thread_id: Each DDL log record is assigned a thread_id, which is used to replay and remove\nDDL logs that belong to a particular DDL operation. DDL operations that involve multiple data file\noperations generate multiple DDL log records.\n• type: The DDL operation type. Types include FREE (drop an index tree), DELETE (delete a file),\nRENAME (rename a file), or DROP (drop metadata from the mysql.innodb_dynamic_metadata\ndata dictionary table).\n• space_id: The tablespace ID.\n• page_no: A page that contains allocation information; an index tree root page, for example.\n• index_id: The index ID.\n• table_id: The table ID.\n• old_file_path: The old tablespace file path. Used by DDL operations that create or drop\ntablespace files; also used by DDL operations that rename a tablespace.\n• new_file_path: The new tablespace file path. Used by DDL operations that rename tablespace\nfiles.\nThis example demonstrates enabling innodb_print_ddl_logs to view DDL logs written to\nstrderr for a CREATE TABLE operation.\nmysql> SET GLOBAL innodb_print_ddl_logs=1;\nmysql> CREATE TABLE t1 (c1 INT) ENGINE = InnoDB;\n[Note] [000000] InnoDB: DDL log insert : [DDL record: DELETE SPACE, id=18, thread_id=7,\nspace_id=5, old_file_path=./test/t1.ibd]\n[Note] [000000] InnoDB: DDL log delete : by id 18\n[Note] [000000] InnoDB: DDL log insert : [DDL record: REMOVE CACHE, id=19, thread_id=7,\ntable_id=1058, new_file_path=test/t1]\n[Note] [000000] InnoDB: DDL log delete : by id 19\n[Note] [000000] InnoDB: DDL log insert : [DDL record: FREE, id=20, thread_id=7,\nspace_id=5, index_id=132, page_no=4]\n[Note] [000000] InnoDB: DDL log delete : by id 20\n[Note] [000000] InnoDB: DDL log post ddl : begin for thread id : 7\n[Note] [000000] InnoDB: DDL log post ddl : end for thread id : 7",
    "15.1.2 ALTER DATABASE Statement": "15.1.2 ALTER DATABASE Statement\nALTER {DATABASE | SCHEMA} [db_name]\n    alter_option ...\nalter_option: {\n    [DEFAULT] CHARACTER SET [=] charset_name\n  | [DEFAULT] COLLATE [=] collation_name\n  | [DEFAULT] ENCRYPTION [=] {'Y' | 'N'}\n  | READ ONLY [=] {DEFAULT | 0 | 1}\n}\nALTER DATABASE enables you to change the overall characteristics of a database. These\ncharacteristics are stored in the data dictionary. This statement requires the ALTER privilege on the\ndatabase. ALTER SCHEMA is a synonym for ALTER DATABASE.\nIf the database name is omitted, the statement applies to the default database. In that case, an error\noccurs if there is no default database.\nFor any alter_option omitted from the statement, the database retains its current option value, with\nthe exception that changing the character set may change the collation and vice versa.\n• Character Set and Collation Options\n• Encryption Option\n• Read Only Option\nCharacter Set and Collation Options\nThe CHARACTER SET option changes the default database character set. The COLLATE option\nchanges the default database collation. For information about character set and collation names, see\nChapter 12, Character Sets, Collations, Unicode.\nTo see the available character sets and collations, use the SHOW CHARACTER SET and SHOW\nCOLLATION statements, respectively. See Section 15.7.7.4, “SHOW CHARACTER SET Statement”,\nand Section 15.7.7.5, “SHOW COLLATION Statement”.\nA stored routine that uses the database defaults when the routine is created includes those defaults\nas part of its definition. (In a stored routine, variables with character data types use the database\ndefaults if the character set or collation are not specified explicitly. See Section 15.1.17, “CREATE\nPROCEDURE and CREATE FUNCTION Statements”.) If you change the default character set or\ncollation for a database, any stored routines that are to use the new defaults must be dropped and\nrecreated.\nEncryption Option\nThe ENCRYPTION option, defines the default database encryption, which is inherited by tables created\nin the database. The permitted values are 'Y' (encryption enabled) and 'N' (encryption disabled).\nThe mysql system schema cannot be set to default encryption. The existing tables within it are part of\nthe general mysql tablespace, which may be encrypted. The information_schema contains only\nviews. It is not possible to create any tables within it. There is nothing on the disk to encrypt. All tables\nin the performance_schema use the PERFORMANCE_SCHEMA engine, which is purely in-memory. It is\nnot possible to create any other tables in it. There is nothing on the disk to encrypt.\nOnly newly created tables inherit the default database encryption. For existing tables associated with\nthe database, their encryption remains unchanged. If the table_encryption_privilege_check\nsystem variable is enabled, the TABLE_ENCRYPTION_ADMIN privilege is required to specify a default\nencryption setting that differs from the value of the default_table_encryption system variable.\nFor more information, see Defining an Encryption Default for Schemas and General Tablespaces.\nRead Only Option\nThe READ ONLY option controls whether to permit modification of the database and objects within\nit. The permitted values are DEFAULT or 0 (not read only) and 1 (read only). This option is useful for\ndatabase migration because a database for which READ ONLY is enabled can be migrated to another\nMySQL instance without concern that the database might be changed during the operation.\nWith NDB Cluster, making a database read only on one mysqld server is synchronized to other\nmysqld servers in the same cluster, so that the database becomes read only on all mysqld servers.\nThe READ ONLY option, if enabled, is displayed in the INFORMATION_SCHEMA\nSCHEMATA_EXTENSIONS table. See Section 28.3.32, “The INFORMATION_SCHEMA\nSCHEMATA_EXTENSIONS Table”.\nThe READ ONLY option cannot be enabled for these system schemas: mysql,\ninformation_schema, performance_schema.\nIn ALTER DATABASE statements, the READ ONLY option interacts with other instances of itself and\nwith other options as follows:\n• An error occurs if multiple instances of READ ONLY conflict (for example, READ ONLY = 1 READ\nONLY = 0).\n• An ALTER DATABASE statement that contains only (nonconflicting) READ ONLY options is permitted\neven for a read-only database.\n• A mix of (nonconflicting) READ ONLY options with other options is permitted if the read-only state of\nthe database either before or after the statement permits modifications. If the read-only state both\nbefore and after prohibits changes, an error occurs.\nThis statement succeeds whether or not the database is read only:\nALTER DATABASE mydb READ ONLY = 0 DEFAULT COLLATE utf8mb4_bin;\nThis statement succeeds if the database is not read only, but fails if it is already read only:\nALTER DATABASE mydb READ ONLY = 1 DEFAULT COLLATE utf8mb4_bin;\nEnabling READ ONLY affects all users of the database, with these exceptions that are not subject to\nread-only checks:\n• Statements executed by the server as part of server initialization, restart, upgrade, or replication.\n• Statements in a file named at server startup by the init_file system variable.\n• TEMPORARY tables; it is possible to create, alter, drop, and write to TEMPORARY tables in a read-only\ndatabase.\n• NDB Cluster non-SQL inserts and updates.\nOther than for the excepted operations just listed, enabling READ ONLY prohibits write operations to\nthe database and its objects, including their definitions, data, and metadata. The following list details\naffected SQL statements and operations:\n• The database itself:\n• CREATE DATABASE\n• ALTER DATABASE (except to change the READ ONLY option)\n• DROP DATABASE\n• Views:\n• CREATE VIEW\n• ALTER VIEW\n• DROP VIEW\n• Selecting from views that invoke functions with side effects.\n• Updating updatable views.\n• Statements that create or drop objects in a writable database are rejected if they affect metadata\nof a view in a read-only database (for example, by making the view valid or invalid).\n• Stored routines:\n• CREATE PROCEDURE\n• DROP PROCEDURE\n• CALL (of procedures with side effects)\n• CREATE FUNCTION\n• DROP FUNCTION\n• SELECT (of functions with side effects)\n• For procedures and functions, read-only checks follow prelocking behavior. For CALL statements,\nread-only checks are done on a per-statement basis, so if some conditionally executed statement\nwriting to a read-only database does not actually execute, the call still succeeds. On the other\nhand, for a function called within a SELECT, execution of the function body happens in prelocked\nmode. As long as a some statement within the function writes to a read-only database, execution\nof the function fails with an error regardless of whether the statement actually executes.\n• Triggers:\n• CREATE TRIGGER\n• DROP TRIGGER\n• Trigger invocation.\n• Events:\n• CREATE EVENT\n• ALTER EVENT\n• DROP EVENT\n• Event execution:\n• Executing an event in the database fails because that would change the last-execution\ntimestamp, which is event metadata stored in the data dictionary. Failure of event execution also\nhas the effect of causing the event scheduler to stop.\n• If an event writes to an object in a read-only database, execution of the event fails with an error,\nbut the event scheduler is not stopped.\n• Tables:\n• CREATE TABLE\n• ALTER TABLE\n• CREATE INDEX\n• DROP INDEX\n• RENAME TABLE\n• TRUNCATE TABLE\n• DROP TABLE\n• DELETE\n• INSERT\n• IMPORT TABLE\n• LOAD DATA\n• LOAD XML\n• REPLACE\n• UPDATE\n• For cascading foreign keys where the child table is in a read-only database, updates and deletes\non the parent are rejected even if the child table is not directly affected.\n• For a MERGE table such as CREATE TABLE s1.t(i int) ENGINE MERGE UNION (s2.t,\ns3.t), INSERT_METHOD=..., the following behavior applies:\n• Inserting into the MERGE table (INSERT into s1.t) fails if at least one of s1, s2, s3 is read\nonly, regardless of insert method. The insert is refused even if it would actually end up in a\nwritable table.\n• Dropping the MERGE table (DROP TABLE s1.t) succeeds as long as s1 is not read only. It is\npermitted to drop a MERGE table that refers to a read-only database.\nAn ALTER DATABASE statement blocks until all concurrent transactions that have already accessed\nan object in the database being altered have committed. Conversely, a write transaction accessing\nan object in a database being altered in a concurrent ALTER DATABASE blocks until the ALTER\nDATABASE has committed.\nIf the Clone plugin is used to clone a local or remote data directory, the databases in the clone retain\nthe read-only state they had in the source data directory. The read-only state does not affect the\ncloning process itself. If it is not desirable to have the same database read-only state in the clone, the\noption must be changed explicitly for the clone after the cloning process has finished, using ALTER\nDATABASE operations on the clone.\nWhen cloning from a donor to a recipient, if the recipient has a user database that is read only, cloning\nfails with an error message. Cloning may be retried after making the database writable.\nREAD ONLY is permitted for ALTER DATABASE, but not for CREATE DATABASE. However, for a read-\nonly database, the statement produced by SHOW CREATE DATABASE does include READ ONLY=1\nwithin a comment to indicate its read-only status:\nmysql> ALTER DATABASE mydb READ ONLY = 1;\nmysql> SHOW CREATE DATABASE mydb\\G\n*************************** 1. row ***************************\n       Database: mydb\nCreate Database: CREATE DATABASE `mydb`\n                 /*!40100 DEFAULT CHARACTER SET utf8mb4\n                          COLLATE utf8mb4_0900_ai_ci */\n                 /*!80016 DEFAULT ENCRYPTION='N' */\n                 /* READ ONLY = 1 */\nIf the server executes a CREATE DATABASE statement containing such a comment, the server ignores\nthe comment and the READ ONLY option is not processed. This has implications for mysqldump, which\nuses SHOW CREATE DATABASE to produce CREATE DATABASE statements in dump output:\n• In a dump file, the CREATE DATABASE statement for a read-only database contains the commented\nREAD ONLY option.\n• The dump file can be restored as usual, but because the server ignores the commented READ ONLY\noption, the restored database is not read only. If the database is to be read only after being restored,\nyou must execute ALTER DATABASE manually to make it so.\nSuppose that mydb is read only and you dump it as follows:\n$> mysqldump --databases mydb > mydb.sql\nA restore operation later must be followed by ALTER DATABASE if mydb should still be read only:\n$> mysql\nmysql> SOURCE mydb.sql;\nmysql> ALTER DATABASE mydb READ ONLY = 1;\nMySQL Enterprise Backup is not subject to this issue. It backs up and restores a read-only database\nlike any other, but enables the READ ONLY option at restore time if it was enabled at backup time.\nALTER DATABASE is written to the binary log, so a change to the READ ONLY option on a replication\nsource server also affects replicas. To prevent this from happening, binary logging must be disabled\nprior to execution of the ALTER DATABASE statement. For example, to prepare for migrating a\ndatabase without affecting replicas, perform these operations:\n1. Within a single session, disable binary logging and enable READ ONLY for the database:\nmysql> SET sql_log_bin = OFF;\nmysql> ALTER DATABASE mydb READ ONLY = 1;\n2. Dump the database, for example, with mysqldump:\n$> mysqldump --databases mydb > mydb.sql\n3. Within a single session, disable binary logging and disable READ ONLY for the database:\nmysql> SET sql_log_bin = OFF;\nmysql> ALTER DATABASE mydb READ ONLY = 0;",
    "15.1.3 ALTER EVENT Statement": "15.1.3 ALTER EVENT Statement\nALTER\n    [DEFINER = user]\n    EVENT event_name\n    [ON SCHEDULE schedule]\n    [ON COMPLETION [NOT] PRESERVE]\n    [RENAME TO new_event_name]\n    [ENABLE | DISABLE | DISABLE ON {REPLICA | SLAVE}]\n    [COMMENT 'string']\n    [DO event_body]\nThe ALTER EVENT statement changes one or more of the characteristics of an existing event\nwithout the need to drop and recreate it. The syntax for each of the DEFINER, ON SCHEDULE, ON\nCOMPLETION, COMMENT, ENABLE / DISABLE, and DO clauses is exactly the same as when used with\nCREATE EVENT. (See Section 15.1.13, “CREATE EVENT Statement”.)\nAny user can alter an event defined on a database for which that user has the EVENT privilege. When\na user executes a successful ALTER EVENT statement, that user becomes the definer for the affected\nevent.\nALTER EVENT works only with an existing event:\nmysql> ALTER EVENT no_such_event \n     >     ON SCHEDULE \n     >       EVERY '2:3' DAY_HOUR;\nERROR 1517 (HY000): Unknown event 'no_such_event'\nIn each of the following examples, assume that the event named myevent is defined as shown here:\nCREATE EVENT myevent\n    ON SCHEDULE\n      EVERY 6 HOUR\n    COMMENT 'A sample comment.'\n    DO\n      UPDATE myschema.mytable SET mycol = mycol + 1;\nThe following statement changes the schedule for myevent from once every six hours starting\nimmediately to once every twelve hours, starting four hours from the time the statement is run:\nALTER EVENT myevent\n    ON SCHEDULE\n      EVERY 12 HOUR\n    STARTS CURRENT_TIMESTAMP + INTERVAL 4 HOUR;\nIt is possible to change multiple characteristics of an event in a single statement. This example\nchanges the SQL statement executed by myevent to one that deletes all records from mytable; it\nalso changes the schedule for the event such that it executes once, one day after this ALTER EVENT\nstatement is run.\nALTER EVENT myevent\n    ON SCHEDULE\n      AT CURRENT_TIMESTAMP + INTERVAL 1 DAY\n    DO\n      TRUNCATE TABLE myschema.mytable;\nSpecify the options in an ALTER EVENT statement only for those characteristics that you want to\nchange; omitted options keep their existing values. This includes any default values for CREATE\nEVENT such as ENABLE.\nTo disable myevent, use this ALTER EVENT statement:\nALTER EVENT myevent\n    DISABLE;\nThe ON SCHEDULE clause may use expressions involving built-in MySQL functions and user variables\nto obtain any of the timestamp or interval values which it contains. You cannot use stored routines\nor loadable functions in such expressions, and you cannot use any table references; however, you\ncan use SELECT FROM DUAL. This is true for both ALTER EVENT and CREATE EVENT statements.\nReferences to stored routines, loadable functions, and tables in such cases are specifically not\npermitted, and fail with an error (see Bug #22830).\nAlthough an ALTER EVENT statement that contains another ALTER EVENT statement in its DO clause\nappears to succeed, when the server attempts to execute the resulting scheduled event, the execution\nfails with an error.\nTo rename an event, use the ALTER EVENT statement's RENAME TO clause. This statement renames\nthe event myevent to yourevent:\nALTER EVENT myevent\n    RENAME TO yourevent;\nYou can also move an event to a different database using ALTER EVENT ... RENAME TO ... and\ndb_name.event_name notation, as shown here:\nALTER EVENT olddb.myevent\n    RENAME TO newdb.myevent;\nTo execute the previous statement, the user executing it must have the EVENT privilege on both the\nolddb and newdb databases.\nNote\nThere is no RENAME EVENT statement.\nThe value DISABLE ON REPLICA is used on a replica instead of ENABLE or DISABLE to indicate\nan event that was created on the replication source server and replicated to the replica, but that is\nnot executed on the replica. Normally, DISABLE ON REPLICA is set automatically as required;\nhowever, there are some circumstances under which you may want or need to change it manually. See\nSection 19.5.1.16, “Replication of Invoked Features”, for more information.\nDISABLE ON REPLICA replaces DISABLE ON SLAVE, which is deprecated, and subject to removal\nin a future version of MySQL.",
    "15.1.4 ALTER FUNCTION Statement": "15.1.4 ALTER FUNCTION Statement\nALTER FUNCTION func_name [characteristic ...]\ncharacteristic: {\n    COMMENT 'string'\n  | LANGUAGE SQL\n  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }\n  | SQL SECURITY { DEFINER | INVOKER }\n}\nThis statement can be used to change the characteristics of a stored function. More than one change\nmay be specified in an ALTER FUNCTION statement. However, you cannot change the parameters or\nbody of a stored function using this statement; to make such changes, you must drop and re-create the\nfunction using DROP FUNCTION and CREATE FUNCTION.\nYou must have the ALTER ROUTINE privilege for the function. (That privilege is granted automatically\nto the function creator.) If binary logging is enabled, the ALTER FUNCTION statement might also\nrequire the SUPER privilege, as described in Section 27.8, “Stored Program Binary Logging”.",
    "15.1.5 ALTER INSTANCE Statement": "15.1.5 ALTER INSTANCE Statement\nALTER INSTANCE instance_action\ninstance_action: {\n  | {ENABLE|DISABLE} INNODB REDO_LOG\n  | ROTATE INNODB MASTER KEY\n  | ROTATE BINLOG MASTER KEY\n  | RELOAD TLS\n      [FOR CHANNEL {mysql_main | mysql_admin}]\n      [NO ROLLBACK ON ERROR]\n  | RELOAD KEYRING\n}\nALTER INSTANCE defines actions applicable to a MySQL server instance. The statement supports\nthese actions:\n• ALTER INSTANCE {ENABLE | DISABLE} INNODB REDO_LOG\nThis action enables or disables InnoDB redo logging. Redo logging is enabled by default. This\nfeature is intended only for loading data into a new MySQL instance. The statement is not written to\nthe binary log.\nWarning\nDo not disable redo logging on a production system. While it is permitted\nto shut down and restart the server while redo logging is disabled, an\nunexpected server stoppage while redo logging is disabled can cause data\nloss and instance corruption.\nAn ALTER INSTANCE [ENABLE|DISABLE] INNODB REDO_LOG operation requires an exclusive\nbackup lock, which prevents other ALTER INSTANCE operations from executing concurrently. Other\nALTER INSTANCE operations must wait for the lock to be released before executing.\nFor more information, see Disabling Redo Logging.\n• ALTER INSTANCE ROTATE INNODB MASTER KEY\nThis action rotates the master encryption key used for InnoDB tablespace encryption. Key rotation\nrequires the ENCRYPTION_KEY_ADMIN or SUPER privilege. To perform this action, a keyring plugin\nmust be installed and configured. For instructions, see Section 8.4.4, “The MySQL Keyring”.\nALTER INSTANCE ROTATE INNODB MASTER KEY supports concurrent DML. However, it cannot\nbe run concurrently with CREATE TABLE ... ENCRYPTION or ALTER TABLE ... ENCRYPTION\noperations, and locks are taken to prevent conflicts that could arise from concurrent execution of\nthese statements. If one of the conflicting statements is running, it must complete before another can\nproceed.\nALTER INSTANCE ROTATE INNODB MASTER KEY statements are written to the binary log so that\nthey can be executed on replicated servers.\nFor additional ALTER INSTANCE ROTATE INNODB MASTER KEY usage information, see\nSection 17.13, “InnoDB Data-at-Rest Encryption”.\n• ALTER INSTANCE ROTATE BINLOG MASTER KEY\nThis action rotates the binary log master key used for binary log encryption. Key rotation for the\nbinary log master key requires the BINLOG_ENCRYPTION_ADMIN or SUPER privilege. The statement\ncannot be used if the binlog_encryption system variable is set to OFF. To perform this action,\na keyring plugin must be installed and configured. For instructions, see Section 8.4.4, “The MySQL\nKeyring”.\nALTER INSTANCE ROTATE BINLOG MASTER KEY actions are not written to the binary log and are\nnot executed on replicas. Binary log master key rotation can therefore be carried out in replication\nenvironments including a mix of MySQL versions. To schedule regular rotation of the binary log\nmaster key on all applicable source and replica servers, you can enable the MySQL Event Scheduler\non each server and issue the ALTER INSTANCE ROTATE BINLOG MASTER KEY statement using\na CREATE EVENT statement. If you rotate the binary log master key because you suspect that the\ncurrent or any of the previous binary log master keys might have been compromised, issue the\nstatement on every applicable source and replica server, which enables you to verify immediate\ncompliance.\nFor additional ALTER INSTANCE ROTATE BINLOG MASTER KEY usage information, including\nwhat to do if the process does not complete correctly or is interrupted by an unexpected server halt,\nsee Section 19.3.2, “Encrypting Binary Log Files and Relay Log Files”.\n• ALTER INSTANCE RELOAD TLS\nThis action reconfigures a TLS context from the current values of the system variables that define\nthe context. It also updates the status variables that reflect the active context values. This action\nrequires the CONNECTION_ADMIN privilege. For additional information about reconfiguring the TLS\ncontext, including which system and status variables are context-related, see Server-Side Runtime\nConfiguration and Monitoring for Encrypted Connections.\nBy default, the statement reloads the TLS context for the main connection interface. If the\nFOR CHANNEL clause is given, the statement reloads the TLS context for the named channel:\nmysql_main for the main connection interface, mysql_admin for the administrative connection\ninterface. For information about the different interfaces, see Section 7.1.12.1, “Connection\nInterfaces”. The updated TLS context properties are exposed in the Performance Schema\ntls_channel_status table. See Section 29.12.22.10, “The tls_channel_status Table”.\nUpdating the TLS context for the main interface may also affect the administrative interface because\nunless some nondefault TLS value is configured for that interface, it uses the same TLS context as\nthe main interface.\nNote\nWhen you reload the TLS context, OpenSSL reloads the file containing the\nCRL (certificate revocation list) as part of the process. If the CRL file is large,\nthe server allocates a large chunk of memory (ten times the file size), which\nis doubled while the new instance is being loaded and the old one has not\nyet been released. The process resident memory is not immediately reduced\nafter a large allocation is freed, so if you issue the ALTER INSTANCE\nRELOAD TLS statement repeatedly with a large CRL file, the process resident\nmemory usage may grow as a result of this.\nBy default, the RELOAD TLS action rolls back with an error and has no effect if the configuration\nvalues do not permit creation of the new TLS context. The previous context values continue to be\nused for new connections. If the optional NO ROLLBACK ON ERROR clause is given and the new\ncontext cannot be created, rollback does not occur. Instead, a warning is generated and encryption is\ndisabled for new connections on the interface to which the statement applies.\nALTER INSTANCE RELOAD TLS statements are not written to the binary log (and thus are not\nreplicated). TLS configuration is local and depends on local files not necessarily present on all\nservers involved.\n• ALTER INSTANCE RELOAD KEYRING\nIf a keyring component is installed, this action tells the component to re-read its configuration file and\nreinitialize any keyring in-memory data. If you modify the component configuration at runtime, the\nnew configuration does not take effect until you perform this action. Keyring reloading requires the\nENCRYPTION_KEY_ADMIN privilege.\nThis action enables reconfiguring only the currently installed keyring component. It does not enable\nchanging which component is installed. For example, if you change the configuration for the installed\nkeyring component, ALTER INSTANCE RELOAD KEYRING causes the new configuration to take\neffect. On the other hand, if you change the keyring component named in the server manifest file,\nALTER INSTANCE RELOAD KEYRING has no effect and the current component remains installed.\nALTER INSTANCE RELOAD KEYRING statements are not written to the binary log (and thus are not\nreplicated).",
    "15.1.6 ALTER LOGFILE GROUP Statement": "15.1.6 ALTER LOGFILE GROUP Statement\nALTER LOGFILE GROUP logfile_group\n    ADD UNDOFILE 'file_name'\n    [INITIAL_SIZE [=] size]\n    [WAIT]\n    ENGINE [=] engine_name\nThis statement adds an UNDO file named 'file_name' to an existing log file group logfile_group.\nAn ALTER LOGFILE GROUP statement has one and only one ADD UNDOFILE clause. No DROP\nUNDOFILE clause is currently supported.\nNote\nAll NDB Cluster Disk Data objects share the same namespace. This means\nthat each Disk Data object must be uniquely named (and not merely each Disk\nData object of a given type). For example, you cannot have a tablespace and\nan undo log file with the same name, or an undo log file and a data file with the\nsame name.\nThe optional INITIAL_SIZE parameter sets the UNDO file's initial size in bytes; if not specified,\nthe initial size defaults to 134217728 (128 MB). You may optionally follow size with a one-letter\nabbreviation for an order of magnitude, similar to those used in my.cnf. Generally, this is one of the\nletters M (megabytes) or G (gigabytes). (Bug #13116514, Bug #16104705, Bug #62858)\nOn 32-bit systems, the maximum supported value for INITIAL_SIZE is 4294967296 (4 GB). (Bug\n#29186)\nThe minimum allowed value for INITIAL_SIZE is 1048576 (1 MB). (Bug #29574)\nNote\nWAIT is parsed but otherwise ignored. This keyword currently has no effect, and\nis intended for future expansion.\nThe ENGINE clause (required) determines the storage engine which is used by this log file group,\nwith engine_name being the name of the storage engine. Currently, the only accepted values for\nengine_name are “NDBCLUSTER” and “NDB”. The two values are equivalent.\nHere is an example, which assumes that the log file group lg_3 has already been created using\nCREATE LOGFILE GROUP (see Section 15.1.16, “CREATE LOGFILE GROUP Statement”):\nALTER LOGFILE GROUP lg_3\n    ADD UNDOFILE 'undo_10.dat'\n    INITIAL_SIZE=32M\n    ENGINE=NDBCLUSTER;\nWhen ALTER LOGFILE GROUP is used with ENGINE = NDBCLUSTER (alternatively, ENGINE =\nNDB), an undo log file is created on each NDB Cluster data node. You can verify that the undo files\nwere created and obtain information about them by querying the Information Schema FILES table. For\nexample:\nmysql> SELECT FILE_NAME, LOGFILE_GROUP_NUMBER, EXTRA\n    -> FROM INFORMATION_SCHEMA.FILES\n    -> WHERE LOGFILE_GROUP_NAME = 'lg_3';\n+-------------+----------------------+----------------+\n| FILE_NAME   | LOGFILE_GROUP_NUMBER | EXTRA          |\n+-------------+----------------------+----------------+\n| newdata.dat |                    0 | CLUSTER_NODE=3 |\n| newdata.dat |                    0 | CLUSTER_NODE=4 |\n| undo_10.dat |                   11 | CLUSTER_NODE=3 |\n| undo_10.dat |                   11 | CLUSTER_NODE=4 |\n+-------------+----------------------+----------------+\n4 rows in set (0.01 sec)\n(See Section 28.3.15, “The INFORMATION_SCHEMA FILES Table”.)\nMemory used for UNDO_BUFFER_SIZE comes from the global pool whose size is determined by the\nvalue of the SharedGlobalMemory data node configuration parameter. This includes any default\nvalue implied for this option by the setting of the InitialLogFileGroup data node configuration\nparameter.\nALTER LOGFILE GROUP is useful only with Disk Data storage for NDB Cluster. For more information,\nsee Section 25.6.11, “NDB Cluster Disk Data Tables”.",
    "15.1.7 ALTER PROCEDURE Statement": "15.1.7 ALTER PROCEDURE Statement\nALTER PROCEDURE proc_name [characteristic ...]\ncharacteristic: {\n    COMMENT 'string'\n  | LANGUAGE SQL\n  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }\n  | SQL SECURITY { DEFINER | INVOKER }\n}\nThis statement can be used to change the characteristics of a stored procedure. More than one change\nmay be specified in an ALTER PROCEDURE statement. However, you cannot change the parameters or\nbody of a stored procedure using this statement; to make such changes, you must drop and re-create\nthe procedure using DROP PROCEDURE and CREATE PROCEDURE.\nYou must have the ALTER ROUTINE privilege for the procedure. By default, that privilege is\ngranted automatically to the procedure creator. This behavior can be changed by disabling the\nautomatic_sp_privileges system variable. See Section 27.2.2, “Stored Routines and MySQL\nPrivileges”.",
    "15.1.8 ALTER SERVER Statement": "15.1.8 ALTER SERVER Statement\nALTER SERVER  server_name\n    OPTIONS (option [, option] ...)\nAlters the server information for server_name, adjusting any of the options permitted in the CREATE\nSERVER statement. The corresponding fields in the mysql.servers table are updated accordingly.\nThis statement requires the SUPER privilege.\nFor example, to update the USER option:\nALTER SERVER s OPTIONS (USER 'sally');\nALTER SERVER causes an implicit commit. See Section 15.3.3, “Statements That Cause an Implicit\nCommit”.\nALTER SERVER is not written to the binary log, regardless of the logging format that is in use.",
    "15.1.9 ALTER TABLE Statement": "15.1.9 ALTER TABLE Statement\nALTER TABLE tbl_name\n    [alter_option [, alter_option] ...]\n    [partition_options]\nalter_option: {\n    table_options\n  | ADD [COLUMN] col_name column_definition\n        [FIRST | AFTER col_name]\n  | ADD [COLUMN] (col_name column_definition,...)\n  | ADD {INDEX | KEY} [index_name]\n        [index_type] (key_part,...) [index_option] ...\n  | ADD {FULLTEXT | SPATIAL} [INDEX | KEY] [index_name]\n        (key_part,...) [index_option] ...\n  | ADD [CONSTRAINT [symbol]] PRIMARY KEY\n        [index_type] (key_part,...)\n        [index_option] ...\n  | ADD [CONSTRAINT [symbol]] UNIQUE [INDEX | KEY]\n        [index_name] [index_type] (key_part,...)\n        [index_option] ...\n  | ADD [CONSTRAINT [symbol]] FOREIGN KEY\n        [index_name] (col_name,...)\n        reference_definition\n  | ADD [CONSTRAINT [symbol]] CHECK (expr) [[NOT] ENFORCED]\n  | DROP {CHECK | CONSTRAINT} symbol\n  | ALTER {CHECK | CONSTRAINT} symbol [NOT] ENFORCED\n  | ALGORITHM [=] {DEFAULT | INSTANT | INPLACE | COPY}\n  | ALTER [COLUMN] col_name {\n        SET DEFAULT {literal | (expr)}\n      | SET {VISIBLE | INVISIBLE}\n      | DROP DEFAULT\n    }\n  | ALTER INDEX index_name {VISIBLE | INVISIBLE}\n  | CHANGE [COLUMN] old_col_name new_col_name column_definition\n        [FIRST | AFTER col_name]\n  | [DEFAULT] CHARACTER SET [=] charset_name [COLLATE [=] collation_name]\n  | CONVERT TO CHARACTER SET charset_name [COLLATE collation_name]\n  | {DISABLE | ENABLE} KEYS\n  | {DISCARD | IMPORT} TABLESPACE\n  | DROP [COLUMN] col_name\n  | DROP {INDEX | KEY} index_name\n  | DROP PRIMARY KEY\n  | DROP FOREIGN KEY fk_symbol\n  | FORCE\n  | LOCK [=] {DEFAULT | NONE | SHARED | EXCLUSIVE}\n  | MODIFY [COLUMN] col_name column_definition\n        [FIRST | AFTER col_name]\n  | ORDER BY col_name [, col_name] ...\n  | RENAME COLUMN old_col_name TO new_col_name\n  | RENAME {INDEX | KEY} old_index_name TO new_index_name\n  | RENAME [TO | AS] new_tbl_name\n  | {WITHOUT | WITH} VALIDATION\n}\npartition_options:\n    partition_option [partition_option] ...\npartition_option: {\n    ADD PARTITION (partition_definition)\n  | DROP PARTITION partition_names\n  | DISCARD PARTITION {partition_names | ALL} TABLESPACE\n  | IMPORT PARTITION {partition_names | ALL} TABLESPACE\n  | TRUNCATE PARTITION {partition_names | ALL}\n  | COALESCE PARTITION number\n  | REORGANIZE PARTITION partition_names INTO (partition_definitions)\n  | EXCHANGE PARTITION partition_name WITH TABLE tbl_name [{WITH | WITHOUT} VALIDATION]\n  | ANALYZE PARTITION {partition_names | ALL}\n  | CHECK PARTITION {partition_names | ALL}\n  | OPTIMIZE PARTITION {partition_names | ALL}\n  | REBUILD PARTITION {partition_names | ALL}\n  | REPAIR PARTITION {partition_names | ALL}\n  | REMOVE PARTITIONING\n}\nkey_part: {col_name [(length)] | (expr)} [ASC | DESC]\nindex_type:\n    USING {BTREE | HASH}\nindex_option: {\n    KEY_BLOCK_SIZE [=] value\n  | index_type\n  | WITH PARSER parser_name\n  | COMMENT 'string'\n  | {VISIBLE | INVISIBLE}\n}\ntable_options:\n    table_option [[,] table_option] ...\ntable_option: {\n    AUTOEXTEND_SIZE [=] value\n  | AUTO_INCREMENT [=] value\n  | AVG_ROW_LENGTH [=] value\n  | [DEFAULT] CHARACTER SET [=] charset_name\n  | CHECKSUM [=] {0 | 1}\n  | [DEFAULT] COLLATE [=] collation_name\n  | COMMENT [=] 'string'\n  | COMPRESSION [=] {'ZLIB' | 'LZ4' | 'NONE'}\n  | CONNECTION [=] 'connect_string'\n  | {DATA | INDEX} DIRECTORY [=] 'absolute path to directory'\n  | DELAY_KEY_WRITE [=] {0 | 1}\n  | ENCRYPTION [=] {'Y' | 'N'}\n  | ENGINE [=] engine_name\n  | ENGINE_ATTRIBUTE [=] 'string'\n  | INSERT_METHOD [=] { NO | FIRST | LAST }\n  | KEY_BLOCK_SIZE [=] value\n  | MAX_ROWS [=] value\n  | MIN_ROWS [=] value\n  | PACK_KEYS [=] {0 | 1 | DEFAULT}\n  | PASSWORD [=] 'string'\n  | ROW_FORMAT [=] {DEFAULT | DYNAMIC | FIXED | COMPRESSED | REDUNDANT | COMPACT}\n  | SECONDARY_ENGINE_ATTRIBUTE [=] 'string'\n  | STATS_AUTO_RECALC [=] {DEFAULT | 0 | 1}\n  | STATS_PERSISTENT [=] {DEFAULT | 0 | 1}\n  | STATS_SAMPLE_PAGES [=] value\n  | TABLESPACE tablespace_name [STORAGE {DISK | MEMORY}]\n  | UNION [=] (tbl_name[,tbl_name]...)\n}\npartition_options:\n    (see CREATE TABLE options)\nALTER TABLE changes the structure of a table. For example, you can add or delete columns, create\nor destroy indexes, change the type of existing columns, or rename columns or the table itself. You can\nalso change characteristics such as the storage engine used for the table or the table comment.\n• To use ALTER TABLE, you need ALTER, CREATE, and INSERT privileges for the table. Renaming a\ntable requires ALTER and DROP on the old table, ALTER, CREATE, and INSERT on the new table.\n• Following the table name, specify the alterations to be made. If none are given, ALTER TABLE does\nnothing.\n• The syntax for many of the permissible alterations is similar to clauses of the CREATE TABLE\nstatement. column_definition clauses use the same syntax for ADD and CHANGE as for CREATE\nTABLE. For more information, see Section 15.1.20, “CREATE TABLE Statement”.\n• The word COLUMN is optional and can be omitted, except for RENAME COLUMN (to distinguish a\ncolumn-renaming operation from the RENAME table-renaming operation).\n• Multiple ADD, ALTER, DROP, and CHANGE clauses are permitted in a single ALTER TABLE statement,\nseparated by commas. This is a MySQL extension to standard SQL, which permits only one of each\nclause per ALTER TABLE statement. For example, to drop multiple columns in a single statement,\ndo this:\nALTER TABLE t2 DROP COLUMN c, DROP COLUMN d;\n• If a storage engine does not support an attempted ALTER TABLE operation, a warning may result.\nSuch warnings can be displayed with SHOW WARNINGS. See Section 15.7.7.41, “SHOW WARNINGS\nStatement”. For information on troubleshooting ALTER TABLE, see Section B.3.6.1, “Problems with\nALTER TABLE”.\n• For information about generated columns, see Section 15.1.9.2, “ALTER TABLE and Generated\nColumns”.\n• For usage examples, see Section 15.1.9.3, “ALTER TABLE Examples”.\n• InnoDB supports addition of multi-valued indexes on JSON columns using a key_part specification\ncan take the form (CAST json_path AS type ARRAY). See Multi-Valued Indexes, for detailed\ninformation regarding multi-valued index creation and usage of, as well as restrictions and limitations\non multi-valued indexes.\n• With the mysql_info() C API function, you can find out how many rows were copied by ALTER\nTABLE. See mysql_info().\nThere are several additional aspects to the ALTER TABLE statement, described under the following\ntopics in this section:\n• Table Options\n• Performance and Space Requirements\n• Concurrency Control\n• Adding and Dropping Columns\n• Renaming, Redefining, and Reordering Columns\n• Primary Keys and Indexes\n• Foreign Keys and Other Constraints\n• Changing the Character Set\n• Importing InnoDB Tables\n• Row Order for MyISAM Tables\n• Partitioning Options\nTable Options\ntable_options signifies table options of the kind that can be used in the CREATE TABLE statement,\nsuch as ENGINE, AUTO_INCREMENT, AVG_ROW_LENGTH, MAX_ROWS, ROW_FORMAT, or TABLESPACE.\nFor descriptions of all table options, see Section 15.1.20, “CREATE TABLE Statement”. However,\nALTER TABLE ignores DATA DIRECTORY and INDEX DIRECTORY when given as table options.\nALTER TABLE permits them only as partitioning options, and requires that you have the FILE\nprivilege.\nUse of table options with ALTER TABLE provides a convenient way of altering single table\ncharacteristics. For example:\n• If t1 is currently not an InnoDB table, this statement changes its storage engine to InnoDB:\nALTER TABLE t1 ENGINE = InnoDB;\n• See Section 17.6.1.5, “Converting Tables from MyISAM to InnoDB” for considerations when\nswitching tables to the InnoDB storage engine.\n• When you specify an ENGINE clause, ALTER TABLE rebuilds the table. This is true even if the\ntable already has the specified storage engine.\n• Running ALTER TABLE tbl_name ENGINE=INNODB on an existing InnoDB table performs a\n“null” ALTER TABLE operation, which can be used to defragment an InnoDB table, as described\nin Section 17.11.4, “Defragmenting a Table”. Running ALTER TABLE tbl_name FORCE on an\nInnoDB table performs the same function.\n• ALTER TABLE tbl_name ENGINE=INNODB and ALTER TABLE tbl_name FORCE use online\nDDL. For more information, see Section 17.12, “InnoDB and Online DDL”.\n• The outcome of attempting to change the storage engine of a table is affected by whether the\ndesired storage engine is available and the setting of the NO_ENGINE_SUBSTITUTION SQL\nmode, as described in Section 7.1.11, “Server SQL Modes”.\n• To prevent inadvertent loss of data, ALTER TABLE cannot be used to change the storage engine\nof a table to MERGE or BLACKHOLE.\n• To change the InnoDB table to use compressed row-storage format:\nALTER TABLE t1 ROW_FORMAT = COMPRESSED;\n• The ENCRYPTION clause enables or disables page-level data encryption for an InnoDB table. A\nkeyring plugin must be installed and configured to enable encryption.\nIf the table_encryption_privilege_check variable is enabled, the\nTABLE_ENCRYPTION_ADMIN privilege is required to use an ENCRYPTION clause with a setting that\ndiffers from the default schema encryption setting.\nENCRYPTION is also supported for tables residing in general tablespaces.\nFor tables that reside in general tablespaces, table and tablespace encryption must match.\nThe ENCRYPTION option is supported only by the InnoDB storage engine; thus it works only\nif the table already uses InnoDB (and you do not change the table's storage engine), or if the\nALTER TABLE statement also specifies ENGINE=InnoDB. Otherwise the statement is rejected with\nER_CHECK_NOT_IMPLEMENTED.\nAltering table encryption by moving a table to a different tablespace or changing the storage engine\nis not permitted without explicitly specifying an ENCRYPTION clause.\nSpecifying an ENCRYPTION clause with a value other than 'N' or '' is not permitted if the table\nuses a storage engine that does not support encryption. Attempting to create a table without an\nENCRYPTION clause in an encryption-enabled schema using a storage engine that does not support\nencryption is also not permitted.\nFor more information, see Section 17.13, “InnoDB Data-at-Rest Encryption”.\n• To reset the current auto-increment value:\nALTER TABLE t1 AUTO_INCREMENT = 13;\nYou cannot reset the counter to a value less than or equal to the value that is currently in use. For\nboth InnoDB and MyISAM, if the value is less than or equal to the maximum value currently in the\nAUTO_INCREMENT column, the value is reset to the current maximum AUTO_INCREMENT column\nvalue plus one.\n• To change the default table character set:\nALTER TABLE t1 CHARACTER SET = utf8mb4;\nSee also Changing the Character Set.\n• To add (or change) a table comment:\nALTER TABLE t1 COMMENT = 'New table comment';\n• Use ALTER TABLE with the TABLESPACE option to move InnoDB tables between existing general\ntablespaces, file-per-table tablespaces, and the system tablespace. See Moving Tables Between\nTablespaces Using ALTER TABLE.\n• ALTER TABLE ... TABLESPACE operations always cause a full table rebuild, even if the\nTABLESPACE attribute has not changed from its previous value.\n• ALTER TABLE ... TABLESPACE syntax does not support moving a table from a temporary\ntablespace to a persistent tablespace.\n• The DATA DIRECTORY clause, which is supported with CREATE TABLE ... TABLESPACE, is\nnot supported with ALTER TABLE ... TABLESPACE, and is ignored if specified.\n• For more information about the capabilities and limitations of the TABLESPACE option, see CREATE\nTABLE.\n• MySQL NDB Cluster 9.1 supports setting NDB_TABLE options for controlling a table's partition\nbalance (fragment count type), read-from-any-replica capability, full replication, or any combination\nof these, as part of the table comment for an ALTER TABLE statement in the same manner as for\nCREATE TABLE, as shown in this example:\nALTER TABLE t1 COMMENT = \"NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RA_BY_NODE\";\nIt is also possible to set NDB_COMMENT options for columns of NDB tables as part of an ALTER\nTABLE statement, like this one:\nALTER TABLE t1 \n  CHANGE COLUMN c1 c1 BLOB \n    COMMENT = 'NDB_COLUMN=BLOB_INLINE_SIZE=4096,MAX_BLOB_PART_SIZE';\nBear in mind that ALTER TABLE ... COMMENT ... discards any existing comment for the table.\nSee Setting NDB_TABLE options, for additional information and examples.\n• ENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE options are used to specify table,\ncolumn, and index attributes for primary and secondary storage engines. These options are reserved\nfor future use. Index attributes cannot be altered. An index must be dropped and added back with the\ndesired change, which can be performed in a single ALTER TABLE statement.\nTo verify that the table options were changed as intended, use SHOW CREATE TABLE, or query the\nInformation Schema TABLES table.\nPerformance and Space Requirements\nALTER TABLE operations are processed using one of the following algorithms:\n• COPY: Operations are performed on a copy of the original table, and table data is copied from the\noriginal table to the new table row by row. Concurrent DML is not permitted.\n• INPLACE: Operations avoid copying table data but may rebuild the table in place. An exclusive\nmetadata lock on the table may be taken briefly during preparation and execution phases of the\noperation. Typically, concurrent DML is supported.\n• INSTANT: Operations only modify metadata in the data dictionary. An exclusive metadata lock on\nthe table may be taken briefly during the execution phase of the operation. Table data is unaffected,\nmaking operations instantaneous. Concurrent DML is permitted.\nFor tables using the NDB storage engine, these algorithms work as follows:\n• COPY: NDB creates a copy of the table and alters it; the NDB Cluster handler then copies the data\nbetween the old and new versions of the table. Subsequently, NDB deletes the old table and renames\nthe new one.\nThis is sometimes also referred to as a “copying” or “offline” ALTER TABLE.\n• INPLACE: The data nodes make the required changes; the NDB Cluster handler does not copy data\nor otherwise take part.\nThis is sometimes also referred to as a “non-copying” or “online” ALTER TABLE.\n• INSTANT: Not supported by NDB.\nSee Section 25.6.12, “Online Operations with ALTER TABLE in NDB Cluster”, for more information.\nThe ALGORITHM clause is optional. If the ALGORITHM clause is omitted, MySQL uses\nALGORITHM=INSTANT for storage engines and ALTER TABLE clauses that support it. Otherwise,\nALGORITHM=INPLACE is used. If ALGORITHM=INPLACE is not supported, ALGORITHM=COPY is used.\nNote\nAfter adding a column to a partitioned table using ALGORITHM=INSTANT, it is\nno longer possible to perform ALTER TABLE ... EXCHANGE PARTITION on\nthe table.\nSpecifying an ALGORITHM clause requires the operation to use the specified algorithm for clauses and\nstorage engines that support it, or fail with an error otherwise. Specifying ALGORITHM=DEFAULT is the\nsame as omitting the ALGORITHM clause.\nALTER TABLE operations that use the COPY algorithm wait for other operations that are modifying the\ntable to complete. After alterations are applied to the table copy, data is copied over, the original table\nis deleted, and the table copy is renamed to the name of the original table. While the ALTER TABLE\noperation executes, the original table is readable by other sessions (with the exception noted shortly).\nUpdates and writes to the table started after the ALTER TABLE operation begins are stalled until the\nnew table is ready, then are automatically redirected to the new table. The temporary copy of the table\nis created in the database directory of the original table unless it is a RENAME TO operation that moves\nthe table to a database that resides in a different directory.\nThe exception referred to earlier is that ALTER TABLE blocks reads (not just writes) at the point where\nit is ready to clear outdated table structures from the table and table definition caches. At this point, it\nmust acquire an exclusive lock. To do so, it waits for current readers to finish, and blocks new reads\nand writes.\nAn ALTER TABLE operation that uses the COPY algorithm prevents concurrent DML operations.\nConcurrent queries are still allowed. That is, a table-copying operation always includes at least\nthe concurrency restrictions of LOCK=SHARED (allow queries but not DML). You can further restrict\nconcurrency for operations that support the LOCK clause by specifying LOCK=EXCLUSIVE, which\nprevents DML and queries. For more information, see Concurrency Control.\nTo force use of the COPY algorithm for an ALTER TABLE operation that would otherwise not use it,\nspecify ALGORITHM=COPY or enable the old_alter_table system variable. If there is a conflict\nbetween the old_alter_table setting and an ALGORITHM clause with a value other than DEFAULT,\nthe ALGORITHM clause takes precedence.\nFor InnoDB tables, an ALTER TABLE operation that uses the COPY algorithm on a table that resides\nin a shared tablespace can increase the amount of space used by the tablespace. Such operations\nrequire as much additional space as the data in the table plus indexes. For a table residing in a shared\ntablespace, the additional space used during the operation is not released back to the operating\nsystem as it is for a table that resides in a file-per-table tablespace.\nFor information about space requirements for online DDL operations, see Section 17.12.3, “Online DDL\nSpace Requirements”.\nALTER TABLE operations that support the INPLACE algorithm include:\n• ALTER TABLE operations supported by the InnoDB online DDL feature. See Section 17.12.1,\n“Online DDL Operations”.\n• Renaming a table. MySQL renames files that correspond to the table tbl_name without making\na copy. (You can also use the RENAME TABLE statement to rename tables. See Section 15.1.36,\n“RENAME TABLE Statement”.) Privileges granted specifically for the renamed table are not migrated\nto the new name. They must be changed manually.\n• Operations that modify table metadata only. These operations are immediate because the server\ndoes not touch table contents. Metadata-only operations include:\n• Renaming a column. In NDB Cluster, this operation can also be performed online.\n• Changing the default value of a column (except for NDB tables).\n• Modifying the definition of an ENUM or SET column by adding new enumeration or set members\nto the end of the list of valid member values, as long as the storage size of the data type does\nnot change. For example, adding a member to a SET column that has 8 members changes the\nrequired storage per value from 1 byte to 2 bytes; this requires a table copy. Adding members in\nthe middle of the list causes renumbering of existing members, which requires a table copy.\n• Changing the definition of a spatial column to remove the SRID attribute. (Adding or changing an\nSRID attribute requires a rebuild, and cannot be done in place, because the server must verify that\nall values have the specified SRID value.)\n• Changing a column character set, when these conditions apply:\n• The column data type is CHAR, VARCHAR, a TEXT type, or ENUM.\n• The character set change is from utf8mb3 to utf8mb4, or any character set to binary.\n• There is no index on the column.\n• Changing a generated column, when these conditions apply:\n• For InnoDB tables, statements that modify generated stored columns but do not change their\ntype, expression, or nullability.\n• For non-InnoDB tables, statements that modify generated stored or virtual columns but do not\nchange their type, expression, or nullability.\nAn example of such a change is a change to the column comment.\n• Renaming an index.\n• Adding or dropping a secondary index, for InnoDB and NDB tables. See Section 17.12.1, “Online\nDDL Operations”.\n• For NDB tables, operations that add and drop indexes on variable-width columns. These operations\noccur online, without table copying and without blocking concurrent DML actions for most of their\nduration. See Section 25.6.12, “Online Operations with ALTER TABLE in NDB Cluster”.\n• Modifying index visibility with an ALTER INDEX operation.\n• Column modifications of tables containing generated columns that depend on columns with a\nDEFAULT value if the modified columns are not involved in the generated column expressions. For\nexample, changing the NULL property of a separate column can be done in place without a table\nrebuild.\nALTER TABLE operations that support the INSTANT algorithm include:\n• Adding a column. This feature is referred to as “Instant ADD COLUMN”. Limitations apply. See\nSection 17.12.1, “Online DDL Operations”.\n• Dropping a column. This feature is referred to as “Instant DROP COLUMN”. Limitations apply. See\nSection 17.12.1, “Online DDL Operations”.\n• Adding or dropping a virtual column.\n• Adding or dropping a column default value.\n• Modifying the definition of an ENUM or SET column. The same restrictions apply as described above\nfor ALGORITHM=INSTANT.\n• Changing the index type.\n• Renaming a table. The same restrictions apply as described above for ALGORITHM=INSTANT.\nFor more information about operations that support ALGORITHM=INSTANT, see Section 17.12.1,\n“Online DDL Operations”.\nALTER TABLE upgrades MySQL 5.5 temporal columns to 5.6 format for ADD COLUMN, CHANGE\nCOLUMN, MODIFY COLUMN, ADD INDEX, and FORCE operations. This conversion cannot be done\nusing the INPLACE algorithm because the table must be rebuilt, so specifying ALGORITHM=INPLACE\nin these cases results in an error. Specify ALGORITHM=COPY if necessary.\nIf an ALTER TABLE operation on a multicolumn index used to partition a table by KEY changes the\norder of the columns, it can only be performed using ALGORITHM=COPY.\nThe WITHOUT VALIDATION and WITH VALIDATION clauses affect whether ALTER TABLE performs\nan in-place operation for virtual generated column modifications. See Section 15.1.9.2, “ALTER TABLE\nand Generated Columns”.\nNDB Cluster 9.1 supports online operations using the same ALGORITHM=INPLACE syntax used with\nthe standard MySQL Server. NDB does not allow changing a tablespace online. See Section 25.6.12,\n“Online Operations with ALTER TABLE in NDB Cluster”, for more information.\nWhen performing a copying ALTER TABLE, NDB checks to ensure that no concurrent writes have\nbeen made to the affected table. If it finds that any have been made, NDB rejects the ALTER TABLE\nstatement and raises ER_TABLE_DEF_CHANGED.\nALTER TABLE with DISCARD ... PARTITION ... TABLESPACE or IMPORT ...\nPARTITION ... TABLESPACE does not create any temporary tables or temporary partition files.\nALTER TABLE with ADD PARTITION, DROP PARTITION, COALESCE PARTITION, REBUILD\nPARTITION, or REORGANIZE PARTITION does not create temporary tables (except when used with\nNDB tables); however, these operations can and do create temporary partition files.\nADD or DROP operations for RANGE or LIST partitions are immediate operations or nearly so. ADD or\nCOALESCE operations for HASH or KEY partitions copy data between all partitions, unless LINEAR\nHASH or LINEAR KEY was used; this is effectively the same as creating a new table, although the ADD\nor COALESCE operation is performed partition by partition. REORGANIZE operations copy only changed\npartitions and do not touch unchanged ones.\nFor MyISAM tables, you can speed up index re-creation (the slowest part of the alteration process) by\nsetting the myisam_sort_buffer_size system variable to a high value.\nConcurrency Control\nFor ALTER TABLE operations that support it, you can use the LOCK clause to control the level of\nconcurrent reads and writes on a table while it is being altered. Specifying a non-default value for this\nclause enables you to require a certain amount of concurrent access or exclusivity during the alter\noperation, and halts the operation if the requested degree of locking is not available.\nOnly LOCK = DEFAULT is permitted for operations that use ALGORITHM=INSTANT. The other LOCK\nclause parameters are not applicable.\nThe parameters for the LOCK clause are:\n• LOCK = DEFAULT\nMaximum level of concurrency for the given ALGORITHM clause (if any) and ALTER TABLE\noperation: Permit concurrent reads and writes if supported. If not, permit concurrent reads if\nsupported. If not, enforce exclusive access.\n• LOCK = NONE\nIf supported, permit concurrent reads and writes. Otherwise, an error occurs.\n• LOCK = SHARED\nIf supported, permit concurrent reads but block writes. Writes are blocked even if concurrent writes\nare supported by the storage engine for the given ALGORITHM clause (if any) and ALTER TABLE\noperation. If concurrent reads are not supported, an error occurs.\n• LOCK = EXCLUSIVE\nEnforce exclusive access. This is done even if concurrent reads/writes are supported by the storage\nengine for the given ALGORITHM clause (if any) and ALTER TABLE operation.\nAdding and Dropping Columns\nUse ADD to add new columns to a table, and DROP to remove existing columns. DROP col_name is a\nMySQL extension to standard SQL.\nTo add a column at a specific position within a table row, use FIRST or AFTER col_name. The default\nis to add the column last.\nIf a table contains only one column, the column cannot be dropped. If what you intend is to remove the\ntable, use the DROP TABLE statement instead.\nIf columns are dropped from a table, the columns are also removed from any index of which they are a\npart. If all columns that make up an index are dropped, the index is dropped as well. If you use CHANGE\nor MODIFY to shorten a column for which an index exists on the column, and the resulting column\nlength is less than the index length, MySQL shortens the index automatically.\nFor ALTER TABLE ... ADD, if the column has an expression default value that uses a\nnondeterministic function, the statement may produce a warning or error. For further information, see\nSection 13.6, “Data Type Default Values”, and Section 19.1.3.7, “Restrictions on Replication with\nGTIDs”.\nRenaming, Redefining, and Reordering Columns\nThe CHANGE, MODIFY, RENAME COLUMN, and ALTER clauses enable the names and definitions of\nexisting columns to be altered. They have these comparative characteristics:\n• CHANGE:\n• Can rename a column and change its definition, or both.\n• Has more capability than MODIFY or RENAME COLUMN, but at the expense of convenience for\nsome operations. CHANGE requires naming the column twice if not renaming it, and requires\nrespecifying the column definition if only renaming it.\n• With FIRST or AFTER, can reorder columns.\n• MODIFY:\n• Can change a column definition but not its name.\n• More convenient than CHANGE to change a column definition without renaming it.\n• With FIRST or AFTER, can reorder columns.\n• RENAME COLUMN:\n• Can change a column name but not its definition.\n• More convenient than CHANGE to rename a column without changing its definition.\n• ALTER: Used only to change a column default value.\nCHANGE is a MySQL extension to standard SQL. MODIFY and RENAME COLUMN are MySQL\nextensions for Oracle compatibility.\nTo alter a column to change both its name and definition, use CHANGE, specifying the old and new\nnames and the new definition. For example, to rename an INT NOT NULL column from a to b and\nchange its definition to use the BIGINT data type while retaining the NOT NULL attribute, do this:\nALTER TABLE t1 CHANGE a b BIGINT NOT NULL;\nTo change a column definition but not its name, use CHANGE or MODIFY. With CHANGE, the syntax\nrequires two column names, so you must specify the same name twice to leave the name unchanged.\nFor example, to change the definition of column b, do this:\nALTER TABLE t1 CHANGE b b INT NOT NULL;\nMODIFY is more convenient to change the definition without changing the name because it requires the\ncolumn name only once:\nALTER TABLE t1 MODIFY b INT NOT NULL;\nTo change a column name but not its definition, use CHANGE or RENAME COLUMN. With CHANGE,\nthe syntax requires a column definition, so to leave the definition unchanged, you must respecify the\ndefinition the column currently has. For example, to rename an INT NOT NULL column from b to a, do\nthis:\nALTER TABLE t1 CHANGE b a INT NOT NULL;\nRENAME COLUMN is more convenient to change the name without changing the definition because it\nrequires only the old and new names:\nALTER TABLE t1 RENAME COLUMN b TO a;\nIn general, you cannot rename a column to a name that already exists in the table. However, this is\nsometimes not the case, such as when you swap names or move them through a cycle. If a table has\ncolumns named a, b, and c, these are valid operations:\n-- swap a and b\nALTER TABLE t1 RENAME COLUMN a TO b,\n               RENAME COLUMN b TO a;\n-- \"rotate\" a, b, c through a cycle\nALTER TABLE t1 RENAME COLUMN a TO b,\n               RENAME COLUMN b TO c,\n               RENAME COLUMN c TO a;\nFor column definition changes using CHANGE or MODIFY, the definition must include the data type and\nall attributes that should apply to the new column, other than index attributes such as PRIMARY KEY\nor UNIQUE. Attributes present in the original definition but not specified for the new definition are not\ncarried forward. Suppose that a column col1 is defined as INT UNSIGNED DEFAULT 1 COMMENT\n'my column' and you modify the column as follows, intending to change only INT to BIGINT:\nALTER TABLE t1 MODIFY col1 BIGINT;\nThat statement changes the data type from INT to BIGINT, but it also drops the UNSIGNED, DEFAULT,\nand COMMENT attributes. To retain them, the statement must include them explicitly:\nALTER TABLE t1 MODIFY col1 BIGINT UNSIGNED DEFAULT 1 COMMENT 'my column';\nFor data type changes using CHANGE or MODIFY, MySQL tries to convert existing column values to the\nnew type as well as possible.\nWarning\nThis conversion may result in alteration of data. For example, if you shorten\na string column, values may be truncated. To prevent the operation from\nsucceeding if conversions to the new data type would result in loss of data,\nenable strict SQL mode before using ALTER TABLE (see Section 7.1.11,\n“Server SQL Modes”).\nIf you use CHANGE or MODIFY to shorten a column for which an index exists on the column, and the\nresulting column length is less than the index length, MySQL shortens the index automatically.\nFor columns renamed by CHANGE or RENAME COLUMN, MySQL automatically renames these\nreferences to the renamed column:\n• Indexes that refer to the old column, including invisible indexes and disabled MyISAM indexes.\n• Foreign keys that refer to the old column.\nFor columns renamed by CHANGE or RENAME COLUMN, MySQL does not automatically rename these\nreferences to the renamed column:\n• Generated column and partition expressions that refer to the renamed column. You must use\nCHANGE to redefine such expressions in the same ALTER TABLE statement as the one that renames\nthe column.\n• Views and stored programs that refer to the renamed column. You must manually alter the definition\nof these objects to refer to the new column name.\nTo reorder columns within a table, use FIRST and AFTER in CHANGE or MODIFY operations.\nALTER ... SET DEFAULT or ALTER ... DROP DEFAULT specify a new default value for a column\nor remove the old default value, respectively. If the old default is removed and the column can be\nNULL, the new default is NULL. If the column cannot be NULL, MySQL assigns a default value as\ndescribed in Section 13.6, “Data Type Default Values”.\nALTER ... SET VISIBLE and ALTER ... SET INVISIBLE enable column visibility to be\nchanged. See Section 15.1.20.10, “Invisible Columns”.\nPrimary Keys and Indexes\nDROP PRIMARY KEY drops the primary key. If there is no primary key, an error occurs. For\ninformation about the performance characteristics of primary keys, especially for InnoDB tables, see\nSection 10.3.2, “Primary Key Optimization”.\nIf the sql_require_primary_key system variable is enabled, attempting to drop a primary key\nproduces an error.\nIf you add a UNIQUE INDEX or PRIMARY KEY to a table, MySQL stores it before any nonunique index\nto permit detection of duplicate keys as early as possible.\nDROP INDEX removes an index. This is a MySQL extension to standard SQL. See Section 15.1.27,\n“DROP INDEX Statement”. To determine index names, use SHOW INDEX FROM tbl_name.\nSome storage engines permit you to specify an index type when creating an index. The syntax for\nthe index_type specifier is USING type_name. For details about USING, see Section 15.1.15,\n“CREATE INDEX Statement”. The preferred position is after the column list. Expect support for use of\nthe option before the column list to be removed in a future MySQL release.\nindex_option values specify additional options for an index. USING is one such option. For details\nabout permissible index_option values, see Section 15.1.15, “CREATE INDEX Statement”.\nRENAME INDEX old_index_name TO new_index_name renames an index. This is a MySQL\nextension to standard SQL. The content of the table remains unchanged. old_index_name must be\nthe name of an existing index in the table that is not dropped by the same ALTER TABLE statement.\nnew_index_name is the new index name, which cannot duplicate the name of an index in the resulting\ntable after changes have been applied. Neither index name can be PRIMARY.\nIf you use ALTER TABLE on a MyISAM table, all nonunique indexes are created in a separate batch\n(as for REPAIR TABLE). This should make ALTER TABLE much faster when you have many indexes.\nFor MyISAM tables, key updating can be controlled explicitly. Use ALTER TABLE ... DISABLE\nKEYS to tell MySQL to stop updating nonunique indexes. Then use ALTER TABLE ... ENABLE\nKEYS to re-create missing indexes. MyISAM does this with a special algorithm that is much faster than\ninserting keys one by one, so disabling keys before performing bulk insert operations should give a\nconsiderable speedup. Using ALTER TABLE ... DISABLE KEYS requires the INDEX privilege in\naddition to the privileges mentioned earlier.\nWhile the nonunique indexes are disabled, they are ignored for statements such as SELECT and\nEXPLAIN that otherwise would use them.\nAfter an ALTER TABLE statement, it may be necessary to run ANALYZE TABLE to update index\ncardinality information. See Section 15.7.7.23, “SHOW INDEX Statement”.\nThe ALTER INDEX operation permits an index to be made visible or invisible. An invisible index is\nnot used by the optimizer. Modification of index visibility applies to indexes other than primary keys\n(either explicit or implicit), and cannot be performed using ALGORITHM=INSTANT. This feature is\nstorage engine neutral (supported for any engine). For more information, see Section 10.3.12, “Invisible\nIndexes”.\nForeign Keys and Other Constraints\nThe FOREIGN KEY and REFERENCES clauses are supported by the InnoDB and NDB storage\nengines, which implement ADD [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (...)\nREFERENCES ... (...). See Section 15.1.20.5, “FOREIGN KEY Constraints”. For other storage\nengines, the clauses are parsed but ignored.\nFor ALTER TABLE, unlike CREATE TABLE, ADD FOREIGN KEY ignores index_name if given and\nuses an automatically generated foreign key name. As a workaround, include the CONSTRAINT clause\nto specify the foreign key name:\nADD CONSTRAINT name FOREIGN KEY (....) ...\nImportant\nMySQL silently ignores inline REFERENCES specifications, where the\nreferences are defined as part of the column specification. MySQL accepts\nonly REFERENCES clauses defined as part of a separate FOREIGN KEY\nspecification.\nNote\nPartitioned InnoDB tables do not support foreign keys. This restriction does not\napply to NDB tables, including those explicitly partitioned by [LINEAR] KEY.\nFor more information, see Section 26.6.2, “Partitioning Limitations Relating to\nStorage Engines”.\nMySQL Server and NDB Cluster both support the use of ALTER TABLE to drop foreign keys:\nALTER TABLE tbl_name DROP FOREIGN KEY fk_symbol;\nAdding and dropping a foreign key in the same ALTER TABLE statement is supported for ALTER\nTABLE ... ALGORITHM=INPLACE but not for ALTER TABLE ... ALGORITHM=COPY.\nThe server prohibits changes to foreign key columns that have the potential to cause loss of referential\nintegrity. A workaround is to use ALTER TABLE ... DROP FOREIGN KEY before changing the\ncolumn definition and ALTER TABLE ... ADD FOREIGN KEY afterward. Examples of prohibited\nchanges include:\n• Changes to the data type of foreign key columns that may be unsafe. For example, changing\nVARCHAR(20) to VARCHAR(30) is permitted, but changing it to VARCHAR(1024) is not because\nthat alters the number of length bytes required to store individual values.\n• Changing a NULL column to NOT NULL in non-strict mode is prohibited to prevent converting NULL\nvalues to default non-NULL values, for which there are no corresponding values in the referenced\ntable. The operation is permitted in strict mode, but an error is returned if any such conversion is\nrequired.\nALTER TABLE tbl_name RENAME new_tbl_name changes internally generated foreign\nkey constraint names and user-defined foreign key constraint names that begin with the string\n“tbl_name_ibfk_” to reflect the new table name. InnoDB interprets foreign key constraint names that\nbegin with the string “tbl_name_ibfk_” as internally generated names.\nALTER TABLE permits CHECK constraints for existing tables to be added, dropped, or altered:\n• Add a new CHECK constraint:\nALTER TABLE tbl_name\n    ADD [CONSTRAINT [symbol]] CHECK (expr) [[NOT] ENFORCED];\nThe meaning of constraint syntax elements is the same as for CREATE TABLE. See\nSection 15.1.20.6, “CHECK Constraints”.\n• Drop an existing CHECK constraint named symbol:\nALTER TABLE tbl_name\n    DROP CHECK symbol;\n• Alter whether an existing CHECK constraint named symbol is enforced:\nALTER TABLE tbl_name\n    ALTER CHECK symbol [NOT] ENFORCED;\nThe DROP CHECK and ALTER CHECK clauses are MySQL extensions to standard SQL.\nALTER TABLE permits more general (and SQL standard) syntax for dropping and altering existing\nconstraints of any type, where the constraint type is determined from the constraint name:\n• Drop an existing constraint named symbol:\nALTER TABLE tbl_name\n    DROP CONSTRAINT symbol;\nIf the sql_require_primary_key system variable is enabled, attempting to drop a primary key\nproduces an error.\n• Alter whether an existing constraint named symbol is enforced:\nALTER TABLE tbl_name\n    ALTER CONSTRAINT symbol [NOT] ENFORCED;\nOnly CHECK constraints can be altered to be unenforced. All other constraint types are always\nenforced.\nThe SQL standard specifies that all types of constraints (primary key, unique index, foreign key,\ncheck) belong to the same namespace. In MySQL, each constraint type has its own namespace per\nschema. Consequently, names for each type of constraint must be unique per schema, but constraints\nof different types can have the same name. When multiple constraints have the same name, DROP\nCONSTRAINT and ADD CONSTRAINT are ambiguous and an error occurs. In such cases, constraint-\nspecific syntax must be used to modify the constraint. For example, use DROP PRIMARY KEY or\nDROP FOREIGN KEY to drop a primary key or foreign key.\nIf a table alteration causes a violation of an enforced CHECK constraint, an error occurs and the table is\nnot modified. Examples of operations for which an error occurs:\n• Attempts to add the AUTO_INCREMENT attribute to a column that is used in a CHECK constraint.\n• Attempts to add an enforced CHECK constraint or enforce a nonenforced CHECK constraint for which\nexisting rows violate the constraint condition.\n• Attempts to modify, rename, or drop a column that is used in a CHECK constraint, unless that\nconstraint is also dropped in the same statement. Exception: If a CHECK constraint refers only to a\nsingle column, dropping the column automatically drops the constraint.\nALTER TABLE tbl_name RENAME new_tbl_name changes internally generated and user-defined\nCHECK constraint names that begin with the string “tbl_name_chk_” to reflect the new table name.\nMySQL interprets CHECK constraint names that begin with the string “tbl_name_chk_” as internally\ngenerated names.\nChanging the Character Set\n To change the table default character set and all character columns (CHAR, VARCHAR, TEXT) to a new\ncharacter set, use a statement like this:\nALTER TABLE tbl_name CONVERT TO CHARACTER SET charset_name;\nThe statement also changes the collation of all character columns. If you specify no COLLATE clause to\nindicate which collation to use, the statement uses default collation for the character set. If this collation\nis inappropriate for the intended table use (for example, if it would change from a case-sensitive\ncollation to a case-insensitive collation), specify a collation explicitly.\nFor a column that has a data type of VARCHAR or one of the TEXT types, CONVERT TO CHARACTER\nSET changes the data type as necessary to ensure that the new column is long enough to store as\nmany characters as the original column. For example, a TEXT column has two length bytes, which\nstore the byte-length of values in the column, up to a maximum of 65,535. For a latin1 TEXT column,\neach character requires a single byte, so the column can store up to 65,535 characters. If the column\nis converted to utf8mb4, each character might require up to 4 bytes, for a maximum possible length\nof 4 × 65,535 = 262,140 bytes. That length does not fit in a TEXT column's length bytes, so MySQL\nconverts the data type to MEDIUMTEXT, which is the smallest string type for which the length bytes can\nrecord a value of 262,140. Similarly, a VARCHAR column might be converted to MEDIUMTEXT.\nTo avoid data type changes of the type just described, do not use CONVERT TO CHARACTER SET.\nInstead, use MODIFY to change individual columns. For example:\nALTER TABLE t MODIFY latin1_text_col TEXT CHARACTER SET utf8mb4;\nALTER TABLE t MODIFY latin1_varchar_col VARCHAR(M) CHARACTER SET utf8mb4;\nIf you specify CONVERT TO CHARACTER SET binary, the CHAR, VARCHAR, and TEXT columns are\nconverted to their corresponding binary string types (BINARY, VARBINARY, BLOB). This means that the\ncolumns no longer have a character set and a subsequent CONVERT TO operation does not apply to\nthem.\nIf charset_name is DEFAULT in a CONVERT TO CHARACTER SET operation, the character set\nnamed by the character_set_database system variable is used.\nWarning\nThe CONVERT TO operation converts column values between the original and\nnamed character sets. This is not what you want if you have a column in one\ncharacter set (like latin1) but the stored values actually use some other,\nincompatible character set (like utf8mb4). In this case, you have to do the\nfollowing for each such column:\nALTER TABLE t1 CHANGE c1 c1 BLOB;\nALTER TABLE t1 CHANGE c1 c1 TEXT CHARACTER SET utf8mb4;\nThe reason this works is that there is no conversion when you convert to or from\nBLOB columns.\nTo change only the default character set for a table, use this statement:\nALTER TABLE tbl_name DEFAULT CHARACTER SET charset_name;\nThe word DEFAULT is optional. The default character set is the character set that is used if you\ndo not specify the character set for columns that you add to a table later (for example, with ALTER\nTABLE ... ADD column).\nWhen the foreign_key_checks system variable is enabled, which is the default setting, character\nset conversion is not permitted on tables that include a character string column used in a foreign key\nconstraint. The workaround is to disable foreign_key_checks before performing the character set\nconversion. You must perform the conversion on both tables involved in the foreign key constraint\nbefore re-enabling foreign_key_checks. If you re-enable foreign_key_checks after converting\nonly one of the tables, an ON DELETE CASCADE or ON UPDATE CASCADE operation could corrupt\ndata in the referencing table due to implicit conversion that occurs during these operations (Bug\n#45290, Bug #74816).\nImporting InnoDB Tables\nAn InnoDB table created in its own file-per-table tablespace can be imported from a backup or from\nanother MySQL server instance using DISCARD TABLEPACE and IMPORT TABLESPACE clauses. See\nSection 17.6.1.3, “Importing InnoDB Tables”.\nRow Order for MyISAM Tables\nORDER BY enables you to create the new table with the rows in a specific order. This option is useful\nprimarily when you know that you query the rows in a certain order most of the time. By using this\noption after major changes to the table, you might be able to get higher performance. In some cases, it\nmight make sorting easier for MySQL if the table is in order by the column that you want to order it by\nlater.\nNote\nThe table does not remain in the specified order after inserts and deletes.\nORDER BY syntax permits one or more column names to be specified for sorting, each of which\noptionally can be followed by ASC or DESC to indicate ascending or descending sort order, respectively.\nThe default is ascending order. Only column names are permitted as sort criteria; arbitrary expressions\nare not permitted. This clause should be given last after any other clauses.\nORDER BY does not make sense for InnoDB tables because InnoDB always orders table rows\naccording to the clustered index.\nWhen used on a partitioned table, ALTER TABLE ... ORDER BY orders rows within each partition\nonly.\nPartitioning Options\npartition_options signifies options that can be used with partitioned tables for repartitioning, to\nadd, drop, discard, import, merge, and split partitions, and to perform partitioning maintenance.\nIt is possible for an ALTER TABLE statement to contain a PARTITION BY or REMOVE PARTITIONING\nclause in an addition to other alter specifications, but the PARTITION BY or REMOVE PARTITIONING\nclause must be specified last after any other specifications. The ADD PARTITION, DROP PARTITION,\nDISCARD PARTITION, IMPORT PARTITION, COALESCE PARTITION, REORGANIZE PARTITION,\nEXCHANGE PARTITION, ANALYZE PARTITION, CHECK PARTITION, and REPAIR PARTITION\noptions cannot be combined with other alter specifications in a single ALTER TABLE, since the options\njust listed act on individual partitions.\nFor more information about partition options, see Section 15.1.20, “CREATE TABLE Statement”, and\nSection 15.1.9.1, “ALTER TABLE Partition Operations”. For information about and examples of ALTER\nTABLE ... EXCHANGE PARTITION statements, see Section 26.3.3, “Exchanging Partitions and\nSubpartitions with Tables”.\n15.1.9.1 ALTER TABLE Partition Operations\nPartitioning-related clauses for ALTER TABLE can be used with partitioned tables for repartitioning, to\nadd, drop, discard, import, merge, and split partitions, and to perform partitioning maintenance.\n• Simply using a partition_options clause with ALTER TABLE on a partitioned table repartitions\nthe table according to the partitioning scheme defined by the partition_options. This clause\nalways begins with PARTITION BY, and follows the same syntax and other rules as apply\nto the partition_options clause for CREATE TABLE (for more detailed information, see\nSection 15.1.20, “CREATE TABLE Statement”), and can also be used to partition an existing table\nthat is not already partitioned. For example, consider a (nonpartitioned) table defined as shown here:\nCREATE TABLE t1 (\n    id INT,\n    year_col INT\n);\nThis table can be partitioned by HASH, using the id column as the partitioning key, into 8 partitions\nby means of this statement:\nALTER TABLE t1\n    PARTITION BY HASH(id)\n    PARTITIONS 8;\nMySQL supports an ALGORITHM option with [SUB]PARTITION BY [LINEAR] KEY.\nALGORITHM=1 causes the server to use the same key-hashing functions as MySQL 5.1 when\ncomputing the placement of rows in partitions; ALGORITHM=2 means that the server employs the\nkey-hashing functions implemented and used by default for new KEY partitioned tables in MySQL\n5.5 and later. (Partitioned tables created with the key-hashing functions employed in MySQL 5.5\nand later cannot be used by a MySQL 5.1 server.) Not specifying the option has the same effect\nas using ALGORITHM=2. This option is intended for use chiefly when upgrading or downgrading\n[LINEAR] KEY partitioned tables between MySQL 5.1 and later MySQL versions, or for creating\ntables partitioned by KEY or LINEAR KEY on a MySQL 5.5 or later server which can be used on a\nMySQL 5.1 server.\nThe table that results from using an ALTER TABLE ... PARTITION BY statement must follow\nthe same rules as one created using CREATE TABLE ... PARTITION BY. This includes the rules\ngoverning the relationship between any unique keys (including any primary key) that the table might\nhave, and the column or columns used in the partitioning expression, as discussed in Section 26.6.1,\n“Partitioning Keys, Primary Keys, and Unique Keys”. The CREATE TABLE ... PARTITION BY\nrules for specifying the number of partitions also apply to ALTER TABLE ... PARTITION BY.\nThe partition_definition clause for ALTER TABLE ADD PARTITION supports the same\noptions as the clause of the same name for the CREATE TABLE statement. (See Section 15.1.20,\n“CREATE TABLE Statement”, for the syntax and description.) Suppose that you have the partitioned\ntable created as shown here:\nCREATE TABLE t1 (\n    id INT,\n    year_col INT\n)\nPARTITION BY RANGE (year_col) (\n    PARTITION p0 VALUES LESS THAN (1991),\n    PARTITION p1 VALUES LESS THAN (1995),\n    PARTITION p2 VALUES LESS THAN (1999)\n);\nYou can add a new partition p3 to this table for storing values less than 2002 as follows:\nALTER TABLE t1 ADD PARTITION (PARTITION p3 VALUES LESS THAN (2002));\nDROP PARTITION can be used to drop one or more RANGE or LIST partitions. This statement\ncannot be used with HASH or KEY partitions; instead, use COALESCE PARTITION (see later in this\nsection). Any data that was stored in the dropped partitions named in the partition_names list is\ndiscarded. For example, given the table t1 defined previously, you can drop the partitions named p0\nand p1 as shown here:\nALTER TABLE t1 DROP PARTITION p0, p1;\nNote\nDROP PARTITION does not work with tables that use the NDB storage\nengine. See Section 26.3.1, “Management of RANGE and LIST Partitions”,\nand Section 25.2.7, “Known Limitations of NDB Cluster”.\nADD PARTITION and DROP PARTITION do not currently support IF [NOT] EXISTS.\nThe DISCARD PARTITION ... TABLESPACE and IMPORT PARTITION ... TABLESPACE\noptions extend the Transportable Tablespace feature to individual InnoDB table partitions. Each\nInnoDB table partition has its own tablespace file (.ibd file). The Transportable Tablespace feature\nmakes it easy to copy the tablespaces from a running MySQL server instance to another running\ninstance, or to perform a restore on the same instance. Both options take a comma-separated list of\none or more partition names. For example:\nALTER TABLE t1 DISCARD PARTITION p2, p3 TABLESPACE;\nALTER TABLE t1 IMPORT PARTITION p2, p3 TABLESPACE;\nWhen running DISCARD PARTITION ... TABLESPACE and IMPORT PARTITION ...\nTABLESPACE on subpartitioned tables, both partition and subpartition names are allowed. When a\npartition name is specified, subpartitions of that partition are included.\nThe Transportable Tablespace feature also supports copying or restoring partitioned InnoDB tables.\nFor more information, see Section 17.6.1.3, “Importing InnoDB Tables”.\nRenames of partitioned tables are supported. You can rename individual partitions indirectly using\nALTER TABLE ... REORGANIZE PARTITION; however, this operation copies the partition's data.\nTo delete rows from selected partitions, use the TRUNCATE PARTITION option. This option takes\na list of one or more comma-separated partition names. Consider the table t1 created by this\nstatement:\nCREATE TABLE t1 (\n    id INT,\n    year_col INT\n)\nPARTITION BY RANGE (year_col) (\n    PARTITION p0 VALUES LESS THAN (1991),\n    PARTITION p1 VALUES LESS THAN (1995),\n    PARTITION p2 VALUES LESS THAN (1999),\n    PARTITION p3 VALUES LESS THAN (2003),\n    PARTITION p4 VALUES LESS THAN (2007)\n);\nTo delete all rows from partition p0, use the following statement:\nALTER TABLE t1 TRUNCATE PARTITION p0;\nThe statement just shown has the same effect as the following DELETE statement:\nDELETE FROM t1 WHERE year_col < 1991;\nWhen truncating multiple partitions, the partitions do not have to be contiguous: This can greatly\nsimplify delete operations on partitioned tables that would otherwise require very complex WHERE\nconditions if done with DELETE statements. For example, this statement deletes all rows from\npartitions p1 and p3:\nALTER TABLE t1 TRUNCATE PARTITION p1, p3;\nAn equivalent DELETE statement is shown here:\nDELETE FROM t1 WHERE\n    (year_col >= 1991 AND year_col < 1995)\n    OR\n    (year_col >= 2003 AND year_col < 2007);\nIf you use the ALL keyword in place of the list of partition names, the statement acts on all table\npartitions.\nTRUNCATE PARTITION merely deletes rows; it does not alter the definition of the table itself, or of\nany of its partitions.\nTo verify that the rows were dropped, check the INFORMATION_SCHEMA.PARTITIONS table, using\na query such as this one:\nSELECT PARTITION_NAME, TABLE_ROWS\n    FROM INFORMATION_SCHEMA.PARTITIONS\n    WHERE TABLE_NAME = 't1';\nCOALESCE PARTITION can be used with a table that is partitioned by HASH or KEY to reduce the\nnumber of partitions by number. Suppose that you have created table t2 as follows:\nCREATE TABLE t2 (\n    name VARCHAR (30),\n    started DATE\n)\nPARTITION BY HASH( YEAR(started) )\nPARTITIONS 6;\nTo reduce the number of partitions used by t2 from 6 to 4, use the following statement:\nALTER TABLE t2 COALESCE PARTITION 2;\nThe data contained in the last number partitions is merged into the remaining partitions. In this case,\npartitions 4 and 5 are merged into the first 4 partitions (the partitions numbered 0, 1, 2, and 3).\nTo change some but not all the partitions used by a partitioned table, you can use REORGANIZE\nPARTITION. This statement can be used in several ways:\n• To merge a set of partitions into a single partition. This is done by naming several partitions in the\npartition_names list and supplying a single definition for partition_definition.\n• To split an existing partition into several partitions. Accomplish this by naming a single partition for\npartition_names and providing multiple partition_definitions.\n• To change the ranges for a subset of partitions defined using VALUES LESS THAN or the value\nlists for a subset of partitions defined using VALUES IN.\nNote\nFor partitions that have not been explicitly named, MySQL automatically\nprovides the default names p0, p1, p2, and so on. The same is true with\nregard to subpartitions.\nFor more detailed information about and examples of ALTER TABLE ... REORGANIZE\nPARTITION statements, see Section 26.3.1, “Management of RANGE and LIST Partitions”.\n• To exchange a table partition or subpartition with a table, use the ALTER TABLE ... EXCHANGE\nPARTITION statement—that is, to move any existing rows in the partition or subpartition to the\nnonpartitioned table, and any existing rows in the nonpartitioned table to the table partition or\nsubpartition.\nOnce one or more columns have been added to a partitioned table using ALGORITHM=INSTANT, it is\nno longer possible to exchange partitions with that table.\nFor usage information and examples, see Section 26.3.3, “Exchanging Partitions and Subpartitions\nwith Tables”.\n• Several options provide partition maintenance and repair functionality analogous to that implemented\nfor nonpartitioned tables by statements such as CHECK TABLE and REPAIR TABLE (which\nare also supported for partitioned tables; for more information, see Section 15.7.3, “Table\nMaintenance Statements”). These include ANALYZE PARTITION, CHECK PARTITION, OPTIMIZE\nPARTITION, REBUILD PARTITION, and REPAIR PARTITION. Each of these options takes a\npartition_names clause consisting of one or more names of partitions, separated by commas.\nThe partitions must already exist in the target table. You can also use the ALL keyword in place of\npartition_names, in which case the statement acts on all table partitions. For more information\nand examples, see Section 26.3.4, “Maintenance of Partitions”.\nInnoDB does not currently support per-partition optimization; ALTER TABLE ... OPTIMIZE\nPARTITION causes the entire table to rebuilt and analyzed, and an appropriate warning to be\nissued. (Bug #11751825, Bug #42822) To work around this problem, use ALTER TABLE ...\nREBUILD PARTITION and ALTER TABLE ... ANALYZE PARTITION instead.\nThe ANALYZE PARTITION, CHECK PARTITION, OPTIMIZE PARTITION, and REPAIR\nPARTITION options are not supported for tables which are not partitioned.\n• REMOVE PARTITIONING enables you to remove a table's partitioning without otherwise affecting the\ntable or its data. This option can be combined with other ALTER TABLE options such as those used\nto add, drop, or rename columns or indexes.\n• Using the ENGINE option with ALTER TABLE changes the storage engine used by the table without\naffecting the partitioning. The target storage engine must provide its own partitioning handler. Only\nthe InnoDB and NDB storage engines have native partitioning handlers.\nIt is possible for an ALTER TABLE statement to contain a PARTITION BY or REMOVE PARTITIONING\nclause in an addition to other alter specifications, but the PARTITION BY or REMOVE PARTITIONING\nclause must be specified last after any other specifications.\nThe ADD PARTITION, DROP PARTITION, COALESCE PARTITION, REORGANIZE PARTITION,\nANALYZE PARTITION, CHECK PARTITION, and REPAIR PARTITION options cannot be combined\nwith other alter specifications in a single ALTER TABLE, since the options just listed act on individual\npartitions. For more information, see Section 15.1.9.1, “ALTER TABLE Partition Operations”.\nOnly a single instance of any one of the following options can be used in a given ALTER TABLE\nstatement: PARTITION BY, ADD PARTITION, DROP PARTITION, TRUNCATE PARTITION,\nEXCHANGE PARTITION, REORGANIZE PARTITION, or COALESCE PARTITION, ANALYZE\nPARTITION, CHECK PARTITION, OPTIMIZE PARTITION, REBUILD PARTITION, REMOVE\nPARTITIONING.\nFor example, the following two statements are invalid:\nALTER TABLE t1 ANALYZE PARTITION p1, ANALYZE PARTITION p2;\nALTER TABLE t1 ANALYZE PARTITION p1, CHECK PARTITION p2;\nIn the first case, you can analyze partitions p1 and p2 of table t1 concurrently using a single statement\nwith a single ANALYZE PARTITION option that lists both of the partitions to be analyzed, like this:\nALTER TABLE t1 ANALYZE PARTITION p1, p2;\nIn the second case, it is not possible to perform ANALYZE and CHECK operations on different partitions\nof the same table concurrently. Instead, you must issue two separate statements, like this:\nALTER TABLE t1 ANALYZE PARTITION p1;\nALTER TABLE t1 CHECK PARTITION p2;\nREBUILD operations are currently unsupported for subpartitions. The REBUILD keyword is expressly\ndisallowed with subpartitions, and causes ALTER TABLE to fail with an error if so used.\nCHECK PARTITION and REPAIR PARTITION operations fail when the partition to be checked or\nrepaired contains any duplicate key errors.\nFor more information about these statements, see Section 26.3.4, “Maintenance of Partitions”.\n15.1.9.2 ALTER TABLE and Generated Columns\nALTER TABLE operations permitted for generated columns are ADD, MODIFY, and CHANGE.\n• Generated columns can be added.\nCREATE TABLE t1 (c1 INT);\nALTER TABLE t1 ADD COLUMN c2 INT GENERATED ALWAYS AS (c1 + 1) STORED;\n• The data type and expression of generated columns can be modified.\nCREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) STORED);\nALTER TABLE t1 MODIFY COLUMN c2 TINYINT GENERATED ALWAYS AS (c1 + 5) STORED;\n• Generated columns can be renamed or dropped, if no other column refers to them.\nCREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) STORED);\nALTER TABLE t1 CHANGE c2 c3 INT GENERATED ALWAYS AS (c1 + 1) STORED;\nALTER TABLE t1 DROP COLUMN c3;\n• Virtual generated columns cannot be altered to stored generated columns, or vice versa. To work\naround this, drop the column, then add it with the new definition.\nCREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) VIRTUAL);\nALTER TABLE t1 DROP COLUMN c2;\nALTER TABLE t1 ADD COLUMN c2 INT GENERATED ALWAYS AS (c1 + 1) STORED;\n• Nongenerated columns can be altered to stored but not virtual generated columns.\nCREATE TABLE t1 (c1 INT, c2 INT);\nALTER TABLE t1 MODIFY COLUMN c2 INT GENERATED ALWAYS AS (c1 + 1) STORED;\n• Stored but not virtual generated columns can be altered to nongenerated columns. The stored\ngenerated values become the values of the nongenerated column.\nCREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) STORED);\nALTER TABLE t1 MODIFY COLUMN c2 INT;\n• ADD COLUMN is not an in-place operation for stored columns (done without using a temporary table)\nbecause the expression must be evaluated by the server. For stored columns, indexing changes are\ndone in place, and expression changes are not done in place. Changes to column comments are\ndone in place.\n• For non-partitioned tables, ADD COLUMN and DROP COLUMN are in-place operations for virtual\ncolumns. However, adding or dropping a virtual column cannot be performed in place in combination\nwith other ALTER TABLE operations.\nFor partitioned tables, ADD COLUMN and DROP COLUMN are not in-place operations for virtual\ncolumns.\n• InnoDB supports secondary indexes on virtual generated columns. Adding or dropping a\nsecondary index on a virtual generated column is an in-place operation. For more information, see\nSection 15.1.20.9, “Secondary Indexes and Generated Columns”.\n• When a VIRTUAL generated column is added to a table or modified, it is not ensured that data being\ncalculated by the generated column expression is not out of range for the column. This can lead to\ninconsistent data being returned and unexpectedly failed statements. To permit control over whether\nvalidation occurs for such columns, ALTER TABLE supports WITHOUT VALIDATION and WITH\nVALIDATION clauses:\n• With WITHOUT VALIDATION (the default if neither clause is specified), an in-place operation is\nperformed (if possible), data integrity is not checked, and the statement finishes more quickly.\nHowever, later reads from the table might report warnings or errors for the column if values are out\nof range.\n• With WITH VALIDATION, ALTER TABLE copies the table. If an out-of-range or any other error\noccurs, the statement fails. Because a table copy is performed, the statement takes longer.\nWITHOUT VALIDATION and WITH VALIDATION are permitted only with ADD COLUMN, CHANGE\nCOLUMN, and MODIFY COLUMN operations. Otherwise, an ER_WRONG_USAGE error occurs.\n• If expression evaluation causes truncation or provides incorrect input to a function, the ALTER\nTABLE statement terminates with an error and the DDL operation is rejected.\n• An ALTER TABLE statement that changes the default value of a column col_name may also\nchange the value of a generated column expression that refers to the column using col_name,\nwhich may change the value of a generated column expression that refers to the column using\nDEFAULT(col_name). For this reason, ALTER TABLE operations that change the definition of a\ncolumn cause a table rebuild if any generated column expression uses DEFAULT().\n15.1.9.3 ALTER TABLE Examples\nBegin with a table t1 created as shown here:\nCREATE TABLE t1 (a INTEGER, b CHAR(10));\nTo rename the table from t1 to t2:\nALTER TABLE t1 RENAME t2;\nTo change column a from INTEGER to TINYINT NOT NULL (leaving the name the same), and to\nchange column b from CHAR(10) to CHAR(20) as well as renaming it from b to c:\nALTER TABLE t2 MODIFY a TINYINT NOT NULL, CHANGE b c CHAR(20);\nTo add a new TIMESTAMP column named d:\nALTER TABLE t2 ADD d TIMESTAMP;\nTo add an index on column d and a UNIQUE index on column a:\nALTER TABLE t2 ADD INDEX (d), ADD UNIQUE (a);\nTo remove column c:\nALTER TABLE t2 DROP COLUMN c;\nTo add a new AUTO_INCREMENT integer column named c:\nALTER TABLE t2 ADD c INT UNSIGNED NOT NULL AUTO_INCREMENT,\n  ADD PRIMARY KEY (c);\nWe indexed c (as a PRIMARY KEY) because AUTO_INCREMENT columns must be indexed, and we\ndeclare c as NOT NULL because primary key columns cannot be NULL.\nFor NDB tables, it is also possible to change the storage type used for a table or column. For example,\nconsider an NDB table created as shown here:\nmysql> CREATE TABLE t1 (c1 INT) TABLESPACE ts_1 ENGINE NDB;\nQuery OK, 0 rows affected (1.27 sec)\nTo convert this table to disk-based storage, you can use the following ALTER TABLE statement:\nmysql> ALTER TABLE t1 TABLESPACE ts_1 STORAGE DISK;\nQuery OK, 0 rows affected (2.99 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `c1` int(11) DEFAULT NULL\n) /*!50100 TABLESPACE ts_1 STORAGE DISK */\nENGINE=ndbcluster DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.01 sec)\nIt is not necessary that the tablespace was referenced when the table was originally created; however,\nthe tablespace must be referenced by the ALTER TABLE:\nmysql> CREATE TABLE t2 (c1 INT) ts_1 ENGINE NDB;\nQuery OK, 0 rows affected (1.00 sec)\nmysql> ALTER TABLE t2 STORAGE DISK;\nERROR 1005 (HY000): Can't create table 'c.#sql-1750_3' (errno: 140)\nmysql> ALTER TABLE t2 TABLESPACE ts_1 STORAGE DISK;\nQuery OK, 0 rows affected (3.42 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> SHOW CREATE TABLE t2\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t2` (\n  `c1` int(11) DEFAULT NULL\n) /*!50100 TABLESPACE ts_1 STORAGE DISK */\nENGINE=ndbcluster DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.01 sec)\nTo change the storage type of an individual column, you can use ALTER TABLE ... MODIFY\n[COLUMN]. For example, suppose you create an NDB Cluster Disk Data table with two columns, using\nthis CREATE TABLE statement:\nmysql> CREATE TABLE t3 (c1 INT, c2 INT)\n    ->     TABLESPACE ts_1 STORAGE DISK ENGINE NDB;\nQuery OK, 0 rows affected (1.34 sec)\nTo change column c2 from disk-based to in-memory storage, include a STORAGE MEMORY clause in\nthe column definition used by the ALTER TABLE statement, as shown here:\nmysql> ALTER TABLE t3 MODIFY c2 INT STORAGE MEMORY;\nQuery OK, 0 rows affected (3.14 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nYou can make an in-memory column into a disk-based column by using STORAGE DISK in a similar\nfashion.\nColumn c1 uses disk-based storage, since this is the default for the table (determined by the table-\nlevel STORAGE DISK clause in the CREATE TABLE statement). However, column c2 uses in-memory\nstorage, as can be seen here in the output of SHOW CREATE TABLE:\nmysql> SHOW CREATE TABLE t3\\G\n*************************** 1. row ***************************\n       Table: t3\nCreate Table: CREATE TABLE `t3` (\n  `c1` int(11) DEFAULT NULL,\n  `c2` int(11) /*!50120 STORAGE MEMORY */ DEFAULT NULL\n) /*!50100 TABLESPACE ts_1 STORAGE DISK */ ENGINE=ndbcluster DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_09\n1 row in set (0.02 sec)\nWhen you add an AUTO_INCREMENT column, column values are filled in with sequence numbers\nautomatically. For MyISAM tables, you can set the first sequence number by executing SET\nINSERT_ID=value before ALTER TABLE or by using the AUTO_INCREMENT=value table option.\nWith MyISAM tables, if you do not change the AUTO_INCREMENT column, the sequence number is not\naffected. If you drop an AUTO_INCREMENT column and then add another AUTO_INCREMENT column,\nthe numbers are resequenced beginning with 1.\nWhen replication is used, adding an AUTO_INCREMENT column to a table might not produce the\nsame ordering of the rows on the replica and the source. This occurs because the order in which the\nrows are numbered depends on the specific storage engine used for the table and the order in which\nthe rows were inserted. If it is important to have the same order on the source and replica, the rows\nmust be ordered before assigning an AUTO_INCREMENT number. Assuming that you want to add an\nAUTO_INCREMENT column to the table t1, the following statements produce a new table t2 identical to\nt1 but with an AUTO_INCREMENT column:\nCREATE TABLE t2 (id INT AUTO_INCREMENT PRIMARY KEY)\nSELECT * FROM t1 ORDER BY col1, col2;\nThis assumes that the table t1 has columns col1 and col2.\nThis set of statements also produces a new table t2 identical to t1, with the addition of an\nAUTO_INCREMENT column:\nCREATE TABLE t2 LIKE t1;\nALTER TABLE t2 ADD id INT AUTO_INCREMENT PRIMARY KEY;\nINSERT INTO t2 SELECT * FROM t1 ORDER BY col1, col2;\nImportant\nTo guarantee the same ordering on both source and replica, all columns of t1\nmust be referenced in the ORDER BY clause.\nRegardless of the method used to create and populate the copy having the AUTO_INCREMENT column,\nthe final step is to drop the original table and then rename the copy:\nDROP TABLE t1;\nALTER TABLE t2 RENAME t1;",
    "15.1.10 ALTER TABLESPACE Statement": "15.1.10 ALTER TABLESPACE Statement\nALTER [UNDO] TABLESPACE tablespace_name\n  NDB only:\n    {ADD | DROP} DATAFILE 'file_name'\n    [INITIAL_SIZE [=] size]\n    [WAIT]\n  InnoDB and NDB:\n    [RENAME TO tablespace_name]\n  InnoDB only:\n    [AUTOEXTEND_SIZE [=] 'value']\n    [SET {ACTIVE | INACTIVE}]\n    [ENCRYPTION [=] {'Y' | 'N'}]\n  InnoDB and NDB:\n    [ENGINE [=] engine_name]\n  Reserved for future use:\n    [ENGINE_ATTRIBUTE [=] 'string']\nThis statement is used with NDB and InnoDB tablespaces. It can be used to add a new data file to, or\nto drop a data file from an NDB tablespace. It can also be used to rename an NDB Cluster Disk Data\ntablespace, rename an InnoDB general tablespace, encrypt an InnoDB general tablespace, or mark\nan InnoDB undo tablespace as active or inactive.\nThe UNDO keyword is used with the SET {ACTIVE | INACTIVE} clause to mark an InnoDB undo\ntablespace as active or inactive. For more information, see Section 17.6.3.4, “Undo Tablespaces”.\nThe ADD DATAFILE variant enables you to specify an initial size for an NDB Disk Data tablespace\nusing an INITIAL_SIZE clause, where size is measured in bytes; the default value is 134217728\n(128 MB). You may optionally follow size with a one-letter abbreviation for an order of magnitude,\nsimilar to those used in my.cnf. Generally, this is one of the letters M (megabytes) or G (gigabytes).\nOn 32-bit systems, the maximum supported value for INITIAL_SIZE is 4294967296 (4 GB). (Bug\n#29186)\nINITIAL_SIZE is rounded, explicitly, as for CREATE TABLESPACE.\nOnce a data file has been created, its size cannot be changed; however, you can add more data files to\nan NDB tablespace using additional ALTER TABLESPACE ... ADD DATAFILE statements.\nWhen ALTER TABLESPACE ... ADD DATAFILE is used with ENGINE = NDB, a data file is created\non each Cluster data node, but only one row is generated in the Information Schema FILES table. See\nthe description of this table, as well as Section 25.6.11.1, “NDB Cluster Disk Data Objects”, for more\ninformation. ADD DATAFILE is not supported with InnoDB tablespaces.\nUsing DROP DATAFILE with ALTER TABLESPACE drops the data file 'file_name' from an NDB\ntablespace. You cannot drop a data file from a tablespace which is in use by any table; in other\nwords, the data file must be empty (no extents used). See Section 25.6.11.1, “NDB Cluster Disk Data\nObjects”. In addition, any data file to be dropped must previously have been added to the tablespace\nwith CREATE TABLESPACE or ALTER TABLESPACE. DROP DATAFILE is not supported with InnoDB\ntablespaces.\nWAIT is parsed but otherwise ignored. It is intended for future expansion.\nThe ENGINE clause, which specifies the storage engine used by the tablespace, is deprecated, since\nthe tablespace storage engine is known by the data dictionary, making the ENGINE clause obsolete. In\nMySQL 9.1, it is supported in the following two cases only:\n•\n \nALTER TABLESPACE tablespace_name ADD DATAFILE 'file_name'\n    ENGINE={NDB|NDBCLUSTER}\n•\nALTER UNDO TABLESPACE tablespace_name SET {ACTIVE|INACTIVE}\n    ENGINE=INNODB\nYou should expect the eventual removal of ENGINE from these statements as well, in a future version\nof MySQL.\nRENAME TO operations are implicitly performed in autocommit mode, regardless of the value of\nautocommit.\nA RENAME TO operation cannot be performed while LOCK TABLES or FLUSH TABLES WITH READ\nLOCK is in effect for tables that reside in the tablespace.\nExclusive metadata locks are taken on tables that reside in a general tablespace while the tablespace\nis renamed, which prevents concurrent DDL. Concurrent DML is supported.\nThe CREATE TABLESPACE privilege is required to rename an InnoDB general tablespace.\nThe AUTOEXTEND_SIZE option defines the amount by which InnoDB extends the size of a tablespace\nwhen it becomes full. The setting must be a multiple of 4MB. The default setting is 0, which causes\nthe tablespace to be extended according to the implicit default behavior. For more information, see\nSection 17.6.3.9, “Tablespace AUTOEXTEND_SIZE Configuration”.\nThe ENCRYPTION clause enables or disables page-level data encryption for an InnoDB general\ntablespace or the mysql system tablespace.\nA keyring plugin must be installed and configured before encryption can be enabled.\nIf the table_encryption_privilege_check variable is enabled, the\nTABLE_ENCRYPTION_ADMIN privilege is required to alter a general tablespace with an ENCRYPTION\nclause setting that differs from the default_table_encryption setting.\nEnabling encryption for a general tablespace fails if any table in the tablespace belongs to a schema\ndefined with DEFAULT ENCRYPTION='N'. Similarly, disabling encryption fails if any table in the\ngeneral tablespace belongs to a schema defined with DEFAULT ENCRYPTION='Y'.\nIf an ALTER TABLESPACE statement executed on a general tablespace does not include an\nENCRYPTION clause, the tablespace retains its current encryption status, regardless of the\ndefault_table_encryption setting.\nWhen a general tablespace or the mysql system tablespace is encrypted, all tables residing in the\ntablespace are encrypted. Likewise, a table created in an encrypted tablespace is encrypted.\nThe INPLACE algorithm is used when altering the ENCRYPTION attribute of a general tablespace or the\nmysql system tablespace. The INPLACE algorithm permits concurrent DML on tables that reside in the\ntablespace. Concurrent DDL is blocked.\nFor more information, see Section 17.13, “InnoDB Data-at-Rest Encryption”.\nThe ENGINE_ATTRIBUTE option is used to specify tablespace attributes for primary storage engines.\nThe option is reserved for future use.\nThe value assigned to this option is a string literal containing a valid JSON document or an empty\nstring (''). Invalid JSON is rejected.\nALTER TABLESPACE ts1 ENGINE_ATTRIBUTE='{\"key\":\"value\"}';\nENGINE_ATTRIBUTE values can be repeated without error. In this case, the last specified value is\nused.\nENGINE_ATTRIBUTE values are not checked by the server, nor are they cleared when the table's\nstorage engine is changed.\nIt is not permitted to alter an individual element of a JSON attribute value. You can only add or replace\nan attribute.",
    "15.1.11 ALTER VIEW Statement": "15.1.11 ALTER VIEW Statement\nALTER\n    [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]\n    [DEFINER = user]\n    [SQL SECURITY { DEFINER | INVOKER }]\n    VIEW view_name [(column_list)]\n    AS select_statement\n    [WITH [CASCADED | LOCAL] CHECK OPTION]\nThis statement changes the definition of a view, which must exist. The syntax is similar to that for\nCREATE VIEW see Section 15.1.23, “CREATE VIEW Statement”). This statement requires the CREATE\nVIEW and DROP privileges for the view, and some privilege for each column referred to in the SELECT\nstatement. ALTER VIEW is permitted only to the definer or users with the SET_ANY_DEFINER or\nALLOW_NONEXISTENT_DEFINER privilege.",
    "15.1.12 CREATE DATABASE Statement": "15.1.12 CREATE DATABASE Statement\nCREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name\n    [create_option] ...\ncreate_option: [DEFAULT] {\n    CHARACTER SET [=] charset_name\n  | COLLATE [=] collation_name\n  | ENCRYPTION [=] {'Y' | 'N'}\n}\nCREATE DATABASE creates a database with the given name. To use this statement, you need the\nCREATE privilege for the database. CREATE SCHEMA is a synonym for CREATE DATABASE.\nAn error occurs if the database exists and you did not specify IF NOT EXISTS.\nCREATE DATABASE is not permitted within a session that has an active LOCK TABLES statement.\nEach create_option specifies a database characteristic. Database characteristics are stored in the\ndata dictionary.\n• The CHARACTER SET option specifies the default database character set. The COLLATE option\nspecifies the default database collation. For information about character set and collation names, see\nChapter 12, Character Sets, Collations, Unicode.\nTo see the available character sets and collations, use the the SHOW CHARACTER SET and SHOW\nCOLLATION statements, respectively. See Section 15.7.7.4, “SHOW CHARACTER SET Statement”,\nand Section 15.7.7.5, “SHOW COLLATION Statement”.\n• The ENCRYPTION option defines the default database encryption, which is inherited\nby tables created in the database. The permitted values are 'Y' (encryption enabled)\nand 'N' (encryption disabled). If the ENCRYPTION option is not specified, the value\nof the default_table_encryption system variable defines the default database\nencryption. If the table_encryption_privilege_check system variable is enabled, the\nTABLE_ENCRYPTION_ADMIN privilege is required to specify a default encryption setting that differs\nfrom the default_table_encryption setting. For more information, see Defining an Encryption\nDefault for Schemas and General Tablespaces.\nA database in MySQL is implemented as a directory containing files that correspond to tables in\nthe database. Because there are no tables in a database when it is initially created, the CREATE\nDATABASE statement creates only a directory under the MySQL data directory. Rules for permissible\ndatabase names are given in Section 11.2, “Schema Object Names”. If a database name contains\nspecial characters, the name for the database directory contains encoded versions of those characters\nas described in Section 11.2.4, “Mapping of Identifiers to File Names”.\nCreating a database directory by manually creating a directory under the data directory (for example,\nwith mkdir) is unsupported in MySQL 9.1.\nWhen you create a database, let the server manage the directory and the files in it. Manipulating\ndatabase directories and files directly can cause inconsistencies and unexpected results.\nMySQL has no limit on the number of databases. The underlying file system may have a limit on the\nnumber of directories.\nYou can also use the mysqladmin program to create databases. See Section 6.5.2, “mysqladmin — A\nMySQL Server Administration Program”.",
    "15.1.13 CREATE EVENT Statement": "15.1.13 CREATE EVENT Statement\nCREATE\n    [DEFINER = user]\n    EVENT\n    [IF NOT EXISTS]\n    event_name\n    ON SCHEDULE schedule\n    [ON COMPLETION [NOT] PRESERVE]\n    [ENABLE | DISABLE | DISABLE ON {REPLICA | SLAVE}]\n    [COMMENT 'string']\n    DO event_body;\nschedule: {\n    AT timestamp [+ INTERVAL interval] ...\n  | EVERY interval\n    [STARTS timestamp [+ INTERVAL interval] ...]\n    [ENDS timestamp [+ INTERVAL interval] ...]\n}\ninterval:\n    quantity {YEAR | QUARTER | MONTH | DAY | HOUR | MINUTE |\n              WEEK | SECOND | YEAR_MONTH | DAY_HOUR | DAY_MINUTE |\n              DAY_SECOND | HOUR_MINUTE | HOUR_SECOND | MINUTE_SECOND}\nThis statement creates and schedules a new event. The event does not run unless the Event\nScheduler is enabled. For information about checking Event Scheduler status and enabling it if\nnecessary, see Section 27.5.2, “Event Scheduler Configuration”.\nCREATE EVENT requires the EVENT privilege for the schema in which the event is to be created. If\nthe DEFINER clause is present, the privileges required depend on the user value, as discussed in\nSection 27.7, “Stored Object Access Control”.\nThe minimum requirements for a valid CREATE EVENT statement are as follows:\n• The keywords CREATE EVENT plus an event name, which uniquely identifies the event in a database\nschema.\n• An ON SCHEDULE clause, which determines when and how often the event executes.\n• A DO clause, which contains the SQL statement to be executed by an event.\nThis is an example of a minimal CREATE EVENT statement:\nCREATE EVENT myevent\n    ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR\n    DO\n      UPDATE myschema.mytable SET mycol = mycol + 1;\nThe previous statement creates an event named myevent. This event executes once—one\nhour following its creation—by running an SQL statement that increments the value of the\nmyschema.mytable table's mycol column by 1.\nThe event_name must be a valid MySQL identifier with a maximum length of 64 characters. Event\nnames are not case-sensitive, so you cannot have two events named myevent and MyEvent in the\nsame schema. In general, the rules governing event names are the same as those for names of stored\nroutines. See Section 11.2, “Schema Object Names”.\nAn event is associated with a schema. If no schema is indicated as part of event_name, the default\n(current) schema is assumed. To create an event in a specific schema, qualify the event name with a\nschema using schema_name.event_name syntax.\nThe DEFINER clause specifies the MySQL account to be used when checking access privileges at\nevent execution time. If the DEFINER clause is present, the user value should be a MySQL account\nspecified as 'user_name'@'host_name', CURRENT_USER, or CURRENT_USER(). The permitted\nuser values depend on the privileges you hold, as discussed in Section 27.7, “Stored Object Access\nControl”. Also see that section for additional information about event security.\nIf the DEFINER clause is omitted, the default definer is the user who executes the CREATE EVENT\nstatement. This is the same as specifying DEFINER = CURRENT_USER explicitly.\nWithin an event body, the CURRENT_USER function returns the account used to check privileges at\nevent execution time, which is the DEFINER user. For information about user auditing within events,\nsee Section 8.2.23, “SQL-Based Account Activity Auditing”.\nIF NOT EXISTS has the same meaning for CREATE EVENT as for CREATE TABLE: If an event\nnamed event_name already exists in the same schema, no action is taken, and no error results.\n(However, a warning is generated in such cases.)\nThe ON SCHEDULE clause determines when, how often, and for how long the event_body defined for\nthe event repeats. This clause takes one of two forms:\n• AT timestamp is used for a one-time event. It specifies that the event executes one time only\nat the date and time given by timestamp, which must include both the date and time, or must be\nan expression that resolves to a datetime value. You may use a value of either the DATETIME or\nTIMESTAMP type for this purpose. If the date is in the past, a warning occurs, as shown here:\nmysql> SELECT NOW();\n+---------------------+\n| NOW()               |\n+---------------------+\n| 2006-02-10 23:59:01 |\n+---------------------+\n1 row in set (0.04 sec)\nmysql> CREATE EVENT e_totals\n    ->     ON SCHEDULE AT '2006-02-10 23:59:00'\n    ->     DO INSERT INTO test.totals VALUES (NOW());\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1588\nMessage: Event execution time is in the past and ON COMPLETION NOT\n         PRESERVE is set. The event was dropped immediately after\n         creation.\nCREATE EVENT statements which are themselves invalid—for whatever reason—fail with an error.\nYou may use CURRENT_TIMESTAMP to specify the current date and time. In such a case, the event\nacts as soon as it is created.\nTo create an event which occurs at some point in the future relative to the current date and time—\nsuch as that expressed by the phrase “three weeks from now”—you can use the optional clause\n+ INTERVAL interval. The interval portion consists of two parts, a quantity and a unit of\ntime, and follows the syntax rules described in Temporal Intervals, except that you cannot use\nany units keywords that involving microseconds when defining an event. With some interval types,\ncomplex time units may be used. For example, “two minutes and ten seconds” can be expressed as\n+ INTERVAL '2:10' MINUTE_SECOND.\nYou can also combine intervals. For example, AT CURRENT_TIMESTAMP + INTERVAL 3 WEEK\n+ INTERVAL 2 DAY is equivalent to “three weeks and two days from now”. Each portion of such a\nclause must begin with + INTERVAL.\n• To repeat actions at a regular interval, use an EVERY clause. The EVERY keyword is followed by an\ninterval as described in the previous discussion of the AT keyword. (+ INTERVAL is not used\nwith EVERY.) For example, EVERY 6 WEEK means “every six weeks”.\nAlthough + INTERVAL clauses are not permitted in an EVERY clause, you can use the same\ncomplex time units permitted in a + INTERVAL.\nAn EVERY clause may contain an optional STARTS clause. STARTS is followed by a timestamp\nvalue that indicates when the action should begin repeating, and may also use + INTERVAL\ninterval to specify an amount of time “from now”. For example, EVERY 3 MONTH STARTS\nCURRENT_TIMESTAMP + INTERVAL 1 WEEK means “every three months, beginning one\nweek from now”. Similarly, you can express “every two weeks, beginning six hours and fifteen\nminutes from now” as EVERY 2 WEEK STARTS CURRENT_TIMESTAMP + INTERVAL '6:15'\nHOUR_MINUTE. Not specifying STARTS is the same as using STARTS CURRENT_TIMESTAMP—that\nis, the action specified for the event begins repeating immediately upon creation of the event.\nAn EVERY clause may contain an optional ENDS clause. The ENDS keyword is followed by a\ntimestamp value that tells MySQL when the event should stop repeating. You may also use +\nINTERVAL interval with ENDS; for instance, EVERY 12 HOUR STARTS CURRENT_TIMESTAMP\n+ INTERVAL 30 MINUTE ENDS CURRENT_TIMESTAMP + INTERVAL 4 WEEK is equivalent to\n“every twelve hours, beginning thirty minutes from now, and ending four weeks from now”. Not using\nENDS means that the event continues executing indefinitely.\nENDS supports the same syntax for complex time units as STARTS does.\nYou may use STARTS, ENDS, both, or neither in an EVERY clause.\nIf a repeating event does not terminate within its scheduling interval, the result may be multiple\ninstances of the event executing simultaneously. If this is undesirable, you should institute a\nmechanism to prevent simultaneous instances. For example, you could use the GET_LOCK()\nfunction, or row or table locking.\nThe ON SCHEDULE clause may use expressions involving built-in MySQL functions and user\nvariables to obtain any of the timestamp or interval values which it contains. You may not use\nstored functions or loadable functions in such expressions, nor may you use any table references;\nhowever, you may use SELECT FROM DUAL. This is true for both CREATE EVENT and ALTER\nEVENT statements. References to stored functions, loadable functions, and tables in such cases are\nspecifically not permitted, and fail with an error (see Bug #22830).\nTimes in the ON SCHEDULE clause are interpreted using the current session time_zone value. This\nbecomes the event time zone; that is, the time zone that is used for event scheduling and is in effect\nwithin the event as it executes. These times are converted to UTC and stored along with the event\ntime zone internally. This enables event execution to proceed as defined regardless of any subsequent\nchanges to the server time zone or daylight saving time effects. For additional information about\nrepresentation of event times, see Section 27.5.4, “Event Metadata”. See also Section 15.7.7.19,\n“SHOW EVENTS Statement”, and Section 28.3.14, “The INFORMATION_SCHEMA EVENTS Table”.\nNormally, once an event has expired, it is immediately dropped. You can override this behavior by\nspecifying ON COMPLETION PRESERVE. Using ON COMPLETION NOT PRESERVE merely makes the\ndefault nonpersistent behavior explicit.\nYou can create an event but prevent it from being active using the DISABLE keyword. Alternatively,\nyou can use ENABLE to make explicit the default status, which is active. This is most useful in\nconjunction with ALTER EVENT (see Section 15.1.3, “ALTER EVENT Statement”).\nA third value may also appear in place of ENABLE or DISABLE; DISABLE ON REPLICA is set for the\nstatus of an event on a replica to indicate that the event was created on the replication source server\nand replicated to the replica, but is not executed on the replica. See Section 19.5.1.16, “Replication of\nInvoked Features”.\nDISABLE ON REPLICA replaces DISABLE ON SLAVE, which is deprecated, and thus subject to\nremoval in a future version of MySQL.\nYou may supply a comment for an event using a COMMENT clause. comment may be any string of up\nto 64 characters that you wish to use for describing the event. The comment text, being a string literal,\nmust be surrounded by quotation marks.\nThe DO clause specifies an action carried by the event, and consists of an SQL statement. Nearly any\nvalid MySQL statement that can be used in a stored routine can also be used as the action statement\nfor a scheduled event. (See Section 27.9, “Restrictions on Stored Programs”.) For example, the\nfollowing event e_hourly deletes all rows from the sessions table once per hour, where this table is\npart of the site_activity schema:\nCREATE EVENT e_hourly\n    ON SCHEDULE\n      EVERY 1 HOUR\n    COMMENT 'Clears out sessions table each hour.'\n    DO\n      DELETE FROM site_activity.sessions;\nMySQL stores the sql_mode system variable setting in effect when an event is created or altered, and\nalways executes the event with this setting in force, regardless of the current server SQL mode when\nthe event begins executing.\nA CREATE EVENT statement that contains an ALTER EVENT statement in its DO clause appears to\nsucceed; however, when the server attempts to execute the resulting scheduled event, the execution\nfails with an error.\nNote\nStatements such as SELECT or SHOW that merely return a result set have no\neffect when used in an event; the output from these is not sent to the MySQL\nMonitor, nor is it stored anywhere. However, you can use statements such as\nSELECT ... INTO and INSERT INTO ... SELECT that store a result. (See\nthe next example in this section for an instance of the latter.)\nThe schema to which an event belongs is the default schema for table references in the DO clause. Any\nreferences to tables in other schemas must be qualified with the proper schema name.\nAs with stored routines, you can use compound-statement syntax in the DO clause by using the BEGIN\nand END keywords, as shown here:\ndelimiter |\nCREATE EVENT e_daily\n    ON SCHEDULE\n      EVERY 1 DAY\n    COMMENT 'Saves total number of sessions then clears the table each day'\n    DO\n      BEGIN\n        INSERT INTO site_activity.totals (time, total)\n          SELECT CURRENT_TIMESTAMP, COUNT(*)\n            FROM site_activity.sessions;\n        DELETE FROM site_activity.sessions;\n      END |\ndelimiter ;\nThis example uses the delimiter command to change the statement delimiter. See Section 27.1,\n“Defining Stored Programs”.\nMore complex compound statements, such as those used in stored routines, are possible in an event.\nThis example uses local variables, an error handler, and a flow control construct:\ndelimiter |\nCREATE EVENT e\n    ON SCHEDULE\n      EVERY 5 SECOND\n    DO\n      BEGIN\n        DECLARE v INTEGER;\n        DECLARE CONTINUE HANDLER FOR SQLEXCEPTION BEGIN END;\n        SET v = 0;\n        WHILE v < 5 DO\n          INSERT INTO t1 VALUES (0);\n          UPDATE t2 SET s1 = s1 + 1;\n          SET v = v + 1;\n        END WHILE;\n    END |\ndelimiter ;\nThere is no way to pass parameters directly to or from events; however, it is possible to invoke a stored\nroutine with parameters within an event:\nCREATE EVENT e_call_myproc\n    ON SCHEDULE\n      AT CURRENT_TIMESTAMP + INTERVAL 1 DAY\n    DO CALL myproc(5, 27);\nIn MySQL 9.1, a CREATE EVENT statement can be prepared, but the statement text must not contain\nany placeholders (?). One way to get around this restriction is to assemble the text of the statement,\nprepare it, and execute it within a stored procedure; variable parts of the CREATE EVENT statement\ncan be passed into the stored procedure as parameters. We demonstrate this in the following example,\nwhich assumes that there already exists a table t in database d created as shown here:\nUSE d;\nCREATE TABLE t (\n  c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  c2 VARCHAR(20),\n  c3 INT\n);\nWe wish to create an event that inserts rows into this table at intervals determined at creation time,\nsimilar to the event defined by the statement shown here:\nCREATE EVENT e \n  ON SCHEDULE EVERY interval SECOND\n  STARTS CURRENT_TIMESTAMP + INTERVAL 10 SECOND\n  ENDS CURRENT_TIMESTAMP + INTERVAL 2 MINUTE\n  ON COMPLETION PRESERVE\n  DO\n    INSERT INTO d.t1 VALUES ROW(NULL, NOW(), FLOOR(RAND()*100));\nWe cannot use ? as a placeholder for interval, but we can pass a parameter value to a stored\nprocedure like this one:\ndelimiter |\nCREATE PROCEDURE sp(n INT)\nBEGIN\n  SET @s1 = \"CREATE EVENT e ON SCHEDULE EVERY \";\n  SET @s2 = \" SECOND\n       STARTS CURRENT_TIMESTAMP + INTERVAL 10 SECOND\n       ENDS CURRENT_TIMESTAMP + INTERVAL 2 MINUTE\n       ON COMPLETION PRESERVE\n       DO\n       INSERT INTO d.t VALUES ROW(NULL, NOW(), FLOOR(RAND()*100))\";\n  \n  SET @s = CONCAT(@s1, n, @s2);\n  PREPARE ps FROM @s;\n  EXECUTE ps;\n  DEALLOCATE PREPARE ps;\nEND |\ndelimiter ;\nmysql> TABLE t;\nEmpty set (0.00 sec)\nmysql> CALL sp(5);\nQuery OK, 0 rows affected (0.01 sec)\n# Wait 2 minutes...\nmysql> TABLE t;\n+----+---------------------+------+\n| c1 | c2                  | c3   |\n+----+---------------------+------+\n|  1 | 2024-06-12 15:53:36 |   41 |\n|  2 | 2024-06-12 15:53:41 |   84 |\n|  3 | 2024-06-12 15:53:46 |   71 |\n|  4 | 2024-06-12 15:53:51 |   78 |\n|  5 | 2024-06-12 15:53:56 |   53 |\n|  6 | 2024-06-12 15:54:01 |    6 |\n|  7 | 2024-06-12 15:54:06 |   48 |\n|  8 | 2024-06-12 15:54:11 |   98 |\n|  9 | 2024-06-12 15:54:16 |   22 |\n| 10 | 2024-06-12 15:54:21 |   88 |\n| 11 | 2024-06-12 15:54:26 |   53 |\n| 12 | 2024-06-12 15:54:31 |   75 |\n| 13 | 2024-06-12 15:54:36 |   93 |\n| 14 | 2024-06-12 15:54:41 |   13 |\n| 15 | 2024-06-12 15:54:46 |   62 |\n| 16 | 2024-06-12 15:54:51 |   47 |\n| 17 | 2024-06-12 15:54:56 |   22 |\n| 18 | 2024-06-12 15:55:01 |   47 |\n| 19 | 2024-06-12 15:55:06 |   43 |\n| 20 | 2024-06-12 15:55:11 |   50 |\n| 21 | 2024-06-12 15:55:16 |   98 |\n| 22 | 2024-06-12 15:55:21 |   15 |\n| 23 | 2024-06-12 15:55:26 |   56 |\n+----+---------------------+------+\n23 rows in set (0.00 sec)\nAfter invoking sp with the argument value 5, as shown, and waiting 2 minutes until event e has\ncompleted its run, we can see that table t was updated every 5 seconds. Since e was created with ON\nCOMPLETION PRESERVE, we can see it in Information Schema EVENTS table and verify that it was\ncreated as expected:\nmysql> SELECT EVENT_NAME, EVENT_SCHEMA, EVENT_DEFINITION, EVENT_TYPE \n     > FROM INFORMATION_SCHEMA.EVENTS WHERE EVENT_NAME='e'\\G\n*************************** 1. row ***************************\n      EVENT_NAME: e\n    EVENT_SCHEMA: d\nEVENT_DEFINITION: INSERT INTO d.t VALUES ROW(NULL, NOW(), FLOOR(RAND()*100))\n      EVENT_TYPE: RECURRING\n1 row in set (0.00 sec)\nIf an event's definer has privileges sufficient to set global system variables (see Section 7.1.9.1,\n“System Variable Privileges”), the event can read and write global variables. As granting such\nprivileges entails a potential for abuse, extreme care must be taken in doing so.\nGenerally, any statements that are valid in stored routines may be used for action statements\nexecuted by events. For more information about statements permissible within stored routines, see\nSection 27.2.1, “Stored Routine Syntax”. It is not possible to create an event as part of a stored routine\nor to create an event by another event.",
    "15.1.14 CREATE FUNCTION Statement": "15.1.14 CREATE FUNCTION Statement\nThe CREATE FUNCTION statement is used to create stored functions and loadable functions:\n• For information about creating stored functions, see Section 15.1.17, “CREATE PROCEDURE and\nCREATE FUNCTION Statements”.\n• For information about creating loadable functions, see Section 15.7.4.1, “CREATE FUNCTION\nStatement for Loadable Functions”.",
    "15.1.15 CREATE INDEX Statement": "15.1.15 CREATE INDEX Statement\nCREATE [UNIQUE | FULLTEXT | SPATIAL] INDEX index_name\n    [index_type]\n    ON tbl_name (key_part,...)\n    [index_option]\n    [algorithm_option | lock_option] ...\nkey_part: {col_name [(length)] | (expr)} [ASC | DESC]\nindex_option: {\n    KEY_BLOCK_SIZE [=] value\n  | index_type\n  | WITH PARSER parser_name\n  | COMMENT 'string'\n  | {VISIBLE | INVISIBLE}\n  | ENGINE_ATTRIBUTE [=] 'string'\n  | SECONDARY_ENGINE_ATTRIBUTE [=] 'string'\n}\nindex_type:\n    USING {BTREE | HASH}\nalgorithm_option:\n    ALGORITHM [=] {DEFAULT | INPLACE | COPY}\nlock_option:\n    LOCK [=] {DEFAULT | NONE | SHARED | EXCLUSIVE}\nNormally, you create all indexes on a table at the time the table itself is created with CREATE TABLE.\nSee Section 15.1.20, “CREATE TABLE Statement”. This guideline is especially important for InnoDB\ntables, where the primary key determines the physical layout of rows in the data file. CREATE INDEX\nenables you to add indexes to existing tables.\nCREATE INDEX is mapped to an ALTER TABLE statement to create indexes. See Section 15.1.9,\n“ALTER TABLE Statement”. CREATE INDEX cannot be used to create a PRIMARY KEY; use ALTER\nTABLE instead. For more information about indexes, see Section 10.3.1, “How MySQL Uses Indexes”.\nInnoDB supports secondary indexes on virtual columns. For more information, see Section 15.1.20.9,\n“Secondary Indexes and Generated Columns”.\nWhen the innodb_stats_persistent setting is enabled, run the ANALYZE TABLE statement for an\nInnoDB table after creating an index on that table.\nThe expr for a key_part specification can also take the form (CAST json_expression AS type\nARRAY) to create a multi-valued index on a JSON column. See Multi-Valued Indexes.\nAn index specification of the form (key_part1, key_part2, ...) creates an index with multiple\nkey parts. Index key values are formed by concatenating the values of the given key parts. For\nexample (col1, col2, col3) specifies a multiple-column index with index keys consisting of\nvalues from col1, col2, and col3.\nA key_part specification can end with ASC or DESC to specify whether index values are stored in\nascending or descending order. The default is ascending if no order specifier is given.\nASC and DESC are not supported for HASH indexes, multi-valued indexes or SPATIAL indexes.\nThe following sections describe different aspects of the CREATE INDEX statement:\n• Column Prefix Key Parts\n• Functional Key Parts\n• Unique Indexes\n• Full-Text Indexes\n• Multi-Valued Indexes\n• Spatial Indexes\n• Index Options\n• Table Copying and Locking Options\nColumn Prefix Key Parts\nFor string columns, indexes can be created that use only the leading part of column values, using\ncol_name(length) syntax to specify an index prefix length:\n• Prefixes can be specified for CHAR, VARCHAR, BINARY, and VARBINARY key parts.\n• Prefixes must be specified for BLOB and TEXT key parts. Additionally, BLOB and TEXT columns can\nbe indexed only for InnoDB, MyISAM, and BLACKHOLE tables.\n• Prefix limits are measured in bytes. However, prefix lengths for index specifications in CREATE\nTABLE, ALTER TABLE, and CREATE INDEX statements are interpreted as number of characters for\nnonbinary string types (CHAR, VARCHAR, TEXT) and number of bytes for binary string types (BINARY,\nVARBINARY, BLOB). Take this into account when specifying a prefix length for a nonbinary string\ncolumn that uses a multibyte character set.\nPrefix support and lengths of prefixes (where supported) are storage engine dependent. For\nexample, a prefix can be up to 767 bytes long for InnoDB tables that use the REDUNDANT or\nCOMPACT row format. The prefix length limit is 3072 bytes for InnoDB tables that use the DYNAMIC\nor COMPRESSED row format. For MyISAM tables, the prefix length limit is 1000 bytes. The NDB\nstorage engine does not support prefixes (see Section 25.2.7.6, “Unsupported or Missing Features in\nNDB Cluster”).\nIf a specified index prefix exceeds the maximum column data type size, CREATE INDEX handles the\nindex as follows:\n• For a nonunique index, either an error occurs (if strict SQL mode is enabled), or the index length is\nreduced to lie within the maximum column data type size and a warning is produced (if strict SQL\nmode is not enabled).\n• For a unique index, an error occurs regardless of SQL mode because reducing the index length\nmight enable insertion of nonunique entries that do not meet the specified uniqueness requirement.\nThe statement shown here creates an index using the first 10 characters of the name column\n(assuming that name has a nonbinary string type):\nCREATE INDEX part_of_name ON customer (name(10));\nIf names in the column usually differ in the first 10 characters, lookups performed using this index\nshould not be much slower than using an index created from the entire name column. Also, using\ncolumn prefixes for indexes can make the index file much smaller, which could save a lot of disk space\nand might also speed up INSERT operations.\nFunctional Key Parts\nA “normal” index indexes column values or prefixes of column values. For example, in the following\ntable, the index entry for a given t1 row includes the full col1 value and a prefix of the col2 value\nconsisting of its first 10 characters:\nCREATE TABLE t1 (\n  col1 VARCHAR(10),\n  col2 VARCHAR(20),\n  INDEX (col1, col2(10))\n);\nFunctional key parts that index expression values canalso be used in place of column or column\nprefix values. Use of functional key parts enables indexing of values not stored directly in the table.\nExamples:\nCREATE TABLE t1 (col1 INT, col2 INT, INDEX func_index ((ABS(col1))));\nCREATE INDEX idx1 ON t1 ((col1 + col2));\nCREATE INDEX idx2 ON t1 ((col1 + col2), (col1 - col2), col1);\nALTER TABLE t1 ADD INDEX ((col1 * 40) DESC);\nAn index with multiple key parts can mix nonfunctional and functional key parts.\nASC and DESC are supported for functional key parts.\nFunctional key parts must adhere to the following rules. An error occurs if a key part definition contains\ndisallowed constructs.\n• In index definitions, enclose expressions within parentheses to distinguish them from columns or\ncolumn prefixes. For example, this is permitted; the expressions are enclosed within parentheses:\nINDEX ((col1 + col2), (col3 - col4))\nThis produces an error; the expressions are not enclosed within parentheses:\nINDEX (col1 + col2, col3 - col4)\n• A functional key part cannot consist solely of a column name. For example, this is not permitted:\nINDEX ((col1), (col2))\nInstead, write the key parts as nonfunctional key parts, without parentheses:\nINDEX (col1, col2)\n• A functional key part expression cannot refer to column prefixes. For a workaround, see the\ndiscussion of SUBSTRING() and CAST() later in this section.\n• Functional key parts are not permitted in foreign key specifications.\nFor CREATE TABLE ... LIKE, the destination table preserves functional key parts from the original\ntable.\nFunctional indexes are implemented as hidden virtual generated columns, which has these\nimplications:\n• Each functional key part counts against the limit on total number of table columns; see\nSection 10.4.7, “Limits on Table Column Count and Row Size”.\n• Functional key parts inherit all restrictions that apply to generated columns. Examples:\n• Only functions permitted for generated columns are permitted for functional key parts.\n• Subqueries, parameters, variables, stored functions, and loadable functions are not permitted.\nFor more information about applicable restrictions, see Section 15.1.20.8, “CREATE TABLE and\nGenerated Columns”, and Section 15.1.9.2, “ALTER TABLE and Generated Columns”.\n• The virtual generated column itself requires no storage. The index itself takes up storage space as\nany other index.\nUNIQUE is supported for indexes that include functional key parts. However, primary keys cannot\ninclude functional key parts. A primary key requires the generated column to be stored, but functional\nkey parts are implemented as virtual generated columns, not stored generated columns.\nSPATIAL and FULLTEXT indexes cannot have functional key parts.\nIf a table contains no primary key, InnoDB automatically promotes the first UNIQUE NOT NULL index\nto the primary key. This is not supported for UNIQUE NOT NULL indexes that have functional key\nparts.\nNonfunctional indexes raise a warning if there are duplicate indexes. Indexes that contain functional\nkey parts do not have this feature.\nTo remove a column that is referenced by a functional key part, the index must be removed first.\nOtherwise, an error occurs.\nAlthough nonfunctional key parts support a prefix length specification, this is not possible for functional\nkey parts. The solution is to use SUBSTRING() (or CAST(), as described later in this section).\nFor a functional key part containing the SUBSTRING() function to be used in a query, the WHERE\nclause must contain SUBSTRING() with the same arguments. In the following example, only the\nsecond SELECT is able to use the index because that is the only query in which the arguments to\nSUBSTRING() match the index specification:\nCREATE TABLE tbl (\n  col1 LONGTEXT,\n  INDEX idx1 ((SUBSTRING(col1, 1, 10)))\n);\nSELECT * FROM tbl WHERE SUBSTRING(col1, 1, 9) = '123456789';\nSELECT * FROM tbl WHERE SUBSTRING(col1, 1, 10) = '1234567890';\nFunctional key parts enable indexing of values that cannot be indexed otherwise, such as JSON values.\nHowever, this must be done correctly to achieve the desired effect. For example, this syntax does not\nwork:\nCREATE TABLE employees (\n  data JSON,\n  INDEX ((data->>'$.name'))\n);\nThe syntax fails because:\n• The ->> operator translates into JSON_UNQUOTE(JSON_EXTRACT(...)).\n• JSON_UNQUOTE() returns a value with a data type of LONGTEXT, and the hidden generated column\nthus is assigned the same data type.\n• MySQL cannot index LONGTEXT columns specified without a prefix length on the key part, and prefix\nlengths are not permitted in functional key parts.\nTo index the JSON column, you could try using the CAST() function as follows:\nCREATE TABLE employees (\n  data JSON,\n  INDEX ((CAST(data->>'$.name' AS CHAR(30))))\n);\nThe hidden generated column is assigned the VARCHAR(30) data type, which can be indexed. But this\napproach produces a new issue when trying to use the index:\n• CAST() returns a string with the collation utf8mb4_0900_ai_ci (the server default collation).\n• JSON_UNQUOTE() returns a string with the collation utf8mb4_bin (hard coded).\nAs a result, there is a collation mismatch between the indexed expression in the preceding table\ndefinition and the WHERE clause expression in the following query:\nSELECT * FROM employees WHERE data->>'$.name' = 'James';\nThe index is not used because the expressions in the query and the index differ. To support this kind of\nscenario for functional key parts, the optimizer automatically strips CAST() when looking for an index\nto use, but only if the collation of the indexed expression matches that of the query expression. For an\nindex with a functional key part to be used, either of the following two solutions work (although they\ndiffer somewhat in effect):\n• Solution 1. Assign the indexed expression the same collation as JSON_UNQUOTE():\nCREATE TABLE employees (\n  data JSON,\n  INDEX idx ((CAST(data->>\"$.name\" AS CHAR(30)) COLLATE utf8mb4_bin))\n);\nINSERT INTO employees VALUES\n  ('{ \"name\": \"james\", \"salary\": 9000 }'),\n  ('{ \"name\": \"James\", \"salary\": 10000 }'),\n  ('{ \"name\": \"Mary\", \"salary\": 12000 }'),\n  ('{ \"name\": \"Peter\", \"salary\": 8000 }');\nSELECT * FROM employees WHERE data->>'$.name' = 'James';\nThe ->> operator is the same as JSON_UNQUOTE(JSON_EXTRACT(...)), and JSON_UNQUOTE()\nreturns a string with collation utf8mb4_bin. The comparison is thus case-sensitive, and only one\nrow matches:\n+------------------------------------+\n| data                               |\n+------------------------------------+\n| {\"name\": \"James\", \"salary\": 10000} |\n+------------------------------------+\n• Solution 2. Specify the full expression in the query:\nCREATE TABLE employees (\n  data JSON,\n  INDEX idx ((CAST(data->>\"$.name\" AS CHAR(30))))\n);\nINSERT INTO employees VALUES\n  ('{ \"name\": \"james\", \"salary\": 9000 }'),\n  ('{ \"name\": \"James\", \"salary\": 10000 }'),\n  ('{ \"name\": \"Mary\", \"salary\": 12000 }'),\n  ('{ \"name\": \"Peter\", \"salary\": 8000 }');\nSELECT * FROM employees WHERE CAST(data->>'$.name' AS CHAR(30)) = 'James';\nCAST() returns a string with collation utf8mb4_0900_ai_ci, so the comparison case-insensitive\nand two rows match:\n+------------------------------------+\n| data                               |\n+------------------------------------+\n| {\"name\": \"james\", \"salary\": 9000}  |\n| {\"name\": \"James\", \"salary\": 10000} |\n+------------------------------------+\nBe aware that although the optimizer supports automatically stripping CAST() with indexed generated\ncolumns, the following approach does not work because it produces a different result with and without\nan index (Bug#27337092):\nmysql> CREATE TABLE employees (\n         data JSON,\n         generated_col VARCHAR(30) AS (CAST(data->>'$.name' AS CHAR(30)))\n       );\nQuery OK, 0 rows affected, 1 warning (0.03 sec)\nmysql> INSERT INTO employees (data)\n       VALUES ('{\"name\": \"james\"}'), ('{\"name\": \"James\"}');\nQuery OK, 2 rows affected, 1 warning (0.01 sec)\nRecords: 2  Duplicates: 0  Warnings: 1\nmysql> SELECT * FROM employees WHERE data->>'$.name' = 'James';\n+-------------------+---------------+\n| data              | generated_col |\n+-------------------+---------------+\n| {\"name\": \"James\"} | James         |\n+-------------------+---------------+\n1 row in set (0.00 sec)\nmysql> ALTER TABLE employees ADD INDEX idx (generated_col);\nQuery OK, 0 rows affected, 1 warning (0.03 sec)\nRecords: 0  Duplicates: 0  Warnings: 1\nmysql> SELECT * FROM employees WHERE data->>'$.name' = 'James';\n+-------------------+---------------+\n| data              | generated_col |\n+-------------------+---------------+\n| {\"name\": \"james\"} | james         |\n| {\"name\": \"James\"} | James         |\n+-------------------+---------------+\n2 rows in set (0.01 sec)\nUnique Indexes\nA UNIQUE index creates a constraint such that all values in the index must be distinct. An error occurs\nif you try to add a new row with a key value that matches an existing row. If you specify a prefix value\nfor a column in a UNIQUE index, the column values must be unique within the prefix length. A UNIQUE\nindex permits multiple NULL values for columns that can contain NULL.\nIf a table has a PRIMARY KEY or UNIQUE NOT NULL index that consists of a single column that has\nan integer type, you can use _rowid to refer to the indexed column in SELECT statements, as follows:\n• _rowid refers to the PRIMARY KEY column if there is a PRIMARY KEY consisting of a single integer\ncolumn. If there is a PRIMARY KEY but it does not consist of a single integer column, _rowid cannot\nbe used.\n• Otherwise, _rowid refers to the column in the first UNIQUE NOT NULL index if that index consists\nof a single integer column. If the first UNIQUE NOT NULL index does not consist of a single integer\ncolumn, _rowid cannot be used.\nFull-Text Indexes\nFULLTEXT indexes are supported only for InnoDB and MyISAM tables and can include only CHAR,\nVARCHAR, and TEXT columns. Indexing always happens over the entire column; column prefix indexing\nis not supported and any prefix length is ignored if specified. See Section 14.9, “Full-Text Search\nFunctions”, for details of operation.\nMulti-Valued Indexes\nInnoDB supports multi-valued indexes. A multi-valued index is a secondary index defined on a column\nthat stores an array of values. A “normal” index has one index record for each data record (1:1). A\nmulti-valued index can have multiple index records for a single data record (N:1). Multi-valued indexes\nare intended for indexing JSON arrays. For example, a multi-valued index defined on the array of zip\ncodes in the following JSON document creates an index record for each zip code, with each index\nrecord referencing the same data record.\n{\n    \"user\":\"Bob\",\n    \"user_id\":31,\n    \"zipcode\":[94477,94536]\n}\nCreating multi-valued Indexes\nYou can create a multi-valued index in a CREATE TABLE, ALTER TABLE, or CREATE INDEX\nstatement. This requires using CAST(... AS ... ARRAY) in the index definition, which casts same-\ntyped scalar values in a JSON array to an SQL data type array. A virtual column is then generated\ntransparently with the values in the SQL data type array; finally, a functional index (also referred to as a\nvirtual index) is created on the virtual column. It is the functional index defined on the virtual column of\nvalues from the SQL data type array that forms the multi-valued index.\nThe examples in the following list show the three different ways in which a multi-valued index zips can\nbe created on an array $.zipcode on a JSON column custinfo in a table named customers. In\neach case, the JSON array is cast to an SQL data type array of UNSIGNED integer values.\n• CREATE TABLE only:\nCREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    modified DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    custinfo JSON,\n    INDEX zips( (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)) )\n    );\n• CREATE TABLE plus ALTER TABLE:\nCREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    modified DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    custinfo JSON\n    );\nALTER TABLE customers ADD INDEX zips( (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)) );\n• CREATE TABLE plus CREATE INDEX:\nCREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    modified DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    custinfo JSON\n    );\nCREATE INDEX zips ON customers ( (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)) );\nA multi-valued index can also be defined as part of a composite index. This example shows a\ncomposite index that includes two single-valued parts (for the id and modified columns), and one\nmulti-valued part (for the custinfo column):\nCREATE TABLE customers (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    modified DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    custinfo JSON\n    );\nALTER TABLE customers ADD INDEX comp(id, modified,\n    (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)) );\nOnly one multi-valued key part can be used in a composite index. The multi-valued key part may be\nused in any order relative to the other parts of the key. In other words, the ALTER TABLE statement\njust shown could have used comp(id, (CAST(custinfo->'$.zipcode' AS UNSIGNED\nARRAY), modified)) (or any other ordering) and still have been valid.\nUsing multi-valued Indexes\nThe optimizer uses a multi-valued index to fetch records when the following functions are specified in a\nWHERE clause:\n• MEMBER OF()\n• JSON_CONTAINS()\n• JSON_OVERLAPS()\nWe can demonstrate this by creating and populating the customers table using the following CREATE\nTABLE and INSERT statements:\nmysql> CREATE TABLE customers (\n    ->     id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    ->     modified DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    ->     custinfo JSON\n    ->     );\nQuery OK, 0 rows affected (0.51 sec)\nmysql> INSERT INTO customers VALUES\n    ->     (NULL, NOW(), '{\"user\":\"Jack\",\"user_id\":37,\"zipcode\":[94582,94536]}'),\n    ->     (NULL, NOW(), '{\"user\":\"Jill\",\"user_id\":22,\"zipcode\":[94568,94507,94582]}'),\n    ->     (NULL, NOW(), '{\"user\":\"Bob\",\"user_id\":31,\"zipcode\":[94477,94507]}'),\n    ->     (NULL, NOW(), '{\"user\":\"Mary\",\"user_id\":72,\"zipcode\":[94536]}'),\n    ->     (NULL, NOW(), '{\"user\":\"Ted\",\"user_id\":56,\"zipcode\":[94507,94582]}');\nQuery OK, 5 rows affected (0.07 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\nFirst we execute three queries on the customers table, one each using MEMBER OF(),\nJSON_CONTAINS(), and JSON_OVERLAPS(), with the result from each query shown here:\nmysql> SELECT * FROM customers\n    ->     WHERE 94507 MEMBER OF(custinfo->'$.zipcode');\n+----+---------------------+-------------------------------------------------------------------+\n| id | modified            | custinfo                                                          |\n+----+---------------------+-------------------------------------------------------------------+\n|  2 | 2019-06-29 22:23:12 | {\"user\": \"Jill\", \"user_id\": 22, \"zipcode\": [94568, 94507, 94582]} |\n|  3 | 2019-06-29 22:23:12 | {\"user\": \"Bob\", \"user_id\": 31, \"zipcode\": [94477, 94507]}         |\n|  5 | 2019-06-29 22:23:12 | {\"user\": \"Ted\", \"user_id\": 56, \"zipcode\": [94507, 94582]}         |\n+----+---------------------+-------------------------------------------------------------------+\n3 rows in set (0.00 sec)\nmysql> SELECT * FROM customers\n    ->     WHERE JSON_CONTAINS(custinfo->'$.zipcode', CAST('[94507,94582]' AS JSON));\n+----+---------------------+-------------------------------------------------------------------+\n| id | modified            | custinfo                                                          |\n+----+---------------------+-------------------------------------------------------------------+\n|  2 | 2019-06-29 22:23:12 | {\"user\": \"Jill\", \"user_id\": 22, \"zipcode\": [94568, 94507, 94582]} |\n|  5 | 2019-06-29 22:23:12 | {\"user\": \"Ted\", \"user_id\": 56, \"zipcode\": [94507, 94582]}         |\n+----+---------------------+-------------------------------------------------------------------+\n2 rows in set (0.00 sec)\nmysql> SELECT * FROM customers\n    ->     WHERE JSON_OVERLAPS(custinfo->'$.zipcode', CAST('[94507,94582]' AS JSON));\n+----+---------------------+-------------------------------------------------------------------+\n| id | modified            | custinfo                                                          |\n+----+---------------------+-------------------------------------------------------------------+\n|  1 | 2019-06-29 22:23:12 | {\"user\": \"Jack\", \"user_id\": 37, \"zipcode\": [94582, 94536]}        |\n|  2 | 2019-06-29 22:23:12 | {\"user\": \"Jill\", \"user_id\": 22, \"zipcode\": [94568, 94507, 94582]} |\n|  3 | 2019-06-29 22:23:12 | {\"user\": \"Bob\", \"user_id\": 31, \"zipcode\": [94477, 94507]}         |\n|  5 | 2019-06-29 22:23:12 | {\"user\": \"Ted\", \"user_id\": 56, \"zipcode\": [94507, 94582]}         |\n+----+---------------------+-------------------------------------------------------------------+\n4 rows in set (0.00 sec)\nNext, we run EXPLAIN on each of the previous three queries:\nmysql> EXPLAIN SELECT * FROM customers\n    ->     WHERE 94507 MEMBER OF(custinfo->'$.zipcode');\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref  | rows | fil\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n|  1 | SIMPLE      | customers | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    5 |   1\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n1 row in set, 1 warning (0.00 sec)\nmysql> EXPLAIN SELECT * FROM customers\n    ->     WHERE JSON_CONTAINS(custinfo->'$.zipcode', CAST('[94507,94582]' AS JSON));\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref  | rows | fil\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n|  1 | SIMPLE      | customers | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    5 |   1\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n1 row in set, 1 warning (0.00 sec)\nmysql> EXPLAIN SELECT * FROM customers\n    ->     WHERE JSON_OVERLAPS(custinfo->'$.zipcode', CAST('[94507,94582]' AS JSON));\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref  | rows | fil\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n|  1 | SIMPLE      | customers | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    5 |   1\n+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----\n1 row in set, 1 warning (0.01 sec)\nNone of the three queries just shown are able to use any keys. To solve this problem, we can add a\nmulti-valued index on the zipcode array in the JSON column (custinfo), like this:\nmysql> ALTER TABLE customers\n    ->     ADD INDEX zips( (CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)) );\nQuery OK, 0 rows affected (0.47 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nWhen we run the previous EXPLAIN statements again, we can now observe that the queries can (and\ndo) use the index zips that was just created:\nmysql> EXPLAIN SELECT * FROM customers\n    ->     WHERE 94507 MEMBER OF(custinfo->'$.zipcode');\n+----+-------------+-----------+------------+------+---------------+------+---------+-------+------+-------\n| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref   | rows | filter\n+----+-------------+-----------+------------+------+---------------+------+---------+-------+------+-------\n|  1 | SIMPLE      | customers | NULL       | ref  | zips          | zips | 9       | const |    1 |   100.\n+----+-------------+-----------+------------+------+---------------+------+---------+-------+------+-------\n1 row in set, 1 warning (0.00 sec)\nmysql> EXPLAIN SELECT * FROM customers\n    ->     WHERE JSON_CONTAINS(custinfo->'$.zipcode', CAST('[94507,94582]' AS JSON));\n+----+-------------+-----------+------------+-------+---------------+------+---------+------+------+-------\n| id | select_type | table     | partitions | type  | possible_keys | key  | key_len | ref  | rows | filter\n+----+-------------+-----------+------------+-------+---------------+------+---------+------+------+-------\n|  1 | SIMPLE      | customers | NULL       | range | zips          | zips | 9       | NULL |    6 |   100.\n+----+-------------+-----------+------------+-------+---------------+------+---------+------+------+-------\n1 row in set, 1 warning (0.00 sec)\nmysql> EXPLAIN SELECT * FROM customers\n    ->     WHERE JSON_OVERLAPS(custinfo->'$.zipcode', CAST('[94507,94582]' AS JSON));\n+----+-------------+-----------+------------+-------+---------------+------+---------+------+------+-------\n| id | select_type | table     | partitions | type  | possible_keys | key  | key_len | ref  | rows | filter\n+----+-------------+-----------+------------+-------+---------------+------+---------+------+------+-------\n|  1 | SIMPLE      | customers | NULL       | range | zips          | zips | 9       | NULL |    6 |   100.\n+----+-------------+-----------+------------+-------+---------------+------+---------+------+------+-------\n1 row in set, 1 warning (0.01 sec)\nA multi-valued index can be defined as a unique key. If defined as a unique key, attempting to insert\na value already present in the multi-valued index returns a duplicate key error. If duplicate values are\nalready present, attempting to add a unique multi-valued index fails, as shown here:\nmysql> ALTER TABLE customers DROP INDEX zips;\nQuery OK, 0 rows affected (0.55 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> ALTER TABLE customers\n    ->     ADD UNIQUE INDEX zips((CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)));\nERROR 1062 (23000): Duplicate entry '[94507, ' for key 'customers.zips'\nmysql> ALTER TABLE customers\n    ->     ADD INDEX zips((CAST(custinfo->'$.zipcode' AS UNSIGNED ARRAY)));\nQuery OK, 0 rows affected (0.36 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nCharacteristics of Multi-Valued Indexes\nMulti-valued indexes have the additional characteristics listed here:\n• DML operations that affect multi-valued indexes are handled in the same way as DML operations\nthat affect a normal index, with the only difference being that there may be more than one insert or\nupdate for a single clustered index record.\n• Nullability and multi-valued indexes:\n• If a multi-valued key part has an empty array, no entries are added to the index, and the data\nrecord is not accessible by an index scan.\n• If multi-valued key part generation returns a NULL value, a single entry containing NULL is added\nto the multi-valued index. If the key part is defined as NOT NULL, an error is reported.\n• If the typed array column is set to NULL, the storage engine stores a single record containing NULL\nthat points to the data record.\n• JSON null values are not permitted in indexed arrays. If any returned value is NULL, it is treated as\na JSON null and an Invalid JSON value error is reported.\n• Because multi-valued indexes are virtual indexes on virtual columns, they must adhere to the same\nrules as secondary indexes on virtual generated columns.\n• Index records are not added for empty arrays.\nLimitations and Restrictions on Multi-valued Indexes\nMulti-valued indexes are subject to the limitations and restrictions listed here:\n• Only one multi-valued key part is permitted per multi-valued index. However, the CAST(...\nAS ... ARRAY) expression can refer to multiple arrays within a JSON document, as shown here:\nCAST(data->'$.arr[*][*]' AS UNSIGNED ARRAY)\nIn this case, all values matching the JSON expression are stored in the index as a single flat array.\n• An index with a multi-valued key part does not support ordering and therefore cannot be used as a\nprimary key. For the same reason, a multi-valued index cannot be defined using the ASC or DESC\nkeyword.\n• A multi-valued index cannot be a covering index.\n• The maximum number of values per record for a multi-valued index is determined by the amount\nof data than can be stored on a single undo log page, which is 65221 bytes (64K minus 315 bytes\nfor overhead), which means that the maximum total length of key values is also 65221 bytes. The\nmaximum number of keys depends on various factors, which prevents defining a specific limit. Tests\nhave shown a multi-valued index to permit as many as 1604 integer keys per record, for example.\nWhen the limit is reached, an error similar to the following is reported: ERROR 3905 (HY000):\nExceeded max number of values per record for multi-valued index 'idx' by 1\nvalue(s).\n• The only type of expression that is permitted in a multi-valued key part is a JSON expression. The\nexpression need not reference an existing element in a JSON document inserted into the indexed\ncolumn, but must itself be syntactically valid.\n• Because index records for the same clustered index record are dispersed throughout a multi-valued\nindex, a multi-valued index does not support range scans or index-only scans.\n• Multi-valued indexes are not permitted in foreign key specifications.\n• Index prefixes cannot be defined for multi-valued indexes.\n• Multi-valued indexes cannot be defined on data cast as BINARY (see the description of the CAST()\nfunction).\n• Online creation of a multi-value index is not supported, which means the operation uses\nALGORITHM=COPY. See Performance and Space Requirements.\n• Character sets and collations other than the following two combinations of character set and collation\nare not supported for multi-valued indexes:\n1. The binary character set with the default binary collation\n2. The utf8mb4 character set with the default utf8mb4_0900_as_cs collation.\n• As with other indexes on columns of InnoDB tables, a multi-valued index cannot be created with\nUSING HASH; attempting to do so results in a warning: This storage engine does not\nsupport the HASH index algorithm, storage engine default was used instead.\n(USING BTREE is supported as usual.)\nSpatial Indexes\nThe MyISAM, InnoDB, NDB, and ARCHIVE storage engines support spatial columns such as POINT\nand GEOMETRY. (Section 13.4, “Spatial Data Types”, describes the spatial data types.) However,\nsupport for spatial column indexing varies among engines. Spatial and nonspatial indexes on spatial\ncolumns are available according to the following rules.\nSpatial indexes on spatial columns have these characteristics:\n• Available only for InnoDB and MyISAM tables. Specifying SPATIAL INDEX for other storage\nengines results in an error.\n• An index on a spatial column must be a SPATIAL index. The SPATIAL keyword is thus optional but\nimplicit for creating an index on a spatial column.\n• Available for single spatial columns only. A spatial index cannot be created over multiple spatial\ncolumns.\n• Indexed columns must be NOT NULL.\n• Column prefix lengths are prohibited. The full width of each column is indexed.\n• Not permitted for a primary key or unique index.\nNonspatial indexes on spatial columns (created with INDEX, UNIQUE, or PRIMARY KEY) have these\ncharacteristics:\n• Permitted for any storage engine that supports spatial columns except ARCHIVE.\n• Columns can be NULL unless the index is a primary key.\n• The index type for a non-SPATIAL index depends on the storage engine. Currently, B-tree is used.\n• Permitted for a column that can have NULL values only for InnoDB, MyISAM, and MEMORY tables.\nIndex Options\nFollowing the key part list, index options can be given. An index_option value can be any of the\nfollowing:\n• KEY_BLOCK_SIZE [=] value\nFor MyISAM tables, KEY_BLOCK_SIZE optionally specifies the size in bytes to use for index\nkey blocks. The value is treated as a hint; a different size could be used if necessary. A\nKEY_BLOCK_SIZE value specified for an individual index definition overrides a table-level\nKEY_BLOCK_SIZE value.\nKEY_BLOCK_SIZE is not supported at the index level for InnoDB tables. See Section 15.1.20,\n“CREATE TABLE Statement”.\n• index_type\nSome storage engines permit you to specify an index type when creating an index. For example:\nCREATE TABLE lookup (id INT) ENGINE = MEMORY;\nCREATE INDEX id_index ON lookup (id) USING BTREE;\nTable 15.1, “Index Types Per Storage Engine” shows the permissible index type values supported by\ndifferent storage engines. Where multiple index types are listed, the first one is the default when no\nindex type specifier is given. Storage engines not listed in the table do not support an index_type\nclause in index definitions.\nTable 15.1 Index Types Per Storage Engine\nStorage Engine\nPermissible Index Types\nInnoDB\nBTREE\nMyISAM\nBTREE\nMEMORY/HEAP\nHASH, BTREE\nNDB\nHASH, BTREE (see note in text)\nThe index_type clause cannot be used for FULLTEXT INDEX specifications. Full-text index\nimplementation is storage-engine dependent. Spatial indexes are implemented as R-tree indexes.\nIf you specify an index type that is not valid for a given storage engine, but another index type is\navailable that the engine can use without affecting query results, the engine uses the available type.\nThe parser recognizes RTREE as a type name. This is permitted only for SPATIAL indexes.\nBTREE indexes are implemented by the NDB storage engine as T-tree indexes.\nNote\nFor indexes on NDB table columns, the USING option can be specified only\nfor a unique index or primary key. USING HASH prevents the creation of an\nordered index; otherwise, creating a unique index or primary key on an NDB\ntable automatically results in the creation of both an ordered index and a hash\nindex, each of which indexes the same set of columns.\nFor unique indexes that include one or more NULL columns of an NDB table,\nthe hash index can be used only to look up literal values, which means that\nIS [NOT] NULL conditions require a full scan of the table. One workaround\nis to make sure that a unique index using one or more NULL columns on such\na table is always created in such a way that it includes the ordered index; that\nis, avoid employing USING HASH when creating the index.\nIf you specify an index type that is not valid for a given storage engine, but another index type is\navailable that the engine can use without affecting query results, the engine uses the available type.\nThe parser recognizes RTREE as a type name, but currently this cannot be specified for any storage\nengine.\nNote\nUse of the index_type option before the ON tbl_name clause is\ndeprecated; expect support for use of the option in this position to be\nremoved in a future MySQL release. If an index_type option is given in\nboth the earlier and later positions, the final option applies.\nTYPE type_name is recognized as a synonym for USING type_name. However, USING is the\npreferred form.\nThe following tables show index characteristics for the storage engines that support the\nindex_type option.\nTable 15.2 InnoDB Storage Engine Index Characteristics\nIndex Class\nIndex Type\nStores NULL\nVALUES\nPermits\nMultiple NULL\nValues\nIS NULL Scan\nType\nIS NOT NULL\nScan Type\nPrimary key\nBTREE\nNo\nNo\nN/A\nN/A\nUnique\nBTREE\nYes\nYes\nIndex\nIndex\nKey\nBTREE\nYes\nYes\nIndex\nIndex\nFULLTEXT\nN/A\nYes\nYes\nTable\nTable\nIndex Class\nIndex Type\nStores NULL\nVALUES\nPermits\nMultiple NULL\nValues\nIS NULL Scan\nType\nIS NOT NULL\nScan Type\nSPATIAL\nN/A\nNo\nNo\nN/A\nN/A\nTable 15.3 MyISAM Storage Engine Index Characteristics\nIndex Class\nIndex Type\nStores NULL\nVALUES\nPermits\nMultiple NULL\nValues\nIS NULL Scan\nType\nIS NOT NULL\nScan Type\nPrimary key\nBTREE\nNo\nNo\nN/A\nN/A\nUnique\nBTREE\nYes\nYes\nIndex\nIndex\nKey\nBTREE\nYes\nYes\nIndex\nIndex\nFULLTEXT\nN/A\nYes\nYes\nTable\nTable\nSPATIAL\nN/A\nNo\nNo\nN/A\nN/A\nTable 15.4 MEMORY Storage Engine Index Characteristics\nIndex Class\nIndex Type\nStores NULL\nVALUES\nPermits\nMultiple NULL\nValues\nIS NULL Scan\nType\nIS NOT NULL\nScan Type\nPrimary key\nBTREE\nNo\nNo\nN/A\nN/A\nUnique\nBTREE\nYes\nYes\nIndex\nIndex\nKey\nBTREE\nYes\nYes\nIndex\nIndex\nPrimary key\nHASH\nNo\nNo\nN/A\nN/A\nUnique\nHASH\nYes\nYes\nIndex\nIndex\nKey\nHASH\nYes\nYes\nIndex\nIndex\nTable 15.5 NDB Storage Engine Index Characteristics\nIndex Class\nIndex Type\nStores NULL\nVALUES\nPermits\nMultiple NULL\nValues\nIS NULL Scan\nType\nIS NOT NULL\nScan Type\nPrimary key\nBTREE\nNo\nNo\nIndex\nIndex\nUnique\nBTREE\nYes\nYes\nIndex\nIndex\nKey\nBTREE\nYes\nYes\nIndex\nIndex\nPrimary key\nHASH\nNo\nNo\nTable (see note\n1)\nTable (see note\n1)\nUnique\nHASH\nYes\nYes\nTable (see note\n1)\nTable (see note\n1)\nKey\nHASH\nYes\nYes\nTable (see note\n1)\nTable (see note\n1)\nTable note:\n1. USING HASH prevents creation of an implicit ordered index.\n• WITH PARSER parser_name\nThis option can be used only with FULLTEXT indexes. It associates a parser plugin with the index if\nfull-text indexing and searching operations need special handling. InnoDB and MyISAM support full-\ntext parser plugins. If you have a MyISAM table with an associated full-text parser plugin, you can\nconvert the table to InnoDB using ALTER TABLE. See Full-Text Parser Plugins and Writing Full-Text\nParser Plugins for more information.\n• COMMENT 'string'\nIndex definitions can include an optional comment of up to 1024 characters.\nThe MERGE_THRESHOLD for index pages can be configured for individual indexes using the\nindex_option COMMENT clause of the CREATE INDEX statement. For example:\nCREATE TABLE t1 (id INT);\nCREATE INDEX id_index ON t1 (id) COMMENT 'MERGE_THRESHOLD=40';\nIf the page-full percentage for an index page falls below the MERGE_THRESHOLD value when a\nrow is deleted or when a row is shortened by an update operation, InnoDB attempts to merge the\nindex page with a neighboring index page. The default MERGE_THRESHOLD value is 50, which is the\npreviously hardcoded value.\nMERGE_THRESHOLD can also be defined at the index level and table level using CREATE TABLE\nand ALTER TABLE statements. For more information, see Section 17.8.11, “Configuring the Merge\nThreshold for Index Pages”.\n• VISIBLE, INVISIBLE\nSpecify index visibility. Indexes are visible by default. An invisible index is not used by the optimizer.\nSpecification of index visibility applies to indexes other than primary keys (either explicit or implicit).\nFor more information, see Section 10.3.12, “Invisible Indexes”.\n• The ENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE are used to specify index\nattributes for primary and secondary storage engines. The options are reserved for future use.\nThe value assigned to this option is a string literal containing a valid JSON document or an empty\nstring (''). Invalid JSON is rejected.\nCREATE INDEX i1 ON t1 (c1) ENGINE_ATTRIBUTE='{\"key\":\"value\"}';\nENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE values can be repeated without error.\nIn this case, the last specified value is used.\nENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE values are not checked by the server,\nnor are they cleared when the table's storage engine is changed.\nTable Copying and Locking Options\nALGORITHM and LOCK clauses may be given to influence the table copying method and level of\nconcurrency for reading and writing the table while its indexes are being modified. They have the\nsame meaning as for the ALTER TABLE statement. For more information, see Section 15.1.9, “ALTER\nTABLE Statement”\nNDB Cluster supports online operations using the same ALGORITHM=INPLACE syntax used with\nthe standard MySQL Server. See Section 25.6.12, “Online Operations with ALTER TABLE in NDB\nCluster”, for more information.",
    "15.1.16 CREATE LOGFILE GROUP Statement": "15.1.16 CREATE LOGFILE GROUP Statement\nCREATE LOGFILE GROUP logfile_group\n    ADD UNDOFILE 'undo_file'\n    [INITIAL_SIZE [=] initial_size]\n    [UNDO_BUFFER_SIZE [=] undo_buffer_size]\n    [REDO_BUFFER_SIZE [=] redo_buffer_size]\n    [NODEGROUP [=] nodegroup_id]\n    [WAIT]\n    [COMMENT [=] 'string']\n    ENGINE [=] engine_name\nThis statement creates a new log file group named logfile_group having a single undo file named\n'undo_file'. A CREATE LOGFILE GROUP statement has one and only one ADD UNDOFILE clause.\nFor rules covering the naming of log file groups, see Section 11.2, “Schema Object Names”.\nNote\nAll NDB Cluster Disk Data objects share the same namespace. This means that\neach Disk Data object must be uniquely named (and not merely each Disk Data\nobject of a given type). For example, you cannot have a tablespace and a log\nfile group with the same name, or a tablespace and a data file with the same\nname.\nThere can be only one log file group per NDB Cluster instance at any given time.\nThe optional INITIAL_SIZE parameter sets the undo file's initial size; if not specified, it defaults to\n128M (128 megabytes). The optional UNDO_BUFFER_SIZE parameter sets the size used by the undo\nbuffer for the log file group; The default value for UNDO_BUFFER_SIZE is 8M (eight megabytes); this\nvalue cannot exceed the amount of system memory available. Both of these parameters are specified\nin bytes. You may optionally follow either or both of these with a one-letter abbreviation for an order of\nmagnitude, similar to those used in my.cnf. Generally, this is one of the letters M (for megabytes) or G\n(for gigabytes).\nMemory used for UNDO_BUFFER_SIZE comes from the global pool whose size is determined by the\nvalue of the SharedGlobalMemory data node configuration parameter. This includes any default\nvalue implied for this option by the setting of the InitialLogFileGroup data node configuration\nparameter.\nThe maximum permitted for UNDO_BUFFER_SIZE is 629145600 (600 MB).\nOn 32-bit systems, the maximum supported value for INITIAL_SIZE is 4294967296 (4 GB). (Bug\n#29186)\nThe minimum allowed value for INITIAL_SIZE is 1048576 (1 MB).\nThe ENGINE option determines the storage engine to be used by this log file group, with engine_name\nbeing the name of the storage engine. This must be NDB (or NDBCLUSTER). If ENGINE is not set,\nMySQL tries to use the engine specified by the default_storage_engine server system variable.\nIn any case, if the engine is not specified as NDB or NDBCLUSTER, the CREATE LOGFILE GROUP\nstatement appears to succeed but actually fails to create the log file group, as shown here:\nmysql> CREATE LOGFILE GROUP lg1\n    ->     ADD UNDOFILE 'undo.dat' INITIAL_SIZE = 10M;\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS;\n+-------+------+-------------------------------------------------------------------------------------------\n| Level | Code | Message                                                                                   \n+-------+------+-------------------------------------------------------------------------------------------\n| Error | 1478 | Table storage engine 'InnoDB' does not support the create option 'TABLESPACE or LOGFILE GR\n+-------+------+-------------------------------------------------------------------------------------------\n1 row in set (0.00 sec)\nmysql> DROP LOGFILE GROUP lg1 ENGINE = NDB;\nERROR 1529 (HY000): Failed to drop LOGFILE GROUP\nmysql> CREATE LOGFILE GROUP lg1\n    ->     ADD UNDOFILE 'undo.dat' INITIAL_SIZE = 10M\n    ->     ENGINE = NDB;\nQuery OK, 0 rows affected (2.97 sec)\nThe fact that the CREATE LOGFILE GROUP statement does not actually return an error when a\nstorage engine other than NDB is specified, but rather appears to succeed, is a known issue which we\nhope to address in a future version of NDB Cluster.\nREDO_BUFFER_SIZE, NODEGROUP, WAIT, and COMMENT are parsed but ignored, and so have no effect\nin MySQL 9.1. These options are intended for future expansion.\nWhen used with ENGINE [=] NDB, a log file group and associated undo log file are created on each\nCluster data node. You can verify that the undo files were created and obtain information about them\nby querying the Information Schema FILES table. For example:\nmysql> SELECT LOGFILE_GROUP_NAME, LOGFILE_GROUP_NUMBER, EXTRA\n    -> FROM INFORMATION_SCHEMA.FILES\n    -> WHERE FILE_NAME = 'undo_10.dat';\n+--------------------+----------------------+----------------+\n| LOGFILE_GROUP_NAME | LOGFILE_GROUP_NUMBER | EXTRA          |\n+--------------------+----------------------+----------------+\n| lg_3               |                   11 | CLUSTER_NODE=3 |\n| lg_3               |                   11 | CLUSTER_NODE=4 |\n+--------------------+----------------------+----------------+\n2 rows in set (0.06 sec)\nCREATE LOGFILE GROUP is useful only with Disk Data storage for NDB Cluster. See Section 25.6.11,\n“NDB Cluster Disk Data Tables”.",
    "15.1.17 CREATE PROCEDURE and CREATE FUNCTION Statements": "15.1.17 CREATE PROCEDURE and CREATE FUNCTION Statements\nCREATE\n    [DEFINER = user]\n    PROCEDURE [IF NOT EXISTS] sp_name ([proc_parameter[,...]])\n    [characteristic ...] [AS] routine_body\nCREATE\n    [DEFINER = user]\n    FUNCTION [IF NOT EXISTS] sp_name ([func_parameter[,...]])\n    RETURNS type\n    [characteristic ...] routine_body\nproc_parameter:\n    [ IN | OUT | INOUT ] param_name type\nfunc_parameter:\n    param_name type\ntype:\n    Any valid MySQL data type\ncharacteristic: {\n    COMMENT 'string'\n  | LANGUAGE {SQL | JAVASCRIPT }\n  | [NOT] DETERMINISTIC\n  | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }\n  | SQL SECURITY { DEFINER | INVOKER }\n}\nroutine_body:\n    SQL routine or JavaScript statements\nThese statements are used to create a stored routine (a stored procedure or function). That is, the\nspecified routine becomes known to the server. By default, a stored routine is associated with the\ndefault database. To associate the routine explicitly with a given database, specify the name as\ndb_name.sp_name when you create it.\nThe CREATE FUNCTION statement is also used in MySQL to support loadable functions. See\nSection 15.7.4.1, “CREATE FUNCTION Statement for Loadable Functions”. A loadable function can\nbe regarded as an external stored function. Stored functions share their namespace with loadable\nfunctions. See Section 11.2.5, “Function Name Parsing and Resolution”, for the rules describing how\nthe server interprets references to different kinds of functions.\nTo invoke a stored procedure, use the CALL statement (see Section 15.2.1, “CALL Statement”). To\ninvoke a stored function, refer to it in an expression. The function returns a value during expression\nevaluation.\nCREATE PROCEDURE and CREATE FUNCTION require the CREATE ROUTINE privilege. If the\nDEFINER clause is present, the privileges required depend on the user value, as discussed in\nSection 27.7, “Stored Object Access Control”. If binary logging is enabled, CREATE FUNCTION might\nrequire the SUPER privilege, as discussed in Section 27.8, “Stored Program Binary Logging”.\nBy default, MySQL automatically grants the ALTER ROUTINE and EXECUTE privileges to the routine\ncreator. This behavior can be changed by disabling the automatic_sp_privileges system\nvariable. See Section 27.2.2, “Stored Routines and MySQL Privileges”.\nThe DEFINER and SQL SECURITY clauses specify the security context to be used when checking\naccess privileges at routine execution time, as described later in this section.\nIf the routine name is the same as the name of a built-in SQL function, a syntax error occurs unless you\nuse a space between the name and the following parenthesis when defining the routine or invoking it\nlater. For this reason, avoid using the names of existing SQL functions for your own stored routines.\nThe IGNORE_SPACE SQL mode applies to built-in functions, not to stored routines. It is always\npermissible to have spaces after a stored routine name, regardless of whether IGNORE_SPACE is\nenabled.\nIF NOT EXISTS prevents an error from occurring if there already exists a routine with the same\nname. This option is supported with both CREATE FUNCTION and CREATE PROCEDURE.\nIf a built-in function with the same name already exists, attempting to create a stored function with\nCREATE FUNCTION ... IF NOT EXISTS succeeds with a warning indicating that it has the same\nname as a native function; this is no different than when performing the same CREATE FUNCTION\nstatement without specifying IF NOT EXISTS.\nIf a loadable function with the same name already exists, attempting to create a stored function using\nIF NOT EXISTS succeeds with a warning. This is the same as without specifying IF NOT EXISTS.\nSee Function Name Resolution, for more information.\nThe parameter list enclosed within parentheses must always be present. If there are no parameters, an\nempty parameter list of () should be used. Parameter names are not case-sensitive.\nEach parameter is an IN parameter by default. To specify otherwise for a parameter, use the keyword\nOUT or INOUT before the parameter name.\nNote\nSpecifying a parameter as IN, OUT, or INOUT is valid only for a PROCEDURE.\nFor a FUNCTION, parameters are always regarded as IN parameters.\nAn IN parameter passes a value into a procedure. The procedure might modify the value, but the\nmodification is not visible to the caller when the procedure returns. An OUT parameter passes a value\nfrom the procedure back to the caller. Its initial value is NULL within the procedure, and its value is\nvisible to the caller when the procedure returns. An INOUT parameter is initialized by the caller, can\nbe modified by the procedure, and any change made by the procedure is visible to the caller when the\nprocedure returns.\nFor each OUT or INOUT parameter, pass a user-defined variable in the CALL statement that invokes\nthe procedure so that you can obtain its value when the procedure returns. If you are calling the\nprocedure from within another stored procedure or function, you can also pass a routine parameter\nor local routine variable as an OUT or INOUT parameter. If you are calling the procedure from within a\ntrigger, you can also pass NEW.col_name as an OUT or INOUT parameter.\nFor information about the effect of unhandled conditions on procedure parameters, see\nSection 15.6.7.8, “Condition Handling and OUT or INOUT Parameters”.\nRoutine parameters cannot be referenced in statements prepared within the routine; see Section 27.9,\n“Restrictions on Stored Programs”.\nThe following example shows a simple stored procedure that, given a country code, counts the number\nof cities for that country that appear in the city table of the world database. The country code is\npassed using an IN parameter, and the city count is returned using an OUT parameter:\nmysql> delimiter //\nmysql> CREATE PROCEDURE citycount (IN country CHAR(3), OUT cities INT)\n       BEGIN\n         SELECT COUNT(*) INTO cities FROM world.city\n         WHERE CountryCode = country;\n       END//\nQuery OK, 0 rows affected (0.01 sec)\nmysql> delimiter ;\nmysql> CALL citycount('JPN', @cities); -- cities in Japan\nQuery OK, 1 row affected (0.00 sec)\nmysql> SELECT @cities;\n+---------+\n| @cities |\n+---------+\n|     248 |\n+---------+\n1 row in set (0.00 sec)\nmysql> CALL citycount('FRA', @cities); -- cities in France\nQuery OK, 1 row affected (0.00 sec)\nmysql> SELECT @cities;\n+---------+\n| @cities |\n+---------+\n|      40 |\n+---------+\n1 row in set (0.00 sec)\nThe example uses the mysql client delimiter command to change the statement delimiter from ; to\n// while the procedure is being defined. This enables the ; delimiter used in the procedure body to be\npassed through to the server rather than being interpreted by mysql itself. See Section 27.1, “Defining\nStored Programs”.\nThe RETURNS clause may be specified only for a FUNCTION, for which it is mandatory. It indicates\nthe return type of the function, and the function body must contain a RETURN value statement. If\nthe RETURN statement returns a value of a different type, the value is coerced to the proper type.\nFor example, if a function specifies an ENUM or SET value in the RETURNS clause, but the RETURN\nstatement returns an integer, the value returned from the function is the string for the corresponding\nENUM member of set of SET members.\nThe following example function takes a parameter, performs an operation using an SQL function, and\nreturns the result. In this case, it is unnecessary to use delimiter because the function definition\ncontains no internal ; statement delimiters:\nmysql> CREATE FUNCTION hello (s CHAR(20))\n    ->   RETURNS CHAR(50) DETERMINISTIC\n    ->   RETURN CONCAT('Hello, ',s,'!');\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT hello('world');\n+----------------+\n| hello('world') |\n+----------------+\n| Hello, world!  |\n+----------------+\n1 row in set (0.00 sec)\nParameter types and function return types can be declared to use any valid data type. The COLLATE\nattribute can be used if preceded by a CHARACTER SET specification.\nThe routine_body consists of a valid SQL routine statement. This can be a simple statement\nsuch as SELECT or INSERT, or a compound statement written using BEGIN and END. Compound\nstatements can contain declarations, loops, and other control structure statements. The syntax for\nthese statements is described in Section 15.6, “Compound Statement Syntax”. In practice, stored\nfunctions tend to use compound statements, unless the body consists of a single RETURN statement.\nThe AS keyword is used to indicate that the routine body that follows is written in a language other than\nSQL; it immediately precedes the opening dollar-quoted delimiter or quotation mark of the routine body.\nSee Section 27.3, “JavaScript Stored Programs”.\nMySQL permits routines to contain DDL statements, such as CREATE and DROP. MySQL also permits\nstored procedures (but not stored functions) to contain SQL transaction statements such as COMMIT.\nStored functions may not contain statements that perform explicit or implicit commit or rollback. Support\nfor these statements is not required by the SQL standard, which states that each DBMS vendor may\ndecide whether to permit them.\nStatements that return a result set can be used within a stored procedure but not within a stored\nfunction. This prohibition includes SELECT statements that do not have an INTO var_list clause\nand other statements such as SHOW, EXPLAIN, and CHECK TABLE. For statements that can be\ndetermined at function definition time to return a result set, a Not allowed to return a result\nset from a function error occurs (ER_SP_NO_RETSET). For statements that can be determined\nonly at runtime to return a result set, a PROCEDURE %s can't return a result set in the\ngiven context error occurs (ER_SP_BADSELECT).\nUSE statements within stored routines are not permitted. When a routine is invoked, an implicit USE\ndb_name is performed (and undone when the routine terminates). The causes the routine to have the\ngiven default database while it executes. References to objects in databases other than the routine\ndefault database should be qualified with the appropriate database name.\nFor additional information about statements that are not permitted in stored routines, see Section 27.9,\n“Restrictions on Stored Programs”.\nFor information about invoking stored procedures from within programs written in a language that has a\nMySQL interface, see Section 15.2.1, “CALL Statement”.\nMySQL stores the sql_mode system variable setting in effect when a routine is created or altered, and\nalways executes the routine with this setting in force, regardless of the current server SQL mode when\nthe routine begins executing.\nThe switch from the SQL mode of the invoker to that of the routine occurs after evaluation of arguments\nand assignment of the resulting values to routine parameters. If you define a routine in strict SQL mode\nbut invoke it in nonstrict mode, assignment of arguments to routine parameters does not take place in\nstrict mode. If you require that expressions passed to a routine be assigned in strict SQL mode, you\nshould invoke the routine with strict mode in effect.\nThe COMMENT characteristic is a MySQL extension, and may be used to describe the stored routine.\nThis information is displayed by the SHOW CREATE PROCEDURE and SHOW CREATE FUNCTION\nstatements.\nThe LANGUAGE characteristic indicates the language in which the routine is written. The server ignores\nthis characteristic; only SQL routines are supported. If this characteristic is not supplied, the language\nis assumed to be SQL. Stored routines written in JavaScript (see Section 27.3, “JavaScript Stored\nPrograms”) require this to be specified using LANGUAGE JAVASCRIPT.\nA routine is considered “deterministic” if it always produces the same result for the same input\nparameters, and “not deterministic” otherwise. If neither DETERMINISTIC nor NOT DETERMINISTIC\nis given in the routine definition, the default is NOT DETERMINISTIC. To declare that a function is\ndeterministic, you must specify DETERMINISTIC explicitly.\nAssessment of the nature of a routine is based on the “honesty” of the creator: MySQL does not\ncheck that a routine declared DETERMINISTIC is free of statements that produce nondeterministic\nresults. However, misdeclaring a routine might affect results or affect performance. Declaring\na nondeterministic routine as DETERMINISTIC might lead to unexpected results by causing\nthe optimizer to make incorrect execution plan choices. Declaring a deterministic routine as\nNONDETERMINISTIC might diminish performance by causing available optimizations not to be used.\nIf binary logging is enabled, the DETERMINISTIC characteristic affects which routine definitions\nMySQL accepts. See Section 27.8, “Stored Program Binary Logging”.\nA routine that contains the NOW() function (or its synonyms) or RAND() is nondeterministic, but it might\nstill be replication-safe. For NOW(), the binary log includes the timestamp and replicates correctly.\nRAND() also replicates correctly as long as it is called only a single time during the execution of a\nroutine. (You can consider the routine execution timestamp and random number seed as implicit inputs\nthat are identical on the source and replica.)\nSeveral characteristics provide information about the nature of data use by the routine. In MySQL,\nthese characteristics are advisory only. The server does not use them to constrain what kinds of\nstatements a routine is permitted to execute.\n• CONTAINS SQL indicates that the routine does not contain statements that read or write data. This\nis the default if none of these characteristics is given explicitly. Examples of such statements are SET\n@x = 1 or DO RELEASE_LOCK('abc'), which execute but neither read nor write data.\n• NO SQL indicates that the routine contains no SQL statements.\n• READS SQL DATA indicates that the routine contains statements that read data (for example,\nSELECT), but not statements that write data.\n• MODIFIES SQL DATA indicates that the routine contains statements that may write data (for\nexample, INSERT or DELETE).\nThe SQL SECURITY characteristic can be DEFINER or INVOKER to specify the security context; that is,\nwhether the routine executes using the privileges of the account named in the routine DEFINER clause\nor the user who invokes it. This account must have permission to access the database with which\nthe routine is associated. The default value is DEFINER. The user who invokes the routine must have\nthe EXECUTE privilege for it, as must the DEFINER account if the routine executes in definer security\ncontext.\nThe DEFINER clause specifies the MySQL account to be used when checking access privileges at\nroutine execution time for routines that have the SQL SECURITY DEFINER characteristic.\nIf the DEFINER clause is present, the user value should be a MySQL account specified as\n'user_name'@'host_name', CURRENT_USER, or CURRENT_USER(). The permitted user values\ndepend on the privileges you hold, as discussed in Section 27.7, “Stored Object Access Control”. Also\nsee that section for additional information about stored routine security.\nIf the DEFINER clause is omitted, the default definer is the user who executes the CREATE\nPROCEDURE or CREATE FUNCTION statement. This is the same as specifying DEFINER =\nCURRENT_USER explicitly.\nWithin the body of a stored routine that is defined with the SQL SECURITY DEFINER characteristic,\nthe CURRENT_USER function returns the routine's DEFINER value. For information about user auditing\nwithin stored routines, see Section 8.2.23, “SQL-Based Account Activity Auditing”.\nConsider the following procedure, which displays a count of the number of MySQL accounts listed in\nthe mysql.user system table:\nCREATE DEFINER = 'admin'@'localhost' PROCEDURE account_count()\nBEGIN\n  SELECT 'Number of accounts:', COUNT(*) FROM mysql.user;\nEND;\nThe procedure is assigned a DEFINER account of 'admin'@'localhost' no matter which user\ndefines it. It executes with the privileges of that account no matter which user invokes it (because the\ndefault security characteristic is DEFINER). The procedure succeeds or fails depending on whether\ninvoker has the EXECUTE privilege for it and 'admin'@'localhost' has the SELECT privilege for the\nmysql.user table.\nNow suppose that the procedure is defined with the SQL SECURITY INVOKER characteristic:\nCREATE DEFINER = 'admin'@'localhost' PROCEDURE account_count()\nSQL SECURITY INVOKER\nBEGIN\n  SELECT 'Number of accounts:', COUNT(*) FROM mysql.user;\nEND;\nThe procedure still has a DEFINER of 'admin'@'localhost', but in this case, it executes with\nthe privileges of the invoking user. Thus, the procedure succeeds or fails depending on whether the\ninvoker has the EXECUTE privilege for it and the SELECT privilege for the mysql.user table.\nBy default, when a routine with the SQL SECURITY DEFINER characteristic is executed, MySQL\nServer does not set any active roles for the MySQL account named in the DEFINER clause, only the\ndefault roles. The exception is if the activate_all_roles_on_login system variable is enabled, in\nwhich case MySQL Server sets all roles granted to the DEFINER user, including mandatory roles. Any\nprivileges granted through roles are therefore not checked by default when the CREATE PROCEDURE\nor CREATE FUNCTION statement is issued. For stored programs, if execution should occur with roles\ndifferent from the default, the program body can execute SET ROLE to activate the required roles. This\nmust be done with caution since the privileges assigned to roles can be changed.\nThe server handles the data type of a routine parameter, local routine variable created with DECLARE,\nor function return value as follows:\n• Assignments are checked for data type mismatches and overflow. Conversion and overflow\nproblems result in warnings, or errors in strict SQL mode.\n• Only scalar values can be assigned. For example, a statement such as SET x = (SELECT 1, 2)\nis invalid.\n• For character data types, if CHARACTER SET is included in the declaration, the specified character\nset and its default collation is used. If the COLLATE attribute is also present, that collation is used\nrather than the default collation.\nIf CHARACTER SET and COLLATE are not present, the database character set and collation in\neffect at routine creation time are used. To avoid having the server use the database character\nset and collation, provide an explicit CHARACTER SET and a COLLATE attribute for character data\nparameters.\nIf you alter the database default character set or collation, stored routines that are to use the new\ndatabase defaults must be dropped and recreated.\nThe database character set and collation are given by the value of the character_set_database\nand collation_database system variables. For more information, see Section 12.3.3, “Database\nCharacter Set and Collation”.",
    "15.1.18 CREATE SERVER Statement": "15.1.18 CREATE SERVER Statement\nCREATE SERVER server_name\n    FOREIGN DATA WRAPPER wrapper_name\n    OPTIONS (option [, option] ...)\noption: {\n    HOST character-literal\n  | DATABASE character-literal\n  | USER character-literal\n  | PASSWORD character-literal\n  | SOCKET character-literal\n  | OWNER character-literal\n  | PORT numeric-literal\n}\nThis statement creates the definition of a server for use with the FEDERATED storage engine. The\nCREATE SERVER statement creates a new row in the servers table in the mysql database. This\nstatement requires the SUPER privilege.\nThe server_name should be a unique reference to the server. Server definitions are global within\nthe scope of the server, it is not possible to qualify the server definition to a specific database.\nserver_name has a maximum length of 64 characters (names longer than 64 characters are silently\ntruncated), and is case-insensitive. You may specify the name as a quoted string.\nThe wrapper_name is an identifier and may be quoted with single quotation marks.\nFor each option you must specify either a character literal or numeric literal. Character literals are\nUTF-8, support a maximum length of 64 characters and default to a blank (empty) string. String literals\nare silently truncated to 64 characters. Numeric literals must be a number between 0 and 9999, default\nvalue is 0.\nNote\nThe OWNER option is currently not applied, and has no effect on the ownership\nor operation of the server connection that is created.\nThe CREATE SERVER statement creates an entry in the mysql.servers table that can later be used\nwith the CREATE TABLE statement when creating a FEDERATED table. The options that you specify\nare used to populate the columns in the mysql.servers table. The table columns are Server_name,\nHost, Db, Username, Password, Port and Socket.\nFor example:\nCREATE SERVER s\nFOREIGN DATA WRAPPER mysql\nOPTIONS (USER 'Remote', HOST '198.51.100.106', DATABASE 'test');\nBe sure to specify all options necessary to establish a connection to the server. The user name, host\nname, and database name are mandatory. Other options might be required as well, such as password.\nThe data stored in the table can be used when creating a connection to a FEDERATED table:\nCREATE TABLE t (s1 INT) ENGINE=FEDERATED CONNECTION='s';\nFor more information, see Section 18.8, “The FEDERATED Storage Engine”.\nCREATE SERVER causes an implicit commit. See Section 15.3.3, “Statements That Cause an Implicit\nCommit”.\nCREATE SERVER is not written to the binary log, regardless of the logging format that is in use.",
    "15.1.19 CREATE SPATIAL REFERENCE SYSTEM Statement": "15.1.19 CREATE SPATIAL REFERENCE SYSTEM Statement\nCREATE OR REPLACE SPATIAL REFERENCE SYSTEM\n    srid srs_attribute ...\nCREATE SPATIAL REFERENCE SYSTEM\n    [IF NOT EXISTS]\n    srid srs_attribute ...\nsrs_attribute: {\n    NAME 'srs_name'\n  | DEFINITION 'definition'\n  | ORGANIZATION 'org_name' IDENTIFIED BY org_id\n  | DESCRIPTION 'description'\n}\nsrid, org_id: 32-bit unsigned integer\nThis statement creates a spatial reference system (SRS) definition and stores it in the data dictionary.\nIt requires the SUPER privilege. The resulting data dictionary entry can be inspected using the\nINFORMATION_SCHEMA ST_SPATIAL_REFERENCE_SYSTEMS table.\nSRID values must be unique, so if neither OR REPLACE nor IF NOT EXISTS is specified, an error\noccurs if an SRS definition with the given srid value already exists.\nWith CREATE OR REPLACE syntax, any existing SRS definition with the same SRID value is replaced,\nunless the SRID value is used by some column in an existing table. In that case, an error occurs. For\nexample:\nmysql> CREATE OR REPLACE SPATIAL REFERENCE SYSTEM 4326 ...;\nERROR 3716 (SR005): Can't modify SRID 4326. There is at\nleast one column depending on it.\nTo identify which column or columns use the SRID, use this query, replacing 4326 with the SRID of the\ndefinition you are trying to create:\nSELECT * FROM INFORMATION_SCHEMA.ST_GEOMETRY_COLUMNS WHERE SRS_ID=4326;\nWith CREATE ... IF NOT EXISTS syntax, any existing SRS definition with the same SRID value\ncauses the new definition to be ignored and a warning occurs.\nSRID values must be in the range of 32-bit unsigned integers, with these restrictions:\n• SRID 0 is a valid SRID but cannot be used with CREATE SPATIAL REFERENCE SYSTEM.\n• If the value is in a reserved SRID range, a warning occurs. Reserved ranges are [0, 32767] (reserved\nby EPSG), [60,000,000, 69,999,999] (reserved by EPSG), and [2,000,000,000, 2,147,483,647]\n(reserved by MySQL). EPSG stands for the European Petroleum Survey Group.\n• Users should not create SRSs with SRIDs in the reserved ranges. Doing so runs the risk of the\nSRIDs conflicting with future SRS definitions distributed with MySQL, with the result that the new\nsystem-provided SRSs are not installed for MySQL upgrades or that the user-defined SRSs are\noverwritten.\nAttributes for the statement must satisfy these conditions:\n• Attributes can be given in any order, but no attribute can be given more than once.\n• The NAME and DEFINITION attributes are mandatory.\n• The NAME srs_name attribute value must be unique. The combination of the ORGANIZATION\norg_name and org_id attribute values must be unique.\n• The NAME srs_name attribute value and ORGANIZATION org_name attribute value cannot be\nempty or begin or end with whitespace.\n• String values in attribute specifications cannot contain control characters, including newline.\n• The following table shows the maximum lengths for string attribute values.\nTable 15.6 CREATE SPATIAL REFERENCE SYSTEM Attribute Lengths\nAttribute\nMaximum Length (characters)\nNAME\n80\nDEFINITION\n4096\nORGANIZATION\n256\nDESCRIPTION\n2048\nHere is an example CREATE SPATIAL REFERENCE SYSTEM statement. The DEFINITION value is\nreformatted across multiple lines for readability. (For the statement to be legal, the value actually must\nbe given on a single line.)\nCREATE SPATIAL REFERENCE SYSTEM 4120\nNAME 'Greek'\nORGANIZATION 'EPSG' IDENTIFIED BY 4120\nDEFINITION\n  'GEOGCS[\"Greek\",DATUM[\"Greek\",SPHEROID[\"Bessel 1841\",\n  6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],\n  AUTHORITY[\"EPSG\",\"6120\"]],PRIMEM[\"Greenwich\",0,\n  AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.017453292519943278,\n  AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Lat\",NORTH],AXIS[\"Lon\",EAST],\n  AUTHORITY[\"EPSG\",\"4120\"]]';\nThe grammar for SRS definitions is based on the grammar defined in OpenGIS Implementation\nSpecification: Coordinate Transformation Services, Revision 1.00, OGC 01-009, January 12, 2001,\nSection 7.2. This specification is available at http://www.opengeospatial.org/standards/ct.\nMySQL incorporates these changes to the specification:\n• Only the <horz cs> production rule is implemented (that is, geographic and projected SRSs).\n• There is an optional, nonstandard <authority> clause for <parameter>. This makes it possible\nto recognize projection parameters by authority instead of name.\n• The specification does not make AXIS clauses mandatory in GEOGCS spatial reference system\ndefinitions. However, if there are no AXIS clauses, MySQL cannot determine whether a definition\nhas axes in latitude-longitude order or longitude-latitude order. MySQL enforces the nonstandard\nrequirement that each GEOGCS definition must include two AXIS clauses. One must be NORTH or\nSOUTH, and the other EAST or WEST. The AXIS clause order determines whether the definition has\naxes in latitude-longitude order or longitude-latitude order.\n• SRS definitions may not contain newlines.\nIf an SRS definition specifies an authority code for the projection (which is recommended), an error\noccurs if the definition is missing mandatory parameters. In this case, the error message indicates what\nthe problem is. The projection methods and mandatory parameters that MySQL supports are shown\nin Table 15.7, “Supported Spatial Reference System Projection Methods” and Table 15.8, “Spatial\nReference System Projection Parameters”.\nThe following table shows the projection methods that MySQL supports. MySQL permits unknown\nprojection methods but cannot check the definition for mandatory parameters and cannot convert\nspatial data to or from an unknown projection. For detailed explanations of how each projection works,\nincluding formulas, see EPSG Guidance Note 7-2.\nTable 15.7 Supported Spatial Reference System Projection Methods\nEPSG Code\nProjection Name\nMandatory Parameters (EPSG\nCodes)\n1024\nPopular Visualisation Pseudo\nMercator\n8801, 8802, 8806, 8807\n1027\nLambert Azimuthal Equal Area\n(Spherical)\n8801, 8802, 8806, 8807\n1028\nEquidistant Cylindrical\n8823, 8802, 8806, 8807\n1029\nEquidistant Cylindrical\n(Spherical)\n8823, 8802, 8806, 8807\n1041\nKrovak (North Orientated)\n8811, 8833, 1036, 8818, 8819,\n8806, 8807\n1042\nKrovak Modified\n8811, 8833, 1036, 8818, 8819,\n8806, 8807, 8617, 8618, 1026,\n1027, 1028, 1029, 1030, 1031,\n1032, 1033, 1034, 1035\n1043\nKrovak Modified (North\nOrientated)\n8811, 8833, 1036, 8818, 8819,\n8806, 8807, 8617, 8618, 1026,\nEPSG Code\nProjection Name\nMandatory Parameters (EPSG\nCodes)\n1027, 1028, 1029, 1030, 1031,\n1032, 1033, 1034, 1035\n1051\nLambert Conic Conformal (2SP\nMichigan)\n8821, 8822, 8823, 8824, 8826,\n8827, 1038\n1052\nColombia Urban\n8801, 8802, 8806, 8807, 1039\n9801\nLambert Conic Conformal (1SP)\n8801, 8802, 8805, 8806, 8807\n9802\nLambert Conic Conformal (2SP)\n8821, 8822, 8823, 8824, 8826,\n8827\n9803\nLambert Conic Conformal (2SP\nBelgium)\n8821, 8822, 8823, 8824, 8826,\n8827\n9804\nMercator (variant A)\n8801, 8802, 8805, 8806, 8807\n9805\nMercator (variant B)\n8823, 8802, 8806, 8807\n9806\nCassini-Soldner\n8801, 8802, 8806, 8807\n9807\nTransverse Mercator\n8801, 8802, 8805, 8806, 8807\n9808\nTransverse Mercator (South\nOrientated)\n8801, 8802, 8805, 8806, 8807\n9809\nOblique Stereographic\n8801, 8802, 8805, 8806, 8807\n9810\nPolar Stereographic (variant A)\n8801, 8802, 8805, 8806, 8807\n9811\nNew Zealand Map Grid\n8801, 8802, 8806, 8807\n9812\nHotine Oblique Mercator (variant\nA)\n8811, 8812, 8813, 8814, 8815,\n8806, 8807\n9813\nLaborde Oblique Mercator\n8811, 8812, 8813, 8815, 8806,\n8807\n9815\nHotine Oblique Mercator (variant\nB)\n8811, 8812, 8813, 8814, 8815,\n8816, 8817\n9816\nTunisia Mining Grid\n8821, 8822, 8826, 8827\n9817\nLambert Conic Near-Conformal\n8801, 8802, 8805, 8806, 8807\n9818\nAmerican Polyconic\n8801, 8802, 8806, 8807\n9819\nKrovak\n8811, 8833, 1036, 8818, 8819,\n8806, 8807\n9820\nLambert Azimuthal Equal Area\n8801, 8802, 8806, 8807\n9822\nAlbers Equal Area\n8821, 8822, 8823, 8824, 8826,\n8827\n9824\nTransverse Mercator Zoned Grid\nSystem\n8801, 8830, 8831, 8805, 8806,\n8807\n9826\nLambert Conic Conformal (West\nOrientated)\n8801, 8802, 8805, 8806, 8807\n9828\nBonne (South Orientated)\n8801, 8802, 8806, 8807\n9829\nPolar Stereographic (variant B)\n8832, 8833, 8806, 8807\n9830\nPolar Stereographic (variant C)\n8832, 8833, 8826, 8827\n9831\nGuam Projection\n8801, 8802, 8806, 8807\n9832\nModified Azimuthal Equidistant\n8801, 8802, 8806, 8807\n9833\nHyperbolic Cassini-Soldner\n8801, 8802, 8806, 8807\nEPSG Code\nProjection Name\nMandatory Parameters (EPSG\nCodes)\n9834\nLambert Cylindrical Equal Area\n(Spherical)\n8823, 8802, 8806, 8807\n9835\nLambert Cylindrical Equal Area\n8823, 8802, 8806, 8807\nThe following table shows the projection parameters that MySQL recognizes. Recognition occurs\nprimarily by authority code. If there is no authority code, MySQL falls back to case-insensitive string\nmatching on the parameter name. For details about each parameter, look it up by code in the EPSG\nOnline Registry.\nTable 15.8 Spatial Reference System Projection Parameters\nEPSG Code\nFallback Name (Recognized by\nMySQL)\nEPSG Name\n1026\nc1\nC1\n1027\nc2\nC2\n1028\nc3\nC3\n1029\nc4\nC4\n1030\nc5\nC5\n1031\nc6\nC6\n1032\nc7\nC7\n1033\nc8\nC8\n1034\nc9\nC9\n1035\nc10\nC10\n1036\nazimuth\nCo-latitude of cone axis\n1038\nellipsoid_scale_factor\nEllipsoid scaling factor\n1039\nprojection_plane_height_at_origin Projection plane origin height\n8617\nevaluation_point_ordinate_1\nOrdinate 1 of evaluation point\n8618\nevaluation_point_ordinate_2\nOrdinate 2 of evaluation point\n8801\nlatitude_of_origin\nLatitude of natural origin\n8802\ncentral_meridian\nLongitude of natural origin\n8805\nscale_factor\nScale factor at natural origin\n8806\nfalse_easting\nFalse easting\n8807\nfalse_northing\nFalse northing\n8811\nlatitude_of_center\nLatitude of projection centre\n8812\nlongitude_of_center\nLongitude of projection centre\n8813\nazimuth\nAzimuth of initial line\n8814\nrectified_grid_angle\nAngle from Rectified to Skew\nGrid\n8815\nscale_factor\nScale factor on initial line\n8816\nfalse_easting\nEasting at projection centre\n8817\nfalse_northing\nNorthing at projection centre\n8818\npseudo_standard_parallel_1\nLatitude of pseudo standard\nparallel\n8819\nscale_factor\nScale factor on pseudo standard\nparallel\nEPSG Code\nFallback Name (Recognized by\nMySQL)\nEPSG Name\n8821\nlatitude_of_origin\nLatitude of false origin\n8822\ncentral_meridian\nLongitude of false origin\n8823\nstandard_parallel_1,\nstandard_parallel1\nLatitude of 1st standard parallel\n8824\nstandard_parallel_2,\nstandard_parallel2\nLatitude of 2nd standard parallel\n8826\nfalse_easting\nEasting at false origin\n8827\nfalse_northing\nNorthing at false origin\n8830\ninitial_longitude\nInitial longitude\n8831\nzone_width\nZone width\n8832\nstandard_parallel\nLatitude of standard parallel\n8833\nlongitude_of_center\nLongitude of origin",
    "15.1.20 CREATE TABLE Statement": "15.1.20 CREATE TABLE Statement\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    (create_definition,...)\n    [table_options]\n    [partition_options]\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    [(create_definition,...)]\n    [table_options]\n    [partition_options]\n    [IGNORE | REPLACE]\n    [AS] query_expression\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    { LIKE old_tbl_name | (LIKE old_tbl_name) }\ncreate_definition: {\n    col_name column_definition\n  | {INDEX | KEY} [index_name] [index_type] (key_part,...)\n      [index_option] ...\n  | {FULLTEXT | SPATIAL} [INDEX | KEY] [index_name] (key_part,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] PRIMARY KEY\n      [index_type] (key_part,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] UNIQUE [INDEX | KEY]\n      [index_name] [index_type] (key_part,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] FOREIGN KEY\n      [index_name] (col_name,...)\n      reference_definition\n  | check_constraint_definition\n}\ncolumn_definition: {\n    data_type [NOT NULL | NULL] [DEFAULT {literal | (expr)} ]\n      [VISIBLE | INVISIBLE]\n      [AUTO_INCREMENT] [UNIQUE [KEY]] [[PRIMARY] KEY]\n      [COMMENT 'string']\n      [COLLATE collation_name]\n      [COLUMN_FORMAT {FIXED | DYNAMIC | DEFAULT}]\n      [ENGINE_ATTRIBUTE [=] 'string']\n      [SECONDARY_ENGINE_ATTRIBUTE [=] 'string']\n      [STORAGE {DISK | MEMORY}]\n      [reference_definition]\n      [check_constraint_definition]\n  | data_type\n      [COLLATE collation_name]\n      [GENERATED ALWAYS] AS (expr)\n      [VIRTUAL | STORED] [NOT NULL | NULL]\n      [VISIBLE | INVISIBLE]\n      [UNIQUE [KEY]] [[PRIMARY] KEY]\n      [COMMENT 'string']\n      [reference_definition]\n      [check_constraint_definition]\n}\ndata_type:\n    (see Chapter 13, Data Types)\nkey_part: {col_name [(length)] | (expr)} [ASC | DESC]\nindex_type:\n    USING {BTREE | HASH}\nindex_option: {\n    KEY_BLOCK_SIZE [=] value\n  | index_type\n  | WITH PARSER parser_name\n  | COMMENT 'string'\n  | {VISIBLE | INVISIBLE}\n  |ENGINE_ATTRIBUTE [=] 'string'\n  |SECONDARY_ENGINE_ATTRIBUTE [=] 'string'\n}\ncheck_constraint_definition:\n    [CONSTRAINT [symbol]] CHECK (expr) [[NOT] ENFORCED]\nreference_definition:\n    REFERENCES tbl_name (key_part,...)\n      [MATCH FULL | MATCH PARTIAL | MATCH SIMPLE]\n      [ON DELETE reference_option]\n      [ON UPDATE reference_option]\nreference_option:\n    RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT\ntable_options:\n    table_option [[,] table_option] ...\ntable_option: {\n    AUTOEXTEND_SIZE [=] value\n  | AUTO_INCREMENT [=] value\n  | AVG_ROW_LENGTH [=] value\n  | [DEFAULT] CHARACTER SET [=] charset_name\n  | CHECKSUM [=] {0 | 1}\n  | [DEFAULT] COLLATE [=] collation_name\n  | COMMENT [=] 'string'\n  | COMPRESSION [=] {'ZLIB' | 'LZ4' | 'NONE'}\n  | CONNECTION [=] 'connect_string'\n  | {DATA | INDEX} DIRECTORY [=] 'absolute path to directory'\n  | DELAY_KEY_WRITE [=] {0 | 1}\n  | ENCRYPTION [=] {'Y' | 'N'}\n  | ENGINE [=] engine_name\n  | ENGINE_ATTRIBUTE [=] 'string'\n  | INSERT_METHOD [=] { NO | FIRST | LAST }\n  | KEY_BLOCK_SIZE [=] value\n  | MAX_ROWS [=] value\n  | MIN_ROWS [=] value\n  | PACK_KEYS [=] {0 | 1 | DEFAULT}\n  | PASSWORD [=] 'string'\n  | ROW_FORMAT [=] {DEFAULT | DYNAMIC | FIXED | COMPRESSED | REDUNDANT | COMPACT}\n  | START TRANSACTION \n  | SECONDARY_ENGINE_ATTRIBUTE [=] 'string'\n  | STATS_AUTO_RECALC [=] {DEFAULT | 0 | 1}\n  | STATS_PERSISTENT [=] {DEFAULT | 0 | 1}\n  | STATS_SAMPLE_PAGES [=] value\n  | tablespace_option\n  | UNION [=] (tbl_name[,tbl_name]...)\n}\npartition_options:\n    PARTITION BY\n        { [LINEAR] HASH(expr)\n        | [LINEAR] KEY [ALGORITHM={1 | 2}] (column_list)\n        | RANGE{(expr) | COLUMNS(column_list)}\n        | LIST{(expr) | COLUMNS(column_list)} }\n    [PARTITIONS num]\n    [SUBPARTITION BY\n        { [LINEAR] HASH(expr)\n        | [LINEAR] KEY [ALGORITHM={1 | 2}] (column_list) }\n      [SUBPARTITIONS num]\n    ]\n    [(partition_definition [, partition_definition] ...)]\npartition_definition:\n    PARTITION partition_name\n        [VALUES\n            {LESS THAN {(expr | value_list) | MAXVALUE}\n            |\n            IN (value_list)}]\n        [[STORAGE] ENGINE [=] engine_name]\n        [COMMENT [=] 'string' ]\n        [DATA DIRECTORY [=] 'data_dir']\n        [INDEX DIRECTORY [=] 'index_dir']\n        [MAX_ROWS [=] max_number_of_rows]\n        [MIN_ROWS [=] min_number_of_rows]\n        [TABLESPACE [=] tablespace_name]\n        [(subpartition_definition [, subpartition_definition] ...)]\nsubpartition_definition:\n    SUBPARTITION logical_name\n        [[STORAGE] ENGINE [=] engine_name]\n        [COMMENT [=] 'string' ]\n        [DATA DIRECTORY [=] 'data_dir']\n        [INDEX DIRECTORY [=] 'index_dir']\n        [MAX_ROWS [=] max_number_of_rows]\n        [MIN_ROWS [=] min_number_of_rows]\n        [TABLESPACE [=] tablespace_name]\ntablespace_option:\n    TABLESPACE tablespace_name [STORAGE DISK]\n  | [TABLESPACE tablespace_name] STORAGE MEMORY\nquery_expression:\n    SELECT ...   (Some valid select or union statement)\nCREATE TABLE creates a table with the given name. You must have the CREATE privilege for the\ntable.\nBy default, tables are created in the default database, using the InnoDB storage engine. An error\noccurs if the table exists, if there is no default database, or if the database does not exist.\nMySQL has no limit on the number of tables. The underlying file system may have a limit on the\nnumber of files that represent tables. Individual storage engines may impose engine-specific\nconstraints. InnoDB permits up to 4 billion tables.\nFor information about the physical representation of a table, see Section 15.1.20.1, “Files Created by\nCREATE TABLE”.\nThere are several aspects to the CREATE TABLE statement, described under the following topics in\nthis section:\n• Table Name\n• Temporary Tables\n• Table Cloning and Copying\n• Column Data Types and Attributes\n• Indexes, Foreign Keys, and CHECK Constraints\n• Table Options\n• Table Partitioning\nTable Name\n• tbl_name\nThe table name can be specified as db_name.tbl_name to create the table in a specific database.\nThis works regardless of whether there is a default database, assuming that the database exists.\nIf you use quoted identifiers, quote the database and table names separately. For example, write\n`mydb`.`mytbl`, not `mydb.mytbl`.\nRules for permissible table names are given in Section 11.2, “Schema Object Names”.\n• IF NOT EXISTS\nPrevents an error from occurring if the table exists. However, there is no verification that the existing\ntable has a structure identical to that indicated by the CREATE TABLE statement.\nTemporary Tables\nYou can use the TEMPORARY keyword when creating a table. A TEMPORARY table is visible only within\nthe current session, and is dropped automatically when the session is closed. For more information,\nsee Section 15.1.20.2, “CREATE TEMPORARY TABLE Statement”.\nTable Cloning and Copying\n• LIKE\nUse CREATE TABLE ... LIKE to create an empty table based on the definition of another table,\nincluding any column attributes and indexes defined in the original table:\nCREATE TABLE new_tbl LIKE orig_tbl;\nFor more information, see Section 15.1.20.3, “CREATE TABLE ... LIKE Statement”.\n• [AS] query_expression\nTo create one table from another, add a SELECT statement at the end of the CREATE TABLE\nstatement:\nCREATE TABLE new_tbl AS SELECT * FROM orig_tbl;\nFor more information, see Section 15.1.20.4, “CREATE TABLE ... SELECT Statement”.\n• IGNORE | REPLACE\nThe IGNORE and REPLACE options indicate how to handle rows that duplicate unique key values\nwhen copying a table using a SELECT statement.\nFor more information, see Section 15.1.20.4, “CREATE TABLE ... SELECT Statement”.\nColumn Data Types and Attributes\nThere is a hard limit of 4096 columns per table, but the effective maximum may be less for a given\ntable and depends on the factors discussed in Section 10.4.7, “Limits on Table Column Count and Row\nSize”.\n• data_type\ndata_type represents the data type in a column definition. For a full description of the syntax\navailable for specifying column data types, as well as information about the properties of each type,\nsee Chapter 13, Data Types.\n• AUTO_INCREMENT applies only to integer types.\n• Character data types (CHAR, VARCHAR, the TEXT types, ENUM, SET, and any synonyms) can\ninclude CHARACTER SET to specify the character set for the column. CHARSET is a synonym for\nCHARACTER SET. A collation for the character set can be specified with the COLLATE attribute,\nalong with any other attributes. For details, see Chapter 12, Character Sets, Collations, Unicode.\nExample:\nCREATE TABLE t (c CHAR(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin);\nMySQL 9.1 interprets length specifications in character column definitions in characters. Lengths\nfor BINARY and VARBINARY are in bytes.\n• For CHAR, VARCHAR, BINARY, and VARBINARY columns, indexes can be created that use only the\nleading part of column values, using col_name(length) syntax to specify an index prefix length.\nBLOB and TEXT columns also can be indexed, but a prefix length must be given. Prefix lengths are\ngiven in characters for nonbinary string types and in bytes for binary string types. That is, index\nentries consist of the first length characters of each column value for CHAR, VARCHAR, and TEXT\ncolumns, and the first length bytes of each column value for BINARY, VARBINARY, and BLOB\ncolumns. Indexing only a prefix of column values like this can make the index file much smaller.\nFor additional information about index prefixes, see Section 15.1.15, “CREATE INDEX Statement”.\nOnly the InnoDB and MyISAM storage engines support indexing on BLOB and TEXT columns. For\nexample:\nCREATE TABLE test (blob_col BLOB, INDEX(blob_col(10)));\nIf a specified index prefix exceeds the maximum column data type size, CREATE TABLE handles\nthe index as follows:\n• For a nonunique index, either an error occurs (if strict SQL mode is enabled), or the index length\nis reduced to lie within the maximum column data type size and a warning is produced (if strict\nSQL mode is not enabled).\n• For a unique index, an error occurs regardless of SQL mode because reducing the index\nlength might enable insertion of nonunique entries that do not meet the specified uniqueness\nrequirement.\n• JSON columns cannot be indexed. You can work around this restriction by creating an index on a\ngenerated column that extracts a scalar value from the JSON column. See Indexing a Generated\nColumn to Provide a JSON Column Index, for a detailed example.\n• NOT NULL | NULL\nIf neither NULL nor NOT NULL is specified, the column is treated as though NULL had been\nspecified.\nIn MySQL 9.1, only the InnoDB, MyISAM, and MEMORY storage engines support indexes on columns\nthat can have NULL values. In other cases, you must declare indexed columns as NOT NULL or an\nerror results.\n• DEFAULT\nSpecifies a default value for a column. For more information about default value handling, including\nthe case that a column definition includes no explicit DEFAULT value, see Section 13.6, “Data Type\nDefault Values”.\nIf the NO_ZERO_DATE or NO_ZERO_IN_DATE SQL mode is enabled and a date-valued default is\nnot correct according to that mode, CREATE TABLE produces a warning if strict SQL mode is not\nenabled and an error if strict mode is enabled. For example, with NO_ZERO_IN_DATE enabled, c1\nDATE DEFAULT '2010-00-00' produces a warning.\n• VISIBLE, INVISIBLE\nSpecify column visibility. The default is VISIBLE if neither keyword is present. A table must have\nat least one visible column. Attempting to make all columns invisible produces an error. For more\ninformation, see Section 15.1.20.10, “Invisible Columns”.\n• AUTO_INCREMENT\nAn integer column can have the additional attribute AUTO_INCREMENT. When you insert a value of\nNULL (recommended) or 0 into an indexed AUTO_INCREMENT column, the column is set to the next\nsequence value. Typically this is value+1, where value is the largest value for the column currently\nin the table. AUTO_INCREMENT sequences begin with 1.\nTo retrieve an AUTO_INCREMENT value after inserting a row, use the LAST_INSERT_ID() SQL\nfunction or the mysql_insert_id() C API function. See Section 14.15, “Information Functions”,\nand mysql_insert_id().\nIf the NO_AUTO_VALUE_ON_ZERO SQL mode is enabled, you can store 0 in AUTO_INCREMENT\ncolumns as 0 without generating a new sequence value. See Section 7.1.11, “Server SQL Modes”.\nThere can be only one AUTO_INCREMENT column per table, it must be indexed, and it cannot have a\nDEFAULT value. An AUTO_INCREMENT column works properly only if it contains only positive values.\nInserting a negative number is regarded as inserting a very large positive number. This is done to\navoid precision problems when numbers “wrap” over from positive to negative and also to ensure\nthat you do not accidentally get an AUTO_INCREMENT column that contains 0.\nFor MyISAM tables, you can specify an AUTO_INCREMENT secondary column in a multiple-column\nkey. See Section 5.6.9, “Using AUTO_INCREMENT”.\nTo make MySQL compatible with some ODBC applications, you can find the AUTO_INCREMENT\nvalue for the last inserted row with the following query:\nSELECT * FROM tbl_name WHERE auto_col IS NULL\nThis method requires that sql_auto_is_null variable is not set to 0. See Section 7.1.8, “Server\nSystem Variables”.\nFor information about InnoDB and AUTO_INCREMENT, see Section 17.6.1.6, “AUTO_INCREMENT\nHandling in InnoDB”. For information about AUTO_INCREMENT and MySQL Replication, see\nSection 19.5.1.1, “Replication and AUTO_INCREMENT”.\n• COMMENT\nA comment for a column can be specified with the COMMENT option, up to 1024 characters long. The\ncomment is displayed by the SHOW CREATE TABLE and SHOW FULL COLUMNS statements. It is\nalso shown in the COLUMN_COMMENT column of the Information Schema COLUMNS table.\n• COLUMN_FORMAT\nIn NDB Cluster, it is also possible to specify a data storage format for individual columns of NDB\ntables using COLUMN_FORMAT. Permissible column formats are FIXED, DYNAMIC, and DEFAULT.\nFIXED is used to specify fixed-width storage, DYNAMIC permits the column to be variable-width,\nand DEFAULT causes the column to use fixed-width or variable-width storage as determined by the\ncolumn's data type (possibly overridden by a ROW_FORMAT specifier).\nFor NDB tables, the default value for COLUMN_FORMAT is FIXED.\nIn NDB Cluster, the maximum possible offset for a column defined with COLUMN_FORMAT=FIXED\nis 8188 bytes. For more information and possible workarounds, see Section 25.2.7.5, “Limits\nAssociated with Database Objects in NDB Cluster”.\nCOLUMN_FORMAT currently has no effect on columns of tables using storage engines other than NDB.\nMySQL 9.1 silently ignores COLUMN_FORMAT.\n• ENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE options are used to specify column\nattributes for primary and secondary storage engines. The options are reserved for future use.\nThe value assigned to this option is a string literal containing a valid JSON document or an empty\nstring (''). Invalid JSON is rejected.\nCREATE TABLE t1 (c1 INT ENGINE_ATTRIBUTE='{\"key\":\"value\"}');\nENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE values can be repeated without error.\nIn this case, the last specified value is used.\nENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE values are not checked by the server,\nnor are they cleared when the table's storage engine is changed.\n• STORAGE\nFor NDB tables, it is possible to specify whether the column is stored on disk or in memory by using\na STORAGE clause. STORAGE DISK causes the column to be stored on disk, and STORAGE MEMORY\ncauses in-memory storage to be used. The CREATE TABLE statement used must still include a\nTABLESPACE clause:\nmysql> CREATE TABLE t1 (\n    ->     c1 INT STORAGE DISK,\n    ->     c2 INT STORAGE MEMORY\n    -> ) ENGINE NDB;\nERROR 1005 (HY000): Can't create table 'c.t1' (errno: 140)\nmysql> CREATE TABLE t1 (\n    ->     c1 INT STORAGE DISK,\n    ->     c2 INT STORAGE MEMORY\n    -> ) TABLESPACE ts_1 ENGINE NDB;\nQuery OK, 0 rows affected (1.06 sec)\nFor NDB tables, STORAGE DEFAULT is equivalent to STORAGE MEMORY.\nThe STORAGE clause has no effect on tables using storage engines other than NDB. The STORAGE\nkeyword is supported only in the build of mysqld that is supplied with NDB Cluster; it is not\nrecognized in any other version of MySQL, where any attempt to use the STORAGE keyword causes\na syntax error.\n• GENERATED ALWAYS\nUsed to specify a generated column expression. For information about generated columns, see\nSection 15.1.20.8, “CREATE TABLE and Generated Columns”.\nStored generated columns can be indexed. InnoDB supports secondary indexes on virtual\ngenerated columns. See Section 15.1.20.9, “Secondary Indexes and Generated Columns”.\nIndexes, Foreign Keys, and CHECK Constraints\nSeveral keywords apply to creation of indexes, foreign keys, and CHECK constraints. For general\nbackground in addition to the following descriptions, see Section 15.1.15, “CREATE INDEX\nStatement”, Section 15.1.20.5, “FOREIGN KEY Constraints”, and Section 15.1.20.6, “CHECK\nConstraints”.\n• CONSTRAINT symbol\nThe CONSTRAINT symbol clause may be given to name a constraint. If the clause is not given,\nor a symbol is not included following the CONSTRAINT keyword, MySQL automatically generates\na constraint name, with the exception noted below. The symbol value, if used, must be unique\nper schema (database), per constraint type. A duplicate symbol results in an error. See also the\ndiscussion about length limits of generated constraint identifiers at Section 11.2.1, “Identifier Length\nLimits”.\nNote\nIf the CONSTRAINT symbol clause is not given in a foreign key definition,\nor a symbol is not included following the CONSTRAINT keyword, MySQL\nautomatically generates a constraint name.\nThe SQL standard specifies that all types of constraints (primary key, unique index, foreign key,\ncheck) belong to the same namespace. In MySQL, each constraint type has its own namespace\nper schema. Consequently, names for each type of constraint must be unique per schema, but\nconstraints of different types can have the same name.\n• PRIMARY KEY\nA unique index where all key columns must be defined as NOT NULL. If they are not explicitly\ndeclared as NOT NULL, MySQL declares them so implicitly (and silently). A table can have only one\nPRIMARY KEY. The name of a PRIMARY KEY is always PRIMARY, which thus cannot be used as the\nname for any other kind of index.\nIf you do not have a PRIMARY KEY and an application asks for the PRIMARY KEY in your tables,\nMySQL returns the first UNIQUE index that has no NULL columns as the PRIMARY KEY.\nIn InnoDB tables, keep the PRIMARY KEY short to minimize storage overhead for secondary\nindexes. Each secondary index entry contains a copy of the primary key columns for the\ncorresponding row. (See Section 17.6.2.1, “Clustered and Secondary Indexes”.)\nIn the created table, a PRIMARY KEY is placed first, followed by all UNIQUE indexes, and then the\nnonunique indexes. This helps the MySQL optimizer to prioritize which index to use and also more\nquickly to detect duplicated UNIQUE keys.\nA PRIMARY KEY can be a multiple-column index. However, you cannot create a multiple-column\nindex using the PRIMARY KEY key attribute in a column specification. Doing so only marks that\nsingle column as primary. You must use a separate PRIMARY KEY(key_part, ...) clause.\nIf a table has a PRIMARY KEY or UNIQUE NOT NULL index that consists of a single column that\nhas an integer type, you can use _rowid to refer to the indexed column in SELECT statements, as\ndescribed in Unique Indexes.\nIn MySQL, the name of a PRIMARY KEY is PRIMARY. For other indexes, if you do not assign a\nname, the index is assigned the same name as the first indexed column, with an optional suffix\n(_2, _3, ...) to make it unique. You can see index names for a table using SHOW INDEX FROM\ntbl_name. See Section 15.7.7.23, “SHOW INDEX Statement”.\n• KEY | INDEX\nKEY is normally a synonym for INDEX. The key attribute PRIMARY KEY can also be specified as just\nKEY when given in a column definition. This was implemented for compatibility with other database\nsystems.\n• UNIQUE\nA UNIQUE index creates a constraint such that all values in the index must be distinct. An error\noccurs if you try to add a new row with a key value that matches an existing row. For all engines,\na UNIQUE index permits multiple NULL values for columns that can contain NULL. If you specify a\nprefix value for a column in a UNIQUE index, the column values must be unique within the prefix\nlength.\nIf a table has a PRIMARY KEY or UNIQUE NOT NULL index that consists of a single column that\nhas an integer type, you can use _rowid to refer to the indexed column in SELECT statements, as\ndescribed in Unique Indexes.\n• FULLTEXT\nA FULLTEXT index is a special type of index used for full-text searches. Only the InnoDB and\nMyISAM storage engines support FULLTEXT indexes. They can be created only from CHAR,\nVARCHAR, and TEXT columns. Indexing always happens over the entire column; column prefix\nindexing is not supported and any prefix length is ignored if specified. See Section 14.9, “Full-\nText Search Functions”, for details of operation. A WITH PARSER clause can be specified as an\nindex_option value to associate a parser plugin with the index if full-text indexing and searching\noperations need special handling. This clause is valid only for FULLTEXT indexes. InnoDB and\nMyISAM support full-text parser plugins. See Full-Text Parser Plugins and Writing Full-Text Parser\nPlugins for more information.\n• SPATIAL\nYou can create SPATIAL indexes on spatial data types. Spatial types are supported only for InnoDB\nand MyISAM tables, and indexed columns must be declared as NOT NULL. See Section 13.4,\n“Spatial Data Types”.\n• FOREIGN KEY\nMySQL supports foreign keys, which let you cross-reference related data across tables, and\nforeign key constraints, which help keep this spread-out data consistent. For definition and option\ninformation, see reference_definition, and reference_option.\nPartitioned tables employing the InnoDB storage engine do not support foreign keys. See\nSection 26.6, “Restrictions and Limitations on Partitioning”, for more information.\n• CHECK\nThe CHECK clause enables the creation of constraints to be checked for data values in table rows.\nSee Section 15.1.20.6, “CHECK Constraints”.\n• key_part\n• A key_part specification can end with ASC or DESC to specify whether index values are stored in\nascending or descending order. The default is ascending if no order specifier is given.\n• Prefixes, defined by the length attribute, can be up to 767 bytes long for InnoDB tables that use\nthe REDUNDANT or COMPACT row format. The prefix length limit is 3072 bytes for InnoDB tables\nthat use the DYNAMIC or COMPRESSED row format. For MyISAM tables, the prefix length limit is\n1000 bytes.\nPrefix limits are measured in bytes. However, prefix lengths for index specifications in CREATE\nTABLE, ALTER TABLE, and CREATE INDEX statements are interpreted as number of characters\nfor nonbinary string types (CHAR, VARCHAR, TEXT) and number of bytes for binary string types\n(BINARY, VARBINARY, BLOB). Take this into account when specifying a prefix length for a\nnonbinary string column that uses a multibyte character set.\n• The expr for a key_part specification can take the form (CAST json_path AS type\nARRAY) to create a multi-valued index on a JSON column. Multi-Valued Indexes, provides detailed\ninformation regarding creation of, usage of, and restrictions and limitations on multi-valued\nindexes.\n• index_type\nSome storage engines permit you to specify an index type when creating an index. The syntax for\nthe index_type specifier is USING type_name.\nExample:\nCREATE TABLE lookup\n  (id INT, INDEX USING BTREE (id)\n) ENGINE = MEMORY;\nThe preferred position for USING is after the index column list. It can be given before the column\nlist, but support for use of the option in that position is deprecated and you should expect it to be\nremoved in a future MySQL release.\n• index_option\nindex_option values specify additional options for an index.\n• KEY_BLOCK_SIZE\nFor MyISAM tables, KEY_BLOCK_SIZE optionally specifies the size in bytes to use for index\nkey blocks. The value is treated as a hint; a different size could be used if necessary. A\nKEY_BLOCK_SIZE value specified for an individual index definition overrides the table-level\nKEY_BLOCK_SIZE value.\nFor information about the table-level KEY_BLOCK_SIZE attribute, see Table Options.\n• WITH PARSER\nThe WITH PARSER option can be used only with FULLTEXT indexes. It associates a parser plugin\nwith the index if full-text indexing and searching operations need special handling. InnoDB and\nMyISAM support full-text parser plugins. If you have a MyISAM table with an associated full-text\nparser plugin, you can convert the table to InnoDB using ALTER TABLE.\n• COMMENT\nIndex definitions can include an optional comment of up to 1024 characters.\nYou can set the InnoDB MERGE_THRESHOLD value for an individual index using the\nindex_option COMMENT clause. See Section 17.8.11, “Configuring the Merge Threshold for\nIndex Pages”.\n• VISIBLE, INVISIBLE\nSpecify index visibility. Indexes are visible by default. An invisible index is not used by the\noptimizer. Specification of index visibility applies to indexes other than primary keys (either explicit\nor implicit). For more information, see Section 10.3.12, “Invisible Indexes”.\n• ENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE options are used to specify index\nattributes for primary and secondary storage engines. The options are reserved for future use.\nFor more information about permissible index_option values, see Section 15.1.15, “CREATE\nINDEX Statement”. For more information about indexes, see Section 10.3.1, “How MySQL Uses\nIndexes”.\n• reference_definition\nFor reference_definition syntax details and examples, see Section 15.1.20.5, “FOREIGN KEY\nConstraints”.\nInnoDB and NDB tables support checking of foreign key constraints. The columns of the referenced\ntable must always be explicitly named. Both ON DELETE and ON UPDATE actions on foreign keys\nare supported. For more detailed information and examples, see Section 15.1.20.5, “FOREIGN KEY\nConstraints”.\nFor other storage engines, MySQL Server parses and ignores the FOREIGN KEY syntax in CREATE\nTABLE statements.\nImportant\nFor users familiar with the ANSI/ISO SQL Standard, please note that no\nstorage engine, including InnoDB, recognizes or enforces the MATCH clause\nused in referential integrity constraint definitions. Use of an explicit MATCH\nclause does not have the specified effect, and also causes ON DELETE and\nON UPDATE clauses to be ignored. For these reasons, specifying MATCH\nshould be avoided.\nThe MATCH clause in the SQL standard controls how NULL values in a\ncomposite (multiple-column) foreign key are handled when comparing to a\nprimary key. InnoDB essentially implements the semantics defined by MATCH\nSIMPLE, which permit a foreign key to be all or partially NULL. In that case,\nthe (child table) row containing such a foreign key is permitted to be inserted,\nand does not match any row in the referenced (parent) table. It is possible to\nimplement other semantics using triggers.\nAdditionally, MySQL requires that the referenced columns be indexed for\nperformance. However, InnoDB does not enforce any requirement that the\nreferenced columns be declared UNIQUE or NOT NULL. The handling of\nforeign key references to nonunique keys or keys that contain NULL values is\nnot well defined for operations such as UPDATE or DELETE CASCADE. You\nare advised to use foreign keys that reference only keys that are both UNIQUE\n(or PRIMARY) and NOT NULL.\nMySQL accepts “inline REFERENCES specifications” (as defined in the\nSQL standard) where the references are defined as part of the column\nspecification. MySQL also accepts implicit references to the parent table's\nprimary key. For more information, see Section 15.1.20.5, “FOREIGN\nKEY Constraints”, as well as Section 1.7.2.3, “FOREIGN KEY Constraint\nDifferences”.\n• reference_option\nFor information about the RESTRICT, CASCADE, SET NULL, NO ACTION, and SET DEFAULT\noptions, see Section 15.1.20.5, “FOREIGN KEY Constraints”.\nTable Options\nTable options are used to optimize the behavior of the table. In most cases, you do not have to specify\nany of them. These options apply to all storage engines unless otherwise indicated. Options that do not\napply to a given storage engine may be accepted and remembered as part of the table definition. Such\noptions then apply if you later use ALTER TABLE to convert the table to use a different storage engine.\n• ENGINE\nSpecifies the storage engine for the table, using one of the names shown in the following table. The\nengine name can be unquoted or quoted. The quoted name 'DEFAULT' is recognized but ignored.\nStorage Engine\nDescription\nInnoDB\nTransaction-safe tables with row locking and\nforeign keys. The default storage engine for\nnew tables. See Chapter 17, The InnoDB\nStorage Engine, and in particular Section 17.1,\n“Introduction to InnoDB” if you have MySQL\nexperience but are new to InnoDB.\nMyISAM\nThe binary portable storage engine that is\nprimarily used for read-only or read-mostly\nworkloads. See Section 18.2, “The MyISAM\nStorage Engine”.\nMEMORY\nThe data for this storage engine is stored only\nin memory. See Section 18.3, “The MEMORY\nStorage Engine”.\nCSV\nTables that store rows in comma-separated\nvalues format. See Section 18.4, “The CSV\nStorage Engine”.\nARCHIVE\nThe archiving storage engine. See Section 18.5,\n“The ARCHIVE Storage Engine”.\nEXAMPLE\nAn example engine. See Section 18.9, “The\nEXAMPLE Storage Engine”.\nFEDERATED\nStorage engine that accesses remote tables.\nSee Section 18.8, “The FEDERATED Storage\nEngine”.\nHEAP\nThis is a synonym for MEMORY.\nMERGE\nA collection of MyISAM tables used as one table.\nAlso known as MRG_MyISAM. See Section 18.7,\n“The MERGE Storage Engine”.\nStorage Engine\nDescription\nNDB\nClustered, fault-tolerant, memory-based tables,\nsupporting transactions and foreign keys. Also\nknown as NDBCLUSTER. See Chapter 25,\nMySQL NDB Cluster 9.1.\nBy default, if a storage engine is specified that is not available, the statement fails with an error. You\ncan override this behavior by removing NO_ENGINE_SUBSTITUTION from the server SQL mode\n(see Section 7.1.11, “Server SQL Modes”) so that MySQL allows substitution of the specified engine\nwith the default storage engine instead. Normally in such cases, this is InnoDB, which is the default\nvalue for the default_storage_engine system variable. When NO_ENGINE_SUBSTITUTION is\ndisabled, a warning occurs if the storage engine specification is not honored.\n• AUTOEXTEND_SIZE\nDefines the amount by which InnoDB extends the size of the tablespace when it becomes full.\nThe setting must be a multiple of 4MB. The default setting is 0, which causes the tablespace to be\nextended according to the implicit default behavior. For more information, see Section 17.6.3.9,\n“Tablespace AUTOEXTEND_SIZE Configuration”.\n• AUTO_INCREMENT\nThe initial AUTO_INCREMENT value for the table. In MySQL 9.1, this works for MyISAM, MEMORY,\nInnoDB, and ARCHIVE tables. To set the first auto-increment value for engines that do not support\nthe AUTO_INCREMENT table option, insert a “dummy” row with a value one less than the desired\nvalue after creating the table, and then delete the dummy row.\nFor engines that support the AUTO_INCREMENT table option in CREATE TABLE statements, you can\nalso use ALTER TABLE tbl_name AUTO_INCREMENT = N to reset the AUTO_INCREMENT value.\nThe value cannot be set lower than the maximum value currently in the column.\n• AVG_ROW_LENGTH\nAn approximation of the average row length for your table. You need to set this only for large tables\nwith variable-size rows.\nWhen you create a MyISAM table, MySQL uses the product of the MAX_ROWS and\nAVG_ROW_LENGTH options to decide how big the resulting table is. If you don't specify either option,\nthe maximum size for MyISAM data and index files is 256TB by default. (If your operating system\ndoes not support files that large, table sizes are constrained by the file size limit.) If you want to\nkeep down the pointer sizes to make the index smaller and faster and you don't really need big files,\nyou can decrease the default pointer size by setting the myisam_data_pointer_size system\nvariable. (See Section 7.1.8, “Server System Variables”.) If you want all your tables to be able\nto grow above the default limit and are willing to have your tables slightly slower and larger than\nnecessary, you can increase the default pointer size by setting this variable. Setting the value to 7\npermits table sizes up to 65,536TB.\n• [DEFAULT] CHARACTER SET\nSpecifies a default character set for the table. CHARSET is a synonym for CHARACTER SET. If the\ncharacter set name is DEFAULT, the database character set is used.\n• CHECKSUM\nSet this to 1 if you want MySQL to maintain a live checksum for all rows (that is, a checksum that\nMySQL updates automatically as the table changes). This makes the table a little slower to update,\nbut also makes it easier to find corrupted tables. The CHECKSUM TABLE statement reports the\nchecksum. (MyISAM only.)\n• [DEFAULT] COLLATE\nSpecifies a default collation for the table.\n• COMMENT\nA comment for the table, up to 2048 characters long.\nYou can set the InnoDB MERGE_THRESHOLD value for a table using the table_option COMMENT\nclause. See Section 17.8.11, “Configuring the Merge Threshold for Index Pages”.\nSetting NDB_TABLE options. \n  The table comment in a CREATE TABLE that creates an NDB\ntable or an ALTER TABLE statement which alters one can also be used to specify one to four of the\nNDB_TABLE options NOLOGGING, READ_BACKUP, PARTITION_BALANCE, or FULLY_REPLICATED\nas a set of name-value pairs, separated by commas if need be, immediately following the string\nNDB_TABLE= that begins the quoted comment text. An example statement using this syntax is\nshown here (emphasized text):\nCREATE TABLE t1 (\n    c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    c2 VARCHAR(100),\n    c3 VARCHAR(100) )\nENGINE=NDB\nCOMMENT=\"NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE\";\nSpaces are not permitted within the quoted string. The string is case-insensitive.\nThe comment is displayed as part of the output of SHOW CREATE TABLE. The text of the comment is\nalso available as the TABLE_COMMENT column of the MySQL Information Schema TABLES table.\nThis comment syntax is also supported with ALTER TABLE statements for NDB tables. Keep in mind\nthat a table comment used with ALTER TABLE replaces any existing comment which the table might\nhave had previously.\nSetting the MERGE_THRESHOLD option in table comments is not supported for NDB tables (it is\nignored).\nFor complete syntax information and examples, see Section 15.1.20.12, “Setting NDB Comment\nOptions”.\n• COMPRESSION\nThe compression algorithm used for page level compression for InnoDB tables. Supported values\ninclude Zlib, LZ4, and None. The COMPRESSION attribute was introduced with the transparent page\ncompression feature. Page compression is only supported with InnoDB tables that reside in file-per-\ntable tablespaces, and is only available on Linux and Windows platforms that support sparse files\nand hole punching. For more information, see Section 17.9.2, “InnoDB Page Compression”.\n• CONNECTION\nThe connection string for a FEDERATED table.\nNote\nOlder versions of MySQL used a COMMENT option for the connection string.\n• DATA DIRECTORY, INDEX DIRECTORY\nFor InnoDB, the DATA DIRECTORY='directory' clause permits creating tables outside of\nthe data directory. The innodb_file_per_table variable must be enabled to use the DATA\nDIRECTORY clause. The full directory path must be specified, and known to InnoDB. For more\ninformation, see Section 17.6.1.2, “Creating Tables Externally”.\nWhen creating MyISAM tables, you can use the DATA DIRECTORY='directory' clause, the\nINDEX DIRECTORY='directory' clause, or both. They specify where to put a MyISAM table's\ndata file and index file, respectively. Unlike InnoDB tables, MySQL does not create subdirectories\nthat correspond to the database name when creating a MyISAM table with a DATA DIRECTORY or\nINDEX DIRECTORY option. Files are created in the directory that is specified.\nYou must have the FILE privilege to use the DATA DIRECTORY or INDEX DIRECTORY table option.\nImportant\nTable-level DATA DIRECTORY and INDEX DIRECTORY options are ignored\nfor partitioned tables. (Bug #32091)\nThese options work only when you are not using the --skip-symbolic-links option. Your\noperating system must also have a working, thread-safe realpath() call. See Section 10.12.2.2,\n“Using Symbolic Links for MyISAM Tables on Unix”, for more complete information.\nIf a MyISAM table is created with no DATA DIRECTORY option, the .MYD file is created in the\ndatabase directory. By default, if MyISAM finds an existing .MYD file in this case, it overwrites it. The\nsame applies to .MYI files for tables created with no INDEX DIRECTORY option. To suppress this\nbehavior, start the server with the --keep_files_on_create option, in which case MyISAM does\nnot overwrite existing files and returns an error instead.\nIf a MyISAM table is created with a DATA DIRECTORY or INDEX DIRECTORY option and an existing\n.MYD or .MYI file is found, MyISAM always returns an error, and does not overwrite a file in the\nspecified directory.\nImportant\nYou cannot use path names that contain the MySQL data directory with DATA\nDIRECTORY or INDEX DIRECTORY. This includes partitioned tables and\nindividual table partitions. (See Bug #32167.)\n• DELAY_KEY_WRITE\nSet this to 1 if you want to delay key updates for the table until the table is closed. See the\ndescription of the delay_key_write system variable in Section 7.1.8, “Server System Variables”.\n(MyISAM only.)\n• ENCRYPTION\nThe ENCRYPTION clause enables or disables page-level data encryption for an InnoDB table. A\nkeyring plugin must be installed and configured before encryption can be enabled. The ENCRYPTION\nclause can be specified when creating a table in an a file-per-table tablespace, or when creating a\ntable in a general tablespace.\nThe ENCRYPTION option is supported only by the InnoDB storage engine; thus it works only\nif the default storage engine is InnoDB, or if the CREATE TABLE statement also specifies\nENGINE=InnoDB. Otherwise the statement is rejected with ER_CHECK_NOT_IMPLEMENTED.\nA table inherits the default schema encryption if an ENCRYPTION clause is not specified. If the\ntable_encryption_privilege_check variable is enabled, the TABLE_ENCRYPTION_ADMIN\nprivilege is required to create a table with an ENCRYPTION clause setting that differs from the default\nschema encryption. When creating a table in a general tablespace, table and tablespace encryption\nmust match.\nSpecifying an ENCRYPTION clause with a value other than 'N' or '' is not permitted when using a\nstorage engine that does not support encryption.\nFor more information, see Section 17.13, “InnoDB Data-at-Rest Encryption”.\n• The ENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE options are used to specify table\nattributes for primary and secondary storage engines. The options are reserved for future use.\nThe value assigned to either of these options must be a string literal containing a valid JSON\ndocument or an empty string (''). Invalid JSON is rejected.\nCREATE TABLE t1 (c1 INT) ENGINE_ATTRIBUTE='{\"key\":\"value\"}';\nENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE values can be repeated without error.\nIn this case, the last specified value is used.\nENGINE_ATTRIBUTE and SECONDARY_ENGINE_ATTRIBUTE values are not checked by the server,\nnor are they cleared when the table's storage engine is changed.\n• INSERT_METHOD\nIf you want to insert data into a MERGE table, you must specify with INSERT_METHOD the table into\nwhich the row should be inserted. INSERT_METHOD is an option useful for MERGE tables only. Use a\nvalue of FIRST or LAST to have inserts go to the first or last table, or a value of NO to prevent inserts.\nSee Section 18.7, “The MERGE Storage Engine”.\n• KEY_BLOCK_SIZE\nFor MyISAM tables, KEY_BLOCK_SIZE optionally specifies the size in bytes to use for index\nkey blocks. The value is treated as a hint; a different size could be used if necessary. A\nKEY_BLOCK_SIZE value specified for an individual index definition overrides the table-level\nKEY_BLOCK_SIZE value.\nFor InnoDB tables, KEY_BLOCK_SIZE specifies the page size in kilobytes to use for compressed\nInnoDB tables. The KEY_BLOCK_SIZE value is treated as a hint; a different size could\nbe used by InnoDB if necessary. KEY_BLOCK_SIZE can only be less than or equal to the\ninnodb_page_size value. A value of 0 represents the default compressed page size, which is half\nof the innodb_page_size value. Depending on innodb_page_size, possible KEY_BLOCK_SIZE\nvalues include 0, 1, 2, 4, 8, and 16. See Section 17.9.1, “InnoDB Table Compression” for more\ninformation.\nOracle recommends enabling innodb_strict_mode when specifying KEY_BLOCK_SIZE for\nInnoDB tables. When innodb_strict_mode is enabled, specifying an invalid KEY_BLOCK_SIZE\nvalue returns an error. If innodb_strict_mode is disabled, an invalid KEY_BLOCK_SIZE value\nresults in a warning, and the KEY_BLOCK_SIZE option is ignored.\nThe Create_options column in response to SHOW TABLE STATUS reports the actual\nKEY_BLOCK_SIZE used by the table, as does SHOW CREATE TABLE.\nInnoDB only supports KEY_BLOCK_SIZE at the table level.\nKEY_BLOCK_SIZE is not supported with 32KB and 64KB innodb_page_size values. InnoDB\ntable compression does not support these pages sizes.\nInnoDB does not support the KEY_BLOCK_SIZE option when creating temporary tables.\n• MAX_ROWS\nThe maximum number of rows you plan to store in the table. This is not a hard limit, but rather a hint\nto the storage engine that the table must be able to store at least this many rows.\nImportant\nThe use of MAX_ROWS with NDB tables to control the number of table\npartitions is deprecated. It remains supported in later versions for\nbackward compatibility, but is subject to removal in a future release. Use\nPARTITION_BALANCE instead; see Setting NDB_TABLE options.\nThe NDB storage engine treats this value as a maximum. If you plan to create very large NDB Cluster\ntables (containing millions of rows), you should use this option to insure that NDB allocates sufficient\nnumber of index slots in the hash table used for storing hashes of the table's primary keys by setting\nMAX_ROWS = 2 * rows, where rows is the number of rows that you expect to insert into the table.\nThe maximum MAX_ROWS value is 4294967295; larger values are truncated to this limit.\n• MIN_ROWS\nThe minimum number of rows you plan to store in the table. The MEMORY storage engine uses this\noption as a hint about memory use.\n• PACK_KEYS\nTakes effect only with MyISAM tables. Set this option to 1 if you want to have smaller indexes.\nThis usually makes updates slower and reads faster. Setting the option to 0 disables all packing of\nkeys. Setting it to DEFAULT tells the storage engine to pack only long CHAR, VARCHAR, BINARY, or\nVARBINARY columns.\nIf you do not use PACK_KEYS, the default is to pack strings, but not numbers. If you use\nPACK_KEYS=1, numbers are packed as well.\nWhen packing binary number keys, MySQL uses prefix compression:\n• Every key needs one extra byte to indicate how many bytes of the previous key are the same for\nthe next key.\n• The pointer to the row is stored in high-byte-first order directly after the key, to improve\ncompression.\nThis means that if you have many equal keys on two consecutive rows, all following “same” keys\nusually only take two bytes (including the pointer to the row). Compare this to the ordinary case\nwhere the following keys takes storage_size_for_key + pointer_size (where the pointer\nsize is usually 4). Conversely, you get a significant benefit from prefix compression only if you have\nmany numbers that are the same. If all keys are totally different, you use one byte more per key, if\nthe key is not a key that can have NULL values. (In this case, the packed key length is stored in the\nsame byte that is used to mark if a key is NULL.)\n• PASSWORD\nThis option is unused.\n• ROW_FORMAT\nDefines the physical format in which the rows are stored.\nWhen creating a table with strict mode disabled, the storage engine's default row format is used\nif the specified row format is not supported. The actual row format of the table is reported in the\nRow_format column in response to SHOW TABLE STATUS. The Create_options column shows\nthe row format that was specified in the CREATE TABLE statement, as does SHOW CREATE TABLE.\nRow format choices differ depending on the storage engine used for the table.\nFor InnoDB tables:\n• The default row format is defined by innodb_default_row_format, which has a default setting\nof DYNAMIC. The default row format is used when the ROW_FORMAT option is not defined or when\nROW_FORMAT=DEFAULT is used.\nIf the ROW_FORMAT option is not defined, or if ROW_FORMAT=DEFAULT is used, operations\nthat rebuild a table also silently change the row format of the table to the default defined by\ninnodb_default_row_format. For more information, see Defining the Row Format of a Table.\n• For more efficient InnoDB storage of data types, especially BLOB types, use the DYNAMIC. See\nDYNAMIC Row Format for requirements associated with the DYNAMIC row format.\n• To enable compression for InnoDB tables, specify ROW_FORMAT=COMPRESSED. The\nROW_FORMAT=COMPRESSED option is not supported when creating temporary tables. See\nSection 17.9, “InnoDB Table and Page Compression” for requirements associated with the\nCOMPRESSED row format.\n• The row format used in older versions of MySQL can still be requested by specifying the\nREDUNDANT row format.\n• When you specify a non-default ROW_FORMAT clause, consider also enabling the\ninnodb_strict_mode configuration option.\n• ROW_FORMAT=FIXED is not supported. If ROW_FORMAT=FIXED is specified while\ninnodb_strict_mode is disabled, InnoDB issues a warning and assumes\nROW_FORMAT=DYNAMIC. If ROW_FORMAT=FIXED is specified while innodb_strict_mode is\nenabled, which is the default, InnoDB returns an error.\n• For additional information about InnoDB row formats, see Section 17.10, “InnoDB Row Formats”.\nFor MyISAM tables, the option value can be FIXED or DYNAMIC for static or variable-length row\nformat. myisampack sets the type to COMPRESSED. See Section 18.2.3, “MyISAM Table Storage\nFormats”.\nFor NDB tables, the default ROW_FORMAT is DYNAMIC.\n• START TRANSACTION\nThis is an internal-use table option, used to permit CREATE TABLE ... SELECT to be logged as a\nsingle, atomic transaction in the binary log when using row-based replication with a storage engine\nthat supports atomic DDL. Only BINLOG, COMMIT, and ROLLBACK statements are permitted after\nCREATE TABLE ... START TRANSACTION. For related information, see Section 15.1.1, “Atomic\nData Definition Statement Support”.\n• STATS_AUTO_RECALC\nSpecifies whether to automatically recalculate persistent statistics for an InnoDB table. The\nvalue DEFAULT causes the persistent statistics setting for the table to be determined by the\ninnodb_stats_auto_recalc configuration option. The value 1 causes statistics to be\nrecalculated when 10% of the data in the table has changed. The value 0 prevents automatic\nrecalculation for this table; with this setting, issue an ANALYZE TABLE statement to recalculate the\nstatistics after making substantial changes to the table. For more information about the persistent\nstatistics feature, see Section 17.8.10.1, “Configuring Persistent Optimizer Statistics Parameters”.\n• STATS_PERSISTENT\nSpecifies whether to enable persistent statistics for an InnoDB table. The value DEFAULT causes\nthe persistent statistics setting for the table to be determined by the innodb_stats_persistent\nconfiguration option. The value 1 enables persistent statistics for the table, while the value 0\nturns off this feature. After enabling persistent statistics through a CREATE TABLE or ALTER\nTABLE statement, issue an ANALYZE TABLE statement to calculate the statistics, after loading\nrepresentative data into the table. For more information about the persistent statistics feature, see\nSection 17.8.10.1, “Configuring Persistent Optimizer Statistics Parameters”.\n• STATS_SAMPLE_PAGES\nThe number of index pages to sample when estimating cardinality and other statistics for an indexed\ncolumn, such as those calculated by ANALYZE TABLE. For more information, see Section 17.8.10.1,\n“Configuring Persistent Optimizer Statistics Parameters”.\n• TABLESPACE\nThe TABLESPACE clause can be used to create an InnoDB table in an existing general tablespace,\na file-per-table tablespace, or the system tablespace.\nCREATE TABLE tbl_name ... TABLESPACE [=] tablespace_name\nThe general tablespace that you specify must exist prior to using the TABLESPACE clause. For\ninformation about general tablespaces, see Section 17.6.3.3, “General Tablespaces”.\nThe tablespace_name is a case-sensitive identifier. It may be quoted or unquoted. The forward\nslash character (“/”) is not permitted. Names beginning with “innodb_” are reserved for special use.\nTo create a table in the system tablespace, specify innodb_system as the tablespace name.\nCREATE TABLE tbl_name ... TABLESPACE [=] innodb_system\nUsing TABLESPACE [=] innodb_system, you can place a table of any uncompressed row format\nin the system tablespace regardless of the innodb_file_per_table setting. For example, you\ncan add a table with ROW_FORMAT=DYNAMIC to the system tablespace using TABLESPACE [=]\ninnodb_system.\nTo create a table in a file-per-table tablespace, specify innodb_file_per_table as the\ntablespace name.\nCREATE TABLE tbl_name ... TABLESPACE [=] innodb_file_per_table\nNote\nIf innodb_file_per_table is enabled, you need not specify\nTABLESPACE=innodb_file_per_table to create an InnoDB file-per-table\ntablespace. InnoDB tables are created in file-per-table tablespaces by default\nwhen innodb_file_per_table is enabled.\nThe DATA DIRECTORY clause is permitted with CREATE TABLE ...\nTABLESPACE=innodb_file_per_table but is otherwise not supported for use in combination\nwith the TABLESPACE clause. The directory specified in a DATA DIRECTORY clause must be known\nto InnoDB. For more information, see Using the DATA DIRECTORY Clause.\nNote\nSupport for TABLESPACE = innodb_file_per_table and TABLESPACE\n= innodb_temporary clauses with CREATE TEMPORARY TABLE is\ndeprecated; expect it to be removed in a future version of MySQL.\nThe STORAGE table option is employed only with NDB tables. STORAGE determines the type of\nstorage used, and can be either of DISK or MEMORY.\nTABLESPACE ... STORAGE DISK assigns a table to an NDB Cluster Disk Data tablespace.\nSTORAGE DISK cannot be used in CREATE TABLE unless preceded by TABLESPACE\ntablespace_name.\nFor STORAGE MEMORY, the tablespace name is optional, thus, you can use TABLESPACE\ntablespace_name STORAGE MEMORY or simply STORAGE MEMORY to specify explicitly that the\ntable is in-memory.\nSee Section 25.6.11, “NDB Cluster Disk Data Tables”, for more information.\n• UNION\nUsed to access a collection of identical MyISAM tables as one. This works only with MERGE tables.\nSee Section 18.7, “The MERGE Storage Engine”.\nYou must have SELECT, UPDATE, and DELETE privileges for the tables you map to a MERGE table.\nNote\nFormerly, all tables used had to be in the same database as the MERGE table\nitself. This restriction no longer applies.\nTable Partitioning\npartition_options can be used to control partitioning of the table created with CREATE TABLE.\nNot all options shown in the syntax for partition_options at the beginning of this section\nare available for all partitioning types. Please see the listings for the following individual types for\ninformation specific to each type, and see Chapter 26, Partitioning, for more complete information\nabout the workings of and uses for partitioning in MySQL, as well as additional examples of table\ncreation and other statements relating to MySQL partitioning.\nPartitions can be modified, merged, added to tables, and dropped from tables. For basic information\nabout the MySQL statements to accomplish these tasks, see Section 15.1.9, “ALTER TABLE\nStatement”. For more detailed descriptions and examples, see Section 26.3, “Partition Management”.\n• PARTITION BY\nIf used, a partition_options clause begins with PARTITION BY. This clause contains the\nfunction that is used to determine the partition; the function returns an integer value ranging from 1 to\nnum, where num is the number of partitions. (The maximum number of user-defined partitions which\na table may contain is 1024; the number of subpartitions—discussed later in this section—is included\nin this maximum.)\nNote\nThe expression (expr) used in a PARTITION BY clause cannot refer to any\ncolumns not in the table being created; such references are specifically not\npermitted and cause the statement to fail with an error. (Bug #29444)\n• HASH(expr)\nHashes one or more columns to create a key for placing and locating rows. expr is an expression\nusing one or more table columns. This can be any valid MySQL expression (including MySQL\nfunctions) that yields a single integer value. For example, these are both valid CREATE TABLE\nstatements using PARTITION BY HASH:\nCREATE TABLE t1 (col1 INT, col2 CHAR(5))\n    PARTITION BY HASH(col1);\nCREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATETIME)\n    PARTITION BY HASH ( YEAR(col3) );\nYou may not use either VALUES LESS THAN or VALUES IN clauses with PARTITION BY HASH.\nPARTITION BY HASH uses the remainder of expr divided by the number of partitions (that is, the\nmodulus). For examples and additional information, see Section 26.2.4, “HASH Partitioning”.\nThe LINEAR keyword entails a somewhat different algorithm. In this case, the number of the partition\nin which a row is stored is calculated as the result of one or more logical AND operations. For\ndiscussion and examples of linear hashing, see Section 26.2.4.1, “LINEAR HASH Partitioning”.\n• KEY(column_list)\nThis is similar to HASH, except that MySQL supplies the hashing function so as to guarantee an even\ndata distribution. The column_list argument is simply a list of 1 or more table columns (maximum:\n16). This example shows a simple table partitioned by key, with 4 partitions:\nCREATE TABLE tk (col1 INT, col2 CHAR(5), col3 DATE)\n    PARTITION BY KEY(col3)\n    PARTITIONS 4;\nFor tables that are partitioned by key, you can employ linear partitioning by using the LINEAR\nkeyword. This has the same effect as with tables that are partitioned by HASH. That is, the partition\nnumber is found using the & operator rather than the modulus (see Section 26.2.4.1, “LINEAR\nHASH Partitioning”, and Section 26.2.5, “KEY Partitioning”, for details). This example uses linear\npartitioning by key to distribute data between 5 partitions:\nCREATE TABLE tk (col1 INT, col2 CHAR(5), col3 DATE)\n    PARTITION BY LINEAR KEY(col3)\n    PARTITIONS 5;\nThe ALGORITHM={1 | 2} option is supported with [SUB]PARTITION BY [LINEAR] KEY.\nALGORITHM=1 causes the server to use the same key-hashing functions as MySQL 5.1;\nALGORITHM=2 means that the server employs the key-hashing functions implemented and used by\ndefault for new KEY partitioned tables in MySQL 5.5 and later. (Partitioned tables created with the\nkey-hashing functions employed in MySQL 5.5 and later cannot be used by a MySQL 5.1 server.)\nNot specifying the option has the same effect as using ALGORITHM=2. This option is intended for\nuse chiefly when upgrading or downgrading [LINEAR] KEY partitioned tables between MySQL\n5.1 and later MySQL versions, or for creating tables partitioned by KEY or LINEAR KEY on a\nMySQL 5.5 or later server which can be used on a MySQL 5.1 server. For more information, see\nSection 15.1.9.1, “ALTER TABLE Partition Operations”.\nmysqldump writes this option encased in versioned comments.\nALGORITHM=1 is shown when necessary in the output of SHOW CREATE TABLE using versioned\ncomments in the same manner as mysqldump. ALGORITHM=2 is always omitted from SHOW\nCREATE TABLE output, even if this option was specified when creating the original table.\nYou may not use either VALUES LESS THAN or VALUES IN clauses with PARTITION BY KEY.\n• RANGE(expr)\nIn this case, expr shows a range of values using a set of VALUES LESS THAN operators. When\nusing range partitioning, you must define at least one partition using VALUES LESS THAN. You\ncannot use VALUES IN with range partitioning.\nNote\nFor tables partitioned by RANGE, VALUES LESS THAN must be used with\neither an integer literal value or an expression that evaluates to a single\ninteger value. In MySQL 9.1, you can overcome this limitation in a table that\nis defined using PARTITION BY RANGE COLUMNS, as described later in this\nsection.\nSuppose that you have a table that you wish to partition on a column containing year values,\naccording to the following scheme.\nPartition Number:\nYears Range:\n0\n1990 and earlier\n1\n1991 to 1994\n2\n1995 to 1998\n3\n1999 to 2002\n4\n2003 to 2005\n5\n2006 and later\nA table implementing such a partitioning scheme can be realized by the CREATE TABLE statement\nshown here:\nCREATE TABLE t1 (\n    year_col  INT,\n    some_data INT\n)\nPARTITION BY RANGE (year_col) (\n    PARTITION p0 VALUES LESS THAN (1991),\n    PARTITION p1 VALUES LESS THAN (1995),\n    PARTITION p2 VALUES LESS THAN (1999),\n    PARTITION p3 VALUES LESS THAN (2002),\n    PARTITION p4 VALUES LESS THAN (2006),\n    PARTITION p5 VALUES LESS THAN MAXVALUE\n);\nPARTITION ... VALUES LESS THAN ... statements work in a consecutive fashion. VALUES\nLESS THAN MAXVALUE works to specify “leftover” values that are greater than the maximum value\notherwise specified.\nVALUES LESS THAN clauses work sequentially in a manner similar to that of the case portions of a\nswitch ... case block (as found in many programming languages such as C, Java, and PHP).\nThat is, the clauses must be arranged in such a way that the upper limit specified in each successive\nVALUES LESS THAN is greater than that of the previous one, with the one referencing MAXVALUE\ncoming last of all in the list.\n• RANGE COLUMNS(column_list)\nThis variant on RANGE facilitates partition pruning for queries using range conditions on multiple\ncolumns (that is, having conditions such as WHERE a = 1 AND b < 10 or WHERE a = 1 AND\nb = 10 AND c < 10). It enables you to specify value ranges in multiple columns by using a list\nof columns in the COLUMNS clause and a set of column values in each PARTITION ... VALUES\nLESS THAN (value_list) partition definition clause. (In the simplest case, this set consists of a\nsingle column.) The maximum number of columns that can be referenced in the column_list and\nvalue_list is 16.\nThe column_list used in the COLUMNS clause may contain only names of columns; each column\nin the list must be one of the following MySQL data types: the integer types; the string types; and\ntime or date column types. Columns using BLOB, TEXT, SET, ENUM, BIT, or spatial data types are\nnot permitted; columns that use floating-point number types are also not permitted. You also may not\nuse functions or arithmetic expressions in the COLUMNS clause.\nThe VALUES LESS THAN clause used in a partition definition must specify a literal value for each\ncolumn that appears in the COLUMNS() clause; that is, the list of values used for each VALUES\nLESS THAN clause must contain the same number of values as there are columns listed in the\nCOLUMNS clause. An attempt to use more or fewer values in a VALUES LESS THAN clause than\nthere are in the COLUMNS clause causes the statement to fail with the error Inconsistency\nin usage of column lists for partitioning.... You cannot use NULL for any value\nappearing in VALUES LESS THAN. It is possible to use MAXVALUE more than once for a given\ncolumn other than the first, as shown in this example:\nCREATE TABLE rc (\n    a INT NOT NULL,\n    b INT NOT NULL\n)\nPARTITION BY RANGE COLUMNS(a,b) (\n    PARTITION p0 VALUES LESS THAN (10,5),\n    PARTITION p1 VALUES LESS THAN (20,10),\n    PARTITION p2 VALUES LESS THAN (50,MAXVALUE),\n    PARTITION p3 VALUES LESS THAN (65,MAXVALUE),\n    PARTITION p4 VALUES LESS THAN (MAXVALUE,MAXVALUE)\n);\nEach value used in a VALUES LESS THAN value list must match the type of the corresponding\ncolumn exactly; no conversion is made. For example, you cannot use the string '1' for a value that\nmatches a column that uses an integer type (you must use the numeral 1 instead), nor can you use\nthe numeral 1 for a value that matches a column that uses a string type (in such a case, you must\nuse a quoted string: '1').\nFor more information, see Section 26.2.1, “RANGE Partitioning”, and Section 26.4, “Partition\nPruning”.\n• LIST(expr)\nThis is useful when assigning partitions based on a table column with a restricted set of possible\nvalues, such as a state or country code. In such a case, all rows pertaining to a certain state or\ncountry can be assigned to a single partition, or a partition can be reserved for a certain set of states\nor countries. It is similar to RANGE, except that only VALUES IN may be used to specify permissible\nvalues for each partition.\nVALUES IN is used with a list of values to be matched. For instance, you could create a partitioning\nscheme such as the following:\nCREATE TABLE client_firms (\n    id   INT,\n    name VARCHAR(35)\n)\nPARTITION BY LIST (id) (\n    PARTITION r0 VALUES IN (1, 5, 9, 13, 17, 21),\n    PARTITION r1 VALUES IN (2, 6, 10, 14, 18, 22),\n    PARTITION r2 VALUES IN (3, 7, 11, 15, 19, 23),\n    PARTITION r3 VALUES IN (4, 8, 12, 16, 20, 24)\n);\nWhen using list partitioning, you must define at least one partition using VALUES IN. You cannot use\nVALUES LESS THAN with PARTITION BY LIST.\nNote\nFor tables partitioned by LIST, the value list used with VALUES IN must\nconsist of integer values only. In MySQL 9.1, you can overcome this limitation\nusing partitioning by LIST COLUMNS, which is described later in this section.\n• LIST COLUMNS(column_list)\nThis variant on LIST facilitates partition pruning for queries using comparison conditions on multiple\ncolumns (that is, having conditions such as WHERE a = 5 AND b = 5 or WHERE a = 1 AND\nb = 10 AND c = 5). It enables you to specify values in multiple columns by using a list of\ncolumns in the COLUMNS clause and a set of column values in each PARTITION ... VALUES IN\n(value_list) partition definition clause.\nThe rules governing regarding data types for the column list used in LIST\nCOLUMNS(column_list) and the value list used in VALUES IN(value_list) are the same\nas those for the column list used in RANGE COLUMNS(column_list) and the value list used\nin VALUES LESS THAN(value_list), respectively, except that in the VALUES IN clause,\nMAXVALUE is not permitted, and you may use NULL.\nThere is one important difference between the list of values used for VALUES IN with PARTITION\nBY LIST COLUMNS as opposed to when it is used with PARTITION BY LIST. When used with\nPARTITION BY LIST COLUMNS, each element in the VALUES IN clause must be a set of column\nvalues; the number of values in each set must be the same as the number of columns used in the\nCOLUMNS clause, and the data types of these values must match those of the columns (and occur in\nthe same order). In the simplest case, the set consists of a single column. The maximum number of\ncolumns that can be used in the column_list and in the elements making up the value_list is\n16.\nThe table defined by the following CREATE TABLE statement provides an example of a table using\nLIST COLUMNS partitioning:\nCREATE TABLE lc (\n    a INT NULL,\n    b INT NULL\n)\nPARTITION BY LIST COLUMNS(a,b) (\n    PARTITION p0 VALUES IN( (0,0), (NULL,NULL) ),\n    PARTITION p1 VALUES IN( (0,1), (0,2), (0,3), (1,1), (1,2) ),\n    PARTITION p2 VALUES IN( (1,0), (2,0), (2,1), (3,0), (3,1) ),\n    PARTITION p3 VALUES IN( (1,3), (2,2), (2,3), (3,2), (3,3) )\n);\n• PARTITIONS num\nThe number of partitions may optionally be specified with a PARTITIONS num clause, where num\nis the number of partitions. If both this clause and any PARTITION clauses are used, num must be\nequal to the total number of any partitions that are declared using PARTITION clauses.\nNote\nWhether or not you use a PARTITIONS clause in creating a table that is\npartitioned by RANGE or LIST, you must still include at least one PARTITION\nVALUES clause in the table definition (see below).\n• SUBPARTITION BY\nA partition may optionally be divided into a number of subpartitions. This can be indicated by using\nthe optional SUBPARTITION BY clause. Subpartitioning may be done by HASH or KEY. Either of\nthese may be LINEAR. These work in the same way as previously described for the equivalent\npartitioning types. (It is not possible to subpartition by LIST or RANGE.)\nThe number of subpartitions can be indicated using the SUBPARTITIONS keyword followed by an\ninteger value.\n• Rigorous checking of the value used in PARTITIONS or SUBPARTITIONS clauses is applied and this\nvalue must adhere to the following rules:\n• The value must be a positive, nonzero integer.\n• No leading zeros are permitted.\n• The value must be an integer literal, and cannot not be an expression. For example, PARTITIONS\n0.2E+01 is not permitted, even though 0.2E+01 evaluates to 2. (Bug #15890)\n• partition_definition\nEach partition may be individually defined using a partition_definition clause. The individual\nparts making up this clause are as follows:\n• PARTITION partition_name\nSpecifies a logical name for the partition.\n• VALUES\nFor range partitioning, each partition must include a VALUES LESS THAN clause; for list\npartitioning, you must specify a VALUES IN clause for each partition. This is used to determine\nwhich rows are to be stored in this partition. See the discussions of partitioning types in\nChapter 26, Partitioning, for syntax examples.\n• [STORAGE] ENGINE\nMySQL accepts a [STORAGE] ENGINE option for both PARTITION and SUBPARTITION.\nCurrently, the only way in which this option can be used is to set all partitions or all subpartitions\nto the same storage engine, and an attempt to set different storage engines for partitions\nor subpartitions in the same table raises the error ERROR 1469 (HY000): The mix of\nhandlers in the partitions is not permitted in this version of MySQL.\n• COMMENT\nAn optional COMMENT clause may be used to specify a string that describes the partition. Example:\nCOMMENT = 'Data for the years previous to 1999'\nThe maximum length for a partition comment is 1024 characters.\n• DATA DIRECTORY and INDEX DIRECTORY\nDATA DIRECTORY and INDEX DIRECTORY may be used to indicate the directory where,\nrespectively, the data and indexes for this partition are to be stored. Both the data_dir and the\nindex_dir must be absolute system path names.\nThe directory specified in a DATA DIRECTORY clause must be known to InnoDB. For more\ninformation, see Using the DATA DIRECTORY Clause.\nYou must have the FILE privilege to use the DATA DIRECTORY or INDEX DIRECTORY partition\noption.\nExample:\nCREATE TABLE th (id INT, name VARCHAR(30), adate DATE)\nPARTITION BY LIST(YEAR(adate))\n(\n  PARTITION p1999 VALUES IN (1995, 1999, 2003)\n    DATA DIRECTORY = '/var/appdata/95/data'\n    INDEX DIRECTORY = '/var/appdata/95/idx',\n  PARTITION p2000 VALUES IN (1996, 2000, 2004)\n    DATA DIRECTORY = '/var/appdata/96/data'\n    INDEX DIRECTORY = '/var/appdata/96/idx',\n  PARTITION p2001 VALUES IN (1997, 2001, 2005)\n    DATA DIRECTORY = '/var/appdata/97/data'\n    INDEX DIRECTORY = '/var/appdata/97/idx',\n  PARTITION p2002 VALUES IN (1998, 2002, 2006)\n    DATA DIRECTORY = '/var/appdata/98/data'\n    INDEX DIRECTORY = '/var/appdata/98/idx'\n);\nDATA DIRECTORY and INDEX DIRECTORY behave in the same way as in the CREATE TABLE\nstatement's table_option clause as used for MyISAM tables.\nOne data directory and one index directory may be specified per partition. If left unspecified, the\ndata and indexes are stored by default in the table's database directory.\nThe DATA DIRECTORY and INDEX DIRECTORY options are ignored for creating partitioned tables\nif NO_DIR_IN_CREATE is in effect.\n• MAX_ROWS and MIN_ROWS\nMay be used to specify, respectively, the maximum and minimum number of rows to be stored in\nthe partition. The values for max_number_of_rows and min_number_of_rows must be positive\nintegers. As with the table-level options with the same names, these act only as “suggestions” to\nthe server and are not hard limits.\n• TABLESPACE\nMay be used to designate an InnoDB file-per-table tablespace for the partition by specifying\nTABLESPACE `innodb_file_per_table`. All partitions must belong to the same storage\nengine.\nPlacing InnoDB table partitions in shared InnoDB tablespaces is not supported. Shared\ntablespaces include the InnoDB system tablespace and general tablespaces.\n• subpartition_definition\nThe partition definition may optionally contain one or more subpartition_definition clauses.\nEach of these consists at a minimum of the SUBPARTITION name, where name is an identifier for\nthe subpartition. Except for the replacement of the PARTITION keyword with SUBPARTITION, the\nsyntax for a subpartition definition is identical to that for a partition definition.\nSubpartitioning must be done by HASH or KEY, and can be done only on RANGE or LIST partitions.\nSee Section 26.2.6, “Subpartitioning”.\nPartitioning by Generated Columns\nPartitioning by generated columns is permitted. For example:\nCREATE TABLE t1 (\n  s1 INT,\n  s2 INT AS (EXP(s1)) STORED\n)\nPARTITION BY LIST (s2) (\n  PARTITION p1 VALUES IN (1)\n);\nPartitioning sees a generated column as a regular column, which enables workarounds for limitations\non functions that are not permitted for partitioning (see Section 26.6.3, “Partitioning Limitations Relating\nto Functions”). The preceding example demonstrates this technique: EXP() cannot be used directly in\nthe PARTITION BY clause, but a generated column defined using EXP() is permitted.\n15.1.20.1 Files Created by CREATE TABLE\nFor an InnoDB table created in a file-per-table tablespace or general tablespace, table data and\nassociated indexes are stored in a .ibd file in the database directory. When an InnoDB table is created\nin the system tablespace, table data and indexes are stored in the ibdata* files that represent the\nsystem tablespace. The innodb_file_per_table option controls whether tables are created in file-\nper-table tablespaces or the system tablespace, by default. The TABLESPACE option can be used to\nplace a table in a file-per-table tablespace, general tablespace, or the system tablespace, regardless of\nthe innodb_file_per_table setting.\nFor MyISAM tables, the storage engine creates data and index files. Thus, for each MyISAM table\ntbl_name, there are two disk files.\nFile\nPurpose\ntbl_name.MYD\nData file\ntbl_name.MYI\nIndex file\nChapter 18, Alternative Storage Engines, describes what files each storage engine creates to represent\ntables. If a table name contains special characters, the names for the table files contain encoded\nversions of those characters as described in Section 11.2.4, “Mapping of Identifiers to File Names”.\n15.1.20.2 CREATE TEMPORARY TABLE Statement\nYou can use the TEMPORARY keyword when creating a table. A TEMPORARY table is visible only within\nthe current session, and is dropped automatically when the session is closed. This means that two\ndifferent sessions can use the same temporary table name without conflicting with each other or with\nan existing non-TEMPORARY table of the same name. (The existing table is hidden until the temporary\ntable is dropped.)\nInnoDB does not support compressed temporary tables. When innodb_strict_mode is enabled\n(the default), CREATE TEMPORARY TABLE returns an error if ROW_FORMAT=COMPRESSED or\nKEY_BLOCK_SIZE is specified. If innodb_strict_mode is disabled, warnings are issued and the\ntemporary table is created using a non-compressed row format. The innodb_file_per-table\noption does not affect the creation of InnoDB temporary tables.\nCREATE TABLE causes an implicit commit, except when used with the TEMPORARY keyword. See\nSection 15.3.3, “Statements That Cause an Implicit Commit”.\nTEMPORARY tables have a very loose relationship with databases (schemas). Dropping a database\ndoes not automatically drop any TEMPORARY tables created within that database.\nTo create a temporary table, you must have the CREATE TEMPORARY TABLES privilege. After a\nsession has created a temporary table, the server performs no further privilege checks on the table.\nThe creating session can perform any operation on the table, such as DROP TABLE, INSERT, UPDATE,\nor SELECT.\nOne implication of this behavior is that a session can manipulate its temporary tables even if the\ncurrent user has no privilege to create them. Suppose that the current user does not have the CREATE\nTEMPORARY TABLES privilege but is able to execute a definer-context stored procedure that executes\nwith the privileges of a user who does have CREATE TEMPORARY TABLES and that creates a\ntemporary table. While the procedure executes, the session uses the privileges of the defining user.\nAfter the procedure returns, the effective privileges revert to those of the current user, which can still\nsee the temporary table and perform any operation on it.\nYou cannot use CREATE TEMPORARY TABLE ... LIKE to create an empty table based\non the definition of a table that resides in the mysql tablespace, InnoDB system tablespace\n(innodb_system), or a general tablespace. The tablespace definition for such a table includes a\nTABLESPACE attribute that defines the tablespace where the table resides, and the aforementioned\ntablespaces do not support temporary tables. To create a temporary table based on the definition of\nsuch a table, use this syntax instead:\nCREATE TEMPORARY TABLE new_tbl SELECT * FROM orig_tbl LIMIT 0;\nNote\nSupport for TABLESPACE = innodb_file_per_table and TABLESPACE =\ninnodb_temporary clauses with CREATE TEMPORARY TABLE is deprecated;\nexpect it to be removed in a future version of MySQL.\n15.1.20.3 CREATE TABLE ... LIKE Statement\nUse CREATE TABLE ... LIKE to create an empty table based on the definition of another table,\nincluding any column attributes and indexes defined in the original table:\nCREATE TABLE new_tbl LIKE orig_tbl;\nThe copy is created using the same version of the table storage format as the original table. The\nSELECT privilege is required on the original table.\nLIKE works only for base tables, not for views.\nImportant\nYou cannot execute CREATE TABLE or CREATE TABLE ... LIKE while a\nLOCK TABLES statement is in effect.\nCREATE TABLE ... LIKE makes the same checks as CREATE TABLE. This\nmeans that if the current SQL mode is different from the mode in effect when\nthe original table was created, the table definition might be considered invalid\nfor the new mode and cause the statement to fail.\nFor CREATE TABLE ... LIKE, the destination table preserves generated column information from\nthe original table.\nFor CREATE TABLE ... LIKE, the destination table preserves expression default values from the\noriginal table.\nFor CREATE TABLE ... LIKE, the destination table preserves CHECK constraints from the original\ntable, except that all the constraint names are generated.\nCREATE TABLE ... LIKE does not preserve any DATA DIRECTORY or INDEX DIRECTORY table\noptions that were specified for the original table, or any foreign key definitions.\nIf the original table is a TEMPORARY table, CREATE TABLE ... LIKE does not preserve TEMPORARY.\nTo create a TEMPORARY destination table, use CREATE TEMPORARY TABLE ... LIKE.\nCREATE TABLE ... LIKE operations apply all ENGINE_ATTRIBUTE and\nSECONDARY_ENGINE_ATTRIBUTE values to the new table.\n15.1.20.4 CREATE TABLE ... SELECT Statement\nYou can create one table from another by adding a SELECT statement at the end of the CREATE\nTABLE statement:\nCREATE TABLE new_tbl [AS] SELECT * FROM orig_tbl;\nMySQL creates new columns for all elements in the SELECT. For example:\nmysql> CREATE TABLE test (a INT NOT NULL AUTO_INCREMENT,\n    ->        PRIMARY KEY (a), KEY(b))\n    ->        ENGINE=InnoDB SELECT b,c FROM test2;\nThis creates an InnoDB table with three columns, a, b, and c. The ENGINE option is part of the\nCREATE TABLE statement, and should not be used following the SELECT; this would result in a syntax\nerror. The same is true for other CREATE TABLE options such as CHARSET.\nNotice that the columns from the SELECT statement are appended to the right side of the table, not\noverlapped onto it. Take the following example:\nmysql> SELECT * FROM foo;\n+---+\n| n |\n+---+\n| 1 |\n+---+\nmysql> CREATE TABLE bar (m INT) SELECT n FROM foo;\nQuery OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\nmysql> SELECT * FROM bar;\n+------+---+\n| m    | n |\n+------+---+\n| NULL | 1 |\n+------+---+\n1 row in set (0.00 sec)\nFor each row in table foo, a row is inserted in bar with the values from foo and default values for the\nnew columns.\nIn a table resulting from CREATE TABLE ... SELECT, columns named only in the CREATE TABLE\npart come first. Columns named in both parts or only in the SELECT part come after that. The data type\nof SELECT columns can be overridden by also specifying the column in the CREATE TABLE part.\nFor storage engines that support both atomic DDL and foreign key constraints, creation of foreign keys\nis not permitted in CREATE TABLE ... SELECT statements when row-based replication is in use.\nForeign key constraints can be added later using ALTER TABLE.\nYou can precede the SELECT by IGNORE or REPLACE to indicate how to handle rows that duplicate\nunique key values. With IGNORE, rows that duplicate an existing row on a unique key value are\ndiscarded. With REPLACE, new rows replace rows that have the same unique key value. If neither\nIGNORE nor REPLACE is specified, duplicate unique key values result in an error. For more information,\nsee The Effect of IGNORE on Statement Execution.\nYou can also use a VALUES statement in the SELECT part of CREATE TABLE ... SELECT; the\nVALUES portion of the statement must include a table alias using an AS clause. To name the columns\ncoming from VALUES, supply column aliases with the table alias; otherwise, the default column names\ncolumn_0, column_1, column_2, ..., are used.\nOtherwise, naming of columns in the table thus created follows the same rules as described previously\nin this section. Examples:\nmysql> CREATE TABLE tv1\n     >     SELECT * FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v;\nmysql> TABLE tv1;\n+----------+----------+----------+\n| column_0 | column_1 | column_2 |\n+----------+----------+----------+\n|        1 |        3 |        5 |\n|        2 |        4 |        6 |\n+----------+----------+----------+\nmysql> CREATE TABLE tv2\n     >     SELECT * FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v(x,y,z);\nmysql> TABLE tv2;\n+---+---+---+\n| x | y | z |\n+---+---+---+\n| 1 | 3 | 5 |\n| 2 | 4 | 6 |\n+---+---+---+\nmysql> CREATE TABLE tv3 (a INT, b INT, c INT)\n     >     SELECT * FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v(x,y,z);\nmysql> TABLE tv3;\n+------+------+------+----------+----------+----------+\n| a    | b    | c    |        x |        y |        z |\n+------+------+------+----------+----------+----------+\n| NULL | NULL | NULL |        1 |        3 |        5 |\n| NULL | NULL | NULL |        2 |        4 |        6 |\n+------+------+------+----------+----------+----------+\nmysql> CREATE TABLE tv4 (a INT, b INT, c INT)\n     >     SELECT * FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v(x,y,z);\nmysql> TABLE tv4;\n+------+------+------+---+---+---+\n| a    | b    | c    | x | y | z |\n+------+------+------+---+---+---+\n| NULL | NULL | NULL | 1 | 3 | 5 |\n| NULL | NULL | NULL | 2 | 4 | 6 |\n+------+------+------+---+---+---+\nmysql> CREATE TABLE tv5 (a INT, b INT, c INT)\n     >     SELECT * FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v(a,b,c);\nmysql> TABLE tv5;\n+------+------+------+\n| a    | b    | c    |\n+------+------+------+\n|    1 |    3 |    5 |\n|    2 |    4 |    6 |\n+------+------+------+\nWhen selecting all columns and using the default column names, you can omit SELECT *, so the\nstatement just used to create table tv1 can also be written as shown here:\nmysql> CREATE TABLE tv1 VALUES ROW(1,3,5), ROW(2,4,6);\nmysql> TABLE tv1;\n+----------+----------+----------+\n| column_0 | column_1 | column_2 |\n+----------+----------+----------+\n|        1 |        3 |        5 |\n|        2 |        4 |        6 |\n+----------+----------+----------+\nWhen using VALUES as the source of the SELECT, all columns are always selected into the new table,\nand individual columns cannot be selected as they can be when selecting from a named table; each of\nthe following statements produces an error (ER_OPERAND_COLUMNS):\nCREATE TABLE tvx\n    SELECT (x,z) FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v(x,y,z);\nCREATE TABLE tvx (a INT, c INT)\n    SELECT (x,z) FROM (VALUES ROW(1,3,5), ROW(2,4,6)) AS v(x,y,z);\nSimilarly, you can use a TABLE statement in place of the SELECT. This follows the same rules as with\nVALUES; all columns of the source table and their names in the source table are always inserted into\nthe new table. Examples:\nmysql> TABLE t1;\n+----+----+\n| a  | b  |\n+----+----+\n|  1 |  2 |\n|  6 |  7 |\n| 10 | -4 |\n| 14 |  6 |\n+----+----+\nmysql> CREATE TABLE tt1 TABLE t1;\nmysql> TABLE tt1;\n+----+----+\n| a  | b  |\n+----+----+\n|  1 |  2 |\n|  6 |  7 |\n| 10 | -4 |\n| 14 |  6 |\n+----+----+\nmysql> CREATE TABLE tt2 (x INT) TABLE t1;\nmysql> TABLE tt2;\n+------+----+----+\n| x    | a  | b  |\n+------+----+----+\n| NULL |  1 |  2 |\n| NULL |  6 |  7 |\n| NULL | 10 | -4 |\n| NULL | 14 |  6 |\n+------+----+----+\nBecause the ordering of the rows in the underlying SELECT statements cannot always be determined,\nCREATE TABLE ... IGNORE SELECT and CREATE TABLE ... REPLACE SELECT statements are\nflagged as unsafe for statement-based replication. Such statements produce a warning in the error log\nwhen using statement-based mode and are written to the binary log using the row-based format when\nusing MIXED mode. See also Section 19.2.1.1, “Advantages and Disadvantages of Statement-Based\nand Row-Based Replication”.\nCREATE TABLE ... SELECT does not automatically create any indexes for you. This is done\nintentionally to make the statement as flexible as possible. If you want to have indexes in the created\ntable, you should specify these before the SELECT statement:\nmysql> CREATE TABLE bar (UNIQUE (n)) SELECT n FROM foo;\nFor CREATE TABLE ... SELECT, the destination table does not preserve information about whether\ncolumns in the selected-from table are generated columns. The SELECT part of the statement cannot\nassign values to generated columns in the destination table.\nFor CREATE TABLE ... SELECT, the destination table does preserve expression default values from\nthe original table.\nSome conversion of data types might occur. For example, the AUTO_INCREMENT attribute is not\npreserved, and VARCHAR columns can become CHAR columns. Retrained attributes are NULL (or NOT\nNULL) and, for those columns that have them, CHARACTER SET, COLLATION, COMMENT, and the\nDEFAULT clause.\nWhen creating a table with CREATE TABLE ... SELECT, make sure to alias any function calls or\nexpressions in the query. If you do not, the CREATE statement might fail or result in undesirable column\nnames.\nCREATE TABLE artists_and_works\n  SELECT artist.name, COUNT(work.artist_id) AS number_of_works\n  FROM artist LEFT JOIN work ON artist.id = work.artist_id\n  GROUP BY artist.id;\nYou can also explicitly specify the data type for a column in the created table:\nCREATE TABLE foo (a TINYINT NOT NULL) SELECT b+1 AS a FROM bar;\nFor CREATE TABLE ... SELECT, if IF NOT EXISTS is given and the target table exists, nothing is\ninserted into the destination table, and the statement is not logged.\nTo ensure that the binary log can be used to re-create the original tables, MySQL does not permit\nconcurrent inserts during CREATE TABLE ... SELECT. For more information, see Section 15.1.1,\n“Atomic Data Definition Statement Support”.\nYou cannot use FOR UPDATE as part of the SELECT in a statement such as CREATE TABLE\nnew_table SELECT ... FROM old_table .... If you attempt to do so, the statement fails.\nCREATE TABLE ... SELECT operations apply ENGINE_ATTRIBUTE and\nSECONDARY_ENGINE_ATTRIBUTE values to columns only. Table and index ENGINE_ATTRIBUTE and\nSECONDARY_ENGINE_ATTRIBUTE values are not applied to the new table unless specified explicitly.\n15.1.20.5 FOREIGN KEY Constraints\nMySQL supports foreign keys, which permit cross-referencing related data across tables, and foreign\nkey constraints, which help keep the related data consistent.\nA foreign key relationship involves a parent table that holds the initial column values, and a child table\nwith column values that reference the parent column values. A foreign key constraint is defined on the\nchild table.\nThe essential syntax for a defining a foreign key constraint in a CREATE TABLE or ALTER TABLE\nstatement includes the following:\n[CONSTRAINT [symbol]] FOREIGN KEY\n    [index_name] (col_name, ...)\n    REFERENCES tbl_name (col_name,...)\n    [ON DELETE reference_option]\n    [ON UPDATE reference_option]\nreference_option:\n    RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT\nForeign key constraint usage is described under the following topics in this section:\n• Identifiers\n• Conditions and Restrictions\n• Referential Actions\n• Foreign Key Constraint Examples\n• Adding Foreign Key Constraints\n• Dropping Foreign Key Constraints\n• Foreign Key Checks\n• Locking\n• Foreign Key Definitions and Metadata\n• Foreign Key Errors\nIdentifiers\nForeign key constraint naming is governed by the following rules:\n• The CONSTRAINT symbol value is used, if defined.\n• If the CONSTRAINT symbol clause is not defined, or a symbol is not included following the\nCONSTRAINT keyword, a constraint name name is generated automatically.\nIf the CONSTRAINT symbol clause is not defined, or a symbol is not included following the\nCONSTRAINT keyword, both InnoDB and NDB storage engines ignore FOREIGN_KEY index_name.\n• The CONSTRAINT symbol value, if defined, must be unique in the database. A duplicate\nsymbol results in an error similar to: ERROR 1005 (HY000): Can't create table\n'test.fk1' (errno: 121).\n• NDB Cluster stores foreign key names using the same lettercase with which they are created.\nTable and column identifiers in a FOREIGN KEY ... REFERENCES clause can be quoted within\nbackticks (`). Alternatively, double quotation marks (\") can be used if the ANSI_QUOTES SQL mode is\nenabled. The lower_case_table_names system variable setting is also taken into account.\nConditions and Restrictions\nForeign key constraints are subject to the following conditions and restrictions:\n• Parent and child tables must use the same storage engine, and they cannot be defined as temporary\ntables.\n• Creating a foreign key constraint requires the REFERENCES privilege on the parent table.\n• Corresponding columns in the foreign key and the referenced key must have similar data types. The\nsize and sign of fixed precision types such as INTEGER and DECIMAL must be the same. The length\nof string types need not be the same. For nonbinary (character) string columns, the character set and\ncollation must be the same.\n• MySQL supports foreign key references between one column and another within a table. (A column\ncannot have a foreign key reference to itself.) In these cases, a “child table record” refers to a\ndependent record within the same table.\n• MySQL requires indexes on foreign keys and referenced keys so that foreign key checks can be\nfast and not require a table scan. In the referencing table, there must be an index where the foreign\nkey columns are listed as the first columns in the same order. Such an index is created on the\nreferencing table automatically if it does not exist. This index might be silently dropped later if you\ncreate another index that can be used to enforce the foreign key constraint. index_name, if given, is\nused as described previously.\n• Previously, InnoDB allowed a foreign key to reference any index column or group of columns,\neven a non-unique index or partial index, an extension of standard SQL. This is still allowed\nfor backwards compatibility, but is now deprecated; in addition, it must be enabled by setting\nrestrict_fk_on_non_standard_key. If this is done, there must still be an index in the\nreferenced table where the referenced columns are the first columns in the same order. Hidden\ncolumns that InnoDB adds to an index are also considered in such cases (see Section 17.6.2.1,\n“Clustered and Secondary Indexes”). You should expect support for use of nonstandard keys to be\nremoved in a future version of MySQL, and migrate away from their use.\nNDB always requires an explicit unique key (or primary key) on any column referenced as a foreign\nkey.\n• Index prefixes on foreign key columns are not supported. Consequently, BLOB and TEXT columns\ncannot be included in a foreign key because indexes on those columns must always include a prefix\nlength.\n• InnoDB does not currently support foreign keys for tables with user-defined partitioning. This\nincludes both parent and child tables.\nThis restriction does not apply for NDB tables that are partitioned by KEY or LINEAR KEY (the only\nuser partitioning types supported by the NDB storage engine); these may have foreign key references\nor be the targets of such references.\n• A table in a foreign key relationship cannot be altered to use another storage engine. To change the\nstorage engine, you must drop any foreign key constraints first.\n• A foreign key constraint cannot reference a virtual generated column.\nFor information about how the MySQL implementation of foreign key constraints differs from the SQL\nstandard, see Section 1.7.2.3, “FOREIGN KEY Constraint Differences”.\nReferential Actions\nWhen an UPDATE or DELETE operation affects a key value in the parent table that has matching rows\nin the child table, the result depends on the referential action specified by ON UPDATE and ON DELETE\nsubclauses of the FOREIGN KEY clause. Referential actions include:\n• CASCADE: Delete or update the row from the parent table and automatically delete or update the\nmatching rows in the child table. Both ON DELETE CASCADE and ON UPDATE CASCADE are\nsupported. Between two tables, do not define several ON UPDATE CASCADE clauses that act on the\nsame column in the parent table or in the child table.\nIf a FOREIGN KEY clause is defined on both tables in a foreign key relationship, making both tables\na parent and child, an ON UPDATE CASCADE or ON DELETE CASCADE subclause defined for one\nFOREIGN KEY clause must be defined for the other in order for cascading operations to succeed.\nIf an ON UPDATE CASCADE or ON DELETE CASCADE subclause is only defined for one FOREIGN\nKEY clause, cascading operations fail with an error.\nNote\nCascaded foreign key actions do not activate triggers.\n• SET NULL: Delete or update the row from the parent table and set the foreign key column or\ncolumns in the child table to NULL. Both ON DELETE SET NULL and ON UPDATE SET NULL\nclauses are supported.\nIf you specify a SET NULL action, make sure that you have not declared the columns in the child\ntable as NOT NULL.\n• RESTRICT: Rejects the delete or update operation for the parent table. Specifying RESTRICT (or NO\nACTION) is the same as omitting the ON DELETE or ON UPDATE clause.\n• NO ACTION: A keyword from standard SQL. For InnoDB, this is equivalent to RESTRICT; the delete\nor update operation for the parent table is immediately rejected if there is a related foreign key value\nin the referenced table. NDB supports deferred checks, and NO ACTION specifies a deferred check;\nwhen this is used, constraint checks are not performed until commit time. Note that for NDB tables,\nthis causes all foreign key checks made for both parent and child tables to be deferred.\n• SET DEFAULT: This action is recognized by the MySQL parser, but both InnoDB and NDB reject\ntable definitions containing ON DELETE SET DEFAULT or ON UPDATE SET DEFAULT clauses.\nFor storage engines that support foreign keys, MySQL rejects any INSERT or UPDATE operation that\nattempts to create a foreign key value in a child table if there is no matching candidate key value in the\nparent table.\nFor an ON DELETE or ON UPDATE that is not specified, the default action is always NO ACTION.\nAs the default, an ON DELETE NO ACTION or ON UPDATE NO ACTION clause that is specified\nexplicitly does not appear in SHOW CREATE TABLE output or in tables dumped with mysqldump.\nRESTRICT, which is an equivalent non-default keyword, appears in SHOW CREATE TABLE output and\nin tables dumped with mysqldump.\nFor NDB tables, ON UPDATE CASCADE is not supported where the reference is to the parent table's\nprimary key.\nFor NDB tables, ON DELETE CASCADE is not supported where the child table contains one or more\ncolumns of any of the TEXT or BLOB types. (Bug #89511, Bug #27484882)\nInnoDB performs cascading operations using a depth-first search algorithm on the records of the index\nthat corresponds to the foreign key constraint.\nA foreign key constraint on a stored generated column cannot use CASCADE, SET NULL, or SET\nDEFAULT as ON UPDATE referential actions, nor can it use SET NULL or SET DEFAULT as ON\nDELETE referential actions.\nA foreign key constraint on the base column of a stored generated column cannot use CASCADE, SET\nNULL, or SET DEFAULT as ON UPDATE or ON DELETE referential actions.\nForeign Key Constraint Examples\nThis simple example relates parent and child tables through a single-column foreign key:\nCREATE TABLE parent (\n    id INT NOT NULL,\n    PRIMARY KEY (id)\n) ENGINE=INNODB;\nCREATE TABLE child (\n    id INT,\n    parent_id INT,\n    INDEX par_ind (parent_id),\n    FOREIGN KEY (parent_id)\n        REFERENCES parent(id)\n        ON DELETE CASCADE\n) ENGINE=INNODB;\nMySQL 9.1 supports inline REFERENCE clauses as well as implicit parent table primary keys, so the\nsecond CREATE TABLE statement can be rewritten as shown here:\nCREATE TABLE child (\n    id INT,\n    parent_id INT NOT NULL REFERENCES parent ON DELETE CASCADE,\n    INDEX par_ind (parent_id)\n) ENGINE=INNODB;\nThis is a more complex example in which a product_order table has foreign keys for two other\ntables. One foreign key references a two-column index in the product table. The other references a\nsingle-column index in the customer table:\nCREATE TABLE product (\n    category INT NOT NULL, id INT NOT NULL,\n    price DECIMAL,\n    PRIMARY KEY(category, id)\n)   ENGINE=INNODB;\nCREATE TABLE customer (\n    id INT NOT NULL,\n    PRIMARY KEY (id)\n)   ENGINE=INNODB;\nCREATE TABLE product_order (\n    no INT NOT NULL AUTO_INCREMENT,\n    product_category INT NOT NULL,\n    product_id INT NOT NULL,\n    customer_id INT NOT NULL,\n    PRIMARY KEY(no),\n    INDEX (product_category, product_id),\n    INDEX (customer_id),\n    FOREIGN KEY (product_category, product_id)\n      REFERENCES product(category, id)\n      ON UPDATE CASCADE ON DELETE RESTRICT,\n    FOREIGN KEY (customer_id)\n      REFERENCES customer(id)\n)   ENGINE=INNODB;\nAdding Foreign Key Constraints\nYou can add a foreign key constraint to an existing table using the following ALTER TABLE syntax:\nALTER TABLE tbl_name\n    ADD [CONSTRAINT [symbol]] FOREIGN KEY\n    [index_name] (col_name, ...)\n    REFERENCES tbl_name (col_name,...)\n    [ON DELETE reference_option]\n    [ON UPDATE reference_option]\nThe foreign key can be self referential (referring to the same table). When you add a foreign key\nconstraint to a table using ALTER TABLE, remember to first create an index on the column(s)\nreferenced by the foreign key.\nDropping Foreign Key Constraints\nYou can drop a foreign key constraint using the following ALTER TABLE syntax:\nALTER TABLE tbl_name DROP FOREIGN KEY fk_symbol;\nIf the FOREIGN KEY clause defined a CONSTRAINT name when you created the constraint, you can\nrefer to that name to drop the foreign key constraint. Otherwise, a constraint name was generated\ninternally, and you must use that value. To determine the foreign key constraint name, use SHOW\nCREATE TABLE:\nmysql> SHOW CREATE TABLE child\\G\n*************************** 1. row ***************************\n       Table: child\nCreate Table: CREATE TABLE `child` (\n  `id` int DEFAULT NULL,\n  `parent_id` int NOT NULL,\n  KEY `par_ind` (`parent_id`),\n  CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`)\n  REFERENCES `parent` (`id`) ON DELETE CASCADE\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nmysql> ALTER TABLE child DROP FOREIGN KEY `child_ibfk_1`;\nAdding and dropping a foreign key in the same ALTER TABLE statement is supported for ALTER\nTABLE ... ALGORITHM=INPLACE. It is not supported for ALTER TABLE ... ALGORITHM=COPY.\nForeign Key Checks\nIn MySQL, InnoDB and NDB tables support checking of foreign key constraints. Foreign key\nchecking is controlled by the foreign_key_checks variable, which is enabled by default.\nTypically, you leave this variable enabled during normal operation to enforce referential integrity. The\nforeign_key_checks variable has the same effect on NDB tables as it does for InnoDB tables.\nThe foreign_key_checks variable is dynamic and supports both global and session scopes. For\ninformation about using system variables, see Section 7.1.9, “Using System Variables”.\nDisabling foreign key checking is useful when:\n• Dropping a table that is referenced by a foreign key constraint. A referenced table can only be\ndropped after foreign_key_checks is disabled. When you drop a table, constraints defined on the\ntable are also dropped.\n• Reloading tables in different order than required by their foreign key relationships. For example,\nmysqldump produces correct definitions of tables in the dump file, including foreign key\nconstraints for child tables. To make it easier to reload dump files for tables with foreign key\nrelationships, mysqldump automatically includes a statement in the dump output that disables\nforeign_key_checks. This enables you to import the tables in any order in case the dump file\ncontains tables that are not correctly ordered for foreign keys. Disabling foreign_key_checks\nalso speeds up the import operation by avoiding foreign key checks.\n• Executing LOAD DATA operations, to avoid foreign key checking.\n• Performing an ALTER TABLE operation on a table that has a foreign key relationship.\nWhen foreign_key_checks is disabled, foreign key constraints are ignored, with the following\nexceptions:\n• Recreating a table that was previously dropped returns an error if the table definition does not\nconform to the foreign key constraints that reference the table. The table must have the correct\ncolumn names and types. It must also have indexes on the referenced keys. If these requirements\nare not satisfied, MySQL returns Error 1005 that refers to errno: 150 in the error message, which\nmeans that a foreign key constraint was not correctly formed.\n• Altering a table returns an error (errno: 150) if a foreign key definition is incorrectly formed for the\naltered table.\n• Dropping an index required by a foreign key constraint. The foreign key constraint must be removed\nbefore dropping the index.\n• Creating a foreign key constraint where a column references a nonmatching column type.\nDisabling foreign_key_checks has these additional implications:\n• It is permitted to drop a database that contains tables with foreign keys that are referenced by tables\noutside the database.\n• It is permitted to drop a table with foreign keys referenced by other tables.\n• Enabling foreign_key_checks does not trigger a scan of table data, which means that rows\nadded to a table while foreign_key_checks is disabled are not checked for consistency when\nforeign_key_checks is re-enabled.\nLocking\nMySQL extends metadata locks, as necessary, to tables that are related by a foreign key constraint.\nExtending metadata locks prevents conflicting DML and DDL operations from executing concurrently\non related tables. This feature also enables updates to foreign key metadata when a parent table is\nmodified. In earlier MySQL releases, foreign key metadata, which is owned by the child table, could not\nbe updated safely.\nIf a table is locked explicitly with LOCK TABLES, any tables related by a foreign key constraint are\nopened and locked implicitly. For foreign key checks, a shared read-only lock (LOCK TABLES READ) is\ntaken on related tables. For cascading updates, a shared-nothing write lock (LOCK TABLES WRITE) is\ntaken on related tables that are involved in the operation.\nForeign Key Definitions and Metadata\nTo view a foreign key definition, use SHOW CREATE TABLE:\nmysql> SHOW CREATE TABLE child\\G\n*************************** 1. row ***************************\n       Table: child\nCreate Table: CREATE TABLE `child` (\n  `id` int DEFAULT NULL,\n  `parent_id` int NOT NULL,\n  KEY `par_ind` (`parent_id`),\n  CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) \n  REFERENCES `parent` (`id`) ON DELETE CASCADE\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nYou can obtain information about foreign keys from the Information Schema KEY_COLUMN_USAGE\ntable. An example of a query against this table is shown here:\nmysql> SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, CONSTRAINT_NAME\n       FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE\n       WHERE REFERENCED_TABLE_SCHEMA IS NOT NULL;\n+--------------+------------+-------------+-----------------+\n| TABLE_SCHEMA | TABLE_NAME | COLUMN_NAME | CONSTRAINT_NAME |\n+--------------+------------+-------------+-----------------+\n| test         | child      | parent_id   | child_ibfk_1    |\n+--------------+------------+-------------+-----------------+\nYou can obtain information specific to InnoDB foreign keys from the INNODB_FOREIGN and\nINNODB_FOREIGN_COLS tables. Example queries are show here:\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_FOREIGN \\G\n*************************** 1. row ***************************\n      ID: test/child_ibfk_1\nFOR_NAME: test/child\nREF_NAME: test/parent\n  N_COLS: 1\n    TYPE: 1\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_FOREIGN_COLS \\G\n*************************** 1. row ***************************\n          ID: test/child_ibfk_1\nFOR_COL_NAME: parent_id\nREF_COL_NAME: id\n         POS: 0\nForeign Key Errors\nIn the event of a foreign key error involving InnoDB tables (usually Error 150 in the MySQL Server),\ninformation about the latest foreign key error can be obtained by checking SHOW ENGINE INNODB\nSTATUS output.\nmysql> SHOW ENGINE INNODB STATUS\\G\n...\n------------------------\nLATEST FOREIGN KEY ERROR\n------------------------\n2018-04-12 14:57:24 0x7f97a9c91700 Transaction:\nTRANSACTION 7717, ACTIVE 0 sec inserting\nmysql tables in use 1, locked 1\n4 lock struct(s), heap size 1136, 3 row lock(s), undo log entries 3\nMySQL thread id 8, OS thread handle 140289365317376, query id 14 localhost root update\nINSERT INTO child VALUES (NULL, 1), (NULL, 2), (NULL, 3), (NULL, 4), (NULL, 5), (NULL, 6)\nForeign key constraint fails for table `test`.`child`:\n,\n  CONSTRAINT `child_ibfk_1` FOREIGN KEY (`parent_id`) REFERENCES `parent` (`id`) ON DELETE\n  CASCADE ON UPDATE CASCADE\nTrying to add in child table, in index par_ind tuple:\nDATA TUPLE: 2 fields;\n 0: len 4; hex 80000003; asc     ;;\n 1: len 4; hex 80000003; asc     ;;\nBut in parent table `test`.`parent`, in index PRIMARY,\nthe closest match we can find is record:\nPHYSICAL RECORD: n_fields 3; compact format; info bits 0\n 0: len 4; hex 80000004; asc     ;;\n 1: len 6; hex 000000001e19; asc       ;;\n 2: len 7; hex 81000001110137; asc       7;;\n...\nWarning\nIf a user has table-level privileges for all parent tables,\nER_NO_REFERENCED_ROW_2 and ER_ROW_IS_REFERENCED_2 error\nmessages for foreign key operations expose information about parent tables.\nIf a user does not have table-level privileges for all parent tables, more generic\nerror messages are displayed instead (ER_NO_REFERENCED_ROW and\nER_ROW_IS_REFERENCED).\nAn exception is that, for stored programs defined to execute with DEFINER\nprivileges, the user against which privileges are assessed is the user in the\nprogram DEFINER clause, not the invoking user. If that user has table-level\nparent table privileges, parent table information is still displayed. In this case,\nit is the responsibility of the stored program creator to hide the information by\nincluding appropriate condition handlers.\n15.1.20.6 CHECK Constraints\nCREATE TABLE permits the core features of table and column CHECK constraints, for all storage\nengines. CREATE TABLE permits the following CHECK constraint syntax, for both table constraints and\ncolumn constraints:\n[CONSTRAINT [symbol]] CHECK (expr) [[NOT] ENFORCED]\nThe optional symbol specifies a name for the constraint. If omitted, MySQL generates a name from\nthe table name, a literal _chk_, and an ordinal number (1, 2, 3, ...). Constraint names have a maximum\nlength of 64 characters. They are case-sensitive, but not accent-sensitive.\nexpr specifies the constraint condition as a boolean expression that must evaluate to TRUE or\nUNKNOWN (for NULL values) for each row of the table. If the condition evaluates to FALSE, it fails and\na constraint violation occurs. The effect of a violation depends on the statement being executed, as\ndescribed later in this section.\nThe optional enforcement clause indicates whether the constraint is enforced:\n• If omitted or specified as ENFORCED, the constraint is created and enforced.\n• If specified as NOT ENFORCED, the constraint is created but not enforced.\nA CHECK constraint is specified as either a table constraint or column constraint:\n• A table constraint does not appear within a column definition and can refer to any table column or\ncolumns. Forward references are permitted to columns appearing later in the table definition.\n• A column constraint appears within a column definition and can refer only to that column.\nConsider this table definition:\nCREATE TABLE t1\n(\n  CHECK (c1 <> c2),\n  c1 INT CHECK (c1 > 10),\n  c2 INT CONSTRAINT c2_positive CHECK (c2 > 0),\n  c3 INT CHECK (c3 < 100),\n  CONSTRAINT c1_nonzero CHECK (c1 <> 0),\n  CHECK (c1 > c3)\n);\nThe definition includes table constraints and column constraints, in named and unnamed formats:\n• The first constraint is a table constraint: It occurs outside any column definition, so it can (and does)\nrefer to multiple table columns. This constraint contains forward references to columns not defined\nyet. No constraint name is specified, so MySQL generates a name.\n• The next three constraints are column constraints: Each occurs within a column definition, and\nthus can refer only to the column being defined. One of the constraints is named explicitly. MySQL\ngenerates a name for each of the other two.\n• The last two constraints are table constraints. One of them is named explicitly. MySQL generates a\nname for the other one.\nAs mentioned, MySQL generates a name for any CHECK constraint specified without one. To see the\nnames generated for the preceding table definition, use SHOW CREATE TABLE:\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `c1` int(11) DEFAULT NULL,\n  `c2` int(11) DEFAULT NULL,\n  `c3` int(11) DEFAULT NULL,\n  CONSTRAINT `c1_nonzero` CHECK ((`c1` <> 0)),\n  CONSTRAINT `c2_positive` CHECK ((`c2` > 0)),\n  CONSTRAINT `t1_chk_1` CHECK ((`c1` <> `c2`)),\n  CONSTRAINT `t1_chk_2` CHECK ((`c1` > 10)),\n  CONSTRAINT `t1_chk_3` CHECK ((`c3` < 100)),\n  CONSTRAINT `t1_chk_4` CHECK ((`c1` > `c3`))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nThe SQL standard specifies that all types of constraints (primary key, unique index, foreign key, check)\nbelong to the same namespace. In MySQL, each constraint type has its own namespace per schema\n(database). Consequently, CHECK constraint names must be unique per schema; no two tables in\nthe same schema can share a CHECK constraint name. (Exception: A TEMPORARY table hides a\nnon-TEMPORARY table of the same name, so it can have the same CHECK constraint names as well.)\nBeginning generated constraint names with the table name helps ensure schema uniqueness because\ntable names also must be unique within the schema.\nCHECK condition expressions must adhere to the following rules. An error occurs if an expression\ncontains disallowed constructs.\n• Nongenerated and generated columns are permitted, except columns with the AUTO_INCREMENT\nattribute and columns in other tables.\n• Literals, deterministic built-in functions, and operators are permitted. A function is deterministic\nif, given the same data in tables, multiple invocations produce the same result, independently\nof the connected user. Examples of functions that are nondeterministic and fail this definition:\nCONNECTION_ID(), CURRENT_USER(), NOW().\n• Stored functions and loadable functions are not permitted.\n• Stored procedure and function parameters are not permitted.\n• Variables (system variables, user-defined variables, and stored program local variables) are not\npermitted.\n• Subqueries are not permitted.\nForeign key referential actions (ON UPDATE, ON DELETE) are prohibited on columns used in CHECK\nconstraints. Likewise, CHECK constraints are prohibited on columns used in foreign key referential\nactions.\nCHECK constraints are evaluated for INSERT, UPDATE, REPLACE, LOAD DATA, and LOAD XML\nstatements and an error occurs if a constraint evaluates to FALSE. If an error occurs, handling of\nchanges already applied differs for transactional and nontransactional storage engines, and also\ndepends on whether strict SQL mode is in effect, as described in Strict SQL Mode.\nCHECK constraints are evaluated for INSERT IGNORE, UPDATE IGNORE, LOAD DATA ... IGNORE,\nand LOAD XML ... IGNORE statements and a warning occurs if a constraint evaluates to FALSE.\nThe insert or update for any offending row is skipped.\nIf the constraint expression evaluates to a data type that differs from the declared column type, implicit\ncoercion to the declared type occurs according to the usual MySQL type-conversion rules. See\nSection 14.3, “Type Conversion in Expression Evaluation”. If type conversion fails or results in a loss of\nprecision, an error occurs.\nNote\nConstraint expression evaluation uses the SQL mode in effect at evaluation\ntime. If any component of the expression depends on the SQL mode, different\nresults may occur for different uses of the table unless the SQL mode is the\nsame during all uses.\nThe Information Schema CHECK_CONSTRAINTS table provides information about CHECK constraints\ndefined on tables. See Section 28.3.5, “The INFORMATION_SCHEMA CHECK_CONSTRAINTS\nTable”.\n15.1.20.7 Silent Column Specification Changes\nIn some cases, MySQL silently changes column specifications from those given in a CREATE TABLE or\nALTER TABLE statement. These might be changes to a data type, to attributes associated with a data\ntype, or to an index specification.\nAll changes are subject to the internal row-size limit of 65,535 bytes, which may cause some attempts\nat data type changes to fail. See Section 10.4.7, “Limits on Table Column Count and Row Size”.\n• Columns that are part of a PRIMARY KEY are made NOT NULL even if not declared that way.\n• Trailing spaces are automatically deleted from ENUM and SET member values when the table is\ncreated.\n• MySQL maps certain data types used by other SQL database vendors to MySQL types. See\nSection 13.9, “Using Data Types from Other Database Engines”.\n• If you include a USING clause to specify an index type that is not permitted for a given storage\nengine, but there is another index type available that the engine can use without affecting query\nresults, the engine uses the available type.\n• If strict SQL mode is not enabled, a VARCHAR column with a length specification greater than 65535\nis converted to TEXT, and a VARBINARY column with a length specification greater than 65535 is\nconverted to BLOB. Otherwise, an error occurs in either of these cases.\n• Specifying the CHARACTER SET binary attribute for a character data type causes the column\nto be created as the corresponding binary data type: CHAR becomes BINARY, VARCHAR becomes\nVARBINARY, and TEXT becomes BLOB. For the ENUM and SET data types, this does not occur; they\nare created as declared. Suppose that you specify a table using this definition:\nCREATE TABLE t\n(\n  c1 VARCHAR(10) CHARACTER SET binary,\n  c2 TEXT CHARACTER SET binary,\n  c3 ENUM('a','b','c') CHARACTER SET binary\n);\nThe resulting table has this definition:\nCREATE TABLE t\n(\n  c1 VARBINARY(10),\n  c2 BLOB,\n  c3 ENUM('a','b','c') CHARACTER SET binary\n);\nTo see whether MySQL used a data type other than the one you specified, issue a DESCRIBE or SHOW\nCREATE TABLE statement after creating or altering the table.\nCertain other data type changes can occur if you compress a table using myisampack. See\nSection 18.2.3.3, “Compressed Table Characteristics”.\n15.1.20.8 CREATE TABLE and Generated Columns\nCREATE TABLE supports the specification of generated columns. Values of a generated column are\ncomputed from an expression included in the column definition.\nGenerated columns are also supported by the NDB storage engine.\nThe following simple example shows a table that stores the lengths of the sides of right triangles in the\nsidea and sideb columns, and computes the length of the hypotenuse in sidec (the square root of\nthe sums of the squares of the other sides):\nCREATE TABLE triangle (\n  sidea DOUBLE,\n  sideb DOUBLE,\n  sidec DOUBLE AS (SQRT(sidea * sidea + sideb * sideb))\n);\nINSERT INTO triangle (sidea, sideb) VALUES(1,1),(3,4),(6,8);\nSelecting from the table yields this result:\nmysql> SELECT * FROM triangle;\n+-------+-------+--------------------+\n| sidea | sideb | sidec              |\n+-------+-------+--------------------+\n|     1 |     1 | 1.4142135623730951 |\n|     3 |     4 |                  5 |\n|     6 |     8 |                 10 |\n+-------+-------+--------------------+\nAny application that uses the triangle table has access to the hypotenuse values without having to\nspecify the expression that calculates them.\nGenerated column definitions have this syntax:\ncol_name data_type [GENERATED ALWAYS] AS (expr)\n  [VIRTUAL | STORED] [NOT NULL | NULL]\n  [UNIQUE [KEY]] [[PRIMARY] KEY]\n  [COMMENT 'string']\nAS (expr) indicates that the column is generated and defines the expression used to compute\ncolumn values. AS may be preceded by GENERATED ALWAYS to make the generated nature of the\ncolumn more explicit. Constructs that are permitted or prohibited in the expression are discussed later.\nThe VIRTUAL or STORED keyword indicates how column values are stored, which has implications for\ncolumn use:\n• VIRTUAL: Column values are not stored, but are evaluated when rows are read, immediately after\nany BEFORE triggers. A virtual column takes no storage.\nInnoDB supports secondary indexes on virtual columns. See Section 15.1.20.9, “Secondary Indexes\nand Generated Columns”.\n• STORED: Column values are evaluated and stored when rows are inserted or updated. A stored\ncolumn does require storage space and can be indexed.\nThe default is VIRTUAL if neither keyword is specified.\nIt is permitted to mix VIRTUAL and STORED columns within a table.\nOther attributes may be given to indicate whether the column is indexed or can be NULL, or provide a\ncomment.\nGenerated column expressions must adhere to the following rules. An error occurs if an expression\ncontains disallowed constructs.\n• Literals, deterministic built-in functions, and operators are permitted. A function is deterministic\nif, given the same data in tables, multiple invocations produce the same result, independently\nof the connected user. Examples of functions that are nondeterministic and fail this definition:\nCONNECTION_ID(), CURRENT_USER(), NOW().\n• Stored functions and loadable functions are not permitted.\n• Stored procedure and function parameters are not permitted.\n• Variables (system variables, user-defined variables, and stored program local variables) are not\npermitted.\n• Subqueries are not permitted.\n• A generated column definition can refer to other generated columns, but only those occurring earlier\nin the table definition. A generated column definition can refer to any base (nongenerated) column in\nthe table whether its definition occurs earlier or later.\n• The AUTO_INCREMENT attribute cannot be used in a generated column definition.\n• An AUTO_INCREMENT column cannot be used as a base column in a generated column definition.\n• If expression evaluation causes truncation or provides incorrect input to a function, the CREATE\nTABLE statement terminates with an error and the DDL operation is rejected.\nIf the expression evaluates to a data type that differs from the declared column type, implicit coercion to\nthe declared type occurs according to the usual MySQL type-conversion rules. See Section 14.3, “Type\nConversion in Expression Evaluation”.\nIf a generated column uses the TIMESTAMP data type, the setting for\nexplicit_defaults_for_timestamp is ignored. In such cases, if this variable is disabled\nthen NULL is not converted to CURRENT_TIMESTAMP. If the column is also declared as NOT NULL,\nattempting to insert NULL is explicitly rejected with ER_BAD_NULL_ERROR.\nNote\nExpression evaluation uses the SQL mode in effect at evaluation time. If any\ncomponent of the expression depends on the SQL mode, different results may\noccur for different uses of the table unless the SQL mode is the same during all\nuses.\nFor CREATE TABLE ... LIKE, the destination table preserves generated column information from\nthe original table.\nFor CREATE TABLE ... SELECT, the destination table does not preserve information about whether\ncolumns in the selected-from table are generated columns. The SELECT part of the statement cannot\nassign values to generated columns in the destination table.\nPartitioning by generated columns is permitted. See Table Partitioning.\nA foreign key constraint on a stored generated column cannot use CASCADE, SET NULL, or SET\nDEFAULT as ON UPDATE referential actions, nor can it use SET NULL or SET DEFAULT as ON\nDELETE referential actions.\nA foreign key constraint on the base column of a stored generated column cannot use CASCADE, SET\nNULL, or SET DEFAULT as ON UPDATE or ON DELETE referential actions.\nA foreign key constraint cannot reference a virtual generated column.\nTriggers cannot use NEW.col_name or use OLD.col_name to refer to generated columns.\nFor INSERT, REPLACE, and UPDATE, if a generated column is inserted into, replaced, or updated\nexplicitly, the only permitted value is DEFAULT.\nA generated column in a view is considered updatable because it is possible to assign to it. However, if\nsuch a column is updated explicitly, the only permitted value is DEFAULT.\nGenerated columns have several use cases, such as these:\n• Virtual generated columns can be used as a way to simplify and unify queries. A complicated\ncondition can be defined as a generated column and referred to from multiple queries on the table to\nensure that all of them use exactly the same condition.\n• Stored generated columns can be used as a materialized cache for complicated conditions that are\ncostly to calculate on the fly.\n• Generated columns can simulate functional indexes: Use a generated column to define a functional\nexpression and index it. This can be useful for working with columns of types that cannot be indexed\ndirectly, such as JSON columns; see Indexing a Generated Column to Provide a JSON Column\nIndex, for a detailed example.\nFor stored generated columns, the disadvantage of this approach is that values are stored twice;\nonce as the value of the generated column and once in the index.\n• If a generated column is indexed, the optimizer recognizes query expressions that match the column\ndefinition and uses indexes from the column as appropriate during query execution, even if a query\ndoes not refer to the column directly by name. For details, see Section 10.3.11, “Optimizer Use of\nGenerated Column Indexes”.\nExample:\nSuppose that a table t1 contains first_name and last_name columns and that applications\nfrequently construct the full name using an expression like this:\nSELECT CONCAT(first_name,' ',last_name) AS full_name FROM t1;\nOne way to avoid writing out the expression is to create a view v1 on t1, which simplifies applications\nby enabling them to select full_name directly without using an expression:\nCREATE VIEW v1 AS\nSELECT *, CONCAT(first_name,' ',last_name) AS full_name FROM t1;\nSELECT full_name FROM v1;\nA generated column also enables applications to select full_name directly without the need to define\na view:\nCREATE TABLE t1 (\n  first_name VARCHAR(10),\n  last_name VARCHAR(10),\n  full_name VARCHAR(255) AS (CONCAT(first_name,' ',last_name))\n);\nSELECT full_name FROM t1;\n15.1.20.9 Secondary Indexes and Generated Columns\nInnoDB supports secondary indexes on virtual generated columns. Other index types are not\nsupported. A secondary index defined on a virtual column is sometimes referred to as a “virtual index”.\nA secondary index may be created on one or more virtual columns or on a combination of virtual\ncolumns and regular columns or stored generated columns. Secondary indexes that include virtual\ncolumns may be defined as UNIQUE.\nWhen a secondary index is created on a virtual generated column, generated column values are\nmaterialized in the records of the index. If the index is a covering index (one that includes all the\ncolumns retrieved by a query), generated column values are retrieved from materialized values in the\nindex structure instead of computed “on the fly”.\nThere are additional write costs to consider when using a secondary index on a virtual column due to\ncomputation performed when materializing virtual column values in secondary index records during\nINSERT and UPDATE operations. Even with additional write costs, secondary indexes on virtual\ncolumns may be preferable to generated stored columns, which are materialized in the clustered index,\nresulting in larger tables that require more disk space and memory. If a secondary index is not defined\non a virtual column, there are additional costs for reads, as virtual column values must be computed\neach time the column's row is examined.\nValues of an indexed virtual column are MVCC-logged to avoid unnecessary recomputation of\ngenerated column values during rollback or during a purge operation. The data length of logged values\nis limited by the index key limit of 767 bytes for COMPACT and REDUNDANT row formats, and 3072 bytes\nfor DYNAMIC and COMPRESSED row formats.\nAdding or dropping a secondary index on a virtual column is an in-place operation.\nIndexing a Generated Column to Provide a JSON Column Index\nAs noted elsewhere, JSON columns cannot be indexed directly. To create an index that references\nsuch a column indirectly, you can define a generated column that extracts the information that should\nbe indexed, then create an index on the generated column, as shown in this example:\nmysql> CREATE TABLE jemp (\n    ->     c JSON,\n    ->     g INT GENERATED ALWAYS AS (c->\"$.id\"),\n    ->     INDEX i (g)\n    -> );\nQuery OK, 0 rows affected (0.28 sec)\nmysql> INSERT INTO jemp (c) VALUES\n     >   ('{\"id\": \"1\", \"name\": \"Fred\"}'), ('{\"id\": \"2\", \"name\": \"Wilma\"}'),\n     >   ('{\"id\": \"3\", \"name\": \"Barney\"}'), ('{\"id\": \"4\", \"name\": \"Betty\"}');\nQuery OK, 4 rows affected (0.04 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\nmysql> SELECT c->>\"$.name\" AS name\n     >     FROM jemp WHERE g > 2;\n+--------+\n| name   |\n+--------+\n| Barney |\n| Betty  |\n+--------+\n2 rows in set (0.00 sec)\nmysql> EXPLAIN SELECT c->>\"$.name\" AS name\n     >    FROM jemp WHERE g > 2\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jemp\n   partitions: NULL\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using where\n1 row in set, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`,'$.name'))\nAS `name` from `test`.`jemp` where (`test`.`jemp`.`g` > 2)\n1 row in set (0.00 sec)\n(We have wrapped the output from the last statement in this example to fit the viewing area.)\nWhen you use EXPLAIN on a SELECT or other SQL statement containing one or more expressions\nthat use the -> or ->> operator, these expressions are translated into their equivalents using\nJSON_EXTRACT() and (if needed) JSON_UNQUOTE() instead, as shown here in the output from SHOW\nWARNINGS immediately following this EXPLAIN statement:\nmysql> EXPLAIN SELECT c->>\"$.name\"\n     > FROM jemp WHERE g > 2 ORDER BY c->\"$.name\"\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jemp\n   partitions: NULL\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 2\n     filtered: 100.00\n        Extra: Using where; Using filesort\n1 row in set, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`,'$.name')) AS\n`c->>\"$.name\"` from `test`.`jemp` where (`test`.`jemp`.`g` > 2) order by\njson_extract(`test`.`jemp`.`c`,'$.name')\n1 row in set (0.00 sec)\nSee the descriptions of the -> and ->> operators, as well as those of the JSON_EXTRACT() and\nJSON_UNQUOTE() functions, for additional information and examples.\nThis technique also can be used to provide indexes that indirectly reference columns of other types that\ncannot be indexed directly, such as GEOMETRY columns.\nIt is also possible to create an index on a JSON column using the JSON_VALUE() function with an\nexpression that can be used to optimize queries employing the expression. See the description of that\nfunction for more information and examples.\nJSON columns and indirect indexing in NDB Cluster\n    It is also possible to use indirect indexing of JSON columns in MySQL NDB Cluster, subject to the\nfollowing conditions:\n1. NDB handles a JSON column value internally as a BLOB. This means that any NDB table having one\nor more JSON columns must have a primary key, else it cannot be recorded in the binary log.\n2. The NDB storage engine does not support indexing of virtual columns. Since the default for\ngenerated columns is VIRTUAL, you must specify explicitly the generated column to which to apply\nthe indirect index as STORED.\nThe CREATE TABLE statement used to create the table jempn shown here is a version of the jemp\ntable shown previously, with modifications making it compatible with NDB:\nCREATE TABLE jempn (\n  a BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  c JSON DEFAULT NULL,\n  g INT GENERATED ALWAYS AS (c->\"$.id\") STORED,\n  INDEX i (g)\n) ENGINE=NDB;\nWe can populate this table using the following INSERT statement:\nINSERT INTO jempn (c) VALUES\n  ('{\"id\": \"1\", \"name\": \"Fred\"}'),\n  ('{\"id\": \"2\", \"name\": \"Wilma\"}'),\n  ('{\"id\": \"3\", \"name\": \"Barney\"}'),\n  ('{\"id\": \"4\", \"name\": \"Betty\"}');\nNow NDB can use index i, as shown here:\nmysql> EXPLAIN SELECT c->>\"$.name\" AS name\n    ->           FROM jempn WHERE g > 2\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: jempn\n   partitions: p0,p1,p2,p3\n         type: range\npossible_keys: i\n          key: i\n      key_len: 5\n          ref: NULL\n         rows: 3\n     filtered: 100.00\n        Extra: Using pushed condition (`test`.`jempn`.`g` > 2)\n1 row in set, 1 warning (0.01 sec)\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select\njson_unquote(json_extract(`test`.`jempn`.`c`,'$.name')) AS `name` from\n`test`.`jempn` where (`test`.`jempn`.`g` > 2)   \n1 row in set (0.00 sec)\nYou should keep in mind that a stored generated column, as well as any index on such a column, uses\nDataMemory.\n15.1.20.10 Invisible Columns\nMySQL 9.1 supports invisible columns. An invisible column is normally hidden to queries, but can be\naccessed if explicitly referenced.\nAs an illustration of when invisible columns may be useful, suppose that an application uses SELECT\n* queries to access a table, and must continue to work without modification even if the table is altered\nto add a new column that the application does not expect to be there. In a SELECT * query, the *\nevaluates to all table columns, except those that are invisible, so the solution is to add the new column\nas an invisible column. The column remains “hidden” from SELECT * queries, and the application\ncontinues to work as previously. A newer version of the application can refer to the invisible column if\nnecessary by explicitly referencing it.\nThe following sections detail how MySQL treats invisible columns.\n• DDL Statements and Invisible Columns\n• DML Statements and Invisible Columns\n• Invisible Column Metadata\n• The Binary Log and Invisible Columns\nDDL Statements and Invisible Columns\nColumns are visible by default. To explicitly specify visibility for a new column, use a VISIBLE or\nINVISIBLE keyword as part of the column definition for CREATE TABLE or ALTER TABLE:\nCREATE TABLE t1 (\n  i INT,\n  j DATE INVISIBLE\n) ENGINE = InnoDB;\nALTER TABLE t1 ADD COLUMN k INT INVISIBLE;\nTo alter the visibility of an existing column, use a VISIBLE or INVISIBLE keyword with one of the\nALTER TABLE column-modification clauses:\nALTER TABLE t1 CHANGE COLUMN j j DATE VISIBLE;\nALTER TABLE t1 MODIFY COLUMN j DATE INVISIBLE;\nALTER TABLE t1 ALTER COLUMN j SET VISIBLE;\nA table must have at least one visible column. Attempting to make all columns invisible produces an\nerror.\nInvisible columns support the usual column attributes: NULL, NOT NULL, AUTO_INCREMENT, and so\nforth.\nGenerated columns can be invisible.\nIndex definitions can name invisible columns, including definitions for PRIMARY KEY and UNIQUE\nindexes. Although a table must have at least one visible column, an index definition need not have any\nvisible columns.\nAn invisible column dropped from a table is dropped in the usual way from any index definition that\nnames the column.\nForeign key constraints can be defined on invisible columns, and foreign key constraints can reference\ninvisible columns.\nCHECK constraints can be defined on invisible columns. For new or modified rows, violation of a CHECK\nconstraint on an invisible column produces an error.\nCREATE TABLE ... LIKE includes invisible columns, and they are invisible in the new table.\nCREATE TABLE ... SELECT does not include invisible columns, unless they are explicitly referenced\nin the SELECT part. However, even if explicitly referenced, a column that is invisible in the existing table\nis visible in the new table:\nmysql> CREATE TABLE t1 (col1 INT, col2 INT INVISIBLE);\nmysql> CREATE TABLE t2 AS SELECT col1, col2 FROM t1;\nmysql> SHOW CREATE TABLE t2\\G\n*************************** 1. row ***************************\n       Table: t2\nCreate Table: CREATE TABLE `t2` (\n  `col1` int DEFAULT NULL,\n  `col2` int DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nIf invisibility should be preserved, provide a definition for the invisible column in the CREATE TABLE\npart of the CREATE TABLE ... SELECT statement:\nmysql> CREATE TABLE t1 (col1 INT, col2 INT INVISIBLE);\nmysql> CREATE TABLE t2 (col2 INT INVISIBLE) AS SELECT col1, col2 FROM t1;\nmysql> SHOW CREATE TABLE t2\\G\n*************************** 1. row ***************************\n       Table: t2\nCreate Table: CREATE TABLE `t2` (\n  `col1` int DEFAULT NULL,\n  `col2` int DEFAULT NULL /*!80023 INVISIBLE */\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nViews can refer to invisible columns by explicitly referencing them in the SELECT statement that\ndefines the view. Changing a column's visibility subsequent to defining a view that references the\ncolumn does not change view behavior.\nDML Statements and Invisible Columns\nFor SELECT statements, an invisible column is not part of the result set unless explicitly referenced\nin the select list. In a select list, the * and tbl_name.* shorthands do not include invisible columns.\nNatural joins do not include invisible columns.\nConsider the following statement sequence:\nmysql> CREATE TABLE t1 (col1 INT, col2 INT INVISIBLE);\nmysql> INSERT INTO t1 (col1, col2) VALUES(1, 2), (3, 4);\nmysql> SELECT * FROM t1;\n+------+\n| col1 |\n+------+\n|    1 |\n|    3 |\n+------+\nmysql> SELECT col1, col2 FROM t1;\n+------+------+\n| col1 | col2 |\n+------+------+\n|    1 |    2 |\n|    3 |    4 |\n+------+------+\nThe first SELECT does not reference the invisible column col2 in the select list (because * does not\ninclude invisible columns), so col2 does not appear in the statement result. The second SELECT\nexplicitly references col2, so the column appears in the result.\nThe statement TABLE t1 produces the same output as the first SELECT statement. Since there is no\nway to specify columns in a TABLE statement, TABLE never displays invisible columns.\nFor statements that create new rows, an invisible column is assigned its implicit default value unless\nexplicitly referenced and assigned a value. For information about implicit defaults, see Implicit Default\nHandling.\nFor INSERT (and REPLACE, for non-replaced rows), implicit default assignment occurs with a missing\ncolumn list, an empty column list, or a nonempty column list that does not include the invisible column:\nCREATE TABLE t1 (col1 INT, col2 INT INVISIBLE);\nINSERT INTO t1 VALUES(...);\nINSERT INTO t1 () VALUES(...);\nINSERT INTO t1 (col1) VALUES(...);\nFor the first two INSERT statements, the VALUES() list must provide a value for each visible column\nand no invisible column. For the third INSERT statement, the VALUES() list must provide the same\nnumber of values as the number of named columns; the same is true when you use VALUES ROW()\nrather than VALUES().\nFor LOAD DATA and LOAD XML, implicit default assignment occurs with a missing column list or a\nnonempty column list that does not include the invisible column. Input rows should not include a value\nfor the invisible column.\nTo assign a value other than the implicit default for the preceding statements, explicitly name the\ninvisible column in the column list and provide a value for it.\nINSERT INTO ... SELECT * and REPLACE INTO ... SELECT * do not include invisible\ncolumns because * does not include invisible columns. Implicit default assignment occurs as described\npreviously.\nFor statements that insert or ignore new rows, or that replace or modify existing rows, based on values\nin a PRIMARY KEY or UNIQUE index, MySQL treats invisible columns the same as visible columns:\nInvisible columns participate in key value comparisons. Specifically, if a new row has the same value\nas an existing row for a unique key value, these behaviors occur whether the index columns are visible\nor invisible:\n• With the IGNORE modifier, INSERT, LOAD DATA, and LOAD XML ignore the new row.\n• REPLACE replaces the existing row with the new row. With the REPLACE modifier, LOAD DATA and\nLOAD XML do the same.\n• INSERT ... ON DUPLICATE KEY UPDATE updates the existing row.\nTo update invisible columns for UPDATE statements, name them and assign a value, just as for visible\ncolumns.\nInvisible Column Metadata\nInformation about whether a column is visible or invisible is available from the EXTRA column of the\nInformation Schema COLUMNS table or SHOW COLUMNS output. For example:\nmysql> SELECT TABLE_NAME, COLUMN_NAME, EXTRA\n       FROM INFORMATION_SCHEMA.COLUMNS\n       WHERE TABLE_SCHEMA = 'test' AND TABLE_NAME = 't1';\n+------------+-------------+-----------+\n| TABLE_NAME | COLUMN_NAME | EXTRA     |\n+------------+-------------+-----------+\n| t1         | i           |           |\n| t1         | j           |           |\n| t1         | k           | INVISIBLE |\n+------------+-------------+-----------+\nColumns are visible by default, so in that case, EXTRA displays no visibility information. For invisible\ncolumns, EXTRA displays INVISIBLE.\nSHOW CREATE TABLE displays invisible columns in the table definition, with the INVISIBLE keyword\nin a version-specific comment:\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `i` int DEFAULT NULL,\n  `j` int DEFAULT NULL,\n  `k` int DEFAULT NULL /*!80023 INVISIBLE */\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nmysqldump uses SHOW CREATE TABLE, so they include invisible columns in dumped table\ndefinitions. They also include invisible column values in dumped data.\nReloading a dump file into an older version of MySQL that does not support invisible columns causes\nthe version-specific comment to be ignored, which creates any invisible columns as visible.\nThe Binary Log and Invisible Columns\nMySQL treats invisible columns as follows with respect to events in the binary log:\n• Table-creation events include the INVISIBLE attribute for invisible columns.\n• Invisible columns are treated like visible columns in row events. They are included if needed\naccording to the binlog_row_image system variable setting.\n• When row events are applied, invisible columns are treated like visible columns in row events.\n• Invisible columns are treated like visible columns when computing writesets. In particular, writesets\ninclude indexes defined on invisible columns.\n• The mysqlbinlog command includes visibility in column metadata.\n15.1.20.11 Generated Invisible Primary Keys\nMySQL 9.1 supports generated invisible primary keys for any InnoDB table that is created without an\nexplicit primary key. When the sql_generate_invisible_primary_key server system variable is\nset to ON, the MySQL server automatically adds a generated invisible primary key (GIPK) to any such\ntable. This setting has no effect on tables created using any other storage engine than InnoDB.\nBy default, the value of sql_generate_invisible_primary_key is OFF, meaning that the\nautomatic addition of GIPKs is disabled. To illustrate how this affects table creation, we begin by\ncreating two identical tables, neither having a primary key, the only difference being that the first (table\nauto_0) is created with sql_generate_invisible_primary_key set to OFF, and the second\n(auto_1) after setting it to ON, as shown here:\nmysql> SELECT @@sql_generate_invisible_primary_key;\n+--------------------------------------+\n| @@sql_generate_invisible_primary_key |\n+--------------------------------------+\n|                                    0 |\n+--------------------------------------+\n1 row in set (0.00 sec)\nmysql> CREATE TABLE auto_0 (c1 VARCHAR(50), c2 INT);\nQuery OK, 0 rows affected (0.02 sec)\nmysql> SET sql_generate_invisible_primary_key=ON;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @@sql_generate_invisible_primary_key;\n+--------------------------------------+\n| @@sql_generate_invisible_primary_key |\n+--------------------------------------+\n|                                    1 |\n+--------------------------------------+\n1 row in set (0.00 sec)\nmysql> CREATE TABLE auto_1 (c1 VARCHAR(50), c2 INT);\nQuery OK, 0 rows affected (0.04 sec)\nCompare the output of these SHOW CREATE TABLE statements to see the difference in how the tables\nwere actually created:\nmysql> SHOW CREATE TABLE auto_0\\G\n*************************** 1. row ***************************\n       Table: auto_0\nCreate Table: CREATE TABLE `auto_0` (\n  `c1` varchar(50) DEFAULT NULL,\n  `c2` int DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\nmysql> SHOW CREATE TABLE auto_1\\G\n*************************** 1. row ***************************\n       Table: auto_1\nCreate Table: CREATE TABLE `auto_1` (\n  `my_row_id` bigint unsigned NOT NULL AUTO_INCREMENT /*!80023 INVISIBLE */,\n  `c1` varchar(50) DEFAULT NULL,\n  `c2` int DEFAULT NULL,\n  PRIMARY KEY (`my_row_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\nSince auto_1 had no primary key specified by the CREATE TABLE statement used to\ncreate it, setting sql_generate_invisible_primary_key = ON causes MySQL to add\nboth the invisible column my_row_id to this table and a primary key on that column. Since\nsql_generate_invisible_primary_key was OFF at the time that auto_0 was created, no such\nadditions were performed on that table.\nWhen a primary key is added to a table by the server, the column and key name is always my_row_id.\nFor this reason, when enabling generated invisible primary keys in this way, you cannot create a table\nhaving a column named my_row_id unless the table creation statement also specifies an explicit\nprimary key. (You are not required to name the column or key my_row_id in such cases.)\nmy_row_id is an invisible column, which means it is not shown in the output of SELECT * or TABLE;\nthe column must be selected explicitly by name. See Section 15.1.20.10, “Invisible Columns”.\nWhen GIPKs are enabled, a generated primary key cannot be altered other than to switch it between\nVISIBLE and INVISIBLE. To make the generated invisible primary key on auto_1 visible, execute\nthis ALTER TABLE statement:\nmysql> ALTER TABLE auto_1 ALTER COLUMN my_row_id SET VISIBLE;\nQuery OK, 0 rows affected (0.02 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> SHOW CREATE TABLE auto_1\\G\n*************************** 1. row ***************************\n       Table: auto_1\nCreate Table: CREATE TABLE `auto_1` (\n  `my_row_id` bigint unsigned NOT NULL AUTO_INCREMENT,\n  `c1` varchar(50) DEFAULT NULL,\n  `c2` int DEFAULT NULL,\n  PRIMARY KEY (`my_row_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.01 sec)\nTo make this generated primary key invisible again, issue ALTER TABLE auto_1 ALTER COLUMN\nmy_row_id SET INVISIBLE.\nA generated invisible primary key is always invisible by default.\nWhenever GIPKs are enabled, you cannot drop a generated primary key if either of the following 2\nconditions would result:\n• The table is left with no primary key.\n• The primary key is dropped, but not the primary key column.\nThe effects of sql_generate_invisible_primary_key apply to tables using the InnoDB storage\nengine only. You can use an ALTER TABLE statement to change the storage engine used by a table\nthat has a generated invisible primary key; in this case, the primary key and column remain in place,\nbut the table and key no longer receive any special treatment.\nBy default, GIPKs are shown in the output of SHOW CREATE TABLE, SHOW COLUMNS, and\nSHOW INDEX, and are visible in the Information Schema COLUMNS and STATISTICS tables. You\ncan cause generated invisible primary keys to be hidden instead in such cases by setting the\nshow_gipk_in_create_table_and_information_schema system variable to OFF. By default,\nthis variable is ON, as shown here:\nmysql> SELECT @@show_gipk_in_create_table_and_information_schema;\n+----------------------------------------------------+\n| @@show_gipk_in_create_table_and_information_schema |\n+----------------------------------------------------+\n|                                                  1 |\n+----------------------------------------------------+\n1 row in set (0.00 sec)\nAs can be seen from the following query against the COLUMNS table, my_row_id is visible among the\ncolumns of auto_1:\nmysql> SELECT COLUMN_NAME, ORDINAL_POSITION, DATA_TYPE, COLUMN_KEY\n    -> FROM INFORMATION_SCHEMA.COLUMNS\n    -> WHERE TABLE_NAME = \"auto_1\";\n+-------------+------------------+-----------+------------+\n| COLUMN_NAME | ORDINAL_POSITION | DATA_TYPE | COLUMN_KEY |\n+-------------+------------------+-----------+------------+\n| my_row_id   |                1 | bigint    | PRI        |\n| c1          |                2 | varchar   |            |\n| c2          |                3 | int       |            |\n+-------------+------------------+-----------+------------+\n3 rows in set (0.01 sec)\nAfter show_gipk_in_create_table_and_information_schema is set to OFF, my_row_id can\nno longer be seen in the COLUMNS table, as shown here:\nmysql> SET show_gipk_in_create_table_and_information_schema = OFF;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @@show_gipk_in_create_table_and_information_schema;\n+----------------------------------------------------+\n| @@show_gipk_in_create_table_and_information_schema |\n+----------------------------------------------------+\n|                                                  0 |\n+----------------------------------------------------+\n1 row in set (0.00 sec)\nmysql> SELECT COLUMN_NAME, ORDINAL_POSITION, DATA_TYPE, COLUMN_KEY\n    -> FROM INFORMATION_SCHEMA.COLUMNS\n    -> WHERE TABLE_NAME = \"auto_1\";\n+-------------+------------------+-----------+------------+\n| COLUMN_NAME | ORDINAL_POSITION | DATA_TYPE | COLUMN_KEY |\n+-------------+------------------+-----------+------------+\n| c1          |                2 | varchar   |            |\n| c2          |                3 | int       |            |\n+-------------+------------------+-----------+------------+\n2 rows in set (0.00 sec)\nThe setting for sql_generate_invisible_primary_key is not replicated, and is ignored by\nreplication applier threads. This means that the setting of this variable on the source has no effect on\nthe replica. You can cause the replica to add a GIPK for tables replicated without primary keys on a\ngiven replication channel using REQUIRE_TABLE_PRIMARY_KEY_CHECK = GENERATE as part of a\nCHANGE REPLICATION SOURCE TO statement.\nGIPKs work with row-based replication of CREATE TABLE ... SELECT; the information written to\nthe binary log for this statement in such cases includes the GIPK definition, and thus is replicated\ncorrectly. Statement-based replication of CREATE TABLE ... SELECT is not supported with\nsql_generate_invisible_primary_key = ON.\nWhen creating or importing backups of installations where GIPKs are in use, it is possible to exclude\ngenerated invisible primary key columns and values. The --skip-generated-invisible-\nprimary-key option for mysqldump causes GIPK information to be excluded in the program's output.\n15.1.20.12 Setting NDB Comment Options\n• NDB_COLUMN Options\n• NDB_TABLE Options\n   It is possible to set a number of options specific to NDB Cluster in the table comment or column\ncomments of an NDB table. Table-level options for controlling read from any replica and partition\nbalance can be embedded in a table comment using NDB_TABLE.\nNDB_COLUMN can be used in a column comment to set the size of the blob parts table column used for\nstoring parts of blob values by NDB to its maximum. This works for BLOB, MEDIUMBLOB, LONGBLOB,\nTEXT, MEDIUMTEXT, LONGTEXT, and JSON columns. A column comment can also be used to control\nthe inline size of a blob column. NDB_COLUMN comments do not support TINYBLOB or TINYTEXT\ncolumns, since these have an inline part (only) of fixed size, and no separate parts to store elsewhere.\nNDB_TABLE can be used in a table comment to set options relating to partition balance and whether\nthe table is fully replicated, among others.\nThe remainder of this section describes these options and their use.\nNDB_COLUMN Options\n    In NDB Cluster, a column comment in a CREATE TABLE or ALTER TABLE statement can\nalso be used to specify an NDB_COLUMN option. NDB supports two column comment options\nBLOB_INLINE_SIZE and MAX_BLOB_PART_SIZE. Syntax for these options is shown here:\nCOMMENT 'NDB_COLUMN=speclist'\nspeclist := spec[,spec]\nspec := \n    BLOB_INLINE_SIZE=value\n  | MAX_BLOB_PART_SIZE[={0|1}]\nBLOB_INLINE_SIZE specifies the number of bytes to be stored inline by the column; its expected\nvalue is an integer in the range 1 - 29980, inclusive. Setting a value greater than 29980 raises an error;\nsetting a value less than 1 is allowed, but causes the default inline size for the column type to be used.\nYou should be aware that the maximum value for this option is actually the maximum number of bytes\nthat can be stored in one row of an NDB table; every column in the row contributes to this total.\nYou should also keep in mind, especially when working with TEXT columns, that the value set by\nMAX_BLOB_PART_SIZE or BLOB_INLINE_SIZE represents column size in bytes. It does not indicate\nthe number of characters, which varies according to the character set and collation used by the\ncolumn.\nTo see the effects of this option, first create a table with two BLOB columns, one (b1) with no extra\noptions, and another (b2) with a setting for BLOB_INLINE_SIZE, as shown here:\nmysql> CREATE TABLE t1 (\n    ->    a INT NOT NULL PRIMARY KEY,\n    ->    b1 BLOB,\n    ->    b2 BLOB COMMENT 'NDB_COLUMN=BLOB_INLINE_SIZE=8000'\n    ->  ) ENGINE NDB;\nQuery OK, 0 rows affected (0.32 sec)\nYou can see the BLOB_INLINE_SIZE settings for the BLOB columns by querying the\nndbinfo.blobs table, like this:\nmysql> SELECT \n    ->   column_name AS 'Column Name', \n    ->   inline_size AS 'Inline Size', \n    ->   part_size AS 'Blob Part Size' \n    -> FROM ndbinfo.blobs \n    -> WHERE table_name = 't1';\n+-------------+-------------+----------------+\n| Column Name | Inline Size | Blob Part Size |\n+-------------+-------------+----------------+\n| b1          |         256 |           2000 |\n| b2          |        8000 |           2000 |\n+-------------+-------------+----------------+\n2 rows in set (0.01 sec)\nYou can also check the output from the ndb_desc utility, as shown here, with the relevant lines\ndisplayed using emphasized text:\n$> ndb_desc -d test t1\n-- t --\nVersion: 1\nFragment type: HashMapPartition\nK Value: 6\nMin load factor: 78\nMax load factor: 80\nTemporary table: no\nNumber of attributes: 3\nNumber of primary keys: 1\nLength of frm data: 945\nMax Rows: 0\nRow Checksum: 1\nRow GCI: 1\nSingleUserMode: 0\nForceVarPart: 1\nPartitionCount: 2\nFragmentCount: 2\nPartitionBalance: FOR_RP_BY_LDM\nExtraRowGciBits: 0\nExtraRowAuthorBits: 0\nTableStatus: Retrieved\nTable options: readbackup\nHashMap: DEFAULT-HASHMAP-3840-2\n-- Attributes --\na Int PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY\nb1 Blob(256,2000,0) NULL AT=MEDIUM_VAR ST=MEMORY BV=2 BT=NDB$BLOB_64_1\nb2 Blob(8000,2000,0) NULL AT=MEDIUM_VAR ST=MEMORY BV=2 BT=NDB$BLOB_64_2\n-- Indexes -- \nPRIMARY KEY(a) - UniqueHashIndex\nPRIMARY(a) - OrderedIndex\nFor MAX_BLOB_PART_SIZE, the = sign and the value following it are optional. Using any value other\nthan 0 or 1 results in a syntax error.\nThe effect of using MAX_BLOB_PART_SIZE in a column comment is to set the blob part size of a\nTEXT or BLOB column to the maximum number of bytes supported for this by NDB (13948). This\noption can be applied to any blob column type supported by MySQL except TINYBLOB or TINYTEXT\n(BLOB, MEDIUMBLOB, LONGBLOB, TEXT, MEDIUMTEXT, LONGTEXT). Unlike BLOB_INLINE_SIZE,\nMAX_BLOB_PART_SIZE has no effect on JSON columns.\nTo see the effects of this option, we first run the following SQL statement in the mysql client\nto create a table with two BLOB columns, one (c1) with no extra options, and another (c2) with\nMAX_BLOB_PART_SIZE:\nmysql> CREATE TABLE test.t2 (\n    ->   p INT PRIMARY KEY, \n    ->   c1 BLOB, \n    ->   c2 BLOB COMMENT 'NDB_COLUMN=MAX_BLOB_PART_SIZE'\n    -> ) ENGINE NDB;\nQuery OK, 0 rows affected (0.32 sec)\nFrom the system shell, run the ndb_desc utility to obtain information about the table just created, as\nshown in this example:\n$> ndb_desc -d test t2\n-- t --\nVersion: 1\nFragment type: HashMapPartition\nK Value: 6\nMin load factor: 78\nMax load factor: 80\nTemporary table: no\nNumber of attributes: 3\nNumber of primary keys: 1\nLength of frm data: 324\nRow Checksum: 1\nRow GCI: 1\nSingleUserMode: 0\nForceVarPart: 1\nFragmentCount: 2\nExtraRowGciBits: 0\nExtraRowAuthorBits: 0\nTableStatus: Retrieved\nHashMap: DEFAULT-HASHMAP-3840-2\n-- Attributes --\np Int PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY\nc1 Blob(256,2000,0) NULL AT=MEDIUM_VAR ST=MEMORY BV=2 BT=NDB$BLOB_22_1\nc2 Blob(256,13948,0) NULL AT=MEDIUM_VAR ST=MEMORY BV=2 BT=NDB$BLOB_22_2\n-- Indexes -- \nPRIMARY KEY(p) - UniqueHashIndex\nPRIMARY(p) - OrderedIndex\nColumn information in the output is listed under Attributes; for columns c1 and c2 it is displayed\nhere in emphasized text. For c1, the blob part size is 2000, the default value; for c2, it is 13948, as set\nby MAX_BLOB_PART_SIZE.\nYou can also query the ndbinfo.blobs table to see this, as shown here:\nmysql> SELECT \n    ->   column_name AS 'Column Name', \n    ->   inline_size AS 'Inline Size', \n    ->   part_size AS 'Blob Part Size' \n    -> FROM ndbinfo.blobs \n    -> WHERE table_name = 't2';\n+-------------+-------------+----------------+\n| Column Name | Inline Size | Blob Part Size |\n+-------------+-------------+----------------+\n| c1          |         256 |           2000 |\n| c2          |         256 |          13948 |\n+-------------+-------------+----------------+\n2 rows in set (0.00 sec)\nYou can change the blob part size for a given blob column of an NDB table using an ALTER TABLE\nstatement such as this one, and verifying the changes afterwards using SHOW CREATE TABLE:\nmysql> ALTER TABLE test.t2 \n    ->    DROP COLUMN c1, \n    ->     ADD COLUMN c1 BLOB COMMENT 'NDB_COLUMN=MAX_BLOB_PART_SIZE',\n    ->     CHANGE COLUMN c2 c2 BLOB AFTER c1;\nQuery OK, 0 rows affected (0.47 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> SHOW CREATE TABLE test.t2\\G\n*************************** 1. row ***************************\n       Table: t\nCreate Table: CREATE TABLE `t2` (\n  `p` int(11) NOT NULL,\n  `c1` blob COMMENT 'NDB_COLUMN=MAX_BLOB_PART_SIZE',\n  `c2` blob,\n  PRIMARY KEY (`p`)\n) ENGINE=ndbcluster DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\nmysql> EXIT\nBye\nThe output of ndb_desc shows that the blob part sizes of the columns have been changed as\nexpected:\n$> ndb_desc -d test t2\n-- t --\nVersion: 16777220\nFragment type: HashMapPartition\nK Value: 6\nMin load factor: 78\nMax load factor: 80\nTemporary table: no\nNumber of attributes: 3\nNumber of primary keys: 1\nLength of frm data: 324\nRow Checksum: 1\nRow GCI: 1\nSingleUserMode: 0\nForceVarPart: 1\nFragmentCount: 2\nExtraRowGciBits: 0\nExtraRowAuthorBits: 0\nTableStatus: Retrieved\nHashMap: DEFAULT-HASHMAP-3840-2\n-- Attributes --\np Int PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY\nc1 Blob(256,13948,0) NULL AT=MEDIUM_VAR ST=MEMORY BV=2 BT=NDB$BLOB_26_1\nc2 Blob(256,2000,0) NULL AT=MEDIUM_VAR ST=MEMORY BV=2 BT=NDB$BLOB_26_2\n-- Indexes -- \nPRIMARY KEY(p) - UniqueHashIndex\nPRIMARY(p) - OrderedIndex\nYou can also see the change by running the query against ndbinfo.blobs again:\nmysql> SELECT \n    ->   column_name AS 'Column Name', \n    ->   inline_size AS 'Inline Size', \n    ->   part_size AS 'Blob Part Size' \n    -> FROM ndbinfo.blobs \n    -> WHERE table_name = 't2';\n+-------------+-------------+----------------+\n| Column Name | Inline Size | Blob Part Size |\n+-------------+-------------+----------------+\n| c1          |         256 |          13948 |\n| c2          |         256 |           2000 |\n+-------------+-------------+----------------+\n2 rows in set (0.00 sec)\nIt is possible to set both BLOB_INLINE_SIZE and MAX_BLOB_PART_SIZE for a blob column, as\nshown in this CREATE TABLE statement:\nmysql> CREATE TABLE test.t3 (\n    ->   p INT NOT NULL PRIMARY KEY,\n    ->   c1 JSON,\n    ->   c2 JSON COMMENT 'NDB_COLUMN=BLOB_INLINE_SIZE=5000,MAX_BLOB_PART_SIZE'\n    -> ) ENGINE NDB;\nQuery OK, 0 rows affected (0.28 sec)\nQuerying the blobs table shows us that the statement worked as expected:\nmysql> SELECT \n    ->   column_name AS 'Column Name', \n    ->   inline_size AS 'Inline Size', \n    ->   part_size AS 'Blob Part Size' \n    -> FROM ndbinfo.blobs \n    -> WHERE table_name = 't3';\n+-------------+-------------+----------------+\n| Column Name | Inline Size | Blob Part Size |\n+-------------+-------------+----------------+\n| c1          |        4000 |           8100 |\n| c2          |        5000 |           8100 |\n+-------------+-------------+----------------+\n2 rows in set (0.00 sec)\nYou can also verify that the statement worked by checking the output of ndb_desc.\nChanging a column's blob part size must be done using a copying ALTER TABLE; this operation\ncannot be performed online (see Section 25.6.12, “Online Operations with ALTER TABLE in NDB\nCluster”).\nFor more information about how NDB stores columns of blob types, see String Type Storage\nRequirements.\nNDB_TABLE Options\n     For an NDB Cluster table, the table comment in a CREATE TABLE or ALTER TABLE statement\ncan also be used to specify an NDB_TABLE option, which consists of one or more name-value pairs,\nseparated by commas if need be, following the string NDB_TABLE=. Complete syntax for names and\nvalues syntax is shown here:\nCOMMENT=\"NDB_TABLE=ndb_table_option[,ndb_table_option[,...]]\"\nndb_table_option: {\n    NOLOGGING={1 | 0}\n  | READ_BACKUP={1 | 0}\n  | PARTITION_BALANCE={FOR_RP_BY_NODE | FOR_RA_BY_NODE | FOR_RP_BY_LDM\n                      | FOR_RA_BY_LDM | FOR_RA_BY_LDM_X_2\n                      | FOR_RA_BY_LDM_X_3 | FOR_RA_BY_LDM_X_4}\n  | FULLY_REPLICATED={1 | 0}\n}\nSpaces are not permitted within the quoted string. The string is case-insensitive.\nThe four NDB table options that can be set as part of a comment in this way are described in more\ndetail in the next few paragraphs.\n   NOLOGGING: By default, NDB tables are logged, and checkpointed. This makes them durable to\nwhole cluster failures. Using NOLOGGING when creating or altering a table means that this table is not\nredo logged or included in local checkpoints. In this case, the table is still replicated across the data\nnodes for high availability, and updated using transactions, but changes made to it are not recorded in\nthe data node's redo logs, and its content is not checkpointed to disk; when recovering from a cluster\nfailure, the cluster retains the table definition, but none of its rows—that is, the table is empty.\nUsing such nonlogging tables reduces the data node's demands on disk I/O and storage, as well as\nCPU for checkpointing CPU. This may be suitable for short-lived data which is frequently updated, and\nwhere the loss of all data in the unlikely event of a total cluster failure is acceptable.\nIt is also possible to use the ndb_table_no_logging system variable to cause any NDB tables\ncreated or altered while this variable is in effect to behave as though it had been created with the\nNOLOGGING comment. Unlike when using the comment directly, there is nothing in this case in the\noutput of SHOW CREATE TABLE to indicate that it is a nonlogging table. Using the table comment\napproach is recommended since it offers per-table control of the feature, and this aspect of the table\nschema is embedded in the table creation statement where it can be found easily by SQL-based tools.\n   READ_BACKUP: Setting this option to 1 has the same effect as though ndb_read_backup were\nenabled; enables reading from any replica. Doing so greatly improves the performance of reads from\nthe table at a relatively small cost to write performance. 1 is the default for READ_BACKUP, and the\ndefault for ndb_read_backup is ON (previously, read from any replica was disabled by default).\nYou can set READ_BACKUP for an existing table online, using an ALTER TABLE statement similar to\none of those shown here:\nALTER TABLE ... ALGORITHM=INPLACE, COMMENT=\"NDB_TABLE=READ_BACKUP=1\";\nALTER TABLE ... ALGORITHM=INPLACE, COMMENT=\"NDB_TABLE=READ_BACKUP=0\";\nFor more information about the ALGORITHM option for ALTER TABLE, see Section 25.6.12, “Online\nOperations with ALTER TABLE in NDB Cluster”.\n   PARTITION_BALANCE: Provides additional control over assignment and placement of partitions. The\nfollowing four schemes are supported:\n1. FOR_RP_BY_NODE: One partition per node.\nOnly one LDM on each node stores a primary partition. Each partition is stored in the same LDM\n(same ID) on all nodes.\n2. FOR_RA_BY_NODE: One partition per node group.\nEach node stores a single partition, which can be either a primary replica or a backup replica. Each\npartition is stored in the same LDM on all nodes.\n3. FOR_RP_BY_LDM: One partition for each LDM on each node; the default.\nThis is the setting used if READ_BACKUP is set to 1.\n4. FOR_RA_BY_LDM: One partition per LDM in each node group.\nThese partitions can be primary or backup partitions.\n5. FOR_RA_BY_LDM_X_2: Two partitions per LDM in each node group.\nThese partitions can be primary or backup partitions.\n6. FOR_RA_BY_LDM_X_3: Three partitions per LDM in each node group.\nThese partitions can be primary or backup partitions.\n7. FOR_RA_BY_LDM_X_4: Four partitions per LDM in each node group.\nThese partitions can be primary or backup partitions.\nPARTITION_BALANCE is the preferred interface for setting the number of partitions per table. Using\nMAX_ROWS to force the number of partitions is deprecated but continues to be supported for backward\ncompatibility; it is subject to removal in a future release of MySQL NDB Cluster. (Bug #81759, Bug\n#23544301)\n  FULLY_REPLICATED controls whether the table is fully replicated, that is, whether each data node\nhas a complete copy of the table. To enable full replication of the table, use FULLY_REPLICATED=1.\nThis setting can also be controlled using the ndb_fully_replicated system variable.\nSetting it to ON enables the option by default for all new NDB tables; the default is OFF. The\nndb_data_node_neighbour system variable is also used for fully replicated tables, to ensure that\nwhen a fully replicated table is accessed, we access the data node which is local to this MySQL Server.\nAn example of a CREATE TABLE statement using such a comment when creating an NDB table is\nshown here:\nmysql> CREATE TABLE t1 (\n     >     c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n     >     c2 VARCHAR(100),\n     >     c3 VARCHAR(100) )\n     > ENGINE=NDB\n     >\nCOMMENT=\"NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE\";\nThe comment is displayed as part of the output of SHOW CREATE TABLE. The text of the comment is\nalso available from querying the MySQL Information Schema TABLES table, as in this example:\nmysql> SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT\n     > FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME=\"t1\"\\G\n*************************** 1. row ***************************\n   TABLE_NAME: t1\n TABLE_SCHEMA: test\nTABLE_COMMENT: NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE\n1 row in set (0.01 sec)\nThis comment syntax is also supported with ALTER TABLE statements for NDB tables, as shown here:\nmysql> ALTER TABLE t1 COMMENT=\"NDB_TABLE=PARTITION_BALANCE=FOR_RA_BY_NODE\";\nQuery OK, 0 rows affected (0.40 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nThe TABLE_COMMENT column displays the comment that is required to re-create the table as it is\nfollowing the ALTER TABLE statement, like this:\nmysql> SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT\n    ->     FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME=\"t1\"\\G\n*************************** 1. row ***************************\n   TABLE_NAME: t1\n TABLE_SCHEMA: test\nTABLE_COMMENT: NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE\n1 row in set (0.01 sec)\nmysql> SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT\n     > FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME=\"t1\";\n+------------+--------------+--------------------------------------------------+\n| TABLE_NAME | TABLE_SCHEMA | TABLE_COMMENT                                    |\n+------------+--------------+--------------------------------------------------+\n| t1         | c            | NDB_TABLE=PARTITION_BALANCE=FOR_RA_BY_NODE       |\n| t1         | d            |                                                  |\n+------------+--------------+--------------------------------------------------+\n2 rows in set (0.01 sec)\nKeep in mind that a table comment used with ALTER TABLE replaces any existing comment which the\ntable might have.\nmysql> ALTER TABLE t1 COMMENT=\"NDB_TABLE=PARTITION_BALANCE=FOR_RA_BY_NODE\";\nQuery OK, 0 rows affected (0.40 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT\n     > FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME=\"t1\";\n+------------+--------------+--------------------------------------------------+\n| TABLE_NAME | TABLE_SCHEMA | TABLE_COMMENT                                    |\n+------------+--------------+--------------------------------------------------+\n| t1         | c            | NDB_TABLE=PARTITION_BALANCE=FOR_RA_BY_NODE       |\n| t1         | d            |                                                  |\n+------------+--------------+--------------------------------------------------+\n2 rows in set (0.01 sec)\nYou can also see the value of the PARTITION_BALANCE option in the output of ndb_desc. ndb_desc\nalso shows whether the READ_BACKUP and FULLY_REPLICATED options are set for the table. See the\ndescription of this program for more information.",
    "15.1.21 CREATE TABLESPACE Statement": "15.1.21 CREATE TABLESPACE Statement\nCREATE [UNDO] TABLESPACE tablespace_name\n  InnoDB and NDB:\n    [ADD DATAFILE 'file_name']\n    [AUTOEXTEND_SIZE [=] value]\n  InnoDB only:\n    [FILE_BLOCK_SIZE = value]\n    [ENCRYPTION [=] {'Y' | 'N'}]\n  NDB only:\n    USE LOGFILE GROUP logfile_group\n    [EXTENT_SIZE [=] extent_size]\n    [INITIAL_SIZE [=] initial_size]\n    [MAX_SIZE [=] max_size]\n    [NODEGROUP [=] nodegroup_id]\n    [WAIT]\n    [COMMENT [=] 'string']\n  InnoDB and NDB:\n    [ENGINE [=] engine_name]\n  Reserved for future use:\n    [ENGINE_ATTRIBUTE [=] 'string']\n \nThis statement is used to create a tablespace. The precise syntax and semantics depend on the\nstorage engine used. In standard MySQL releases, this is always an InnoDB tablespace. MySQL NDB\nCluster also supports tablespaces using the NDB storage engine.\n• Considerations for InnoDB\n• Considerations for NDB Cluster\n• Options\n• Notes\n• InnoDB Examples\n• NDB Example\nConsiderations for InnoDB\nCREATE TABLESPACE syntax is used to create general tablespaces or undo tablespaces. The UNDO\nkeyword must be specified to create an undo tablespace.\nA general tablespace is a shared tablespace. It can hold multiple tables, and supports all table row\nformats. General tablespaces can be created in a location relative to or independent of the data\ndirectory.\nAfter creating an InnoDB general tablespace, use CREATE TABLE tbl_name ... TABLESPACE\n[=] tablespace_name or ALTER TABLE tbl_name TABLESPACE [=] tablespace_name to\nadd tables to the tablespace. For more information, see Section 17.6.3.3, “General Tablespaces”.\nUndo tablespaces contain undo logs. Undo tablespaces can be created in a chosen location\nby specifying a fully qualified data file path. For more information, see Section 17.6.3.4, “Undo\nTablespaces”.\nConsiderations for NDB Cluster\nThis statement is used to create a tablespace, which can contain one or more data files, providing\nstorage space for NDB Cluster Disk Data tables (see Section 25.6.11, “NDB Cluster Disk Data\nTables”). One data file is created and added to the tablespace using this statement. Additional\ndata files may be added to the tablespace by using the ALTER TABLESPACE statement (see\nSection 15.1.10, “ALTER TABLESPACE Statement”).\nNote\nAll NDB Cluster Disk Data objects share the same namespace. This means that\neach Disk Data object must be uniquely named (and not merely each Disk Data\nobject of a given type). For example, you cannot have a tablespace and a log\nfile group with the same name, or a tablespace and a data file with the same\nname.\nA log file group of one or more UNDO log files must be assigned to the tablespace to be created with\nthe USE LOGFILE GROUP clause. logfile_group must be an existing log file group created with\nCREATE LOGFILE GROUP (see Section 15.1.16, “CREATE LOGFILE GROUP Statement”). Multiple\ntablespaces may use the same log file group for UNDO logging.\nWhen setting EXTENT_SIZE or INITIAL_SIZE, you may optionally follow the number with a one-\nletter abbreviation for an order of magnitude, similar to those used in my.cnf. Generally, this is one of\nthe letters M (for megabytes) or G (for gigabytes).\nINITIAL_SIZE and EXTENT_SIZE are subject to rounding as follows:\n• EXTENT_SIZE is rounded up to the nearest whole multiple of 32K.\n• INITIAL_SIZE is rounded down to the nearest whole multiple of 32K; this result is rounded up to\nthe nearest whole multiple of EXTENT_SIZE (after any rounding).\nNote\nNDB reserves 4% of a tablespace for data node restart operations. This\nreserved space cannot be used for data storage.\nThe rounding just described is done explicitly, and a warning is issued by the MySQL Server when\nany such rounding is performed. The rounded values are also used by the NDB kernel for calculating\nINFORMATION_SCHEMA.FILES column values and other purposes. However, to avoid an unexpected\nresult, we suggest that you always use whole multiples of 32K in specifying these options.\nWhen CREATE TABLESPACE is used with ENGINE [=] NDB, a tablespace and associated data file\nare created on each Cluster data node. You can verify that the data files were created and obtain\ninformation about them by querying the Information Schema FILES table. (See the example later in\nthis section.)\n(See Section 28.3.15, “The INFORMATION_SCHEMA FILES Table”.)\nOptions\n• ADD DATAFILE: Defines the name of a tablespace data file. This option is always required when\ncreating an NDB tablespace; for InnoDB, it is required only when creating an undo tablespace. The\nfile_name, including any specified path, must be quoted with single or double quotation marks. File\nnames (not counting the file extension) and directory names must be at least one byte in length. Zero\nlength file names and directory names are not supported.\nBecause there are considerable differences in how InnoDB and NDB treat data files, the two storage\nengines are covered separately in the discussion that follows.\nInnoDB data files. \n An InnoDB tablespace supports only a single data file, whose name must\ninclude an .ibd extension.\nTo place an InnoDB general tablespace data file in a location outside of the data directory, include\na fully qualified path or a path relative to the data directory. Only a fully qualified path is permitted for\nundo tablespaces. If you do not specify a path, a general tablespace is created in the data directory.\nAn undo tablespace created without specifying a path is created in the directory defined by the\ninnodb_undo_directory variable. If innodb_undo_directory is not set, undo tablespaces\nare created in the data directory.\nTo avoid conflicts with implicitly created file-per-table tablespaces, creating an InnoDB general\ntablespace in a subdirectory under the data directory is not supported. When creating a general\ntablespace or undo tablespace outside of the data directory, the directory must exist and must be\nknown to InnoDB prior to creating the tablespace. To make a directory known to InnoDB, add it to\nthe innodb_directories value or to one of the variables whose values are appended to the value\nof innodb_directories. innodb_directories is a read-only variable. Configuring it requires\nrestarting the server.\nIf the ADD DATAFILE clause is not specified when creating an InnoDB tablespace, a tablespace\ndata file with a unique file name is created implicitly. The unique file name is a 128 bit UUID\nformatted into five groups of hexadecimal numbers separated by dashes (aaaaaaaa-bbbb-cccc-\ndddd-eeeeeeeeeeee). A file extension is added if required by the storage engine. An .ibd file\nextension is added for InnoDB general tablespace data files. In a replication environment, the data\nfile name created on the replication source server is not the same as the data file name created on\nthe replica.\nThe ADD DATAFILE clause does not permit circular directory references when creating an InnoDB\ntablespace. For example, the circular directory reference (/../) in the following statement is not\npermitted:\nCREATE TABLESPACE ts1 ADD DATAFILE ts1.ibd 'any_directory/../ts1.ibd';\nAn exception to this restriction exists on Linux, where a circular directory reference is permitted if\nthe preceding directory is a symbolic link. For example, the data file path in the example above is\npermitted if any_directory is a symbolic link. (It is still permitted for data file paths to begin with\n'../'.)\nNDB data files. \n An NDB tablespace supports multiple data files which can have any legal file\nnames; more data files can be added to an NDB Cluster tablespace following its creation by using an\nALTER TABLESPACE statement.\nAn NDB tablespace data file is created by default in the data node file system directory—that is,\nthe directory named ndb_nodeid_fs/TS under the data node's data directory (DataDir), where\nnodeid is the data node's NodeId. To place the data file in a location other than the default, include\nan absolute directory path or a path relative to the default location. If the directory specified does\nnot exist, NDB attempts to create it; the system user account under which the data node process is\nrunning must have the appropriate permissions to do so.\nNote\nWhen determining the path used for a data file, NDB does not expand the ~\n(tilde) character.\nWhen multiple data nodes are run on the same physical host, the following considerations apply:\n• You cannot specify an absolute path when creating a data file.\n• It is not possible to create tablespace data files outside the data node file system directory, unless\neach data node has a separate data directory.\n• If each data node has its own data directory, data files can be created anywhere within this\ndirectory.\n• If each data node has its own data directory, it may also be possible to create a data file outside\nthe node's data directory using a relative path, as long as this path resolves to a unique location on\nthe host file system for each data node running on that host.\n• FILE_BLOCK_SIZE: This option—which is specific to InnoDB general tablespaces, and is\nignored by NDB—defines the block size for the tablespace data file. Values can be specified in\nbytes or kilobytes. For example, an 8 kilobyte file block size can be specified as 8192 or 8K. If\nyou do not specify this option, FILE_BLOCK_SIZE defaults to the innodb_page_size value.\nFILE_BLOCK_SIZE is required when you intend to use the tablespace for storing compressed\nInnoDB tables (ROW_FORMAT=COMPRESSED). In this case, you must define the tablespace\nFILE_BLOCK_SIZE when creating the tablespace.\nIf FILE_BLOCK_SIZE is equal the innodb_page_size value, the tablespace can contain only\ntables having an uncompressed row format (COMPACT, REDUNDANT, and DYNAMIC). Tables with a\nCOMPRESSED row format have a different physical page size than uncompressed tables. Therefore,\ncompressed tables cannot coexist in the same tablespace as uncompressed tables.\nFor a general tablespace to contain compressed tables, FILE_BLOCK_SIZE must be\nspecified, and the FILE_BLOCK_SIZE value must be a valid compressed page size in\nrelation to the innodb_page_size value. Also, the physical page size of the compressed\ntable (KEY_BLOCK_SIZE) must be equal to FILE_BLOCK_SIZE/1024. For example, if\ninnodb_page_size=16K, and FILE_BLOCK_SIZE=8K, the KEY_BLOCK_SIZE of the table must\nbe 8. For more information, see Section 17.6.3.3, “General Tablespaces”.\n• USE LOGFILE GROUP: Required for NDB, this is the name of a log file group previously created\nusing CREATE LOGFILE GROUP. Not supported for InnoDB, where it fails with an error.\n• EXTENT_SIZE: This option is specific to NDB, and is not supported by InnoDB, where it fails with\nan error. EXTENT_SIZE sets the size, in bytes, of the extents used by any files belonging to the\ntablespace. The default value is 1M. The minimum size is 32K, and theoretical maximum is 2G,\nalthough the practical maximum size depends on a number of factors. In most cases, changing\nthe extent size does not have any measurable effect on performance, and the default value is\nrecommended for all but the most unusual situations.\nAn extent is a unit of disk space allocation. One extent is filled with as much data as that extent\ncan contain before another extent is used. In theory, up to 65,535 (64K) extents may used per data\nfile; however, the recommended maximum is 32,768 (32K). The recommended maximum size\nfor a single data file is 32G—that is, 32K extents × 1 MB per extent. In addition, once an extent is\nallocated to a given partition, it cannot be used to store data from a different partition; an extent\ncannot store data from more than one partition. This means, for example that a tablespace having\na single datafile whose INITIAL_SIZE (described in the following item) is 256 MB and whose\nEXTENT_SIZE is 128M has just two extents, and so can be used to store data from at most two\ndifferent disk data table partitions.\nYou can see how many extents remain free in a given data file by querying the Information Schema\nFILES table, and so derive an estimate for how much space remains free in the file. For further\ndiscussion and examples, see Section 28.3.15, “The INFORMATION_SCHEMA FILES Table”.\n• INITIAL_SIZE: This option is specific to NDB, and is not supported by InnoDB, where it fails with\nan error.\nThe INITIAL_SIZE parameter sets the total size in bytes of the data file that was specific using\nADD DATATFILE. Once this file has been created, its size cannot be changed; however, you can\nadd more data files to the tablespace using ALTER TABLESPACE ... ADD DATAFILE.\nINITIAL_SIZE is optional; its default value is 134217728 (128 MB).\nOn 32-bit systems, the maximum supported value for INITIAL_SIZE is 4294967296 (4 GB).\n• AUTOEXTEND_SIZE: Defines the amount by which InnoDB extends the size of the tablespace when\nit becomes full. The setting must be a multiple of 4MB. The default setting is 0, which causes the\ntablespace to be extended according to the implicit default behavior. For more information, see\nSection 17.6.3.9, “Tablespace AUTOEXTEND_SIZE Configuration”.\nHas no effect in any release of MySQL NDB Cluster, regardless of the storage engine used.\n• MAX_SIZE: Currently ignored by MySQL; reserved for possible future use. Has no effect in any\nrelease of MySQL or MySQL NDB Cluster, regardless of the storage engine used.\n• NODEGROUP: Currently ignored by MySQL; reserved for possible future use. Has no effect in any\nrelease of MySQL or MySQL NDB Cluster, regardless of the storage engine used.\n• WAIT: Currently ignored by MySQL; reserved for possible future use. Has no effect in any release of\nMySQL or MySQL NDB Cluster, regardless of the storage engine used.\n• COMMENT: Currently ignored by MySQL; reserved for possible future use. Has no effect in any\nrelease of MySQL or MySQL NDB Cluster, regardless of the storage engine used.\n• The ENCRYPTION clause enables or disables page-level data encryption for an InnoDB general\ntablespace.\nIf the ENCRYPTION clause is not specified, the default_table_encryption\nsetting controls whether encryption is enabled. The ENCRYPTION clause overrides the\ndefault_table_encryption setting. However, if the table_encryption_privilege_check\nvariable is enabled, the TABLE_ENCRYPTION_ADMIN privilege is required to use an ENCRYPTION\nclause setting that differs from the default_table_encryption setting.\nA keyring plugin must be installed and configured before an encryption-enabled tablespace can be\ncreated.\nWhen a general tablespace is encrypted, all tables residing in the tablespace are encrypted.\nLikewise, a table created in an encrypted tablespace is encrypted.\nFor more information, see Section 17.13, “InnoDB Data-at-Rest Encryption”\n• ENGINE: Defines the storage engine which uses the tablespace, where engine_name is the name\nof the storage engine. Currently, only the InnoDB storage engine is supported by standard MySQL\n9.1 releases. MySQL NDB Cluster supports both NDB and InnoDB tablespaces. The value of the\ndefault_storage_engine system variable is used for ENGINE if the option is not specified.\n• The ENGINE_ATTRIBUTE option is used to specify tablespace attributes for primary storage\nengines. The option is reserved for future use.\nThe value assigned to this option must be a string literal containing a valid JSON document or an\nempty string (''). Invalid JSON is rejected.\nCREATE TABLESPACE ts1 ENGINE_ATTRIBUTE='{\"key\":\"value\"}';\nENGINE_ATTRIBUTE values can be repeated without error. In this case, the last specified value is\nused.\nENGINE_ATTRIBUTE values are not checked by the server, nor are they cleared when the table's\nstorage engine is changed.\nNotes\n• For the rules covering the naming of MySQL tablespaces, see Section 11.2, “Schema Object\nNames”. In addition to these rules, the slash character (“/”) is not permitted, nor can you use names\nbeginning with innodb_, as this prefix is reserved for system use.\n• Creation of temporary general tablespaces is not supported.\n• General tablespaces do not support temporary tables.\n• The TABLESPACE option may be used with CREATE TABLE or ALTER TABLE to assign an InnoDB\ntable partition or subpartition to a file-per-table tablespace. All partitions must belong to the same\nstorage engine. Assigning table partitions to shared InnoDB tablespaces is not supported. Shared\ntablespaces include the InnoDB system tablespace and general tablespaces.\n• General tablespaces support the addition of tables of any row format using CREATE TABLE ...\nTABLESPACE. innodb_file_per_table does not need to be enabled.\n• innodb_strict_mode is not applicable to general tablespaces. Tablespace management rules\nare strictly enforced independently of innodb_strict_mode. If CREATE TABLESPACE parameters\nare incorrect or incompatible, the operation fails regardless of the innodb_strict_mode setting.\nWhen a table is added to a general tablespace using CREATE TABLE ... TABLESPACE or ALTER\nTABLE ... TABLESPACE, innodb_strict_mode is ignored but the statement is evaluated as if\ninnodb_strict_mode is enabled.\n• Use DROP TABLESPACE to remove a tablespace. All tables must be dropped from a tablespace\nusing DROP TABLE prior to dropping the tablespace. Before dropping an NDB Cluster tablespace\nyou must also remove all its data files using one or more ALTER TABLESPACE ... DROP\nDATATFILE statements. See Section 25.6.11.1, “NDB Cluster Disk Data Objects”.\n• All parts of an InnoDB table added to an InnoDB general tablespace reside in the general\ntablespace, including indexes and BLOB pages.\nFor an NDB table assigned to a tablespace, only those columns which are not indexed are stored on\ndisk, and actually use the tablespace data files. Indexes and indexed columns for all NDB tables are\nalways kept in memory.\n• Similar to the system tablespace, truncating or dropping tables stored in a general tablespace\ncreates free space internally in the general tablespace .ibd data file which can only be used for\nnew InnoDB data. Space is not released back to the operating system as it is for file-per-table\ntablespaces.\n• A general tablespace is not associated with any database or schema.\n• ALTER TABLE ... DISCARD TABLESPACE and ALTER TABLE ...IMPORT TABLESPACE are\nnot supported for tables that belong to a general tablespace.\n• The server uses tablespace-level metadata locking for DDL that references general tablespaces.\nBy comparison, the server uses table-level metadata locking for DDL that references file-per-table\ntablespaces.\n• A generated or existing tablespace cannot be changed to a general tablespace.\n• There is no conflict between general tablespace names and file-per-table tablespace names. The “/”\ncharacter, which is present in file-per-table tablespace names, is not permitted in general tablespace\nnames.\n• mysqldump does not dump InnoDB CREATE TABLESPACE statements.\nInnoDB Examples\nThis example demonstrates creating a general tablespace and adding three uncompressed tables of\ndifferent row formats.\nmysql> CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' ENGINE=INNODB;\nmysql> CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=REDUNDANT;\nmysql> CREATE TABLE t2 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=COMPACT;\nmysql> CREATE TABLE t3 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=DYNAMIC;\nThis example demonstrates creating a general tablespace and adding a compressed table. The\nexample assumes a default innodb_page_size value of 16K. The FILE_BLOCK_SIZE of 8192\nrequires that the compressed table have a KEY_BLOCK_SIZE of 8.\nmysql> CREATE TABLESPACE `ts2` ADD DATAFILE 'ts2.ibd' FILE_BLOCK_SIZE = 8192 ENGINE=InnoDB;\nmysql> CREATE TABLE t4 (c1 INT PRIMARY KEY) TABLESPACE ts2 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8;\nThis example demonstrates creating a general tablespace without specifying the ADD DATAFILE\nclause, which is optional:\nmysql> CREATE TABLESPACE `ts3` ENGINE=INNODB;\nThis example demonstrates creating an undo tablespace:\nmysql> CREATE UNDO TABLESPACE undo_003 ADD DATAFILE 'undo_003.ibu';\nNDB Example\nSuppose that you wish to create an NDB Cluster Disk Data tablespace named myts using a datafile\nnamed mydata-1.dat. An NDB tablespace always requires the use of a log file group consisting of\none or more undo log files. For this example, we first create a log file group named mylg that contains\none undo long file named myundo-1.dat, using the CREATE LOGFILE GROUP statement shown\nhere:\nmysql> CREATE LOGFILE GROUP myg1\n    ->     ADD UNDOFILE 'myundo-1.dat'\n    ->     ENGINE=NDB;\nQuery OK, 0 rows affected (3.29 sec)\nNow you can create the tablespace previously described using the following statement:\nmysql> CREATE TABLESPACE myts\n    ->     ADD DATAFILE 'mydata-1.dat'\n    ->     USE LOGFILE GROUP mylg\n    ->     ENGINE=NDB;\nQuery OK, 0 rows affected (2.98 sec)\nYou can now create a Disk Data table using a CREATE TABLE statement with the TABLESPACE and\nSTORAGE DISK options, similar to what is shown here:\nmysql> CREATE TABLE mytable (\n    ->     id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    ->     lname VARCHAR(50) NOT NULL,\n    ->     fname VARCHAR(50) NOT NULL,\n    ->     dob DATE NOT NULL,\n    ->     joined DATE NOT NULL,\n    ->     INDEX(last_name, first_name)\n    -> )\n    ->     TABLESPACE myts STORAGE DISK\n    ->     ENGINE=NDB;\nQuery OK, 0 rows affected (1.41 sec)\nIt is important to note that only the dob and joined columns from mytable are actually stored on\ndisk, due to the fact that the id, lname, and fname columns are all indexed.\nAs mentioned previously, when CREATE TABLESPACE is used with ENGINE [=] NDB, a tablespace\nand its associated data file are created on each NDB Cluster data node. You can verify that the data\nfiles were created and obtain information about them by querying the Information Schema FILES table,\nas shown here:\nmysql> SELECT FILE_NAME, FILE_TYPE, LOGFILE_GROUP_NAME, STATUS, EXTRA\n    ->     FROM INFORMATION_SCHEMA.FILES\n    ->     WHERE TABLESPACE_NAME = 'myts';\n+--------------+------------+--------------------+--------+----------------+\n| file_name    | file_type  | logfile_group_name | status | extra          |\n+--------------+------------+--------------------+--------+----------------+\n| mydata-1.dat | DATAFILE   | mylg               | NORMAL | CLUSTER_NODE=5 |\n| mydata-1.dat | DATAFILE   | mylg               | NORMAL | CLUSTER_NODE=6 |\n| NULL         | TABLESPACE | mylg               | NORMAL | NULL           |\n+--------------+------------+--------------------+--------+----------------+\n3 rows in set (0.01 sec)\nFor additional information and examples, see Section 25.6.11.1, “NDB Cluster Disk Data Objects”.",
    "15.1.22 CREATE TRIGGER Statement": "15.1.22 CREATE TRIGGER Statement\nCREATE\n    [DEFINER = user]\n    TRIGGER [IF NOT EXISTS] trigger_name\n    trigger_time trigger_event\n    ON tbl_name FOR EACH ROW\n    [trigger_order]\n    trigger_body\ntrigger_time: { BEFORE | AFTER }\ntrigger_event: { INSERT | UPDATE | DELETE }\ntrigger_order: { FOLLOWS | PRECEDES } other_trigger_name\nThis statement creates a new trigger. A trigger is a named database object that is associated with a\ntable, and that activates when a particular event occurs for the table. The trigger becomes associated\nwith the table named tbl_name, which must refer to a permanent table. You cannot associate a trigger\nwith a TEMPORARY table or a view.\nTrigger names exist in the schema namespace, meaning that all triggers must have unique names\nwithin a schema. Triggers in different schemas can have the same name.\nIF NOT EXISTS prevents an error from occurring if a trigger having the same name, on the same\ntable, exists in the same schema.\nThis section describes CREATE TRIGGER syntax. For additional discussion, see Section 27.4.1,\n“Trigger Syntax and Examples”.\nCREATE TRIGGER requires the TRIGGER privilege for the table associated with the trigger. If the\nDEFINER clause is present, the privileges required depend on the user value, as discussed in\nSection 27.7, “Stored Object Access Control”. If binary logging is enabled, CREATE TRIGGER might\nrequire the SUPER privilege, as discussed in Section 27.8, “Stored Program Binary Logging”.\nThe DEFINER clause determines the security context to be used when checking access privileges at\ntrigger activation time, as described later in this section.\ntrigger_time is the trigger action time. It can be BEFORE or AFTER to indicate that the trigger\nactivates before or after each row to be modified.\nBasic column value checks occur prior to trigger activation, so you cannot use BEFORE triggers to\nconvert values inappropriate for the column type to valid values.\ntrigger_event indicates the kind of operation that activates the trigger. These trigger_event\nvalues are permitted:\n• INSERT: The trigger activates whenever a new row is inserted into the table (for example, through\nINSERT, LOAD DATA, and REPLACE statements).\n• UPDATE: The trigger activates whenever a row is modified (for example, through UPDATE\nstatements).\n• DELETE: The trigger activates whenever a row is deleted from the table (for example, through\nDELETE and REPLACE statements). DROP TABLE and TRUNCATE TABLE statements on the table\ndo not activate this trigger, because they do not use DELETE. Dropping a partition does not activate\nDELETE triggers, either.\nThe trigger_event does not represent a literal type of SQL statement that activates the trigger so\nmuch as it represents a type of table operation. For example, an INSERT trigger activates not only for\nINSERT statements but also LOAD DATA statements because both statements insert rows into a table.\nA potentially confusing example of this is the INSERT INTO ... ON DUPLICATE KEY\nUPDATE ... syntax: a BEFORE INSERT trigger activates for every row, followed by either an AFTER\nINSERT trigger or both the BEFORE UPDATE and AFTER UPDATE triggers, depending on whether\nthere was a duplicate key for the row.\nNote\nCascaded foreign key actions do not activate triggers.\nIt is possible to define multiple triggers for a given table that have the same trigger event and action\ntime. For example, you can have two BEFORE UPDATE triggers for a table. By default, triggers that\nhave the same trigger event and action time activate in the order they were created. To affect trigger\norder, specify a trigger_order clause that indicates FOLLOWS or PRECEDES and the name of an\nexisting trigger that also has the same trigger event and action time. With FOLLOWS, the new trigger\nactivates after the existing trigger. With PRECEDES, the new trigger activates before the existing trigger.\ntrigger_body is the statement to execute when the trigger activates. To execute multiple\nstatements, use the BEGIN ... END compound statement construct. This also enables you to use\nthe same statements that are permitted within stored routines. See Section 15.6.1, “BEGIN ... END\nCompound Statement”. Some statements are not permitted in triggers; see Section 27.9, “Restrictions\non Stored Programs”.\nWithin the trigger body, you can refer to columns in the subject table (the table associated with the\ntrigger) by using the aliases OLD and NEW. OLD.col_name refers to a column of an existing row before\nit is updated or deleted. NEW.col_name refers to the column of a new row to be inserted or an existing\nrow after it is updated.\nTriggers cannot use NEW.col_name or use OLD.col_name to refer to generated columns. For\ninformation about generated columns, see Section 15.1.20.8, “CREATE TABLE and Generated\nColumns”.\nMySQL stores the sql_mode system variable setting in effect when a trigger is created, and always\nexecutes the trigger body with this setting in force, regardless of the current server SQL mode when\nthe trigger begins executing.\nThe DEFINER clause specifies the MySQL account to be used when checking access privileges at\ntrigger activation time. If the DEFINER clause is present, the user value should be a MySQL account\nspecified as 'user_name'@'host_name', CURRENT_USER, or CURRENT_USER(). The permitted\nuser values depend on the privileges you hold, as discussed in Section 27.7, “Stored Object Access\nControl”. Also see that section for additional information about trigger security.\nIf the DEFINER clause is omitted, the default definer is the user who executes the CREATE TRIGGER\nstatement. This is the same as specifying DEFINER = CURRENT_USER explicitly.\nMySQL takes the DEFINER user into account when checking trigger privileges as follows:\n• At CREATE TRIGGER time, the user who issues the statement must have the TRIGGER privilege.\n• At trigger activation time, privileges are checked against the DEFINER user. This user must have\nthese privileges:\n• The TRIGGER privilege for the subject table.\n• The SELECT privilege for the subject table if references to table columns occur using\nOLD.col_name or NEW.col_name in the trigger body.\n• The UPDATE privilege for the subject table if table columns are targets of SET NEW.col_name =\nvalue assignments in the trigger body.\n• Whatever other privileges normally are required for the statements executed by the trigger.\nWithin a trigger body, the CURRENT_USER function returns the account used to check privileges at\ntrigger activation time. This is the DEFINER user, not the user whose actions caused the trigger to be\nactivated. For information about user auditing within triggers, see Section 8.2.23, “SQL-Based Account\nActivity Auditing”.\nIf you use LOCK TABLES to lock a table that has triggers, the tables used within the trigger are also\nlocked, as described in LOCK TABLES and Triggers.\nFor additional discussion of trigger use, see Section 27.4.1, “Trigger Syntax and Examples”.",
    "15.1.23 CREATE VIEW Statement": "15.1.23 CREATE VIEW Statement\nCREATE\n    [OR REPLACE]\n    [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]\n    [DEFINER = user]\n    [SQL SECURITY { DEFINER | INVOKER }]\n    VIEW view_name [(column_list)]\n    AS select_statement\n    [WITH [CASCADED | LOCAL] CHECK OPTION]\nCREATE\n    [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]\n    [DEFINER = user]\n    [SQL SECURITY { DEFINER | INVOKER }]\n    [IF NOT EXISTS] VIEW view_name [(column_list)]\n    AS select_statement\n    [WITH [CASCADED | LOCAL] CHECK OPTION]\nThe CREATE VIEW statement creates a new view, or replaces an existing view if the OR REPLACE\nclause is given. If the view does not exist, CREATE OR REPLACE VIEW is the same as CREATE VIEW.\nIf the view does exist, CREATE OR REPLACE VIEW replaces it.\nThe select_statement is a SELECT statement that provides the definition of the view. (Selecting\nfrom the view selects, in effect, using the SELECT statement.) The select_statement can select\nfrom base tables or from other views. The SELECT statement can use a VALUES statement as its\nsource, or can be replaced with a TABLE statement, as with CREATE TABLE ... SELECT.\nIF NOT EXISTS causes the view to be created if it does not already exist. If the view already exists\nand IF NOT EXISTS is specified, the statement is succeeds with a warning rather than an error; in\nthis case, the view definition is not changed. For example:\nmysql> CREATE VIEW v1 AS SELECT c1, c3 FROM t1;\nQuery OK, 0 rows affected (0.01 sec)\nmysql> CREATE VIEW v1 AS SELECT c1, c3 FROM t1;\nERROR 1050 (42S01): Table 'v1' already exists\nmysql> CREATE VIEW IF NOT EXISTS v1 AS SELECT c1, c3 FROM t1;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\nmysql> SHOW WARNINGS;\n+-------+------+---------------------------+\n| Level | Code | Message                   |\n+-------+------+---------------------------+\n| Note  | 1050 | Table 'v1' already exists |\n+-------+------+---------------------------+\n1 row in set (0.00 sec)\nmysql> SHOW CREATE VIEW v1\\G\n*************************** 1. row ***************************\n                View: v1\n         Create View: CREATE ALGORITHM=UNDEFINED DEFINER=`vuser`@`localhost` SQL \nSECURITY DEFINER VIEW `v1` AS select `t1`.`c1` AS `c1`,`t1`.`c3` AS `c3` from `t1`\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\nIF NOT EXISTS and OR REPLACE are mutually exclusive and cannot be used together in the same\nCREATE VIEW statement. Attempting to do so causes the statement to be rejected with a syntax error.\nFor information about restrictions on view use, see Section 27.10, “Restrictions on Views”.\nThe view definition is “frozen” at creation time and is not affected by subsequent changes to the\ndefinitions of the underlying tables. For example, if a view is defined as SELECT * on a table, new\ncolumns added to the table later do not become part of the view, and columns dropped from the table\nresult in an error when selecting from the view.\nThe ALGORITHM clause affects how MySQL processes the view. The DEFINER and SQL SECURITY\nclauses specify the security context to be used when checking access privileges at view invocation\ntime. The WITH CHECK OPTION clause can be given to constrain inserts or updates to rows in tables\nreferenced by the view. These clauses are described later in this section.\nThe CREATE VIEW statement requires the CREATE VIEW privilege for the view, and some privilege\nfor each column selected by the SELECT statement. For columns used elsewhere in the SELECT\nstatement, you must have the SELECT privilege. If the OR REPLACE clause is present, you must also\nhave the DROP privilege for the view. If the DEFINER clause is present, the privileges required depend\non the user value, as discussed in Section 27.7, “Stored Object Access Control”.\nWhen a view is referenced, privilege checking occurs as described later in this section.\nA view belongs to a database. By default, a new view is created in the default database. To create the\nview explicitly in a given database, use db_name.view_name syntax to qualify the view name with the\ndatabase name:\nCREATE VIEW test.v AS SELECT * FROM t;\nUnqualified table or view names in the SELECT statement are also interpreted with respect to the\ndefault database. A view can refer to tables or views in other databases by qualifying the table or view\nname with the appropriate database name.\nWithin a database, base tables and views share the same namespace, so a base table and a view\ncannot have the same name.\nColumns retrieved by the SELECT statement can be simple references to table columns, or\nexpressions that use functions, constant values, operators, and so forth.\nA view must have unique column names with no duplicates, just like a base table. By default, the\nnames of the columns retrieved by the SELECT statement are used for the view column names.\nTo define explicit names for the view columns, specify the optional column_list clause as a list\nof comma-separated identifiers. The number of names in column_list must be the same as the\nnumber of columns retrieved by the SELECT statement.\nA view can be created from many kinds of SELECT statements. It can refer to base tables or other\nviews. It can use joins, UNION, and subqueries. The SELECT need not even refer to any tables:\nCREATE VIEW v_today (today) AS SELECT CURRENT_DATE;\nThe following example defines a view that selects two columns from another table as well as an\nexpression calculated from those columns:\nmysql> CREATE TABLE t (qty INT, price INT);\nmysql> INSERT INTO t VALUES(3, 50);\nmysql> CREATE VIEW v AS SELECT qty, price, qty*price AS value FROM t;\nmysql> SELECT * FROM v;\n+------+-------+-------+\n| qty  | price | value |\n+------+-------+-------+\n|    3 |    50 |   150 |\n+------+-------+-------+\nA view definition is subject to the following restrictions:\n• The SELECT statement cannot refer to system variables or user-defined variables.\n• Within a stored program, the SELECT statement cannot refer to program parameters or local\nvariables.\n• The SELECT statement cannot refer to prepared statement parameters.\n• Any table or view referred to in the definition must exist. If, after the view has been created, a table\nor view that the definition refers to is dropped, use of the view results in an error. To check a view\ndefinition for problems of this kind, use the CHECK TABLE statement.\n• The definition cannot refer to a TEMPORARY table, and you cannot create a TEMPORARY view.\n• You cannot associate a trigger with a view.\n• Aliases for column names in the SELECT statement are checked against the maximum column\nlength of 64 characters (not the maximum alias length of 256 characters).\nORDER BY is permitted in a view definition, but it is ignored if you select from a view using a statement\nthat has its own ORDER BY.\nFor other options or clauses in the definition, they are added to the options or clauses of the statement\nthat references the view, but the effect is undefined. For example, if a view definition includes a\nLIMIT clause, and you select from the view using a statement that has its own LIMIT clause, it is\nundefined which limit applies. This same principle applies to options such as ALL, DISTINCT, or\nSQL_SMALL_RESULT that follow the SELECT keyword, and to clauses such as INTO, FOR UPDATE,\nFOR SHARE, LOCK IN SHARE MODE, and PROCEDURE.\nThe results obtained from a view may be affected if you change the query processing environment by\nchanging system variables:\nmysql> CREATE VIEW v (mycol) AS SELECT 'abc';\nQuery OK, 0 rows affected (0.01 sec)\nmysql> SET sql_mode = '';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT \"mycol\" FROM v;\n+-------+\n| mycol |\n+-------+\n| mycol |\n+-------+\n1 row in set (0.01 sec)\nmysql> SET sql_mode = 'ANSI_QUOTES';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT \"mycol\" FROM v;\n+-------+\n| mycol |\n+-------+\n| abc   |\n+-------+\n1 row in set (0.00 sec)\nThe DEFINER and SQL SECURITY clauses determine which MySQL account to use when checking\naccess privileges for the view when a statement is executed that references the view. The valid SQL\nSECURITY characteristic values are DEFINER (the default) and INVOKER. These indicate that the\nrequired privileges must be held by the user who defined or invoked the view, respectively.\nIf the DEFINER clause is present, the user value should be a MySQL account specified as\n'user_name'@'host_name', CURRENT_USER, or CURRENT_USER(). The permitted user values\ndepend on the privileges you hold, as discussed in Section 27.7, “Stored Object Access Control”. Also\nsee that section for additional information about view security.\nIf the DEFINER clause is omitted, the default definer is the user who executes the CREATE VIEW\nstatement. This is the same as specifying DEFINER = CURRENT_USER explicitly.\nWithin a view definition, the CURRENT_USER function returns the view's DEFINER value by default. For\nviews defined with the SQL SECURITY INVOKER characteristic, CURRENT_USER returns the account\nfor the view's invoker. For information about user auditing within views, see Section 8.2.23, “SQL-\nBased Account Activity Auditing”.\nWithin a stored routine that is defined with the SQL SECURITY DEFINER characteristic,\nCURRENT_USER returns the routine's DEFINER value. This also affects a view defined within such a\nroutine, if the view definition contains a DEFINER value of CURRENT_USER.\nMySQL checks view privileges like this:\n• At view definition time, the view creator must have the privileges needed to use the top-level objects\naccessed by the view. For example, if the view definition refers to table columns, the creator must\nhave some privilege for each column in the select list of the definition, and the SELECT privilege\nfor each column used elsewhere in the definition. If the definition refers to a stored function, only\nthe privileges needed to invoke the function can be checked. The privileges required at function\ninvocation time can be checked only as it executes: For different invocations, different execution\npaths within the function might be taken.\n• The user who references a view must have appropriate privileges to access it (SELECT to select from\nit, INSERT to insert into it, and so forth.)\n• When a view has been referenced, privileges for objects accessed by the view are checked against\nthe privileges held by the view DEFINER account or invoker, depending on whether the SQL\nSECURITY characteristic is DEFINER or INVOKER, respectively.\n• If reference to a view causes execution of a stored function, privilege checking for statements\nexecuted within the function depend on whether the function SQL SECURITY characteristic is\nDEFINER or INVOKER. If the security characteristic is DEFINER, the function runs with the privileges\nof the DEFINER account. If the characteristic is INVOKER, the function runs with the privileges\ndetermined by the view's SQL SECURITY characteristic.\nExample: A view might depend on a stored function, and that function might invoke other stored\nroutines. For example, the following view invokes a stored function f():\nCREATE VIEW v AS SELECT * FROM t WHERE t.id = f(t.name);\nSuppose that f() contains a statement such as this:\nIF name IS NULL then\n  CALL p1();\nELSE\n  CALL p2();\nEND IF;\nThe privileges required for executing statements within f() need to be checked when f() executes.\nThis might mean that privileges are needed for p1() or p2(), depending on the execution path within\nf(). Those privileges must be checked at runtime, and the user who must possess the privileges is\ndetermined by the SQL SECURITY values of the view v and the function f().\nThe DEFINER and SQL SECURITY clauses for views are extensions to standard SQL. In standard\nSQL, views are handled using the rules for SQL SECURITY DEFINER. The standard says that the\ndefiner of the view, which is the same as the owner of the view's schema, gets applicable privileges\non the view (for example, SELECT) and may grant them. MySQL has no concept of a schema “owner”,\nso MySQL adds a clause to identify the definer. The DEFINER clause is an extension where the intent\nis to have what the standard has; that is, a permanent record of who defined the view. This is why the\ndefault DEFINER value is the account of the view creator.\nThe optional ALGORITHM clause is a MySQL extension to standard SQL. It affects how MySQL\nprocesses the view. ALGORITHM takes three values: MERGE, TEMPTABLE, or UNDEFINED. For more\ninformation, see Section 27.6.2, “View Processing Algorithms”, as well as Section 10.2.2.4, “Optimizing\nDerived Tables, View References, and Common Table Expressions with Merging or Materialization”.\nSome views are updatable. That is, you can use them in statements such as UPDATE, DELETE, or\nINSERT to update the contents of the underlying table. For a view to be updatable, there must be a\none-to-one relationship between the rows in the view and the rows in the underlying table. There are\nalso certain other constructs that make a view nonupdatable.\nA generated column in a view is considered updatable because it is possible to assign to it. However,\nif such a column is updated explicitly, the only permitted value is DEFAULT. For information about\ngenerated columns, see Section 15.1.20.8, “CREATE TABLE and Generated Columns”.\nThe WITH CHECK OPTION clause can be given for an updatable view to prevent inserts or updates to\nrows except those for which the WHERE clause in the select_statement is true.\nIn a WITH CHECK OPTION clause for an updatable view, the LOCAL and CASCADED keywords\ndetermine the scope of check testing when the view is defined in terms of another view. The LOCAL\nkeyword restricts the CHECK OPTION only to the view being defined. CASCADED causes the checks for\nunderlying views to be evaluated as well. When neither keyword is given, the default is CASCADED.\nFor more information about updatable views and the WITH CHECK OPTION clause, see\nSection 27.6.3, “Updatable and Insertable Views”, and Section 27.6.4, “The View WITH CHECK\nOPTION Clause”.",
    "15.1.24 DROP DATABASE Statement": "15.1.24 DROP DATABASE Statement\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\nDROP DATABASE drops all tables in the database and deletes the database. Be very careful with this\nstatement! To use DROP DATABASE, you need the DROP privilege on the database. DROP SCHEMA is a\nsynonym for DROP DATABASE.\nImportant\nWhen a database is dropped, privileges granted specifically for the database\nare not automatically dropped. They must be dropped manually. See\nSection 15.7.1.6, “GRANT Statement”.\nIF EXISTS is used to prevent an error from occurring if the database does not exist.\nIf the default database is dropped, the default database is unset (the DATABASE() function returns\nNULL).\nIf you use DROP DATABASE on a symbolically linked database, both the link and the original database\nare deleted.\nDROP DATABASE returns the number of tables that were removed.\nThe DROP DATABASE statement removes from the given database directory those files and directories\nthat MySQL itself may create during normal operation. This includes all files with the extensions shown\nin the following list:\n• .BAK\n• .DAT\n• .HSH\n• .MRG\n• .MYD\n• .MYI\n• .cfg\n• .db\n• .ibd\n• .ndb\nIf other files or directories remain in the database directory after MySQL removes those just listed, the\ndatabase directory cannot be removed. In this case, you must remove any remaining files or directories\nmanually and issue the DROP DATABASE statement again. To keep this from happening, ensure that\nall tables in the database use a storage engine that supports atomic DDL (see Section 15.1.1, “Atomic\nData Definition Statement Support”), such as InnoDB.\nDropping a database does not remove any TEMPORARY tables that were created in that database.\nTEMPORARY tables are automatically removed when the session that created them ends. See\nSection 15.1.20.2, “CREATE TEMPORARY TABLE Statement”.\nYou can also drop databases with mysqladmin. See Section 6.5.2, “mysqladmin — A MySQL Server\nAdministration Program”.",
    "15.1.25 DROP EVENT Statement": "15.1.25 DROP EVENT Statement\nDROP EVENT [IF EXISTS] event_name\nThis statement drops the event named event_name. The event immediately ceases being active, and\nis deleted completely from the server.\nIf the event does not exist, the error ERROR 1517 (HY000): Unknown event 'event_name'\nresults. You can override this and cause the statement to generate a warning for nonexistent events\ninstead using IF EXISTS.\nThis statement requires the EVENT privilege for the schema to which the event to be dropped belongs.",
    "15.1.26 DROP FUNCTION Statement": "15.1.26 DROP FUNCTION Statement\nThe DROP FUNCTION statement is used to drop stored functions and loadable functions:\n• For information about dropping stored functions, see Section 15.1.29, “DROP PROCEDURE and\nDROP FUNCTION Statements”.\n• For information about dropping loadable functions, see Section 15.7.4.2, “DROP FUNCTION\nStatement for Loadable Functions”.",
    "15.1.27 DROP INDEX Statement": "15.1.27 DROP INDEX Statement\nDROP INDEX index_name ON tbl_name\n    [algorithm_option | lock_option] ...\nalgorithm_option:\n    ALGORITHM [=] {DEFAULT | INPLACE | COPY}\nlock_option:\n    LOCK [=] {DEFAULT | NONE | SHARED | EXCLUSIVE}\nDROP INDEX drops the index named index_name from the table tbl_name. This statement is\nmapped to an ALTER TABLE statement to drop the index. See Section 15.1.9, “ALTER TABLE\nStatement”.\nTo drop a primary key, the index name is always PRIMARY, which must be specified as a quoted\nidentifier because PRIMARY is a reserved word:\nDROP INDEX `PRIMARY` ON t;\nIndexes on variable-width columns of NDB tables are dropped online; that is, without any table copying.\nThe table is not locked against access from other NDB Cluster API nodes, although it is locked against\nother operations on the same API node for the duration of the operation. This is done automatically by\nthe server whenever it determines that it is possible to do so; you do not have to use any special SQL\nsyntax or server options to cause it to happen.\nALGORITHM and LOCK clauses may be given to influence the table copying method and level of\nconcurrency for reading and writing the table while its indexes are being modified. They have the\nsame meaning as for the ALTER TABLE statement. For more information, see Section 15.1.9, “ALTER\nTABLE Statement”\nMySQL NDB Cluster supports online operations using the same ALGORITHM=INPLACE syntax\nsupported in the standard MySQL Server. See Section 25.6.12, “Online Operations with ALTER TABLE\nin NDB Cluster”, for more information.",
    "15.1.28 DROP LOGFILE GROUP Statement": "15.1.28 DROP LOGFILE GROUP Statement\nDROP LOGFILE GROUP logfile_group\n    ENGINE [=] engine_name\nThis statement drops the log file group named logfile_group. The log file group must already\nexist or an error results. (For information on creating log file groups, see Section 15.1.16, “CREATE\nLOGFILE GROUP Statement”.)\nImportant\nBefore dropping a log file group, you must drop all tablespaces that use that log\nfile group for UNDO logging.\nThe required ENGINE clause provides the name of the storage engine used by the log file group to be\ndropped. The only permitted values for engine_name are NDB and NDBCLUSTER.\nDROP LOGFILE GROUP is useful only with Disk Data storage for NDB Cluster. See Section 25.6.11,\n“NDB Cluster Disk Data Tables”.",
    "15.1.29 DROP PROCEDURE and DROP FUNCTION Statements": "15.1.29 DROP PROCEDURE and DROP FUNCTION Statements\nDROP {PROCEDURE | FUNCTION} [IF EXISTS] sp_name\nThese statements are used to drop a stored routine (a stored procedure or function). That is, the\nspecified routine is removed from the server. (DROP FUNCTION is also used to drop loadable functions;\nsee Section 15.7.4.2, “DROP FUNCTION Statement for Loadable Functions”.)\nTo drop a stored routine, you must have the ALTER ROUTINE privilege for it. (If the\nautomatic_sp_privileges system variable is enabled, that privilege and EXECUTE are granted\nautomatically to the routine creator when the routine is created and dropped from the creator when the\nroutine is dropped. See Section 27.2.2, “Stored Routines and MySQL Privileges”.)\nIn addition, if the definer of the routine has the SYSTEM_USER privilege, the user dropping it must also\nhave this privilege.\nThe IF EXISTS clause is a MySQL extension. It prevents an error from occurring if the procedure or\nfunction does not exist. A warning is produced that can be viewed with SHOW WARNINGS.\nDROP FUNCTION is also used to drop loadable functions (see Section 15.7.4.2, “DROP FUNCTION\nStatement for Loadable Functions”).",
    "15.1.30 DROP SERVER Statement": "15.1.30 DROP SERVER Statement\nDROP SERVER [ IF EXISTS ] server_name\nDrops the server definition for the server named server_name. The corresponding row in the\nmysql.servers table is deleted. This statement requires the SUPER privilege.\nDropping a server for a table does not affect any FEDERATED tables that used this connection\ninformation when they were created. See Section 15.1.18, “CREATE SERVER Statement”.\nDROP SERVER causes an implicit commit. See Section 15.3.3, “Statements That Cause an Implicit\nCommit”.\nDROP SERVER is not written to the binary log, regardless of the logging format that is in use.",
    "15.1.31 DROP SPATIAL REFERENCE SYSTEM Statement": "15.1.31 DROP SPATIAL REFERENCE SYSTEM Statement\nDROP SPATIAL REFERENCE SYSTEM\n    [IF EXISTS]\n    srid\nsrid: 32-bit unsigned integer\nThis statement removes a spatial reference system (SRS) definition from the data dictionary. It requires\nthe SUPER privilege.\nExample:\nDROP SPATIAL REFERENCE SYSTEM 4120;\nIf no SRS definition with the SRID value exists, an error occurs unless IF EXISTS is specified. In that\ncase, a warning occurs rather than an error.\nIf the SRID value is used by some column in an existing table, an error occurs. For example:\nmysql> DROP SPATIAL REFERENCE SYSTEM 4326;\nERROR 3716 (SR005): Can't modify SRID 4326. There is at\nleast one column depending on it.\nTo identify which column or columns use the SRID, use this query:\nSELECT * FROM INFORMATION_SCHEMA.ST_GEOMETRY_COLUMNS WHERE SRS_ID=4326;\nSRID values must be in the range of 32-bit unsigned integers, with these restrictions:\n• SRID 0 is a valid SRID but cannot be used with DROP SPATIAL REFERENCE SYSTEM.\n• If the value is in a reserved SRID range, a warning occurs. Reserved ranges are [0, 32767] (reserved\nby EPSG), [60,000,000, 69,999,999] (reserved by EPSG), and [2,000,000,000, 2,147,483,647]\n(reserved by MySQL). EPSG stands for the European Petroleum Survey Group.\n• Users should not drop SRSs with SRIDs in the reserved ranges. If system-installed SRSs are\ndropped, the SRS definitions may be recreated for MySQL upgrades.",
    "15.1.32 DROP TABLE Statement": "15.1.32 DROP TABLE Statement\nDROP [TEMPORARY] TABLE [IF EXISTS]\n    tbl_name [, tbl_name] ...\n    [RESTRICT | CASCADE]\nDROP TABLE removes one or more tables. You must have the DROP privilege for each table.\nBe careful with this statement! For each table, it removes the table definition and all table data. If the\ntable is partitioned, the statement removes the table definition, all its partitions, all data stored in those\npartitions, and all partition definitions associated with the dropped table.\nDropping a table also drops any triggers for the table.\nDROP TABLE causes an implicit commit, except when used with the TEMPORARY keyword. See\nSection 15.3.3, “Statements That Cause an Implicit Commit”.\nImportant\nWhen a table is dropped, privileges granted specifically for the table are not\nautomatically dropped. They must be dropped manually. See Section 15.7.1.6,\n“GRANT Statement”.\nIf any tables named in the argument list do not exist, DROP TABLE behavior depends on whether the\nIF EXISTS clause is given:\n• Without IF EXISTS, the statement fails with an error indicating which nonexisting tables it was\nunable to drop, and no changes are made.\n• With IF EXISTS, no error occurs for nonexisting tables. The statement drops all named tables that\ndo exist, and generates a NOTE diagnostic for each nonexistent table. These notes can be displayed\nwith SHOW WARNINGS. See Section 15.7.7.41, “SHOW WARNINGS Statement”.\nIF EXISTS can also be useful for dropping tables in unusual circumstances under which there is an\nentry in the data dictionary but no table managed by the storage engine. (For example, if an abnormal\nserver exit occurs after removal of the table from the storage engine but before removal of the data\ndictionary entry.)\nThe TEMPORARY keyword has the following effects:\n• The statement drops only TEMPORARY tables.\n• The statement does not cause an implicit commit.\n• No access rights are checked. A TEMPORARY table is visible only with the session that created it, so\nno check is necessary.\nIncluding the TEMPORARY keyword is a good way to prevent accidentally dropping non-TEMPORARY\ntables.\nThe RESTRICT and CASCADE keywords do nothing. They are permitted to make porting easier from\nother database systems.\nDROP TABLE is not supported with all innodb_force_recovery settings. See Section 17.20.3,\n“Forcing InnoDB Recovery”.",
    "15.1.33 DROP TABLESPACE Statement": "15.1.33 DROP TABLESPACE Statement\nDROP [UNDO] TABLESPACE tablespace_name\nThis statement drops a tablespace that was previously created using CREATE TABLESPACE. It is\nsupported by the NDB and InnoDB storage engines.\nThe UNDO keyword must be specified to drop an undo tablespace. Only undo tablespaces created\nusing CREATE UNDO TABLESPACE syntax can be dropped. An undo tablespace must be in an empty\nstate before it can be dropped. For more information, see Section 17.6.3.4, “Undo Tablespaces”.\ntablespace_name is a case-sensitive identifier in MySQL.\nFor an InnoDB general tablespace, all tables must be dropped from the tablespace prior to a DROP\nTABLESPACE operation. If the tablespace is not empty, DROP TABLESPACE returns an error.\nAn NDB tablespace to be dropped must not contain any data files; in other words, before you can drop\nan NDB tablespace, you must first drop each of its data files using ALTER TABLESPACE ... DROP\nDATAFILE.\nNotes\n• A general InnoDB tablespace is not deleted automatically when the last table in the tablespace is\ndropped. The tablespace must be dropped explicitly using DROP TABLESPACE tablespace_name.\n• A DROP DATABASE operation can drop tables that belong to a general tablespace but it cannot drop\nthe tablespace, even if the operation drops all tables that belong to the tablespace. The tablespace\nmust be dropped explicitly using DROP TABLESPACE tablespace_name.\n• Similar to the system tablespace, truncating or dropping tables stored in a general tablespace\ncreates free space internally in the general tablespace .ibd data file which can only be used for\nnew InnoDB data. Space is not released back to the operating system as it is for file-per-table\ntablespaces.\nInnoDB Examples\nThis example demonstrates how to drop an InnoDB general tablespace. The general tablespace ts1\nis created with a single table. Before dropping the tablespace, the table must be dropped.\nmysql> CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' Engine=InnoDB;\nmysql> CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts1 Engine=InnoDB;\nmysql> DROP TABLE t1;\nmysql> DROP TABLESPACE ts1;\nThis example demonstrates dropping an undo tablespace. An undo tablespace must be in an empty\nstate before it can be dropped. For more information, see Section 17.6.3.4, “Undo Tablespaces”.\nmysql> DROP UNDO TABLESPACE undo_003;\nNDB Example\nThis example shows how to drop an NDB tablespace myts having a data file named mydata-1.dat\nafter first creating the tablespace, and assumes the existence of a log file group named mylg (see\nSection 15.1.16, “CREATE LOGFILE GROUP Statement”).\nmysql> CREATE TABLESPACE myts\n    ->     ADD DATAFILE 'mydata-1.dat'\n    ->     USE LOGFILE GROUP mylg\n    ->     ENGINE=NDB;\nYou must remove all data files from the tablespace using ALTER TABLESPACE, as shown here, before\nit can be dropped:\nmysql> ALTER TABLESPACE myts\n    ->     DROP DATAFILE 'mydata-1.dat';\nmysql> DROP TABLESPACE myts;",
    "15.1.34 DROP TRIGGER Statement": "15.1.34 DROP TRIGGER Statement\nDROP TRIGGER [IF EXISTS] [schema_name.]trigger_name\nThis statement drops a trigger. The schema (database) name is optional. If the schema is omitted, the\ntrigger is dropped from the default schema. DROP TRIGGER requires the TRIGGER privilege for the\ntable associated with the trigger.\nUse IF EXISTS to prevent an error from occurring for a trigger that does not exist. A NOTE is\ngenerated for a nonexistent trigger when using IF EXISTS. See Section 15.7.7.41, “SHOW\nWARNINGS Statement”.\nTriggers for a table are also dropped if you drop the table.",
    "15.1.35 DROP VIEW Statement": "15.1.35 DROP VIEW Statement\nDROP VIEW [IF EXISTS]\n    view_name [, view_name] ...\n    [RESTRICT | CASCADE]\nDROP VIEW removes one or more views. You must have the DROP privilege for each view.\nIf any views named in the argument list do not exist, the statement fails with an error indicating by\nname which nonexisting views it was unable to drop, and no changes are made.\nThe IF EXISTS clause prevents an error from occurring for views that don't exist. When this clause\nis given, a NOTE is generated for each nonexistent view. See Section 15.7.7.41, “SHOW WARNINGS\nStatement”.\nRESTRICT and CASCADE, if given, are parsed and ignored.",
    "15.1.36 RENAME TABLE Statement": "15.1.36 RENAME TABLE Statement\nRENAME TABLE\n    tbl_name TO new_tbl_name\n    [, tbl_name2 TO new_tbl_name2] ...\nRENAME TABLE renames one or more tables. You must have ALTER and DROP privileges for the\noriginal table, and CREATE and INSERT privileges for the new table.\nFor example, to rename a table named old_table to new_table, use this statement:\nRENAME TABLE old_table TO new_table;\nThat statement is equivalent to the following ALTER TABLE statement:\nALTER TABLE old_table RENAME new_table;\nRENAME TABLE, unlike ALTER TABLE, can rename multiple tables within a single statement:\nRENAME TABLE old_table1 TO new_table1,\n             old_table2 TO new_table2,\n             old_table3 TO new_table3;\nRenaming operations are performed left to right. Thus, to swap two table names, do this (assuming that\na table with the intermediary name tmp_table does not already exist):\nRENAME TABLE old_table TO tmp_table,\n             new_table TO old_table,\n             tmp_table TO new_table;\nMetadata locks on tables are acquired in name order, which in some cases can make a difference in\noperation outcome when multiple transactions execute concurrently. See Section 10.11.4, “Metadata\nLocking”.\nYou can rename tables locked with a LOCK TABLES statement, provided that they are locked with a\nWRITE lock or are the product of renaming WRITE-locked tables from earlier steps in a multiple-table\nrename operation. For example, this is permitted:\nLOCK TABLE old_table1 WRITE;\nRENAME TABLE old_table1 TO new_table1,\n             new_table1 TO new_table2;\nThis is not permitted:\nLOCK TABLE old_table1 READ;\nRENAME TABLE old_table1 TO new_table1,\n             new_table1 TO new_table2;\nWith the transaction table locking conditions satisfied, the rename operation is done atomically; no\nother session can access any of the tables while the rename is in progress.\nIf any errors occur during a RENAME TABLE, the statement fails and no changes are made.\nYou can use RENAME TABLE to move a table from one database to another:\nRENAME TABLE current_db.tbl_name TO other_db.tbl_name;\nUsing this method to move all tables from one database to a different one in effect renames the\ndatabase (an operation for which MySQL has no single statement), except that the original database\ncontinues to exist, albeit with no tables.\nLike RENAME TABLE, ALTER TABLE ... RENAME can also be used to move a table to a different\ndatabase. Regardless of the statement used, if the rename operation would move the table to a\ndatabase located on a different file system, the success of the outcome is platform specific and\ndepends on the underlying operating system calls used to move table files.\nIf a table has triggers, attempts to rename the table into a different database fail with a Trigger in\nwrong schema (ER_TRG_IN_WRONG_SCHEMA) error.\nAn unencrypted table can be moved to an encryption-enabled database and vice versa. However, if\nthe table_encryption_privilege_check variable is enabled, the TABLE_ENCRYPTION_ADMIN\nprivilege is required if the table encryption setting differs from the default database encryption.\nTo rename TEMPORARY tables, RENAME TABLE does not work. Use ALTER TABLE instead.\nRENAME TABLE works for views, except that views cannot be renamed into a different database.\nAny privileges granted specifically for a renamed table or view are not migrated to the new name. They\nmust be changed manually.\nRENAME TABLE tbl_name TO new_tbl_name changes internally generated foreign key constraint\nnames and user-defined foreign key constraint names that begin with the string “tbl_name_ibfk_” to\nreflect the new table name. InnoDB interprets foreign key constraint names that begin with the string\n“tbl_name_ibfk_” as internally generated names.\nForeign key constraint names that point to the renamed table are automatically updated unless there\nis a conflict, in which case the statement fails with an error. A conflict occurs if the renamed constraint\nname already exists. In such cases, you must drop and re-create the foreign keys for them to function\nproperly.\nRENAME TABLE tbl_name TO new_tbl_name changes internally generated and user-defined\nCHECK constraint names that begin with the string “tbl_name_chk_” to reflect the new table name.\nMySQL interprets CHECK constraint names that begin with the string “tbl_name_chk_” as internally\ngenerated names. Example:\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `i1` int(11) DEFAULT NULL,\n  `i2` int(11) DEFAULT NULL,\n  CONSTRAINT `t1_chk_1` CHECK ((`i1` > 0)),\n  CONSTRAINT `t1_chk_2` CHECK ((`i2` < 0))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.02 sec)\nmysql> RENAME TABLE t1 TO t3;\nQuery OK, 0 rows affected (0.03 sec)\nmysql> SHOW CREATE TABLE t3\\G\n*************************** 1. row ***************************\n       Table: t3\nCreate Table: CREATE TABLE `t3` (\n  `i1` int(11) DEFAULT NULL,\n  `i2` int(11) DEFAULT NULL,\n  CONSTRAINT `t3_chk_1` CHECK ((`i1` > 0)),\n  CONSTRAINT `t3_chk_2` CHECK ((`i2` < 0))\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.01 sec)",
    "15.1.37 TRUNCATE TABLE Statement": "15.1.37 TRUNCATE TABLE Statement\nTRUNCATE [TABLE] tbl_name\nTRUNCATE TABLE empties a table completely. It requires the DROP privilege. Logically, TRUNCATE\nTABLE is similar to a DELETE statement that deletes all rows, or a sequence of DROP TABLE and\nCREATE TABLE statements.\nTo achieve high performance, TRUNCATE TABLE bypasses the DML method of deleting data.\nThus, it does not cause ON DELETE triggers to fire, it cannot be performed for InnoDB tables with\nparent-child foreign key relationships, and it cannot be rolled back like a DML operation. However,\nTRUNCATE TABLE operations on tables that use an atomic DDL-supported storage engine are either\nfully committed or rolled back if the server halts during their operation. For more information, see\nSection 15.1.1, “Atomic Data Definition Statement Support”.\nAlthough TRUNCATE TABLE is similar to DELETE, it is classified as a DDL statement rather than a DML\nstatement. It differs from DELETE in the following ways:\n• Truncate operations drop and re-create the table, which is much faster than deleting rows one by\none, particularly for large tables.\n• Truncate operations cause an implicit commit, and so cannot be rolled back. See Section 15.3.3,\n“Statements That Cause an Implicit Commit”.\n• Truncation operations cannot be performed if the session holds an active table lock.\n• TRUNCATE TABLE fails for an InnoDB table or NDB table if there are any FOREIGN KEY constraints\nfrom other tables that reference the table. Foreign key constraints between columns of the same\ntable are permitted.\n• Truncation operations do not return a meaningful value for the number of deleted rows. The usual\nresult is “0 rows affected,” which should be interpreted as “no information.”\n• As long as the table definition is valid, the table can be re-created as an empty table with TRUNCATE\nTABLE, even if the data or index files have become corrupted.\n• Any AUTO_INCREMENT value is reset to its start value. This is true even for MyISAM and InnoDB,\nwhich normally do not reuse sequence values.\n• When used with partitioned tables, TRUNCATE TABLE preserves the partitioning; that is, the data\nand index files are dropped and re-created, while the partition definitions are unaffected.\n• The TRUNCATE TABLE statement does not invoke ON DELETE triggers.\n• Truncating a corrupted InnoDB table is supported.\nTRUNCATE TABLE is treated for purposes of binary logging and replication as DDL rather than DML,\nand is always logged as a statement.\nTRUNCATE TABLE for a table closes all handlers for the table that were opened with HANDLER OPEN.\nTRUNCATE TABLE can be used with Performance Schema summary tables, but the effect is to reset\nthe summary columns to 0 or NULL, not to remove rows. See Section 29.12.20, “Performance Schema\nSummary Tables”.\nTruncating an InnoDB table that resides in a file-per-table tablespace drops the existing tablespace\nand creates a new one. If the tablespace was created with an earlier version and resides in an\nunknown directory, InnoDB creates the new tablespace in the default location and writes the following\nwarning to the error log: The DATA DIRECTORY location must be in a known directory.\nThe DATA DIRECTORY location will be ignored and the file will be put into\nthe default datadir location. Known directories are those defined by the datadir,\ninnodb_data_home_dir, and innodb_directories variables. To have TRUNCATE TABLE create\nthe tablespace in its current location, add the directory to the innodb_directories setting before\nrunning TRUNCATE TABLE.",
    "15.2 Data Manipulation Statements": "15.2 Data Manipulation Statements",
    "15.2.1 CALL Statement": "15.2.1 CALL Statement\nCALL sp_name([parameter[,...]])\nCALL sp_name[()]\nThe CALL statement invokes a stored procedure that was defined previously with CREATE\nPROCEDURE.\nStored procedures that take no arguments can be invoked without parentheses. That is, CALL p()\nand CALL p are equivalent.\nCALL can pass back values to its caller using parameters that are declared as OUT or INOUT\nparameters. When the procedure returns, a client program can also obtain the number of rows affected\nfor the final statement executed within the routine: At the SQL level, call the ROW_COUNT() function;\nfrom the C API, call the mysql_affected_rows() function.\nFor information about the effect of unhandled conditions on procedure parameters, see\nSection 15.6.7.8, “Condition Handling and OUT or INOUT Parameters”.\nTo get back a value from a procedure using an OUT or INOUT parameter, pass the parameter by\nmeans of a user variable, and then check the value of the variable after the procedure returns. (If you\nare calling the procedure from within another stored procedure or function, you can also pass a routine\nparameter or local routine variable as an IN or INOUT parameter.) For an INOUT parameter, initialize\nits value before passing it to the procedure. The following procedure has an OUT parameter that the\nprocedure sets to the current server version, and an INOUT value that the procedure increments by\none from its current value:\nDELIMITER //\nCREATE PROCEDURE p (OUT ver_param VARCHAR(25), INOUT incr_param INT)\nBEGIN\n  # Set value of OUT parameter\n  SELECT VERSION() INTO ver_param;\n  # Increment value of INOUT parameter\n  SET incr_param = incr_param + 1;\nEND //\nDELIMITER ;\nBefore calling the procedure, initialize the variable to be passed as the INOUT parameter. After calling\nthe procedure, you can see that the values of the two variables are set or modified:\nmysql> SET @increment = 10;\nmysql> CALL p(@version, @increment);\nmysql> SELECT @version, @increment;\n+----------+------------+\n| @version | @increment |\n+----------+------------+\n| 9.1.0   |         11 |\n+----------+------------+\nIn prepared CALL statements used with PREPARE and EXECUTE, placeholders can be used for IN\nparameters, OUT, and INOUT parameters. These types of parameters can be used as follows:\nmysql> SET @increment = 10;\nmysql> PREPARE s FROM 'CALL p(?, ?)';\nmysql> EXECUTE s USING @version, @increment;\nmysql> SELECT @version, @increment;\n+----------+------------+\n| @version | @increment |\n+----------+------------+\n| 9.1.0   |         11 |\n+----------+------------+\nTo write C programs that use the CALL SQL statement to execute stored procedures that produce\nresult sets, the CLIENT_MULTI_RESULTS flag must be enabled. This is because each CALL returns\na result to indicate the call status, in addition to any result sets that might be returned by statements\nexecuted within the procedure. CLIENT_MULTI_RESULTS must also be enabled if CALL is used to\nexecute any stored procedure that contains prepared statements. It cannot be determined when such\na procedure is loaded whether those statements produce result sets, so it is necessary to assume that\nthey do so.\nCLIENT_MULTI_RESULTS can be enabled when you call mysql_real_connect(),\neither explicitly by passing the CLIENT_MULTI_RESULTS flag itself, or implicitly by\npassing CLIENT_MULTI_STATEMENTS (which also enables CLIENT_MULTI_RESULTS).\nCLIENT_MULTI_RESULTS is enabled by default.\nTo process the result of a CALL statement executed using mysql_query() or\nmysql_real_query(), use a loop that calls mysql_next_result() to determine whether there\nare more results. For an example, see Multiple Statement Execution Support.\nC programs can use the prepared-statement interface to execute CALL statements and access OUT\nand INOUT parameters. This is done by processing the result of a CALL statement using a loop that\ncalls mysql_stmt_next_result() to determine whether there are more results. For an example,\nsee Prepared CALL Statement Support. Languages that provide a MySQL interface can use prepared\nCALL statements to directly retrieve OUT and INOUT procedure parameters.\nMetadata changes to objects referred to by stored programs are detected and cause automatic\nreparsing of the affected statements when the program is next executed. For more information, see\nSection 10.10.3, “Caching of Prepared Statements and Stored Programs”.",
    "15.2.2 DELETE Statement": "15.2.2 DELETE Statement\nDELETE is a DML statement that removes rows from a table.\nA DELETE statement can start with a WITH clause to define common table expressions accessible\nwithin the DELETE. See Section 15.2.20, “WITH (Common Table Expressions)”.\nSingle-Table Syntax\nDELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name [[AS] tbl_alias]\n    [PARTITION (partition_name [, partition_name] ...)]\n    [WHERE where_condition]\n    [ORDER BY ...]\n    [LIMIT row_count]\nThe DELETE statement deletes rows from tbl_name and returns the number of deleted rows. To\ncheck the number of deleted rows, call the ROW_COUNT() function described in Section 14.15,\n“Information Functions”.\nMain Clauses\nThe conditions in the optional WHERE clause identify which rows to delete. With no WHERE clause, all\nrows are deleted.\nwhere_condition is an expression that evaluates to true for each row to be deleted. It is specified as\ndescribed in Section 15.2.13, “SELECT Statement”.\nIf the ORDER BY clause is specified, the rows are deleted in the order that is specified. The LIMIT\nclause places a limit on the number of rows that can be deleted. These clauses apply to single-table\ndeletes, but not multi-table deletes.\nMultiple-Table Syntax\nDELETE [LOW_PRIORITY] [QUICK] [IGNORE]\n    tbl_name[.*] [, tbl_name[.*]] ...\n    FROM table_references\n    [WHERE where_condition]\nDELETE [LOW_PRIORITY] [QUICK] [IGNORE]\n    FROM tbl_name[.*] [, tbl_name[.*]] ...\n    USING table_references\n    [WHERE where_condition]\nPrivileges\nYou need the DELETE privilege on a table to delete rows from it. You need only the SELECT privilege\nfor any columns that are only read, such as those named in the WHERE clause.\nPerformance\nWhen you do not need to know the number of deleted rows, the TRUNCATE TABLE statement is\na faster way to empty a table than a DELETE statement with no WHERE clause. Unlike DELETE,\nTRUNCATE TABLE cannot be used within a transaction or if you have a lock on the table. See\nSection 15.1.37, “TRUNCATE TABLE Statement” and Section 15.3.6, “LOCK TABLES and UNLOCK\nTABLES Statements”.\nThe speed of delete operations may also be affected by factors discussed in Section 10.2.5.3,\n“Optimizing DELETE Statements”.\nTo ensure that a given DELETE statement does not take too much time, the MySQL-specific LIMIT\nrow_count clause for DELETE specifies the maximum number of rows to be deleted. If the number of\nrows to delete is larger than the limit, repeat the DELETE statement until the number of affected rows is\nless than the LIMIT value.\nSubqueries\nYou cannot delete from a table and select from the same table in a subquery.\nPartitioned Table Support\nDELETE supports explicit partition selection using the PARTITION clause, which takes a list of the\ncomma-separated names of one or more partitions or subpartitions (or both) from which to select rows\nto be dropped. Partitions not included in the list are ignored. Given a partitioned table t with a partition\nnamed p0, executing the statement DELETE FROM t PARTITION (p0) has the same effect on\nthe table as executing ALTER TABLE t TRUNCATE PARTITION (p0); in both cases, all rows in\npartition p0 are dropped.\nPARTITION can be used along with a WHERE condition, in which case the condition is tested only\non rows in the listed partitions. For example, DELETE FROM t PARTITION (p0) WHERE c < 5\ndeletes rows only from partition p0 for which the condition c < 5 is true; rows in any other partitions\nare not checked and thus not affected by the DELETE.\nThe PARTITION clause can also be used in multiple-table DELETE statements. You can use up to one\nsuch option per table named in the FROM option.\nFor more information and examples, see Section 26.5, “Partition Selection”.\nAuto-Increment Columns\nIf you delete the row containing the maximum value for an AUTO_INCREMENT column, the value\nis not reused for a MyISAM or InnoDB table. If you delete all rows in the table with DELETE FROM\ntbl_name (without a WHERE clause) in autocommit mode, the sequence starts over for all storage\nengines except InnoDB and MyISAM. There are some exceptions to this behavior for InnoDB tables,\nas discussed in Section 17.6.1.6, “AUTO_INCREMENT Handling in InnoDB”.\nFor MyISAM tables, you can specify an AUTO_INCREMENT secondary column in a multiple-column key.\nIn this case, reuse of values deleted from the top of the sequence occurs even for MyISAM tables. See\nSection 5.6.9, “Using AUTO_INCREMENT”.\nModifiers\nThe DELETE statement supports the following modifiers:\n• If you specify the LOW_PRIORITY modifier, the server delays execution of the DELETE until no other\nclients are reading from the table. This affects only storage engines that use only table-level locking\n(such as MyISAM, MEMORY, and MERGE).\n• For MyISAM tables, if you use the QUICK modifier, the storage engine does not merge index leaves\nduring delete, which may speed up some kinds of delete operations.\n• The IGNORE modifier causes MySQL to ignore ignorable errors during the process of deleting rows.\n(Errors encountered during the parsing stage are processed in the usual manner.) Errors that are\nignored due to the use of IGNORE are returned as warnings. For more information, see The Effect of\nIGNORE on Statement Execution.\nOrder of Deletion\nIf the DELETE statement includes an ORDER BY clause, rows are deleted in the order specified by the\nclause. This is useful primarily in conjunction with LIMIT. For example, the following statement finds\nrows matching the WHERE clause, sorts them by timestamp_column, and deletes the first (oldest)\none:\nDELETE FROM somelog WHERE user = 'jcole'\nORDER BY timestamp_column LIMIT 1;\nORDER BY also helps to delete rows in an order required to avoid referential integrity violations.\nInnoDB Tables\nIf you are deleting many rows from a large table, you may exceed the lock table size for an InnoDB\ntable. To avoid this problem, or simply to minimize the time that the table remains locked, the following\nstrategy (which does not use DELETE at all) might be helpful:\n1. Select the rows not to be deleted into an empty table that has the same structure as the original\ntable:\nINSERT INTO t_copy SELECT * FROM t WHERE ... ;\n2. Use RENAME TABLE to atomically move the original table out of the way and rename the copy to\nthe original name:\nRENAME TABLE t TO t_old, t_copy TO t;\n3. Drop the original table:\nDROP TABLE t_old;\nNo other sessions can access the tables involved while RENAME TABLE executes, so the rename\noperation is not subject to concurrency problems. See Section 15.1.36, “RENAME TABLE Statement”.\nMyISAM Tables\nIn MyISAM tables, deleted rows are maintained in a linked list and subsequent INSERT operations\nreuse old row positions. To reclaim unused space and reduce file sizes, use the OPTIMIZE TABLE\nstatement or the myisamchk utility to reorganize tables. OPTIMIZE TABLE is easier to use, but\nmyisamchk is faster. See Section 15.7.3.4, “OPTIMIZE TABLE Statement”, and Section 6.6.4,\n“myisamchk — MyISAM Table-Maintenance Utility”.\nThe QUICK modifier affects whether index leaves are merged for delete operations. DELETE QUICK is\nmost useful for applications where index values for deleted rows are replaced by similar index values\nfrom rows inserted later. In this case, the holes left by deleted values are reused.\nDELETE QUICK is not useful when deleted values lead to underfilled index blocks spanning a range of\nindex values for which new inserts occur again. In this case, use of QUICK can lead to wasted space in\nthe index that remains unreclaimed. Here is an example of such a scenario:\n1. Create a table that contains an indexed AUTO_INCREMENT column.\n2. Insert many rows into the table. Each insert results in an index value that is added to the high end\nof the index.\n3. Delete a block of rows at the low end of the column range using DELETE QUICK.\nIn this scenario, the index blocks associated with the deleted index values become underfilled but\nare not merged with other index blocks due to the use of QUICK. They remain underfilled when new\ninserts occur, because new rows do not have index values in the deleted range. Furthermore, they\nremain underfilled even if you later use DELETE without QUICK, unless some of the deleted index\nvalues happen to lie in index blocks within or adjacent to the underfilled blocks. To reclaim unused\nindex space under these circumstances, use OPTIMIZE TABLE.\nIf you are going to delete many rows from a table, it might be faster to use DELETE QUICK followed by\nOPTIMIZE TABLE. This rebuilds the index rather than performing many index block merge operations.\nMulti-Table Deletes\nYou can specify multiple tables in a DELETE statement to delete rows from one or more tables\ndepending on the condition in the WHERE clause. You cannot use ORDER BY or LIMIT in a multiple-\ntable DELETE. The table_references clause lists the tables involved in the join, as described in\nSection 15.2.13.2, “JOIN Clause”.\nFor the first multiple-table syntax, only matching rows from the tables listed before the FROM clause are\ndeleted. For the second multiple-table syntax, only matching rows from the tables listed in the FROM\nclause (before the USING clause) are deleted. The effect is that you can delete rows from many tables\nat the same time and have additional tables that are used only for searching:\nDELETE t1, t2 FROM t1 INNER JOIN t2 INNER JOIN t3\nWHERE t1.id=t2.id AND t2.id=t3.id;\nOr:\nDELETE FROM t1, t2 USING t1 INNER JOIN t2 INNER JOIN t3\nWHERE t1.id=t2.id AND t2.id=t3.id;\nThese statements use all three tables when searching for rows to delete, but delete matching rows only\nfrom tables t1 and t2.\nThe preceding examples use INNER JOIN, but multiple-table DELETE statements can use other types\nof join permitted in SELECT statements, such as LEFT JOIN. For example, to delete rows that exist in\nt1 that have no match in t2, use a LEFT JOIN:\nDELETE t1 FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL;\nThe syntax permits .* after each tbl_name for compatibility with Access.\nIf you use a multiple-table DELETE statement involving InnoDB tables for which there are foreign key\nconstraints, the MySQL optimizer might process tables in an order that differs from that of their parent/\nchild relationship. In this case, the statement fails and rolls back. Instead, you should delete from a\nsingle table and rely on the ON DELETE capabilities that InnoDB provides to cause the other tables to\nbe modified accordingly.\nNote\nIf you declare an alias for a table, you must use the alias when referring to the\ntable:\nDELETE t1 FROM test AS t1, test2 WHERE ...\nTable aliases in a multiple-table DELETE should be declared only in the table_references part of\nthe statement. Elsewhere, alias references are permitted but not alias declarations.\nCorrect:\nDELETE a1, a2 FROM t1 AS a1 INNER JOIN t2 AS a2\nWHERE a1.id=a2.id;\nDELETE FROM a1, a2 USING t1 AS a1 INNER JOIN t2 AS a2\nWHERE a1.id=a2.id;\nIncorrect:\nDELETE t1 AS a1, t2 AS a2 FROM t1 INNER JOIN t2\nWHERE a1.id=a2.id;\nDELETE FROM t1 AS a1, t2 AS a2 USING t1 INNER JOIN t2\nWHERE a1.id=a2.id;\nTable aliases are also supported for single-table DELETE statements.",
    "15.2.3 DO Statement": "15.2.3 DO Statement\nDO expr [, expr] ...\nDO executes the expressions but does not return any results. In most respects, DO is shorthand for\nSELECT expr, ..., but has the advantage that it is slightly faster when you do not care about the\nresult.\nDO is useful primarily with functions that have side effects, such as RELEASE_LOCK().\nExample: This SELECT statement pauses, but also produces a result set:\nmysql> SELECT SLEEP(5);\n+----------+\n| SLEEP(5) |\n+----------+\n|        0 |\n+----------+\n1 row in set (5.02 sec)\nDO, on the other hand, pauses without producing a result set.:\nmysql> DO SLEEP(5);\nQuery OK, 0 rows affected (4.99 sec)\nThis could be useful, for example in a stored function or trigger, which prohibit statements that produce\nresult sets.\nDO only executes expressions. It cannot be used in all cases where SELECT can be used. For example,\nDO id FROM t1 is invalid because it references a table.",
    "15.2.4 EXCEPT Clause": "15.2.4 EXCEPT Clause\nquery_expression_body EXCEPT [ALL | DISTINCT] query_expression_body\n    [EXCEPT [ALL | DISTINCT] query_expression_body]\n    [...]\nquery_expression_body:\n    See Section 15.2.14, “Set Operations with UNION, INTERSECT, and EXCEPT”\nEXCEPT limits the result from the first query block to those rows which are (also) not found in the\nsecond. As with UNION and INTERSECT, either query block can make use of any of SELECT, TABLE,\nor VALUES. An example using the tables a, b, and c defined in Section 15.2.8, “INTERSECT Clause”,\nis shown here:\nmysql> TABLE a EXCEPT TABLE b;\n+------+------+\n| m    | n    |\n+------+------+\n|    2 |    3 |\n+------+------+\n1 row in set (0.00 sec)\nmysql> TABLE a EXCEPT TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    2 |\n|    2 |    3 |\n+------+------+\n2 rows in set (0.00 sec)\nmysql> TABLE b EXCEPT TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    2 |\n+------+------+\n1 row in set (0.00 sec)\nAs with UNION and INTERSECT, if neither DISTINCT nor ALL is specified, the default is DISTINCT.\nDISTINCT removes duplicates found on either side of the relation, as shown here:\nmysql> TABLE c EXCEPT DISTINCT TABLE a;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    3 |\n+------+------+\n1 row in set (0.00 sec)\nmysql> TABLE c EXCEPT ALL TABLE a;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    3 |\n|    1 |    3 |\n+------+------+\n2 rows in set (0.00 sec)\n(The first statement has the same effect as TABLE c EXCEPT TABLE a.)\nUnlike UNION or INTERSECT, EXCEPT is not commutative—that is, the result depends on the order of\nthe operands, as shown here:\nmysql> TABLE a EXCEPT TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    2 |\n|    2 |    3 |\n+------+------+\n2 rows in set (0.00 sec)\nmysql> TABLE c EXCEPT TABLE a;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    3 |\n+------+------+\n1 row in set (0.00 sec)\nAs with UNION, the result sets to be compared must have the same number of columns. Result set\ncolumn types are also determined as for UNION.",
    "15.2.5 HANDLER Statement": "15.2.5 HANDLER Statement\nHANDLER tbl_name OPEN [ [AS] alias]\nHANDLER tbl_name READ index_name { = | <= | >= | < | > } (value1,value2,...)\n    [ WHERE where_condition ] [LIMIT ... ]\nHANDLER tbl_name READ index_name { FIRST | NEXT | PREV | LAST }\n    [ WHERE where_condition ] [LIMIT ... ]\nHANDLER tbl_name READ { FIRST | NEXT }\n    [ WHERE where_condition ] [LIMIT ... ]\nHANDLER tbl_name CLOSE\nThe HANDLER statement provides direct access to table storage engine interfaces. It is available for\nInnoDB and MyISAM tables.\nThe HANDLER ... OPEN statement opens a table, making it accessible using subsequent\nHANDLER ... READ statements. This table object is not shared by other sessions and is not closed\nuntil the session calls HANDLER ... CLOSE or the session terminates.\nIf you open the table using an alias, further references to the open table with other HANDLER\nstatements must use the alias rather than the table name. If you do not use an alias, but open the table\nusing a table name qualified by the database name, further references must use the unqualified table\nname. For example, for a table opened using mydb.mytable, further references must use mytable.\nThe first HANDLER ... READ syntax fetches a row where the index specified satisfies the given\nvalues and the WHERE condition is met. If you have a multiple-column index, specify the index column\nvalues as a comma-separated list. Either specify values for all the columns in the index, or specify\nvalues for a leftmost prefix of the index columns. Suppose that an index my_idx includes three\ncolumns named col_a, col_b, and col_c, in that order. The HANDLER statement can specify values\nfor all three columns in the index, or for the columns in a leftmost prefix. For example:\nHANDLER ... READ my_idx = (col_a_val,col_b_val,col_c_val) ...\nHANDLER ... READ my_idx = (col_a_val,col_b_val) ...\nHANDLER ... READ my_idx = (col_a_val) ...\nTo employ the HANDLER interface to refer to a table's PRIMARY KEY, use the quoted identifier\n`PRIMARY`:\nHANDLER tbl_name READ `PRIMARY` ...\nThe second HANDLER ... READ syntax fetches a row from the table in index order that matches the\nWHERE condition.\nThe third HANDLER ... READ syntax fetches a row from the table in natural row order that matches\nthe WHERE condition. It is faster than HANDLER tbl_name READ index_name when a full table scan\nis desired. Natural row order is the order in which rows are stored in a MyISAM table data file. This\nstatement works for InnoDB tables as well, but there is no such concept because there is no separate\ndata file.\nWithout a LIMIT clause, all forms of HANDLER ... READ fetch a single row if one is available. To\nreturn a specific number of rows, include a LIMIT clause. It has the same syntax as for the SELECT\nstatement. See Section 15.2.13, “SELECT Statement”.\nHANDLER ... CLOSE closes a table that was opened with HANDLER ... OPEN.\nThere are several reasons to use the HANDLER interface instead of normal SELECT statements:\n• HANDLER is faster than SELECT:\n• A designated storage engine handler object is allocated for the HANDLER ... OPEN. The object\nis reused for subsequent HANDLER statements for that table; it need not be reinitialized for each\none.\n• There is less parsing involved.\n• There is no optimizer or query-checking overhead.\n• The handler interface does not have to provide a consistent look of the data (for example, dirty\nreads are permitted), so the storage engine can use optimizations that SELECT does not normally\npermit.\n• HANDLER makes it easier to port to MySQL applications that use a low-level ISAM-like interface.\n• HANDLER enables you to traverse a database in a manner that is difficult (or even impossible) to\naccomplish with SELECT. The HANDLER interface is a more natural way to look at data when working\nwith applications that provide an interactive user interface to the database.\nHANDLER is a somewhat low-level statement. For example, it does not provide consistency. That is,\nHANDLER ... OPEN does not take a snapshot of the table, and does not lock the table. This means\nthat after a HANDLER ... OPEN statement is issued, table data can be modified (by the current\nsession or other sessions) and these modifications might be only partially visible to HANDLER ...\nNEXT or HANDLER ... PREV scans.\nAn open handler can be closed and marked for reopen, in which case the handler loses its position in\nthe table. This occurs when both of the following circumstances are true:\n• Any session executes FLUSH TABLES or DDL statements on the handler's table.\n• The session in which the handler is open executes non-HANDLER statements that use tables.\nTRUNCATE TABLE for a table closes all handlers for the table that were opened with HANDLER OPEN.\nIf a table is flushed with FLUSH TABLES tbl_name WITH READ LOCK was opened with HANDLER,\nthe handler is implicitly flushed and loses its position.",
    "15.2.6 IMPORT TABLE Statement": "15.2.6 IMPORT TABLE Statement\nIMPORT TABLE FROM sdi_file [, sdi_file] ...\nThe IMPORT TABLE statement imports MyISAM tables based on information contained in .sdi\n(serialized dictionary information) metadata files. IMPORT TABLE requires the FILE privilege to read\nthe .sdi and table content files, and the CREATE privilege for the table to be created.\nTables can be exported from one server using mysqldump to write a file of SQL statements and\nimported into another server using mysql to process the dump file. IMPORT TABLE provides a faster\nalternative using the “raw” table files.\nPrior to import, the files that provide the table content must be placed in the appropriate schema\ndirectory for the import server, and the .sdi file must be located in a directory accessible to the server.\nFor example, the .sdi file can be placed in the directory named by the secure_file_priv system\nvariable, or (if secure_file_priv is empty) in a directory under the server data directory.\nThe following example describes how to export MyISAM tables named employees and managers\nfrom the hr schema of one server and import them into the hr schema of another server. The example\nuses these assumptions (to perform a similar operation on your own system, modify the path names as\nappropriate):\n• For the export server, export_basedir represents its base directory, and its data directory is\nexport_basedir/data.\n• For the import server, import_basedir represents its base directory, and its data directory is\nimport_basedir/data.\n• Table files are exported from the export server into the /tmp/export directory and this directory is\nsecure (not accessible to other users).\n• The import server uses /tmp/mysql-files as the directory named by its secure_file_priv\nsystem variable.\nTo export tables from the export server, use this procedure:\n1. Ensure a consistent snapshot by executing this statement to lock the tables so that they cannot be\nmodified during export:\nmysql> FLUSH TABLES hr.employees, hr.managers WITH READ LOCK;\nWhile the lock is in effect, the tables can still be used, but only for read access.\n2. At the file system level, copy the .sdi and table content files from the hr schema directory to the\nsecure export directory:\n• The .sdi file is located in the hr schema directory, but might not have exactly the same\nbasename as the table name. For example, the .sdi files for the employees and managers\ntables might be named employees_125.sdi and managers_238.sdi.\n• For a MyISAM table, the content files are its .MYD data file and .MYI index file.\nGiven those file names, the copy commands look like this:\n$> cd export_basedir/data/hr\n$> cp employees_125.sdi /tmp/export\n$> cp managers_238.sdi /tmp/export\n$> cp employees.{MYD,MYI} /tmp/export\n$> cp managers.{MYD,MYI} /tmp/export\n3. Unlock the tables:\nmysql> UNLOCK TABLES;\nTo import tables into the import server, use this procedure:\n1. The import schema must exist. If necessary, execute this statement to create it:\nmysql> CREATE SCHEMA hr;\n2. At the file system level, copy the .sdi files to the import server secure_file_priv directory, /\ntmp/mysql-files. Also, copy the table content files to the hr schema directory:\n$> cd /tmp/export\n$> cp employees_125.sdi /tmp/mysql-files\n$> cp managers_238.sdi /tmp/mysql-files\n$> cp employees.{MYD,MYI} import_basedir/data/hr\n$> cp managers.{MYD,MYI} import_basedir/data/hr\n3. Import the tables by executing an IMPORT TABLE statement that names the .sdi files:\nmysql> IMPORT TABLE FROM\n       '/tmp/mysql-files/employees.sdi',\n       '/tmp/mysql-files/managers.sdi';\nThe .sdi file need not be placed in the import server directory named by the secure_file_priv\nsystem variable if that variable is empty; it can be in any directory accessible to the server, including\nthe schema directory for the imported table. If the .sdi file is placed in that directory, however, it may\nbe rewritten; the import operation creates a new .sdi file for the table, which overwrites the old .sdi\nfile if the operation uses the same file name for the new file.\nEach sdi_file value must be a string literal that names the .sdi file for a table or is a pattern that\nmatches .sdi files. If the string is a pattern, any leading directory path and the .sdi file name suffix\nmust be given literally. Pattern characters are permitted only in the base name part of the file name:\n• ? matches any single character\n• * matches any sequence of characters, including no characters\nUsing a pattern, the previous IMPORT TABLE statement could have been written like this (assuming\nthat the /tmp/mysql-files directory contains no other .sdi files matching the pattern):\nIMPORT TABLE FROM '/tmp/mysql-files/*.sdi';\nTo interpret the location of .sdi file path names, the server uses the same rules for IMPORT TABLE\nas the server-side rules for LOAD DATA (that is, the non-LOCAL rules). See Section 15.2.9, “LOAD\nDATA Statement”, paying particular attention to the rules used to interpret relative path names.\nIMPORT TABLE fails if the .sdi or table files cannot be located. After importing a table, the server\nattempts to open it and reports as warnings any problems detected. To attempt a repair to correct any\nreported issues, use REPAIR TABLE.\nIMPORT TABLE is not written to the binary log.\nRestrictions and Limitations\nIMPORT TABLE applies only to non-TEMPORARY MyISAM tables. It does not apply to tables created\nwith a transactional storage engine, tables created with CREATE TEMPORARY TABLE, or views.\nAn .sdi file used in an import operation must be generated on a server with the same data dictionary\nversion and sdi version as the import server. The version information of the generating server is found\nin the .sdi file:\n{\n   \"mysqld_version_id\":80019,\n   \"dd_version\":80017,\n   \"sdi_version\":80016,\n   ...\n}\nTo determine the data dictionary and sdi version of the import server, you can check the .sdi file of a\nrecently created table on the import server.\nThe table data and index files must be placed in the schema directory for the import server prior to\nthe import operation, unless the table as defined on the export server uses the DATA DIRECTORY\nor INDEX DIRECTORY table options. In that case, modify the import procedure using one of these\nalternatives before executing the IMPORT TABLE statement:\n• Put the data and index files into the same directory on the import server host as on the export server\nhost, and create symlinks in the import server schema directory to those files.\n• Put the data and index files into an import server host directory different from that on the export\nserver host, and create symlinks in the import server schema directory to those files. In addition,\nmodify the .sdi file to reflect the different file locations.\n• Put the data and index files into the schema directory on the import server host, and modify the .sdi\nfile to remove the data and index directory table options.\nAny collation IDs stored in the .sdi file must refer to the same collations on the export and import\nservers.\nTrigger information for a table is not serialized into the table .sdi file, so triggers are not restored by\nthe import operation.\nSome edits to an .sdi file are permissible prior to executing the IMPORT TABLE statement, whereas\nothers are problematic or may even cause the import operation to fail:\n• Changing the data directory and index directory table options is required if the locations of the data\nand index files differ between the export and import servers.\n• Changing the schema name is required to import the table into a different schema on the import\nserver than on the export server.\n• Changing schema and table names may be required to accommodate differences between\nfile system case-sensitivity semantics on the export and import servers or differences in\nlower_case_table_names settings. Changing the table names in the .sdi file may require\nrenaming the table files as well.\n• In some cases, changes to column definitions are permitted. Changing data types is likely to cause\nproblems.",
    "15.2.7 INSERT Statement": "15.2.7 INSERT Statement\nINSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [(col_name [, col_name] ...)]\n    { {VALUES | VALUE} (value_list) [, (value_list)] ... }\n    [AS row_alias[(col_alias [, col_alias] ...)]]\n    [ON DUPLICATE KEY UPDATE assignment_list]\nINSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    SET assignment_list\n    [AS row_alias[(col_alias [, col_alias] ...)]]\n    [ON DUPLICATE KEY UPDATE assignment_list]\nINSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [(col_name [, col_name] ...)]\n    { SELECT ... \n      | TABLE table_name \n      | VALUES row_constructor_list\n    }\n    [ON DUPLICATE KEY UPDATE assignment_list]\nvalue:\n    {expr | DEFAULT}\nvalue_list:\n    value [, value] ...\nrow_constructor_list:\n    ROW(value_list)[, ROW(value_list)][, ...]\nassignment:\n    col_name = \n          value\n        | [row_alias.]col_name\n        | [tbl_name.]col_name\n        | [row_alias.]col_alias\nassignment_list:\n    assignment [, assignment] ...\nINSERT inserts new rows into an existing table. The INSERT ... VALUES, INSERT ... VALUES\nROW(), and INSERT ... SET forms of the statement insert rows based on explicitly specified values.\nThe INSERT ... SELECT form inserts rows selected from another table or tables. You can also\nuse INSERT ... TABLE to insert rows from a single table. INSERT with an ON DUPLICATE KEY\nUPDATE clause enables existing rows to be updated if a row to be inserted would cause a duplicate\nvalue in a UNIQUE index or PRIMARY KEY. A row alias with one or more optional column aliases can\nbe used with ON DUPLICATE KEY UPDATE to refer to the row to be inserted.\nFor additional information about INSERT ... SELECT and INSERT ... ON DUPLICATE KEY\nUPDATE, see Section 15.2.7.1, “INSERT ... SELECT Statement”, and Section 15.2.7.2, “INSERT ... ON\nDUPLICATE KEY UPDATE Statement”.\nIn MySQL 9.1, the DELAYED keyword is accepted but ignored by the server. For the reasons for this,\nsee Section 15.2.7.3, “INSERT DELAYED Statement”,\nInserting into a table requires the INSERT privilege for the table. If the ON DUPLICATE KEY UPDATE\nclause is used and a duplicate key causes an UPDATE to be performed instead, the statement requires\nthe UPDATE privilege for the columns to be updated. For columns that are read but not modified you\nneed only the SELECT privilege (such as for a column referenced only on the right hand side of an\ncol_name=expr assignment in an ON DUPLICATE KEY UPDATE clause).\nWhen inserting into a partitioned table, you can control which partitions and subpartitions accept new\nrows. The PARTITION clause takes a list of the comma-separated names of one or more partitions or\nsubpartitions (or both) of the table. If any of the rows to be inserted by a given INSERT statement do\nnot match one of the partitions listed, the INSERT statement fails with the error Found a row not\nmatching the given partition set. For more information and examples, see Section 26.5,\n“Partition Selection”.\ntbl_name is the table into which rows should be inserted. Specify the columns for which the statement\nprovides values as follows:\n• Provide a parenthesized list of comma-separated column names following the table name. In this\ncase, a value for each named column must be provided by the VALUES list, VALUES ROW() list, or\nSELECT statement. For the INSERT TABLE form, the number of columns in the source table must\nmatch the number of columns to be inserted.\n• If you do not specify a list of column names for INSERT ... VALUES or INSERT ... SELECT,\nvalues for every column in the table must be provided by the VALUES list, SELECT statement,\nor TABLE statement. If you do not know the order of the columns in the table, use DESCRIBE\ntbl_name to find out.\n• A SET clause indicates columns explicitly by name, together with the value to assign each one.\nColumn values can be given in several ways:\n• If strict SQL mode is not enabled, any column not explicitly given a value is set to its default (explicit\nor implicit) value. For example, if you specify a column list that does not name all the columns in the\ntable, unnamed columns are set to their default values. Default value assignment is described in\nSection 13.6, “Data Type Default Values”.\nIf strict SQL mode is enabled, an INSERT statement generates an error if it does not specify an\nexplicit value for every column that has no default value. See Section 7.1.11, “Server SQL Modes”.\n• If both the column list and the VALUES list are empty, INSERT creates a row with each column set to\nits default value:\nINSERT INTO tbl_name () VALUES();\nIf strict mode is not enabled, MySQL uses the implicit default value for any column that has no\nexplicitly defined default. If strict mode is enabled, an error occurs if any column has no default value.\n• Use the keyword DEFAULT to set a column explicitly to its default value. This makes it easier to\nwrite INSERT statements that assign values to all but a few columns, because it enables you to\navoid writing an incomplete VALUES list that does not include a value for each column in the table.\nOtherwise, you must provide the list of column names corresponding to each value in the VALUES\nlist.\n• If a generated column is inserted into explicitly, the only permitted value is DEFAULT. For information\nabout generated columns, see Section 15.1.20.8, “CREATE TABLE and Generated Columns”.\n• In expressions, you can use DEFAULT(col_name) to produce the default value for column\ncol_name.\n• Type conversion of an expression expr that provides a column value might occur if the expression\ndata type does not match the column data type. Conversion of a given value can result in different\ninserted values depending on the column type. For example, inserting the string '1999.0e-2' into\nan INT, FLOAT, DECIMAL(10,6), or YEAR column inserts the value 1999, 19.9921, 19.992100,\nor 1999, respectively. The value stored in the INT and YEAR columns is 1999 because the string-to-\nnumber conversion looks only at as much of the initial part of the string as may be considered a valid\ninteger or year. For the FLOAT and DECIMAL columns, the string-to-number conversion considers\nthe entire string a valid numeric value.\n• An expression expr can refer to any column that was set earlier in a value list. For example, you can\ndo this because the value for col2 refers to col1, which has previously been assigned:\nINSERT INTO tbl_name (col1,col2) VALUES(15,col1*2);\nBut the following is not legal, because the value for col1 refers to col2, which is assigned after\ncol1:\nINSERT INTO tbl_name (col1,col2) VALUES(col2*2,15);\nAn exception occurs for columns that contain AUTO_INCREMENT values. Because\nAUTO_INCREMENT values are generated after other value assignments, any reference to an\nAUTO_INCREMENT column in the assignment returns a 0.\nINSERT statements that use VALUES syntax can insert multiple rows. To do this, include multiple lists\nof comma-separated column values, with lists enclosed within parentheses and separated by commas.\nExample:\nINSERT INTO tbl_name (a,b,c)\n    VALUES(1,2,3), (4,5,6), (7,8,9);\nEach values list must contain exactly as many values as are to be inserted per row. The following\nstatement is invalid because it contains one list of nine values, rather than three lists of three values\neach:\nINSERT INTO tbl_name (a,b,c) VALUES(1,2,3,4,5,6,7,8,9);\nVALUE is a synonym for VALUES in this context. Neither implies anything about the number of values\nlists, nor about the number of values per list. Either may be used whether there is a single values list or\nmultiple lists, and regardless of the number of values per list.\nINSERT statements using VALUES ROW() syntax can also insert multiple rows. In this case, each\nvalue list must be contained within a ROW() (row constructor), like this:\nINSERT INTO tbl_name (a,b,c)\n    VALUES ROW(1,2,3), ROW(4,5,6), ROW(7,8,9);\nThe affected-rows value for an INSERT can be obtained using the ROW_COUNT() SQL function or\nthe mysql_affected_rows() C API function. See Section 14.15, “Information Functions”, and\nmysql_affected_rows().\nIf you use INSERT ... VALUES or INSERT ... VALUES ROW() with multiple value lists, or\nINSERT ... SELECT or INSERT ... TABLE, the statement returns an information string in this\nformat:\nRecords: N1 Duplicates: N2 Warnings: N3\nIf you are using the C API, the information string can be obtained by invoking the mysql_info()\nfunction. See mysql_info().\nRecords indicates the number of rows processed by the statement. (This is not necessarily the\nnumber of rows actually inserted because Duplicates can be nonzero.) Duplicates indicates the\nnumber of rows that could not be inserted because they would duplicate some existing unique index\nvalue. Warnings indicates the number of attempts to insert column values that were problematic in\nsome way. Warnings can occur under any of the following conditions:\n• Inserting NULL into a column that has been declared NOT NULL. For multiple-row INSERT\nstatements or INSERT INTO ... SELECT statements, the column is set to the implicit default\nvalue for the column data type. This is 0 for numeric types, the empty string ('') for string types,\nand the “zero” value for date and time types. INSERT INTO ... SELECT statements are handled\nthe same way as multiple-row inserts because the server does not examine the result set from the\nSELECT to see whether it returns a single row. (For a single-row INSERT, no warning occurs when\nNULL is inserted into a NOT NULL column. Instead, the statement fails with an error.)\n• Setting a numeric column to a value that lies outside the column range. The value is clipped to the\nclosest endpoint of the range.\n• Assigning a value such as '10.34 a' to a numeric column. The trailing nonnumeric text is stripped\noff and the remaining numeric part is inserted. If the string value has no leading numeric part, the\ncolumn is set to 0.\n• Inserting a string into a string column (CHAR, VARCHAR, TEXT, or BLOB) that exceeds the column\nmaximum length. The value is truncated to the column maximum length.\n• Inserting a value into a date or time column that is illegal for the data type. The column is set to the\nappropriate zero value for the type.\n• For INSERT examples involving AUTO_INCREMENT column values, see Section 5.6.9, “Using\nAUTO_INCREMENT”.\nIf INSERT inserts a row into a table that has an AUTO_INCREMENT column, you can find the value\nused for that column by using the LAST_INSERT_ID() SQL function or the mysql_insert_id()\nC API function.\nNote\nThese two functions do not always behave identically. The behavior of\nINSERT statements with respect to AUTO_INCREMENT columns is discussed\nfurther in Section 14.15, “Information Functions”, and mysql_insert_id().\nThe INSERT statement supports the following modifiers:\n• If you use the LOW_PRIORITY modifier, execution of the INSERT is delayed until no other clients\nare reading from the table. This includes other clients that began reading while existing clients are\nreading, and while the INSERT LOW_PRIORITY statement is waiting. It is possible, therefore, for a\nclient that issues an INSERT LOW_PRIORITY statement to wait for a very long time.\nLOW_PRIORITY affects only storage engines that use only table-level locking (such as MyISAM,\nMEMORY, and MERGE).\nNote\nLOW_PRIORITY should normally not be used with MyISAM tables because\ndoing so disables concurrent inserts. See Section 10.11.3, “Concurrent\nInserts”.\n• If you specify HIGH_PRIORITY, it overrides the effect of the --low-priority-updates option\nif the server was started with that option. It also causes concurrent inserts not to be used. See\nSection 10.11.3, “Concurrent Inserts”.\nHIGH_PRIORITY affects only storage engines that use only table-level locking (such as MyISAM,\nMEMORY, and MERGE).\n• If you use the IGNORE modifier, ignorable errors that occur while executing the INSERT statement\nare ignored. For example, without IGNORE, a row that duplicates an existing UNIQUE index or\nPRIMARY KEY value in the table causes a duplicate-key error and the statement is aborted. With\nIGNORE, the row is discarded and no error occurs. Ignored errors generate warnings instead.\n IGNORE has a similar effect on inserts into partitioned tables where no partition matching a given\nvalue is found. Without IGNORE, such INSERT statements are aborted with an error. When INSERT\nIGNORE is used, the insert operation fails silently for rows containing the unmatched value, but\ninserts rows that are matched. For an example, see Section 26.2.2, “LIST Partitioning”.\nData conversions that would trigger errors abort the statement if IGNORE is not specified. With\nIGNORE, invalid values are adjusted to the closest values and inserted; warnings are produced but\nthe statement does not abort. You can determine with the mysql_info() C API function how many\nrows were actually inserted into the table.\nFor more information, see The Effect of IGNORE on Statement Execution.\nYou can use REPLACE instead of INSERT to overwrite old rows. REPLACE is the counterpart\nto INSERT IGNORE in the treatment of new rows that contain unique key values that duplicate\nold rows: The new rows replace the old rows rather than being discarded. See Section 15.2.12,\n“REPLACE Statement”.\n• If you specify ON DUPLICATE KEY UPDATE, and a row is inserted that would cause a duplicate\nvalue in a UNIQUE index or PRIMARY KEY, an UPDATE of the old row occurs. The affected-rows\nvalue per row is 1 if the row is inserted as a new row, 2 if an existing row is updated, and 0 if\nan existing row is set to its current values. If you specify the CLIENT_FOUND_ROWS flag to the\nmysql_real_connect() C API function when connecting to mysqld, the affected-rows value\nis 1 (not 0) if an existing row is set to its current values. See Section 15.2.7.2, “INSERT ... ON\nDUPLICATE KEY UPDATE Statement”.\n• INSERT DELAYED was deprecated in MySQL 5.6, and is scheduled for eventual removal. In MySQL\n9.1, the DELAYED modifier is accepted but ignored. Use INSERT (without DELAYED) instead. See\nSection 15.2.7.3, “INSERT DELAYED Statement”.\n15.2.7.1 INSERT ... SELECT Statement\nINSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [(col_name [, col_name] ...)]\n    {   SELECT ... \n      | TABLE table_name \n      | VALUES row_constructor_list\n    }\n    [ON DUPLICATE KEY UPDATE assignment_list]\nvalue:\n    {expr | DEFAULT}\nvalue_list:\n    value [, value] ...\nrow_constructor_list:\n    ROW(value_list)[, ROW(value_list)][, ...]\nassignment:\n    col_name = \n          value\n        | [row_alias.]col_name\n        | [tbl_name.]col_name\n        | [row_alias.]col_alias\nassignment_list:\n    assignment [, assignment] ...\nWith INSERT ... SELECT, you can quickly insert many rows into a table from the result of a SELECT\nstatement, which can select from one or many tables. For example:\nINSERT INTO tbl_temp2 (fld_id)\n  SELECT tbl_temp1.fld_order_id\n  FROM tbl_temp1 WHERE tbl_temp1.fld_order_id > 100;\nTABLE statement in place of SELECT, as shown here:\nINSERT INTO ta TABLE tb;\nTABLE tb is equivalent to SELECT * FROM tb. It can be useful when inserting all columns from the\nsource table into the target table, and no filtering with WHERE is required. In addition, the rows from\nTABLE can be ordered by one or more columns using ORDER BY, and the number of rows inserted can\nbe limited using a LIMIT clause. For more information, see Section 15.2.16, “TABLE Statement”.\nThe following conditions hold for INSERT ... SELECT statements, and, except where noted, for\nINSERT ... TABLE as well:\n• Specify IGNORE to ignore rows that would cause duplicate-key violations.\n• The target table of the INSERT statement may appear in the FROM clause of the SELECT part of the\nquery, or as the table named by TABLE. However, you cannot insert into a table and select from the\nsame table in a subquery.\nWhen selecting from and inserting into the same table, MySQL creates an internal temporary table\nto hold the rows from the SELECT and then inserts those rows into the target table. However, you\ncannot use INSERT INTO t ... SELECT ... FROM t when t is a TEMPORARY table, because\nTEMPORARY tables cannot be referred to twice in the same statement. For the same reason, you\ncannot use INSERT INTO t ... TABLE t when t is a temporary table. See Section 10.4.4,\n“Internal Temporary Table Use in MySQL”, and Section B.3.6.2, “TEMPORARY Table Problems”.\n• AUTO_INCREMENT columns work as usual.\n• To ensure that the binary log can be used to re-create the original tables, MySQL does not\npermit concurrent inserts for INSERT ... SELECT or INSERT ... TABLE statements (see\nSection 10.11.3, “Concurrent Inserts”).\n• To avoid ambiguous column reference problems when the SELECT and the INSERT refer to the\nsame table, provide a unique alias for each table used in the SELECT part, and qualify column\nnames in that part with the appropriate alias.\nThe TABLE statement does not support aliases.\nYou can explicitly select which partitions or subpartitions (or both) of the source or target table (or\nboth) are to be used with a PARTITION clause following the name of the table. When PARTITION\nis used with the name of the source table in the SELECT portion of the statement, rows are selected\nonly from the partitions or subpartitions named in its partition list. When PARTITION is used with the\nname of the target table for the INSERT portion of the statement, it must be possible to insert all rows\nselected into the partitions or subpartitions named in the partition list following the option. Otherwise,\nthe INSERT ... SELECT statement fails. For more information and examples, see Section 26.5,\n“Partition Selection”.\nTABLE does not support a PARTITION clause.\nFor INSERT ... SELECT statements, see Section 15.2.7.2, “INSERT ... ON DUPLICATE KEY\nUPDATE Statement” for conditions under which the SELECT columns can be referred to in an ON\nDUPLICATE KEY UPDATE clause. This also works for INSERT ... TABLE.\nThe order in which a SELECT or TABLE statement with no ORDER BY clause returns rows is\nnondeterministic. This means that, when using replication, there is no guarantee that such a SELECT\nreturns rows in the same order on the source and the replica, which can lead to inconsistencies\nbetween them. To prevent this from occurring, always write INSERT ... SELECT or INSERT ...\nTABLE statements that are to be replicated using an ORDER BY clause that produces the same row\norder on the source and the replica. See also Section 19.5.1.19, “Replication and LIMIT”.\nDue to this issue, INSERT ... SELECT ON DUPLICATE KEY UPDATE and INSERT IGNORE ...\nSELECT statements are flagged as unsafe for statement-based replication. Such statements produce a\nwarning in the error log when using statement-based mode and are written to the binary log using the\nrow-based format when using MIXED mode. (Bug #11758262, Bug #50439)\nSee also Section 19.2.1.1, “Advantages and Disadvantages of Statement-Based and Row-Based\nReplication”.\n15.2.7.2 INSERT ... ON DUPLICATE KEY UPDATE Statement\nIf you specify an ON DUPLICATE KEY UPDATE clause and a row to be inserted would cause a\nduplicate value in a UNIQUE index or PRIMARY KEY, an UPDATE of the old row occurs. For example,\nif column a is declared as UNIQUE and contains the value 1, the following two statements have similar\neffect:\nINSERT INTO t1 (a,b,c) VALUES (1,2,3)\n  ON DUPLICATE KEY UPDATE c=c+1;\nUPDATE t1 SET c=c+1 WHERE a=1;\nThe effects are not quite identical: For an InnoDB table where a is an auto-increment column, the\nINSERT statement increases the auto-increment value but the UPDATE does not.\nIf column b is also unique, the INSERT is equivalent to this UPDATE statement instead:\nUPDATE t1 SET c=c+1 WHERE a=1 OR b=2 LIMIT 1;\nIf a=1 OR b=2 matches several rows, only one row is updated. In general, you should try to avoid\nusing an ON DUPLICATE KEY UPDATE clause on tables with multiple unique indexes.\nWith ON DUPLICATE KEY UPDATE, the affected-rows value per row is 1 if the row is inserted as\na new row, 2 if an existing row is updated, and 0 if an existing row is set to its current values. If\nyou specify the CLIENT_FOUND_ROWS flag to the mysql_real_connect() C API function when\nconnecting to mysqld, the affected-rows value is 1 (not 0) if an existing row is set to its current values.\nIf a table contains an AUTO_INCREMENT column and INSERT ... ON DUPLICATE KEY UPDATE\ninserts or updates a row, the LAST_INSERT_ID() function returns the AUTO_INCREMENT value.\nThe ON DUPLICATE KEY UPDATE clause can contain multiple column assignments, separated by\ncommas.\nIt is possible to use IGNORE with ON DUPLICATE KEY UPDATE in an INSERT statement, but this may\nnot behave as you expect when inserting multiple rows into a table that has multiple unique keys. This\nbecomes apparent when an updated value is itself a duplicate key value. Consider the table t, created\nand populated by the statements shown here:\nmysql> CREATE TABLE t (a SERIAL, b BIGINT NOT NULL, UNIQUE KEY (b));;\nQuery OK, 0 rows affected (0.03 sec)\nmysql> INSERT INTO t VALUES ROW(1,1), ROW(2,2);\nQuery OK, 2 rows affected (0.01 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\nmysql> TABLE t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 1 |\n| 2 | 2 |\n+---+---+\n2 rows in set (0.00 sec)\nNow we attempt to insert two rows, one of which contains a duplicate key value, using ON DUPLICATE\nKEY UPDATE, where the UPDATE clause itself results in a duplicate key value:\nmysql> INSERT INTO t VALUES ROW(2,3), ROW(3,3) ON DUPLICATE KEY UPDATE a=a+1, b=b-1;\nERROR 1062 (23000): Duplicate entry '1' for key 't.b'\nmysql> TABLE t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 1 |\n| 2 | 2 |\n+---+---+\n2 rows in set (0.00 sec)\nThe first row contains a duplicate value for one of the table's unique keys (column a), but b=b+1 in the\nUPDATE clause results in a unique key violation for column b; the statement is immediately rejected\nwith an error, and no rows are updated. Let us repeat the statement, this time adding the IGNORE\nkeyword, like this:\nmysql> INSERT IGNORE INTO t VALUES ROW(2,3), ROW(3,3) \n    -> ON DUPLICATE KEY UPDATE a=a+1, b=b-1;\nQuery OK, 1 row affected, 1 warning (0.00 sec)\nRecords: 2  Duplicates: 1  Warnings: 1\nThis time, the previous error is demoted to a warning, as shown here:\nmysql> SHOW WARNINGS;\n+---------+------+-----------------------------------+\n| Level   | Code | Message                           |\n+---------+------+-----------------------------------+\n| Warning | 1062 | Duplicate entry '1' for key 't.b' |\n+---------+------+-----------------------------------+\n1 row in set (0.00 sec)\nBecause the statement was not rejected, execution continues. This means that the second row is\ninserted into t, as we can see here:\nmysql> TABLE t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 1 |\n| 2 | 2 |\n| 3 | 3 |\n+---+---+\n3 rows in set (0.00 sec)\nIn assignment value expressions in the ON DUPLICATE KEY UPDATE clause, you can use the\nVALUES(col_name) function to refer to column values from the INSERT portion of the INSERT ...\nON DUPLICATE KEY UPDATE statement. In other words, VALUES(col_name) in the ON DUPLICATE\nKEY UPDATE clause refers to the value of col_name that would be inserted, had no duplicate-key\nconflict occurred. This function is especially useful in multiple-row inserts. The VALUES() function\nis meaningful only as an introducer for INSERT statement value lists, or in the ON DUPLICATE KEY\nUPDATE clause of an INSERT statement, and returns NULL otherwise. For example:\nINSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6)\n  ON DUPLICATE KEY UPDATE c=VALUES(a)+VALUES(b);\nThat statement is identical to the following two statements:\nINSERT INTO t1 (a,b,c) VALUES (1,2,3)\n  ON DUPLICATE KEY UPDATE c=3;\nINSERT INTO t1 (a,b,c) VALUES (4,5,6)\n  ON DUPLICATE KEY UPDATE c=9;\nNote\nThe use of VALUES() to refer to the new row and columns is deprecated, and\nsubject to removal in a future version of MySQL. Instead, use row and column\naliases, as described in the next few paragraphs of this section.\nIt is possible to use an alias for the row, with, optionally, one or more of its columns to be inserted,\nfollowing the VALUES or SET clause, and preceded by the AS keyword. Using the row alias new, the\nstatement shown previously using VALUES() to access the new column values can be written in the\nform shown here:\nINSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6) AS new\n  ON DUPLICATE KEY UPDATE c = new.a+new.b;\nIf, in addition, you use the column aliases m, n, and p, you can omit the row alias in the assignment\nclause and write the same statement like this:\nINSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6) AS new(m,n,p)\n  ON DUPLICATE KEY UPDATE c = m+n;\nWhen using column aliases in this fashion, you must still use a row alias following the VALUES clause,\neven if you do not make direct use of it in the assignment clause.\nAn INSERT ... SELECT ... ON DUPLICATE KEY UPDATE statement that uses VALUES() in the\nUPDATE clause, like this one, throws a warning:\nINSERT INTO t1\n  SELECT c, c+d FROM t2\n  ON DUPLICATE KEY UPDATE b = VALUES(b);\nYou can eliminate such warnings by using a subquery instead, like this:\nINSERT INTO t1\n  SELECT * FROM (SELECT c, c+d AS e FROM t2) AS dt\n  ON DUPLICATE KEY UPDATE b = e;\nYou can also use row and column aliases with a SET clause, as mentioned previously. Employing SET\ninstead of VALUES in the two INSERT ... ON DUPLICATE KEY UPDATE statements just shown can\nbe done as shown here:\nINSERT INTO t1 SET a=1,b=2,c=3 AS new\n  ON DUPLICATE KEY UPDATE c = new.a+new.b;\nINSERT INTO t1 SET a=1,b=2,c=3 AS new(m,n,p)\n  ON DUPLICATE KEY UPDATE c = m+n;\nThe row alias must not be the same as the name of the table. If column aliases are not used, or if\nthey are the same as the column names, they must be distinguished using the row alias in the ON\nDUPLICATE KEY UPDATE clause. Column aliases must be unique with regard to the row alias to\nwhich they apply (that is, no column aliases referring to columns of the same row may be the same).\nFor INSERT ... SELECT statements, these rules apply regarding acceptable forms of SELECT query\nexpressions that you can refer to in an ON DUPLICATE KEY UPDATE clause:\n• References to columns from queries on a single table, which may be a derived table.\n• References to columns from queries on a join over multiple tables.\n• References to columns from DISTINCT queries.\n• References to columns in other tables, as long as the SELECT does not use GROUP BY. One side\neffect is that you must qualify references to nonunique column names.\nReferences to columns from a UNION are not supported. To work around this restriction, rewrite the\nUNION as a derived table so that its rows can be treated as a single-table result set. For example, this\nstatement produces an error:\nINSERT INTO t1 (a, b)\n  SELECT c, d FROM t2\n  UNION\n  SELECT e, f FROM t3\nON DUPLICATE KEY UPDATE b = b + c;\nInstead, use an equivalent statement that rewrites the UNION as a derived table:\nINSERT INTO t1 (a, b)\nSELECT * FROM\n  (SELECT c, d FROM t2\n   UNION\n   SELECT e, f FROM t3) AS dt\nON DUPLICATE KEY UPDATE b = b + c;\nThe technique of rewriting a query as a derived table also enables references to columns from GROUP\nBY queries.\nBecause the results of INSERT ... SELECT statements depend on the ordering of rows from\nthe SELECT and this order cannot always be guaranteed, it is possible when logging INSERT ...\nSELECT ON DUPLICATE KEY UPDATE statements for the source and the replica to diverge.\nThus, INSERT ... SELECT ON DUPLICATE KEY UPDATE statements are flagged as unsafe\nfor statement-based replication. Such statements produce a warning in the error log when using\nstatement-based mode and are written to the binary log using the row-based format when using MIXED\nmode. An INSERT ... ON DUPLICATE KEY UPDATE statement against a table having more than\none unique or primary key is also marked as unsafe. (Bug #11765650, Bug #58637)\nSee also Section 19.2.1.1, “Advantages and Disadvantages of Statement-Based and Row-Based\nReplication”.\n15.2.7.3 INSERT DELAYED Statement\nINSERT DELAYED ...\nThe DELAYED option for the INSERT statement is a MySQL extension to standard SQL. In previous\nversions of MySQL, it can be used for certain kinds of tables (such as MyISAM), such that when a client\nuses INSERT DELAYED, it gets an okay from the server at once, and the row is queued to be inserted\nwhen the table is not in use by any other thread.\nDELAYED inserts and replaces were deprecated in MySQL 5.6. In MySQL 9.1, DELAYED is not\nsupported. The server recognizes but ignores the DELAYED keyword, handles the insert as a\nnondelayed insert, and generates an ER_WARN_LEGACY_SYNTAX_CONVERTED warning: INSERT\nDELAYED is no longer supported. The statement was converted to INSERT. The\nDELAYED keyword is scheduled for removal in a future release.",
    "15.2.8 INTERSECT Clause": "15.2.8 INTERSECT Clause\nquery_expression_body INTERSECT [ALL | DISTINCT] query_expression_body\n    [INTERSECT [ALL | DISTINCT] query_expression_body]\n    [...]\nquery_expression_body:\n    See Section 15.2.14, “Set Operations with UNION, INTERSECT, and EXCEPT”\nINTERSECT limits the result from multiple query blocks to those rows which are common to all.\nExample:\nmysql> TABLE a;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    2 |\n|    2 |    3 |\n|    3 |    4 |\n+------+------+\n3 rows in set (0.00 sec)\nmysql> TABLE b;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    2 |\n|    1 |    3 |\n|    3 |    4 |\n+------+------+\n3 rows in set (0.00 sec)\nmysql> TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    3 |\n|    1 |    3 |\n|    3 |    4 |\n+------+------+\n3 rows in set (0.00 sec)\nmysql> TABLE a INTERSECT TABLE b;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    2 |\n|    3 |    4 |\n+------+------+\n2 rows in set (0.00 sec)\nmysql> TABLE a INTERSECT TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    3 |    4 |\n+------+------+\n1 row in set (0.00 sec)\nAs with UNION and EXCEPT, if neither DISTINCT nor ALL is specified, the default is DISTINCT.\nDISTINCT can remove duplicates from either side of the intersection, as shown here:\nmysql> TABLE c INTERSECT DISTINCT TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    3 |\n|    3 |    4 |\n+------+------+\n2 rows in set (0.00 sec)\nmysql> TABLE c INTERSECT ALL TABLE c;\n+------+------+\n| m    | n    |\n+------+------+\n|    1 |    3 |\n|    1 |    3 |\n|    3 |    4 |\n+------+------+\n3 rows in set (0.00 sec)\n(TABLE c INTERSECT TABLE c is the equivalent of the first of the two statements just shown.)\nAs with UNION, the operands must have the same number of columns. Result set column types are\nalso determined as for UNION.\nINTERSECT has greater precedence than and is evaluated before UNION and EXCEPT, so that the two\nstatements shown here are equivalent:\nTABLE r EXCEPT TABLE s INTERSECT TABLE t;\nTABLE r EXCEPT (TABLE s INTERSECT TABLE t);\nFor INTERSECT ALL, the maximum supported number of duplicates of any unique row in the left hand\ntable is 4294967295.",
    "15.2.9 LOAD DATA Statement": "15.2.9 LOAD DATA Statement\nLOAD DATA\n    [LOW_PRIORITY | CONCURRENT] [LOCAL]\n    INFILE 'file_name'\n    [REPLACE | IGNORE]\n    INTO TABLE tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [CHARACTER SET charset_name]\n    [{FIELDS | COLUMNS}\n        [TERMINATED BY 'string']\n        [[OPTIONALLY] ENCLOSED BY 'char']\n        [ESCAPED BY 'char']\n    ]\n    [LINES\n        [STARTING BY 'string']\n        [TERMINATED BY 'string']\n    ]\n    [IGNORE number {LINES | ROWS}]\n    [(col_name_or_user_var\n        [, col_name_or_user_var] ...)]\n    [SET col_name={expr | DEFAULT}\n        [, col_name={expr | DEFAULT}] ...]\nThe LOAD DATA statement reads rows from a text file into a table at a very high speed. The file can be\nread from the server host or the client host, depending on whether the LOCAL modifier is given. LOCAL\nalso affects data interpretation and error handling.\nLOAD DATA is the complement of SELECT ... INTO OUTFILE. (See Section 15.2.13.1, “SELECT ...\nINTO Statement”.) To write data from a table to a file, use SELECT ... INTO OUTFILE. To read the\nfile back into a table, use LOAD DATA. The syntax of the FIELDS and LINES clauses is the same for\nboth statements.\nThe mysqlimport utility provides another way to load data files; it operates by sending a LOAD DATA\nstatement to the server. See Section 6.5.5, “mysqlimport — A Data Import Program”.\nFor information about the efficiency of INSERT versus LOAD DATA and speeding up LOAD DATA, see\nSection 10.2.5.1, “Optimizing INSERT Statements”.\n• Non-LOCAL Versus LOCAL Operation\n• Input File Character Set\n• Input File Location\n• Security Requirements\n• Duplicate-Key and Error Handling\n• Index Handling\n• Field and Line Handling\n• Column List Specification\n• Input Preprocessing\n• Column Value Assignment\n• Partitioned Table Support\n• Concurrency Considerations\n• Statement Result Information\n• Replication Considerations\n• Miscellaneous Topics\nNon-LOCAL Versus LOCAL Operation\nThe LOCAL modifier affects these aspects of LOAD DATA, compared to non-LOCAL operation:\n• It changes the expected location of the input file; see Input File Location.\n• It changes the statement security requirements; see Security Requirements.\n• Unless REPLACE is also specified, LOCAL has the same effect as the IGNORE modifier on the\ninterpretation of input file contents and error handling; see Duplicate-Key and Error Handling, and\nColumn Value Assignment.\nLOCAL works only if the server and your client both have been configured to permit it. For example, if\nmysqld was started with the local_infile system variable disabled, LOCAL produces an error. See\nSection 8.1.6, “Security Considerations for LOAD DATA LOCAL”.\nInput File Character Set\nThe file name must be given as a literal string. On Windows, specify backslashes in path names as\nforward slashes or doubled backslashes. The server interprets the file name using the character set\nindicated by the character_set_filesystem system variable.\nBy default, the server interprets the file contents using the character set indicated by the\ncharacter_set_database system variable. If the file contents use a character set different from this\ndefault, it is a good idea to specify that character set by using the CHARACTER SET clause. A character\nset of binary specifies “no conversion.”\nSET NAMES and the setting of character_set_client do not affect interpretation of file contents.\nLOAD DATA interprets all fields in the file as having the same character set, regardless of the data\ntypes of the columns into which field values are loaded. For proper interpretation of the file, you must\nensure that it was written with the correct character set. For example, if you write a data file with\nmysqldump -T or by issuing a SELECT ... INTO OUTFILE statement in mysql, be sure to use a\n--default-character-set option to write output in the character set to be used when the file is\nloaded with LOAD DATA.\nNote\nIt is not possible to load data files that use the ucs2, utf16, utf16le, or\nutf32 character set.\nInput File Location\nThese rules determine the LOAD DATA input file location:\n• If LOCAL is not specified, the file must be located on the server host. The server reads the file\ndirectly, locating it as follows:\n• If the file name is an absolute path name, the server uses it as given.\n• If the file name is a relative path name with leading components, the server looks for the file\nrelative to its data directory.\n• If the file name has no leading components, the server looks for the file in the database directory of\nthe default database.\n• If LOCAL is specified, the file must be located on the client host. The client program reads the file,\nlocating it as follows:\n• If the file name is an absolute path name, the client program uses it as given.\n• If the file name is a relative path name, the client program looks for the file relative to its invocation\ndirectory.\nWhen LOCAL is used, the client program reads the file and sends its contents to the server. The\nserver creates a copy of the file in the directory where it stores temporary files. See Section B.3.3.5,\n“Where MySQL Stores Temporary Files”. Lack of sufficient space for the copy in this directory can\ncause the LOAD DATA LOCAL statement to fail.\nThe non-LOCAL rules mean that the server reads a file named as ./myfile.txt relative to its data\ndirectory, whereas it reads a file named as myfile.txt from the database directory of the default\ndatabase. For example, if the following LOAD DATA statement is executed while db1 is the default\ndatabase, the server reads the file data.txt from the database directory for db1, even though the\nstatement explicitly loads the file into a table in the db2 database:\nLOAD DATA INFILE 'data.txt' INTO TABLE db2.my_table;\nNote\nThe server also uses the non-LOCAL rules to locate .sdi files for the IMPORT\nTABLE statement.\nSecurity Requirements\nFor a non-LOCAL load operation, the server reads a text file located on the server host, so these\nsecurity requirements must be satisfied:\n• You must have the FILE privilege. See Section 8.2.2, “Privileges Provided by MySQL”.\n• The operation is subject to the secure_file_priv system variable setting:\n• If the variable value is a nonempty directory name, the file must be located in that directory.\n• If the variable value is empty (which is insecure), the file need only be readable by the server.\nFor a LOCAL load operation, the client program reads a text file located on the client host. Because the\nfile contents are sent over the connection by the client to the server, using LOCAL is a bit slower than\nwhen the server accesses the file directly. On the other hand, you do not need the FILE privilege, and\nthe file can be located in any directory the client program can access.\nDuplicate-Key and Error Handling\nThe REPLACE and IGNORE modifiers control handling of new (input) rows that duplicate existing table\nrows on unique key values (PRIMARY KEY or UNIQUE index values):\n• With REPLACE, new rows that have the same value as a unique key value in an existing row replace\nthe existing row. See Section 15.2.12, “REPLACE Statement”.\n• With IGNORE, new rows that duplicate an existing row on a unique key value are discarded. For\nmore information, see The Effect of IGNORE on Statement Execution.\nThe LOCAL modifier has the same effect as IGNORE. This occurs because the server has no way to\nstop transmission of the file in the middle of the operation.\nIf none of REPLACE, IGNORE, or LOCAL is specified, an error occurs when a duplicate key value is\nfound, and the rest of the text file is ignored.\nIn addition to affecting duplicate-key handling as just described, IGNORE and LOCAL also affect error\nhandling:\n• When neither IGNORE nor LOCAL is specified, data-interpretation errors terminate the operation.\n• When IGNORE—or LOCAL without REPLACE—is specified, data interpretation errors become\nwarnings and the load operation continues, even if the SQL mode is restrictive. For examples, see\nColumn Value Assignment.\nIndex Handling\nTo ignore foreign key constraints during the load operation, execute a SET foreign_key_checks =\n0 statement before executing LOAD DATA.\nIf you use LOAD DATA on an empty MyISAM table, all nonunique indexes are created in a separate\nbatch (as for REPAIR TABLE). Normally, this makes LOAD DATA much faster when you have many\nindexes. In some extreme cases, you can create the indexes even faster by turning them off with\nALTER TABLE ... DISABLE KEYS before loading the file into the table and re-creating the indexes\nwith ALTER TABLE ... ENABLE KEYS after loading the file. See Section 10.2.5.1, “Optimizing\nINSERT Statements”.\nField and Line Handling\nFor both the LOAD DATA and SELECT ... INTO OUTFILE statements, the syntax of the FIELDS\nand LINES clauses is the same. Both clauses are optional, but FIELDS must precede LINES if both\nare specified.\nIf you specify a FIELDS clause, each of its subclauses (TERMINATED BY, [OPTIONALLY] ENCLOSED\nBY, and ESCAPED BY) is also optional, except that you must specify at least one of them. Arguments to\nthese clauses are permitted to contain only ASCII characters.\nIf you specify no FIELDS or LINES clause, the defaults are the same as if you had written this:\nFIELDS TERMINATED BY '\\t' ENCLOSED BY '' ESCAPED BY '\\\\'\nLINES TERMINATED BY '\\n' STARTING BY ''\nBackslash is the MySQL escape character within strings in SQL statements. Thus, to specify a literal\nbackslash, you must specify two backslashes for the value to be interpreted as a single backslash. The\nescape sequences '\\t' and '\\n' specify tab and newline characters, respectively.\nIn other words, the defaults cause LOAD DATA to act as follows when reading input:\n• Look for line boundaries at newlines.\n• Do not skip any line prefix.\n• Break lines into fields at tabs.\n• Do not expect fields to be enclosed within any quoting characters.\n• Interpret characters preceded by the escape character \\ as escape sequences. For example,\n\\t, \\n, and \\\\ signify tab, newline, and backslash, respectively. See the discussion of FIELDS\nESCAPED BY later for the full list of escape sequences.\nConversely, the defaults cause SELECT ... INTO OUTFILE to act as follows when writing output:\n• Write tabs between fields.\n• Do not enclose fields within any quoting characters.\n• Use \\ to escape instances of tab, newline, or \\ that occur within field values.\n• Write newlines at the ends of lines.\nNote\nFor a text file generated on a Windows system, proper file reading might require\nLINES TERMINATED BY '\\r\\n' because Windows programs typically use\ntwo characters as a line terminator. Some programs, such as WordPad, might\nuse \\r as a line terminator when writing files. To read such files, use LINES\nTERMINATED BY '\\r'.\nIf all the input lines have a common prefix that you want to ignore, you can use LINES STARTING BY\n'prefix_string' to skip the prefix and anything before it. If a line does not include the prefix, the\nentire line is skipped. Suppose that you issue the following statement:\nLOAD DATA INFILE '/tmp/test.txt' INTO TABLE test\n  FIELDS TERMINATED BY ','  LINES STARTING BY 'xxx';\nIf the data file looks like this:\nxxx\"abc\",1\nsomething xxx\"def\",2\n\"ghi\",3\nThe resulting rows are (\"abc\",1) and (\"def\",2). The third row in the file is skipped because it\ndoes not contain the prefix.\nThe IGNORE number LINES clause can be used to ignore lines at the start of the file. For example,\nyou can use IGNORE 1 LINES to skip an initial header line containing column names:\nLOAD DATA INFILE '/tmp/test.txt' INTO TABLE test IGNORE 1 LINES;\nWhen you use SELECT ... INTO OUTFILE in tandem with LOAD DATA to write data from a\ndatabase into a file and then read the file back into the database later, the field- and line-handling\noptions for both statements must match. Otherwise, LOAD DATA does not interpret the contents of the\nfile properly. Suppose that you use SELECT ... INTO OUTFILE to write a file with fields delimited by\ncommas:\nSELECT * INTO OUTFILE 'data.txt'\n  FIELDS TERMINATED BY ','\n  FROM table2;\nTo read the comma-delimited file, the correct statement is:\nLOAD DATA INFILE 'data.txt' INTO TABLE table2\n  FIELDS TERMINATED BY ',';\nIf instead you tried to read the file with the statement shown following, it would not work because it\ninstructs LOAD DATA to look for tabs between fields:\nLOAD DATA INFILE 'data.txt' INTO TABLE table2\n  FIELDS TERMINATED BY '\\t';\nThe likely result is that each input line would be interpreted as a single field.\nLOAD DATA can be used to read files obtained from external sources. For example, many programs\ncan export data in comma-separated values (CSV) format, such that lines have fields separated by\ncommas and enclosed within double quotation marks, with an initial line of column names. If the lines\nin such a file are terminated by carriage return/newline pairs, the statement shown here illustrates the\nfield- and line-handling options you would use to load the file:\nLOAD DATA INFILE 'data.txt' INTO TABLE tbl_name\n  FIELDS TERMINATED BY ',' ENCLOSED BY '\"'\n  LINES TERMINATED BY '\\r\\n'\n  IGNORE 1 LINES;\nIf the input values are not necessarily enclosed within quotation marks, use OPTIONALLY before the\nENCLOSED BY option.\nAny of the field- or line-handling options can specify an empty string (''). If not empty, the FIELDS\n[OPTIONALLY] ENCLOSED BY and FIELDS ESCAPED BY values must be a single character. The\nFIELDS TERMINATED BY, LINES STARTING BY, and LINES TERMINATED BY values can be more\nthan one character. For example, to write lines that are terminated by carriage return/linefeed pairs, or\nto read a file containing such lines, specify a LINES TERMINATED BY '\\r\\n' clause.\nTo read a file containing jokes that are separated by lines consisting of %%, you can do this\nCREATE TABLE jokes\n  (a INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n  joke TEXT NOT NULL);\nLOAD DATA INFILE '/tmp/jokes.txt' INTO TABLE jokes\n  FIELDS TERMINATED BY ''\n  LINES TERMINATED BY '\\n%%\\n' (joke);\nFIELDS [OPTIONALLY] ENCLOSED BY controls quoting of fields. For output (SELECT ... INTO\nOUTFILE), if you omit the word OPTIONALLY, all fields are enclosed by the ENCLOSED BY character.\nAn example of such output (using a comma as the field delimiter) is shown here:\n\"1\",\"a string\",\"100.20\"\n\"2\",\"a string containing a , comma\",\"102.20\"\n\"3\",\"a string containing a \\\" quote\",\"102.20\"\n\"4\",\"a string containing a \\\", quote and comma\",\"102.20\"\nIf you specify OPTIONALLY, the ENCLOSED BY character is used only to enclose values from columns\nthat have a string data type (such as CHAR, BINARY, TEXT, or ENUM):\n1,\"a string\",100.20\n2,\"a string containing a , comma\",102.20\n3,\"a string containing a \\\" quote\",102.20\n4,\"a string containing a \\\", quote and comma\",102.20\nOccurrences of the ENCLOSED BY character within a field value are escaped by prefixing them with the\nESCAPED BY character. Also, if you specify an empty ESCAPED BY value, it is possible to inadvertently\ngenerate output that cannot be read properly by LOAD DATA. For example, the preceding output just\nshown would appear as follows if the escape character is empty. Observe that the second field in the\nfourth line contains a comma following the quote, which (erroneously) appears to terminate the field:\n1,\"a string\",100.20\n2,\"a string containing a , comma\",102.20\n3,\"a string containing a \" quote\",102.20\n4,\"a string containing a \", quote and comma\",102.20\nFor input, the ENCLOSED BY character, if present, is stripped from the ends of field values. (This is true\nregardless of whether OPTIONALLY is specified; OPTIONALLY has no effect on input interpretation.)\nOccurrences of the ENCLOSED BY character preceded by the ESCAPED BY character are interpreted\nas part of the current field value.\nIf the field begins with the ENCLOSED BY character, instances of that character are recognized as\nterminating a field value only if followed by the field or line TERMINATED BY sequence. To avoid\nambiguity, occurrences of the ENCLOSED BY character within a field value can be doubled and are\ninterpreted as a single instance of the character. For example, if ENCLOSED BY '\"' is specified,\nquotation marks are handled as shown here:\n\"The \"\"BIG\"\" boss\"  -> The \"BIG\" boss\nThe \"BIG\" boss      -> The \"BIG\" boss\nThe \"\"BIG\"\" boss    -> The \"\"BIG\"\" boss\nFIELDS ESCAPED BY controls how to read or write special characters:\n• For input, if the FIELDS ESCAPED BY character is not empty, occurrences of that character are\nstripped and the following character is taken literally as part of a field value. Some two-character\nsequences that are exceptions, where the first character is the escape character. These sequences\nare shown in the following table (using \\ for the escape character). The rules for NULL handling are\ndescribed later in this section.\nCharacter\nEscape Sequence\n\\0\nAn ASCII NUL (X'00') character\n\\b\nA backspace character\n\\n\nA newline (linefeed) character\n\\r\nA carriage return character\n\\t\nA tab character.\n\\Z\nASCII 26 (Control+Z)\n\\N\nNULL\nFor more information about \\-escape syntax, see Section 11.1.1, “String Literals”.\nIf the FIELDS ESCAPED BY character is empty, escape-sequence interpretation does not occur.\n• For output, if the FIELDS ESCAPED BY character is not empty, it is used to prefix the following\ncharacters on output:\n• The FIELDS ESCAPED BY character.\n• The FIELDS [OPTIONALLY] ENCLOSED BY character.\n• The first character of the FIELDS TERMINATED BY and LINES TERMINATED BY values, if the\nENCLOSED BY character is empty or unspecified.\n• ASCII 0 (what is actually written following the escape character is ASCII 0, not a zero-valued byte).\nIf the FIELDS ESCAPED BY character is empty, no characters are escaped and NULL is output as\nNULL, not \\N. It is probably not a good idea to specify an empty escape character, particularly if field\nvalues in your data contain any of the characters in the list just given.\nIn certain cases, field- and line-handling options interact:\n• If LINES TERMINATED BY is an empty string and FIELDS TERMINATED BY is nonempty, lines are\nalso terminated with FIELDS TERMINATED BY.\n• If the FIELDS TERMINATED BY and FIELDS ENCLOSED BY values are both empty (''), a fixed-\nrow (nondelimited) format is used. With fixed-row format, no delimiters are used between fields\n(but you can still have a line terminator). Instead, column values are read and written using a field\nwidth wide enough to hold all values in the field. For TINYINT, SMALLINT, MEDIUMINT, INT, and\nBIGINT, the field widths are 4, 6, 8, 11, and 20, respectively, no matter what the declared display\nwidth is.\nLINES TERMINATED BY is still used to separate lines. If a line does not contain all fields, the rest of\nthe columns are set to their default values. If you do not have a line terminator, you should set this to\n''. In this case, the text file must contain all fields for each row.\nFixed-row format also affects handling of NULL values, as described later.\nNote\nFixed-size format does not work if you are using a multibyte character set.\nHandling of NULL values varies according to the FIELDS and LINES options in use:\n• For the default FIELDS and LINES values, NULL is written as a field value of \\N for output, and a\nfield value of \\N is read as NULL for input (assuming that the ESCAPED BY character is \\).\n• If FIELDS ENCLOSED BY is not empty, a field containing the literal word NULL as its value is read as\na NULL value. This differs from the word NULL enclosed within FIELDS ENCLOSED BY characters,\nwhich is read as the string 'NULL'.\n• If FIELDS ESCAPED BY is empty, NULL is written as the word NULL.\n• With fixed-row format (which is used when FIELDS TERMINATED BY and FIELDS ENCLOSED\nBY are both empty), NULL is written as an empty string. This causes both NULL values and empty\nstrings in the table to be indistinguishable when written to the file because both are written as empty\nstrings. If you need to be able to tell the two apart when reading the file back in, you should not use\nfixed-row format.\nAn attempt to load NULL into a NOT NULL column produces either a warning or an error according to\nthe rules described in Column Value Assignment.\nSome cases are not supported by LOAD DATA:\n• Fixed-size rows (FIELDS TERMINATED BY and FIELDS ENCLOSED BY both empty) and BLOB or\nTEXT columns.\n• If you specify one separator that is the same as or a prefix of another, LOAD DATA cannot interpret\nthe input properly. For example, the following FIELDS clause would cause problems:\nFIELDS TERMINATED BY '\"' ENCLOSED BY '\"'\n• If FIELDS ESCAPED BY is empty, a field value that contains an occurrence of FIELDS ENCLOSED\nBY or LINES TERMINATED BY followed by the FIELDS TERMINATED BY value causes LOAD\nDATA to stop reading a field or line too early. This happens because LOAD DATA cannot properly\ndetermine where the field or line value ends.\nColumn List Specification\nThe following example loads all columns of the persondata table:\nLOAD DATA INFILE 'persondata.txt' INTO TABLE persondata;\nBy default, when no column list is provided at the end of the LOAD DATA statement, input lines are\nexpected to contain a field for each table column. If you want to load only some of a table's columns,\nspecify a column list:\nLOAD DATA INFILE 'persondata.txt' INTO TABLE persondata\n(col_name_or_user_var [, col_name_or_user_var] ...);\nYou must also specify a column list if the order of the fields in the input file differs from the order of the\ncolumns in the table. Otherwise, MySQL cannot tell how to match input fields with table columns.\nInput Preprocessing\nEach instance of col_name_or_user_var in LOAD DATA syntax is either a column name or a user\nvariable. With user variables, the SET clause enables you to perform preprocessing transformations on\ntheir values before assigning the result to columns.\nUser variables in the SET clause can be used in several ways. The following example uses the first\ninput column directly for the value of t1.column1, and assigns the second input column to a user\nvariable that is subjected to a division operation before being used for the value of t1.column2:\nLOAD DATA INFILE 'file.txt'\n  INTO TABLE t1\n  (column1, @var1)\n  SET column2 = @var1/100;\nThe SET clause can be used to supply values not derived from the input file. The following statement\nsets column3 to the current date and time:\nLOAD DATA INFILE 'file.txt'\n  INTO TABLE t1\n  (column1, column2)\n  SET column3 = CURRENT_TIMESTAMP;\nYou can also discard an input value by assigning it to a user variable and not assigning the variable to\nany table column:\nLOAD DATA INFILE 'file.txt'\n  INTO TABLE t1\n  (column1, @dummy, column2, @dummy, column3);\nUse of the column/variable list and SET clause is subject to the following restrictions:\n• Assignments in the SET clause should have only column names on the left hand side of assignment\noperators.\n• You can use subqueries in the right hand side of SET assignments. A subquery that returns a value\nto be assigned to a column may be a scalar subquery only. Also, you cannot use a subquery to\nselect from the table that is being loaded.\n• Lines ignored by an IGNORE number LINES clause are not processed for the column/variable list\nor SET clause.\n• User variables cannot be used when loading data with fixed-row format because user variables do\nnot have a display width.\nColumn Value Assignment\nTo process an input line, LOAD DATA splits it into fields and uses the values according to the column/\nvariable list and the SET clause, if they are present. Then the resulting row is inserted into the table. If\nthere are BEFORE INSERT or AFTER INSERT triggers for the table, they are activated before or after\ninserting the row, respectively.\nInterpretation of field values and assignment to table columns depends on these factors:\n• The SQL mode (the value of the sql_mode system variable). The mode can be nonrestrictive, or\nrestrictive in various ways. For example, strict SQL mode can be enabled, or the mode can include\nvalues such as NO_ZERO_DATE or NO_ZERO_IN_DATE.\n• Presence or absence of the IGNORE and LOCAL modifiers.\nThose factors combine to produce restrictive or nonrestrictive data interpretation by LOAD DATA:\n• Data interpretation is restrictive if the SQL mode is restrictive and neither the IGNORE nor the LOCAL\nmodifier is specified. Errors terminate the load operation.\n• Data interpretation is nonrestrictive if the SQL mode is nonrestrictive or the IGNORE or LOCAL\nmodifier is specified. (In particular, either modifier if specified overrides a restrictive SQL mode when\nthe REPLACE modifier is omitted.) Errors become warnings and the load operation continues.\nRestrictive data interpretation uses these rules:\n• Too many or too few fields results an error.\n• Assigning NULL (that is, \\N) to a non-NULL column results in an error.\n• A value that is out of range for the column data type results in an error.\n• Invalid values produce errors. For example, a value such as 'x' for a numeric column results in an\nerror, not conversion to 0.\nBy contrast, nonrestrictive data interpretation uses these rules:\n• If an input line has too many fields, the extra fields are ignored and the number of warnings is\nincremented.\n• If an input line has too few fields, the columns for which input fields are missing are assigned their\ndefault values. Default value assignment is described in Section 13.6, “Data Type Default Values”.\n• Assigning NULL (that is, \\N) to a non-NULL column results in assignment of the implicit default value\nfor the column data type. Implicit default values are described in Section 13.6, “Data Type Default\nValues”.\n• Invalid values produce warnings rather than errors, and are converted to the “closest” valid value for\nthe column data type. Examples:\n• A value such as 'x' for a numeric column results in conversion to 0.\n• An out-of-range numeric or temporal value is clipped to the closest endpoint of the range for the\ncolumn data type.\n• An invalid value for a DATETIME, DATE, or TIME column is inserted as the implicit default value,\nregardless of the SQL mode NO_ZERO_DATE setting. The implicit default is the appropriate\n“zero” value for the type ('0000-00-00 00:00:00', '0000-00-00', or '00:00:00'). See\nSection 13.2, “Date and Time Data Types”.\n• LOAD DATA interprets an empty field value differently from a missing field:\n• For string types, the column is set to the empty string.\n• For numeric types, the column is set to 0.\n• For date and time types, the column is set to the appropriate “zero” value for the type. See\nSection 13.2, “Date and Time Data Types”.\nThese are the same values that result if you assign an empty string explicitly to a string, numeric, or\ndate or time type explicitly in an INSERT or UPDATE statement.\nTIMESTAMP columns are set to the current date and time only if there is a NULL value for the column\n(that is, \\N) and the column is not declared to permit NULL values, or if the TIMESTAMP column default\nvalue is the current timestamp and it is omitted from the field list when a field list is specified.\nLOAD DATA regards all input as strings, so you cannot use numeric values for ENUM or SET columns\nthe way you can with INSERT statements. All ENUM and SET values must be specified as strings.\nBIT values cannot be loaded directly using binary notation (for example, b'011010'). To work around\nthis, use the SET clause to strip off the leading b' and trailing ' and perform a base-2 to base-10\nconversion so that MySQL loads the values into the BIT column properly:\n$> cat /tmp/bit_test.txt\nb'10'\nb'1111111'\n$> mysql test\nmysql> LOAD DATA INFILE '/tmp/bit_test.txt'\n       INTO TABLE bit_test (@var1)\n       SET b = CAST(CONV(MID(@var1, 3, LENGTH(@var1)-3), 2, 10) AS UNSIGNED);\nQuery OK, 2 rows affected (0.00 sec)\nRecords: 2  Deleted: 0  Skipped: 0  Warnings: 0\nmysql> SELECT BIN(b+0) FROM bit_test;\n+----------+\n| BIN(b+0) |\n+----------+\n| 10       |\n| 1111111  |\n+----------+\n2 rows in set (0.00 sec)\nFor BIT values in 0b binary notation (for example, 0b011010), use this SET clause instead to strip off\nthe leading 0b:\nSET b = CAST(CONV(MID(@var1, 3, LENGTH(@var1)-2), 2, 10) AS UNSIGNED)\nPartitioned Table Support\nLOAD DATA supports explicit partition selection using the PARTITION clause with a list of one or\nmore comma-separated names of partitions, subpartitions, or both. When this clause is used, if any\nrows from the file cannot be inserted into any of the partitions or subpartitions named in the list, the\nstatement fails with the error Found a row not matching the given partition set. For\nmore information and examples, see Section 26.5, “Partition Selection”.\nConcurrency Considerations\nWith the LOW_PRIORITY modifier, execution of the LOAD DATA statement is delayed until no other\nclients are reading from the table. This affects only storage engines that use only table-level locking\n(such as MyISAM, MEMORY, and MERGE).\nWith the CONCURRENT modifier and a MyISAM table that satisfies the condition for concurrent inserts\n(that is, it contains no free blocks in the middle), other threads can retrieve data from the table while\nLOAD DATA is executing. This modifier affects the performance of LOAD DATA a bit, even if no other\nthread is using the table at the same time.\nStatement Result Information\nWhen the LOAD DATA statement finishes, it returns an information string in the following format:\nRecords: 1  Deleted: 0  Skipped: 0  Warnings: 0\nWarnings occur under the same circumstances as when values are inserted using the INSERT\nstatement (see Section 15.2.7, “INSERT Statement”), except that LOAD DATA also generates warnings\nwhen there are too few or too many fields in the input row.\nYou can use SHOW WARNINGS to get a list of the first max_error_count warnings as information\nabout what went wrong. See Section 15.7.7.41, “SHOW WARNINGS Statement”.\nIf you are using the C API, you can get information about the statement by calling the mysql_info()\nfunction. See mysql_info().\nReplication Considerations\nLOAD DATA is considered unsafe for statement-based replication. If you use LOAD DATA with\nbinlog_format=STATEMENT, each replica on which the changes are to be applied creates a\ntemporary file containing the data. This temporary file is not encrypted, even if binary log encryption is\nactive on the source, If encryption is required, use row-based or mixed binary logging format instead,\nfor which replicas do not create the temporary file. For more information on the interaction between\nLOAD DATA and replication, see Section 19.5.1.20, “Replication and LOAD DATA”.\nMiscellaneous Topics\nOn Unix, if you need LOAD DATA to read from a pipe, you can use the following technique (the\nexample loads a listing of the / directory into the table db1.t1):\nmkfifo /mysql/data/db1/ls.dat\nchmod 666 /mysql/data/db1/ls.dat\nfind / -ls > /mysql/data/db1/ls.dat &\nmysql -e \"LOAD DATA INFILE 'ls.dat' INTO TABLE t1\" db1\nHere you must run the command that generates the data to be loaded and the mysql commands\neither on separate terminals, or run the data generation process in the background (as shown in the\npreceding example). If you do not do this, the pipe blocks until data is read by the mysql process.",
    "15.2.10 LOAD XML Statement": "15.2.10 LOAD XML Statement\nLOAD XML\n    [LOW_PRIORITY | CONCURRENT] [LOCAL]\n    INFILE 'file_name'\n    [REPLACE | IGNORE]\n    INTO TABLE [db_name.]tbl_name\n    [CHARACTER SET charset_name]\n    [ROWS IDENTIFIED BY '<tagname>']\n    [IGNORE number {LINES | ROWS}]\n    [(field_name_or_user_var\n        [, field_name_or_user_var] ...)]\n    [SET col_name={expr | DEFAULT}\n        [, col_name={expr | DEFAULT}] ...]\nThe LOAD XML statement reads data from an XML file into a table. The file_name must be given as\na literal string. The tagname in the optional ROWS IDENTIFIED BY clause must also be given as a\nliteral string, and must be surrounded by angle brackets (< and >).\nLOAD XML acts as the complement of running the mysql client in XML output mode (that is, starting\nthe client with the --xml option). To write data from a table to an XML file, you can invoke the mysql\nclient with the --xml and -e options from the system shell, as shown here:\n$> mysql --xml -e 'SELECT * FROM mydb.mytable' > file.xml\nTo read the file back into a table, use LOAD XML. By default, the <row> element is considered to be\nthe equivalent of a database table row; this can be changed using the ROWS IDENTIFIED BY clause.\nThis statement supports three different XML formats:\n• Column names as attributes and column values as attribute values:\n<row column1=\"value1\" column2=\"value2\" .../>\n• Column names as tags and column values as the content of these tags:\n<row>\n  <column1>value1</column1>\n  <column2>value2</column2>\n</row>\n• Column names are the name attributes of <field> tags, and values are the contents of these tags:\n<row>\n  <field name='column1'>value1</field>\n  <field name='column2'>value2</field>\n</row>\nThis is the format used by other MySQL tools, such as mysqldump.\nAll three formats can be used in the same XML file; the import routine automatically detects the format\nfor each row and interprets it correctly. Tags are matched based on the tag or attribute name and the\ncolumn name.\nThe following clauses work essentially the same way for LOAD XML as they do for LOAD DATA:\n• LOW_PRIORITY or CONCURRENT\n• LOCAL\n• REPLACE or IGNORE\n• CHARACTER SET\n• SET\nSee Section 15.2.9, “LOAD DATA Statement”, for more information about these clauses.\n(field_name_or_user_var, ...) is a list of one or more comma-separated XML fields or user\nvariables. The name of a user variable used for this purpose must match the name of a field from the\nXML file, prefixed with @. You can use field names to select only desired fields. User variables can be\nemployed to store the corresponding field values for subsequent re-use.\nThe IGNORE number LINES or IGNORE number ROWS clause causes the first number rows in the\nXML file to be skipped. It is analogous to the LOAD DATA statement's IGNORE ... LINES clause.\nSuppose that we have a table named person, created as shown here:\nUSE test;\nCREATE TABLE person (\n    person_id INT NOT NULL PRIMARY KEY,\n    fname VARCHAR(40) NULL,\n    lname VARCHAR(40) NULL,\n    created TIMESTAMP\n);\nSuppose further that this table is initially empty.\nNow suppose that we have a simple XML file person.xml, whose contents are as shown here:\n<list>\n  <person person_id=\"1\" fname=\"Kapek\" lname=\"Sainnouine\"/>\n  <person person_id=\"2\" fname=\"Sajon\" lname=\"Rondela\"/>\n  <person person_id=\"3\"><fname>Likame</fname><lname>Örrtmons</lname></person>\n  <person person_id=\"4\"><fname>Slar</fname><lname>Manlanth</lname></person>\n  <person><field name=\"person_id\">5</field><field name=\"fname\">Stoma</field>\n    <field name=\"lname\">Milu</field></person>\n  <person><field name=\"person_id\">6</field><field name=\"fname\">Nirtam</field>\n    <field name=\"lname\">Sklöd</field></person>\n  <person person_id=\"7\"><fname>Sungam</fname><lname>Dulbåd</lname></person>\n  <person person_id=\"8\" fname=\"Sraref\" lname=\"Encmelt\"/>\n</list>\nEach of the permissible XML formats discussed previously is represented in this example file.\nTo import the data in person.xml into the person table, you can use this statement:\nmysql> LOAD XML LOCAL INFILE 'person.xml'\n    ->   INTO TABLE person\n    ->   ROWS IDENTIFIED BY '<person>';\nQuery OK, 8 rows affected (0.00 sec)\nRecords: 8  Deleted: 0  Skipped: 0  Warnings: 0\nHere, we assume that person.xml is located in the MySQL data directory. If the file cannot be found,\nthe following error results:\nERROR 2 (HY000): File '/person.xml' not found (Errcode: 2)\nThe ROWS IDENTIFIED BY '<person>' clause means that each <person> element in the XML\nfile is considered equivalent to a row in the table into which the data is to be imported. In this case, this\nis the person table in the test database.\nAs can be seen by the response from the server, 8 rows were imported into the test.person table.\nThis can be verified by a simple SELECT statement:\nmysql> SELECT * FROM person;\n+-----------+--------+------------+---------------------+\n| person_id | fname  | lname      | created             |\n+-----------+--------+------------+---------------------+\n|         1 | Kapek  | Sainnouine | 2007-07-13 16:18:47 |\n|         2 | Sajon  | Rondela    | 2007-07-13 16:18:47 |\n|         3 | Likame | Örrtmons   | 2007-07-13 16:18:47 |\n|         4 | Slar   | Manlanth   | 2007-07-13 16:18:47 |\n|         5 | Stoma  | Nilu       | 2007-07-13 16:18:47 |\n|         6 | Nirtam | Sklöd      | 2007-07-13 16:18:47 |\n|         7 | Sungam | Dulbåd     | 2007-07-13 16:18:47 |\n|         8 | Sreraf | Encmelt    | 2007-07-13 16:18:47 |\n+-----------+--------+------------+---------------------+\n8 rows in set (0.00 sec)\nThis shows, as stated earlier in this section, that any or all of the 3 permitted XML formats may appear\nin a single file and be read using LOAD XML.\nThe inverse of the import operation just shown—that is, dumping MySQL table data into an XML file—\ncan be accomplished using the mysql client from the system shell, as shown here:\n$> mysql --xml -e \"SELECT * FROM test.person\" > person-dump.xml\n$> cat person-dump.xml\n<?xml version=\"1.0\"?>\n<resultset statement=\"SELECT * FROM test.person\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n  <row>\n <field name=\"person_id\">1</field>\n <field name=\"fname\">Kapek</field>\n <field name=\"lname\">Sainnouine</field>\n  </row>\n  <row>\n <field name=\"person_id\">2</field>\n <field name=\"fname\">Sajon</field>\n <field name=\"lname\">Rondela</field>\n  </row>\n  <row>\n <field name=\"person_id\">3</field>\n <field name=\"fname\">Likema</field>\n <field name=\"lname\">Örrtmons</field>\n  </row>\n  <row>\n <field name=\"person_id\">4</field>\n <field name=\"fname\">Slar</field>\n <field name=\"lname\">Manlanth</field>\n  </row>\n  <row>\n <field name=\"person_id\">5</field>\n <field name=\"fname\">Stoma</field>\n <field name=\"lname\">Nilu</field>\n  </row>\n  <row>\n <field name=\"person_id\">6</field>\n <field name=\"fname\">Nirtam</field>\n <field name=\"lname\">Sklöd</field>\n  </row>\n  <row>\n <field name=\"person_id\">7</field>\n <field name=\"fname\">Sungam</field>\n <field name=\"lname\">Dulbåd</field>\n  </row>\n  <row>\n <field name=\"person_id\">8</field>\n <field name=\"fname\">Sreraf</field>\n <field name=\"lname\">Encmelt</field>\n  </row>\n</resultset>\nNote\nThe --xml option causes the mysql client to use XML formatting for its output;\nthe -e option causes the client to execute the SQL statement immediately\nfollowing the option. See Section 6.5.1, “mysql — The MySQL Command-Line\nClient”.\nYou can verify that the dump is valid by creating a copy of the person table and importing the dump\nfile into the new table, like this:\nmysql> USE test;\nmysql> CREATE TABLE person2 LIKE person;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> LOAD XML LOCAL INFILE 'person-dump.xml'\n    ->   INTO TABLE person2;\nQuery OK, 8 rows affected (0.01 sec)\nRecords: 8  Deleted: 0  Skipped: 0  Warnings: 0\nmysql> SELECT * FROM person2;\n+-----------+--------+------------+---------------------+\n| person_id | fname  | lname      | created             |\n+-----------+--------+------------+---------------------+\n|         1 | Kapek  | Sainnouine | 2007-07-13 16:18:47 |\n|         2 | Sajon  | Rondela    | 2007-07-13 16:18:47 |\n|         3 | Likema | Örrtmons   | 2007-07-13 16:18:47 |\n|         4 | Slar   | Manlanth   | 2007-07-13 16:18:47 |\n|         5 | Stoma  | Nilu       | 2007-07-13 16:18:47 |\n|         6 | Nirtam | Sklöd      | 2007-07-13 16:18:47 |\n|         7 | Sungam | Dulbåd     | 2007-07-13 16:18:47 |\n|         8 | Sreraf | Encmelt    | 2007-07-13 16:18:47 |\n+-----------+--------+------------+---------------------+\n8 rows in set (0.00 sec)\nThere is no requirement that every field in the XML file be matched with a column in the corresponding\ntable. Fields which have no corresponding columns are skipped. You can see this by first emptying the\nperson2 table and dropping the created column, then using the same LOAD XML statement we just\nemployed previously, like this:\nmysql> TRUNCATE person2;\nQuery OK, 8 rows affected (0.26 sec)\nmysql> ALTER TABLE person2 DROP COLUMN created;\nQuery OK, 0 rows affected (0.52 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\nmysql> SHOW CREATE TABLE person2\\G\n*************************** 1. row ***************************\n       Table: person2\nCreate Table: CREATE TABLE `person2` (\n  `person_id` int NOT NULL,\n  `fname` varchar(40) DEFAULT NULL,\n  `lname` varchar(40) DEFAULT NULL,\n  PRIMARY KEY (`person_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\nmysql> LOAD XML LOCAL INFILE 'person-dump.xml'\n    ->   INTO TABLE person2;\nQuery OK, 8 rows affected (0.01 sec)\nRecords: 8  Deleted: 0  Skipped: 0  Warnings: 0\nmysql> SELECT * FROM person2;\n+-----------+--------+------------+\n| person_id | fname  | lname      |\n+-----------+--------+------------+\n|         1 | Kapek  | Sainnouine |\n|         2 | Sajon  | Rondela    |\n|         3 | Likema | Örrtmons   |\n|         4 | Slar   | Manlanth   |\n|         5 | Stoma  | Nilu       |\n|         6 | Nirtam | Sklöd      |\n|         7 | Sungam | Dulbåd     |\n|         8 | Sreraf | Encmelt    |\n+-----------+--------+------------+\n8 rows in set (0.00 sec)\nThe order in which the fields are given within each row of the XML file does not affect the operation of\nLOAD XML; the field order can vary from row to row, and is not required to be in the same order as the\ncorresponding columns in the table.\nAs mentioned previously, you can use a (field_name_or_user_var, ...) list of one or more\nXML fields (to select desired fields only) or user variables (to store the corresponding field values for\nlater use). User variables can be especially useful when you want to insert data from an XML file into\ntable columns whose names do not match those of the XML fields. To see how this works, we first\ncreate a table named individual whose structure matches that of the person table, but whose\ncolumns are named differently:\nmysql> CREATE TABLE individual (\n    ->     individual_id INT NOT NULL PRIMARY KEY,\n    ->     name1 VARCHAR(40) NULL,\n    ->     name2 VARCHAR(40) NULL,\n    ->     made TIMESTAMP\n    -> );\nQuery OK, 0 rows affected (0.42 sec)\nIn this case, you cannot simply load the XML file directly into the table, because the field and column\nnames do not match:\nmysql> LOAD XML INFILE '../bin/person-dump.xml' INTO TABLE test.individual;\nERROR 1263 (22004): Column set to default value; NULL supplied to NOT NULL column 'individual_id' at ro\nThis happens because the MySQL server looks for field names matching the column names of the\ntarget table. You can work around this problem by selecting the field values into user variables, then\nsetting the target table's columns equal to the values of those variables using SET. You can perform\nboth of these operations in a single statement, as shown here:\nmysql> LOAD XML INFILE '../bin/person-dump.xml'\n    ->     INTO TABLE test.individual (@person_id, @fname, @lname, @created)\n    ->     SET individual_id=@person_id, name1=@fname, name2=@lname, made=@created;\nQuery OK, 8 rows affected (0.05 sec)\nRecords: 8  Deleted: 0  Skipped: 0  Warnings: 0\nmysql> SELECT * FROM individual;\n+---------------+--------+------------+---------------------+\n| individual_id | name1  | name2      | made                |\n+---------------+--------+------------+---------------------+\n|             1 | Kapek  | Sainnouine | 2007-07-13 16:18:47 |\n|             2 | Sajon  | Rondela    | 2007-07-13 16:18:47 |\n|             3 | Likema | Örrtmons   | 2007-07-13 16:18:47 |\n|             4 | Slar   | Manlanth   | 2007-07-13 16:18:47 |\n|             5 | Stoma  | Nilu       | 2007-07-13 16:18:47 |\n|             6 | Nirtam | Sklöd      | 2007-07-13 16:18:47 |\n|             7 | Sungam | Dulbåd     | 2007-07-13 16:18:47 |\n|             8 | Srraf  | Encmelt    | 2007-07-13 16:18:47 |\n+---------------+--------+------------+---------------------+\n8 rows in set (0.00 sec)\nThe names of the user variables must match those of the corresponding fields from the XML file, with\nthe addition of the required @ prefix to indicate that they are variables. The user variables need not be\nlisted or assigned in the same order as the corresponding fields.\nUsing a ROWS IDENTIFIED BY '<tagname>' clause, it is possible to import data from the same\nXML file into database tables with different definitions. For this example, suppose that you have a file\nnamed address.xml which contains the following XML:\n<?xml version=\"1.0\"?>\n<list>\n  <person person_id=\"1\">\n    <fname>Robert</fname>\n    <lname>Jones</lname>\n    <address address_id=\"1\" street=\"Mill Creek Road\" zip=\"45365\" city=\"Sidney\"/>\n    <address address_id=\"2\" street=\"Main Street\" zip=\"28681\" city=\"Taylorsville\"/>\n  </person>\n  <person person_id=\"2\">\n    <fname>Mary</fname>\n    <lname>Smith</lname>\n    <address address_id=\"3\" street=\"River Road\" zip=\"80239\" city=\"Denver\"/>\n    <!-- <address address_id=\"4\" street=\"North Street\" zip=\"37920\" city=\"Knoxville\"/> -->\n  </person>\n</list>\nYou can again use the test.person table as defined previously in this section, after clearing all the\nexisting records from the table and then showing its structure as shown here:\nmysql< TRUNCATE person;\nQuery OK, 0 rows affected (0.04 sec)\nmysql< SHOW CREATE TABLE person\\G\n*************************** 1. row ***************************\n       Table: person\nCreate Table: CREATE TABLE `person` (\n  `person_id` int(11) NOT NULL,\n  `fname` varchar(40) DEFAULT NULL,\n  `lname` varchar(40) DEFAULT NULL,\n  `created` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (`person_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n1 row in set (0.00 sec)\nNow create an address table in the test database using the following CREATE TABLE statement:\nCREATE TABLE address (\n    address_id INT NOT NULL PRIMARY KEY,\n    person_id INT NULL,\n    street VARCHAR(40) NULL,\n    zip INT NULL,\n    city VARCHAR(40) NULL,\n    created TIMESTAMP\n);\nTo import the data from the XML file into the person table, execute the following LOAD XML\nstatement, which specifies that rows are to be specified by the <person> element, as shown here;\nmysql> LOAD XML LOCAL INFILE 'address.xml'\n    ->   INTO TABLE person\n    ->   ROWS IDENTIFIED BY '<person>';\nQuery OK, 2 rows affected (0.00 sec)\nRecords: 2  Deleted: 0  Skipped: 0  Warnings: 0\nYou can verify that the records were imported using a SELECT statement:\nmysql> SELECT * FROM person;\n+-----------+--------+-------+---------------------+\n| person_id | fname  | lname | created             |\n+-----------+--------+-------+---------------------+\n|         1 | Robert | Jones | 2007-07-24 17:37:06 |\n|         2 | Mary   | Smith | 2007-07-24 17:37:06 |\n+-----------+--------+-------+---------------------+\n2 rows in set (0.00 sec)\nSince the <address> elements in the XML file have no corresponding columns in the person table,\nthey are skipped.\nTo import the data from the <address> elements into the address table, use the LOAD XML\nstatement shown here:\nmysql> LOAD XML LOCAL INFILE 'address.xml'\n    ->   INTO TABLE address\n    ->   ROWS IDENTIFIED BY '<address>';\nQuery OK, 3 rows affected (0.00 sec)\nRecords: 3  Deleted: 0  Skipped: 0  Warnings: 0\nYou can see that the data was imported using a SELECT statement such as this one:\nmysql> SELECT * FROM address;\n+------------+-----------+-----------------+-------+--------------+---------------------+\n| address_id | person_id | street          | zip   | city         | created             |\n+------------+-----------+-----------------+-------+--------------+---------------------+\n|          1 |         1 | Mill Creek Road | 45365 | Sidney       | 2007-07-24 17:37:37 |\n|          2 |         1 | Main Street     | 28681 | Taylorsville | 2007-07-24 17:37:37 |\n|          3 |         2 | River Road      | 80239 | Denver       | 2007-07-24 17:37:37 |\n+------------+-----------+-----------------+-------+--------------+---------------------+\n3 rows in set (0.00 sec)\nThe data from the <address> element that is enclosed in XML comments is not imported. However,\nsince there is a person_id column in the address table, the value of the person_id attribute from\nthe parent <person> element for each <address> is imported into the address table.\nSecurity Considerations. \n As with the LOAD DATA statement, the transfer of the XML file from the\nclient host to the server host is initiated by the MySQL server. In theory, a patched server could be built\nthat would tell the client program to transfer a file of the server's choosing rather than the file named by\nthe client in the LOAD XML statement. Such a server could access any file on the client host to which\nthe client user has read access.\nIn a Web environment, clients usually connect to MySQL from a Web server. A user that can run any\ncommand against the MySQL server can use LOAD XML LOCAL to read any files to which the Web\nserver process has read access. In this environment, the client with respect to the MySQL server\nis actually the Web server, not the remote program being run by the user who connects to the Web\nserver.\nYou can disable loading of XML files from clients by starting the server with --local-infile=0 or\n--local-infile=OFF. This option can also be used when starting the mysql client to disable LOAD\nXML for the duration of the client session.\nTo prevent a client from loading XML files from the server, do not grant the FILE privilege to the\ncorresponding MySQL user account, or revoke this privilege if the client user account already has it.\nImportant\nRevoking the FILE privilege (or not granting it in the first place) keeps the user\nonly from executing the LOAD XML statement (as well as the LOAD_FILE()\nfunction; it does not prevent the user from executing LOAD XML LOCAL. To\ndisallow this statement, you must start the server or the client with --local-\ninfile=OFF.\nIn other words, the FILE privilege affects only whether the client can read files\non the server; it has no bearing on whether the client can read files on the local\nfile system.",
    "15.2.11 Parenthesized Query Expressions": "15.2.11 Parenthesized Query Expressions\nparenthesized_query_expression:\n    ( query_expression [order_by_clause] [limit_clause] )\n      [order_by_clause]\n      [limit_clause]\n      [into_clause]\nquery_expression:\n    query_block [set_op query_block [set_op query_block ...]]\n      [order_by_clause]\n      [limit_clause]\n      [into_clause]\nquery_block:\n    SELECT ... | TABLE | VALUES\norder_by_clause:\n    ORDER BY as for SELECT\nlimit_clause:\n    LIMIT as for SELECT\ninto_clause:\n    INTO as for SELECT\nset_op:\n    UNION | INTERSECT | EXCEPT\nMySQL 9.1 supports parenthesized query expressions according to the preceding syntax. At its\nsimplest, a parenthesized query expression contains a single SELECT or other statement returning a\nresult set and no following optional clauses:\n(SELECT 1);\n(SELECT * FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = 'mysql');\nTABLE t;\nVALUES ROW(2, 3, 4), ROW(1, -2, 3);\nA parenthesized query expression can also contain queries linked by one or more set operations such\nas UNION, and end with any or all of the optional clauses:\nmysql> (SELECT 1 AS result UNION SELECT 2);\n+--------+\n| result |\n+--------+\n|      1 |\n|      2 |\n+--------+\nmysql> (SELECT 1 AS result UNION SELECT 2) LIMIT 1;\n+--------+\n| result |\n+--------+\n|      1 |\n+--------+\nmysql> (SELECT 1 AS result UNION SELECT 2) LIMIT 1 OFFSET 1;\n+--------+\n| result |\n+--------+\n|      2 |\n+--------+\nmysql> (SELECT 1 AS result UNION SELECT 2)\n       ORDER BY result DESC LIMIT 1;\n+--------+\n| result |\n+--------+\n|      2 |\n+--------+\nmysql> (SELECT 1 AS result UNION SELECT 2)\n       ORDER BY result DESC LIMIT 1 OFFSET 1;\n+--------+\n| result |\n+--------+\n|      1 |\n+--------+\nmysql> (SELECT 1 AS result UNION SELECT 3 UNION SELECT 2)\n       ORDER BY result LIMIT 1 OFFSET 1 INTO @var;\nmysql> SELECT @var;\n+------+\n| @var |\n+------+\n|    2 |\n+------+\nINTERSECT acts before UNION and EXCEPT, so that the following two statements are equivalent:\nSELECT a FROM t1 EXCEPT SELECT b FROM t2 INTERSECT SELECT c FROM t3;\nSELECT a FROM t1 EXCEPT (SELECT b FROM t2 INTERSECT SELECT c FROM t3);\nParenthesized query expressions are also used as query expressions, so a query expression, usually\ncomposed of query blocks, may also consist of parenthesized query expressions:\n(TABLE t1 ORDER BY a) UNION (TABLE t2 ORDER BY b) ORDER BY z;\nQuery blocks may have trailing ORDER BY and LIMIT clauses, which are applied before the outer set\noperation, ORDER BY, and LIMIT.\nYou cannot have a query block with a trailing ORDER BY or LIMIT without wrapping it in parentheses\nbut parentheses may be used for enforcement in various ways:\n• To enforce LIMIT on each query block:\n(SELECT 1 LIMIT 1) UNION (VALUES ROW(2) LIMIT 1);\n(VALUES ROW(1), ROW(2) LIMIT 2) EXCEPT (SELECT 2 LIMIT 1);\n• To enforce LIMIT on both query blocks and the entire query expression:\n(SELECT 1 LIMIT 1) UNION (SELECT 2 LIMIT 1) LIMIT 1;\n• To enforce LIMIT on the entire query expression (with no parentheses):\nVALUES ROW(1), ROW(2) INTERSECT VALUES ROW(2), ROW(1) LIMIT 1;\n• Hybrid enforcement: LIMIT on the first query block and on the entire query expression:\n(SELECT 1 LIMIT 1) UNION SELECT 2 LIMIT 1;\nThe syntax described in this section is subject to certain restrictions:\n• A trailing INTO clause for a query expression is not permitted if there is another INTO clause inside\nparentheses.\n• An ORDER BY or LIMIT within a parenthesized query expression which is also applied in the outer\nquery is handled in accordance with the SQL standard.\nNested parenthesized query expressions are permitted. The maximum level of nesting supported is\n63; this is after any simplifications or merges have been performed by the parser.\nAn example of such a statement is shown here:\nmysql> (SELECT 'a' UNION SELECT 'b' LIMIT 2) LIMIT 3;\n+---+\n| a |\n+---+\n| a |\n| b |\n+---+\n2 rows in set (0.00 sec)\nYou should be aware that, when collapsing parenthesized expression bodies, MySQL follows SQL\nstandard semantics, so that a higher outer limit cannot override an inner lower one. For example,\n(SELECT ... LIMIT 5) LIMIT 10 can return no more than five rows.",
    "15.2.12 REPLACE Statement": "15.2.12 REPLACE Statement\nREPLACE [LOW_PRIORITY | DELAYED]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [(col_name [, col_name] ...)]\n    { {VALUES | VALUE} (value_list) [, (value_list)] ...\n      |\n      VALUES row_constructor_list\n    }\nREPLACE [LOW_PRIORITY | DELAYED]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    SET assignment_list\nREPLACE [LOW_PRIORITY | DELAYED]\n    [INTO] tbl_name\n    [PARTITION (partition_name [, partition_name] ...)]\n    [(col_name [, col_name] ...)]\n    {SELECT ... | TABLE table_name}\nvalue:\n    {expr | DEFAULT}\nvalue_list:\n    value [, value] ...\nrow_constructor_list:\n    ROW(value_list)[, ROW(value_list)][, ...]\nassignment:\n    col_name = value\nassignment_list:\n    assignment [, assignment] ...\nREPLACE works exactly like INSERT, except that if an old row in the table has the same value as a new\nrow for a PRIMARY KEY or a UNIQUE index, the old row is deleted before the new row is inserted. See\nSection 15.2.7, “INSERT Statement”.\nREPLACE is a MySQL extension to the SQL standard. It either inserts, or deletes and inserts. For\nanother MySQL extension to standard SQL—that either inserts or updates—see Section 15.2.7.2,\n“INSERT ... ON DUPLICATE KEY UPDATE Statement”.\nDELAYED inserts and replaces were deprecated in MySQL 5.6. In MySQL 9.1, DELAYED is not\nsupported. The server recognizes but ignores the DELAYED keyword, handles the replace as a\nnondelayed replace, and generates an ER_WARN_LEGACY_SYNTAX_CONVERTED warning: REPLACE\nDELAYED is no longer supported. The statement was converted to REPLACE. The\nDELAYED keyword is scheduled for removal in a future release. release.\nNote\nREPLACE makes sense only if a table has a PRIMARY KEY or UNIQUE index.\nOtherwise, it becomes equivalent to INSERT, because there is no index to be\nused to determine whether a new row duplicates another.\nValues for all columns are taken from the values specified in the REPLACE statement. Any\nmissing columns are set to their default values, just as happens for INSERT. You cannot refer to\nvalues from the current row and use them in the new row. If you use an assignment such as SET\ncol_name = col_name + 1, the reference to the column name on the right hand side is treated as\nDEFAULT(col_name), so the assignment is equivalent to SET col_name = DEFAULT(col_name)\n+ 1.\nYou can specify the column values that REPLACE attempts to insert using VALUES ROW().\nTo use REPLACE, you must have both the INSERT and DELETE privileges for the table.\nIf a generated column is replaced explicitly, the only permitted value is DEFAULT. For information about\ngenerated columns, see Section 15.1.20.8, “CREATE TABLE and Generated Columns”.\nREPLACE supports explicit partition selection using the PARTITION clause with a list of comma-\nseparated names of partitions, subpartitions, or both. As with INSERT, if it is not possible to insert the\nnew row into any of these partitions or subpartitions, the REPLACE statement fails with the error Found\na row not matching the given partition set. For more information and examples, see\nSection 26.5, “Partition Selection”.\nThe REPLACE statement returns a count to indicate the number of rows affected. This is the sum of the\nrows deleted and inserted. If the count is 1 for a single-row REPLACE, a row was inserted and no rows\nwere deleted. If the count is greater than 1, one or more old rows were deleted before the new row was\ninserted. It is possible for a single row to replace more than one old row if the table contains multiple\nunique indexes and the new row duplicates values for different old rows in different unique indexes.\nThe affected-rows count makes it easy to determine whether REPLACE only added a row or whether it\nalso replaced any rows: Check whether the count is 1 (added) or greater (replaced).\nIf you are using the C API, the affected-rows count can be obtained using the\nmysql_affected_rows() function.\nYou cannot replace into a table and select from the same table in a subquery.\nMySQL uses the following algorithm for REPLACE (and LOAD DATA ... REPLACE):\n1. Try to insert the new row into the table\n2. While the insertion fails because a duplicate-key error occurs for a primary key or unique index:\na. Delete from the table the conflicting row that has the duplicate key value\nb. Try again to insert the new row into the table\nIt is possible that in the case of a duplicate-key error, a storage engine may perform the REPLACE as\nan update rather than a delete plus insert, but the semantics are the same. There are no user-visible\neffects other than a possible difference in how the storage engine increments Handler_xxx status\nvariables.\nBecause the results of REPLACE ... SELECT statements depend on the ordering of rows from the\nSELECT and this order cannot always be guaranteed, it is possible when logging these statements for\nthe source and the replica to diverge. For this reason, REPLACE ... SELECT statements are flagged\nas unsafe for statement-based replication. such statements produce a warning in the error log when\nusing statement-based mode and are written to the binary log using the row-based format when using\nMIXED mode. See also Section 19.2.1.1, “Advantages and Disadvantages of Statement-Based and\nRow-Based Replication”.\nMySQL 9.1 supports TABLE as well as SELECT with REPLACE, just as it does with INSERT. See\nSection 15.2.7.1, “INSERT ... SELECT Statement”, for more information and examples.\nWhen modifying an existing table that is not partitioned to accommodate partitioning, or, when\nmodifying the partitioning of an already partitioned table, you may consider altering the table's primary\nkey (see Section 26.6.1, “Partitioning Keys, Primary Keys, and Unique Keys”). You should be aware\nthat, if you do this, the results of REPLACE statements may be affected, just as they would be if you\nmodified the primary key of a nonpartitioned table. Consider the table created by the following CREATE\nTABLE statement:\nCREATE TABLE test (\n  id INT UNSIGNED NOT NULL AUTO_INCREMENT,\n  data VARCHAR(64) DEFAULT NULL,\n  ts TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (id)\n);\nWhen we create this table and run the statements shown in the mysql client, the result is as follows:\nmysql> REPLACE INTO test VALUES (1, 'Old', '2014-08-20 18:47:00');\nQuery OK, 1 row affected (0.04 sec)\nmysql> REPLACE INTO test VALUES (1, 'New', '2014-08-20 18:47:42');\nQuery OK, 2 rows affected (0.04 sec)\nmysql> SELECT * FROM test;\n+----+------+---------------------+\n| id | data | ts                  |\n+----+------+---------------------+\n|  1 | New  | 2014-08-20 18:47:42 |\n+----+------+---------------------+\n1 row in set (0.00 sec)\nNow we create a second table almost identical to the first, except that the primary key now covers 2\ncolumns, as shown here (emphasized text):\nCREATE TABLE test2 (\n  id INT UNSIGNED NOT NULL AUTO_INCREMENT,\n  data VARCHAR(64) DEFAULT NULL,\n  ts TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (id, ts)\n);\nWhen we run on test2 the same two REPLACE statements as we did on the original test table, we\nobtain a different result:\nmysql> REPLACE INTO test2 VALUES (1, 'Old', '2014-08-20 18:47:00');\nQuery OK, 1 row affected (0.05 sec)\nmysql> REPLACE INTO test2 VALUES (1, 'New', '2014-08-20 18:47:42');\nQuery OK, 1 row affected (0.06 sec)\nmysql> SELECT * FROM test2;\n+----+------+---------------------+\n| id | data | ts                  |\n+----+------+---------------------+\n|  1 | Old  | 2014-08-20 18:47:00 |\n|  1 | New  | 2014-08-20 18:47:42 |\n+----+------+---------------------+\n2 rows in set (0.00 sec)\nThis is due to the fact that, when run on test2, both the id and ts column values must match those\nof an existing row for the row to be replaced; otherwise, a row is inserted.",
    "15.2.13 SELECT Statement": "15.2.13 SELECT Statement\nSELECT\n    [ALL | DISTINCT | DISTINCTROW ]\n    [HIGH_PRIORITY]\n    [STRAIGHT_JOIN]\n    [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT]\n    [SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS]\n    select_expr [, select_expr] ...\n    [into_option]\n    [FROM table_references\n      [PARTITION partition_list]]\n    [WHERE where_condition]\n    [GROUP BY {col_name | expr | position}, ... [WITH ROLLUP]]\n    [HAVING where_condition]\n    [WINDOW window_name AS (window_spec)\n        [, window_name AS (window_spec)] ...]\n    [ORDER BY {col_name | expr | position}\n      [ASC | DESC], ... [WITH ROLLUP]]\n    [LIMIT {[offset,] row_count | row_count OFFSET offset}]\n    [into_option]\n    [FOR {UPDATE | SHARE}\n        [OF tbl_name [, tbl_name] ...]\n        [NOWAIT | SKIP LOCKED]\n      | LOCK IN SHARE MODE]\n    [into_option]\ninto_option: {\n    INTO OUTFILE 'file_name'\n        [CHARACTER SET charset_name]\n        export_options\n  | INTO DUMPFILE 'file_name'\n  | INTO var_name [, var_name] ...\n}\nexport_options:\n    [{FIELDS | COLUMNS}\n        [TERMINATED BY 'string']\n        [[OPTIONALLY] ENCLOSED BY 'char']\n        [ESCAPED BY 'char']\n    ]\n    [LINES\n        [STARTING BY 'string']\n        [TERMINATED BY 'string']\n    ]\nSELECT is used to retrieve rows selected from one or more tables, and can include UNION operations\nand subqueries. INTERSECT and EXCEPT operations are also supported. The UNION, INTERSECT,\nand EXCEPT operators are described in more detail later in this section. See also Section 15.2.15,\n“Subqueries”.\nA SELECT statement can start with a WITH clause to define common table expressions accessible\nwithin the SELECT. See Section 15.2.20, “WITH (Common Table Expressions)”.\nThe most commonly used clauses of SELECT statements are these:\n• Each select_expr indicates a column that you want to retrieve. There must be at least one\nselect_expr.\n• table_references indicates the table or tables from which to retrieve rows. Its syntax is described\nin Section 15.2.13.2, “JOIN Clause”.\n• SELECT supports explicit partition selection using the PARTITION clause with a list of partitions\nor subpartitions (or both) following the name of the table in a table_reference (see\nSection 15.2.13.2, “JOIN Clause”). In this case, rows are selected only from the partitions listed, and\nany other partitions of the table are ignored. For more information and examples, see Section 26.5,\n“Partition Selection”.\n• The WHERE clause, if given, indicates the condition or conditions that rows must satisfy to be\nselected. where_condition is an expression that evaluates to true for each row to be selected.\nThe statement selects all rows if there is no WHERE clause.\nIn the WHERE expression, you can use any of the functions and operators that MySQL supports,\nexcept for aggregate (group) functions. See Section 11.5, “Expressions”, and Chapter 14, Functions\nand Operators.\nSELECT can also be used to retrieve rows computed without reference to any table.\nFor example:\nmysql> SELECT 1 + 1;\n        -> 2\n You are permitted to specify DUAL as a dummy table name in situations where no tables are\nreferenced:\nmysql> SELECT 1 + 1 FROM DUAL;\n        -> 2\nDUAL is purely for the convenience of people who require that all SELECT statements should have\nFROM and possibly other clauses. MySQL may ignore the clauses. MySQL does not require FROM\nDUAL if no tables are referenced.\nIn general, clauses used must be given in exactly the order shown in the syntax description. For\nexample, a HAVING clause must come after any GROUP BY clause and before any ORDER BY clause.\nThe INTO clause, if present, can appear in any position indicated by the syntax description, but within a\ngiven statement can appear only once, not in multiple positions. For more information about INTO, see\nSection 15.2.13.1, “SELECT ... INTO Statement”.\nThe list of select_expr terms comprises the select list that indicates which columns to retrieve.\nTerms specify a column or expression or can use *-shorthand:\n• A select list consisting only of a single unqualified * can be used as shorthand to select all columns\nfrom all tables:\nSELECT * FROM t1 INNER JOIN t2 ...\n• tbl_name.* can be used as a qualified shorthand to select all columns from the named table:\nSELECT t1.*, t2.* FROM t1 INNER JOIN t2 ...\n• If a table has invisible columns, * and tbl_name.* do not include them. To be included, invisible\ncolumns must be referenced explicitly.\n• Use of an unqualified * with other items in the select list may produce a parse error. For example:\nSELECT id, * FROM t1\nTo avoid this problem, use a qualified tbl_name.* reference:\nSELECT id, t1.* FROM t1\nUse qualified tbl_name.* references for each table in the select list:\nSELECT AVG(score), t1.* FROM t1 ...\nThe following list provides additional information about other SELECT clauses:\n•   A select_expr can be given an alias using AS alias_name. The alias is used as the\nexpression's column name and can be used in GROUP BY, ORDER BY, or HAVING clauses. For\nexample:\nSELECT CONCAT(last_name,', ',first_name) AS full_name\n  FROM mytable ORDER BY full_name;\nThe AS keyword is optional when aliasing a select_expr with an identifier. The preceding example\ncould have been written like this:\nSELECT CONCAT(last_name,', ',first_name) full_name\n  FROM mytable ORDER BY full_name;\nHowever, because the AS is optional, a subtle problem can occur if you forget the comma between\ntwo select_expr expressions: MySQL interprets the second as an alias name. For example, in the\nfollowing statement, columnb is treated as an alias name:\nSELECT columna columnb FROM mytable;\nFor this reason, it is good practice to be in the habit of using AS explicitly when specifying column\naliases.\nIt is not permissible to refer to a column alias in a WHERE clause, because the column value might not\nyet be determined when the WHERE clause is executed. See Section B.3.4.4, “Problems with Column\nAliases”.\n•   The FROM table_references clause indicates the table or tables from which to retrieve rows.\nIf you name more than one table, you are performing a join. For information on join syntax, see\nSection 15.2.13.2, “JOIN Clause”. For each table specified, you can optionally specify an alias.\ntbl_name [[AS] alias] [index_hint]\nThe use of index hints provides the optimizer with information about how to choose indexes during\nquery processing. For a description of the syntax for specifying these hints, see Section 10.9.4,\n“Index Hints”.\nYou can use SET max_seeks_for_key=value as an alternative way to force MySQL to prefer\nkey scans instead of table scans. See Section 7.1.8, “Server System Variables”.\n• You can refer to a table within the default database as tbl_name, or as db_name.tbl_name to\nspecify a database explicitly. You can refer to a column as col_name, tbl_name.col_name, or\ndb_name.tbl_name.col_name. You need not specify a tbl_name or db_name.tbl_name prefix\nfor a column reference unless the reference would be ambiguous. See Section 11.2.2, “Identifier\nQualifiers”, for examples of ambiguity that require the more explicit column reference forms.\n•   A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name.\nThese statements are equivalent:\nSELECT t1.name, t2.salary FROM employee AS t1, info AS t2\n  WHERE t1.name = t2.name;\nSELECT t1.name, t2.salary FROM employee t1, info t2\n  WHERE t1.name = t2.name;\n•  Columns selected for output can be referred to in ORDER BY and GROUP BY clauses using column\nnames, column aliases, or column positions. Column positions are integers and begin with 1:\nSELECT college, region, seed FROM tournament\n  ORDER BY region, seed;\nSELECT college, region AS r, seed AS s FROM tournament\n  ORDER BY r, s;\nSELECT college, region, seed FROM tournament\n  ORDER BY 2, 3;\nTo sort in reverse order, add the DESC (descending) keyword to the name of the column in the\nORDER BY clause that you are sorting by. The default is ascending order; this can be specified\nexplicitly using the ASC keyword.\nIf ORDER BY occurs within a parenthesized query expression and also is applied in the outer query,\nthe results are undefined and may change in a future version of MySQL.\nUse of column positions is deprecated because the syntax has been removed from the SQL\nstandard.\n•   When you use ORDER BY or GROUP BY to sort a column in a SELECT, the server sorts values using\nonly the initial number of bytes indicated by the max_sort_length system variable.\n• MySQL extends the use of GROUP BY to permit selecting fields that are not mentioned in the\nGROUP BY clause. If you are not getting the results that you expect from your query, please read the\ndescription of GROUP BY found in Section 14.19, “Aggregate Functions”.\n• The HAVING clause, like the WHERE clause, specifies selection conditions. The WHERE clause\nspecifies conditions on columns in the select list, but cannot refer to aggregate functions. The\nHAVING clause specifies conditions on groups, typically formed by the GROUP BY clause. The query\nresult includes only groups satisfying the HAVING conditions. (If no GROUP BY is present, all rows\nimplicitly form a single aggregate group.)\nThe HAVING clause is applied nearly last, just before items are sent to the client, with no\noptimization. (LIMIT is applied after HAVING.)\nThe SQL standard requires that HAVING must reference only columns in the GROUP BY clause or\ncolumns used in aggregate functions. However, MySQL supports an extension to this behavior, and\npermits HAVING to refer to columns in the SELECT list and columns in outer subqueries as well.\nIf the HAVING clause refers to a column that is ambiguous, a warning occurs. In the following\nstatement, col2 is ambiguous because it is used as both an alias and a column name:\nSELECT COUNT(col1) AS col2 FROM t GROUP BY col2 HAVING col2 = 2;\nPreference is given to standard SQL behavior, so if a HAVING column name is used both in GROUP\nBY and as an aliased column in the select column list, preference is given to the column in the GROUP\nBY column.\n• Do not use HAVING for items that should be in the WHERE clause. For example, do not write the\nfollowing:\nSELECT col_name FROM tbl_name HAVING col_name > 0;\nWrite this instead:\nSELECT col_name FROM tbl_name WHERE col_name > 0;\n• The HAVING clause can refer to aggregate functions, which the WHERE clause cannot:\nSELECT user, MAX(salary) FROM users\n  GROUP BY user HAVING MAX(salary) > 10;\n(This did not work in some older versions of MySQL.)\n• MySQL permits duplicate column names. That is, there can be more than one select_expr with\nthe same name. This is an extension to standard SQL. Because MySQL also permits GROUP BY and\nHAVING to refer to select_expr values, this can result in an ambiguity:\nSELECT 12 AS a, a FROM t GROUP BY a;\nIn that statement, both columns have the name a. To ensure that the correct column is used for\ngrouping, use different names for each select_expr.\n• The WINDOW clause, if present, defines named windows that can be referred to by window functions.\nFor details, see Section 14.20.4, “Named Windows”.\n• MySQL resolves unqualified column or alias references in ORDER BY clauses by searching in the\nselect_expr values, then in the columns of the tables in the FROM clause. For GROUP BY or\nHAVING clauses, it searches the FROM clause before searching in the select_expr values. (For\nGROUP BY and HAVING, this differs from the pre-MySQL 5.0 behavior that used the same rules as\nfor ORDER BY.)\n•  The LIMIT clause can be used to constrain the number of rows returned by the SELECT statement.\nLIMIT takes one or two numeric arguments, which must both be nonnegative integer constants, with\nthese exceptions:\n• Within prepared statements, LIMIT parameters can be specified using ? placeholder markers.\n• Within stored programs, LIMIT parameters can be specified using integer-valued routine\nparameters or local variables.\nWith two arguments, the first argument specifies the offset of the first row to return, and the second\nspecifies the maximum number of rows to return. The offset of the initial row is 0 (not 1):\nSELECT * FROM tbl LIMIT 5,10;  # Retrieve rows 6-15\nTo retrieve all rows from a certain offset up to the end of the result set, you can use some large\nnumber for the second parameter. This statement retrieves all rows from the 96th row to the last:\nSELECT * FROM tbl LIMIT 95,18446744073709551615;\nWith one argument, the value specifies the number of rows to return from the beginning of the result\nset:\nSELECT * FROM tbl LIMIT 5;     # Retrieve first 5 rows\nIn other words, LIMIT row_count is equivalent to LIMIT 0, row_count.\nFor prepared statements, you can use placeholders. The following statements return one row from\nthe tbl table:\nSET @a=1;\nPREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?';\nEXECUTE STMT USING @a;\nThe following statements return the second to sixth rows from the tbl table:\nSET @skip=1; SET @numrows=5;\nPREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?, ?';\nEXECUTE STMT USING @skip, @numrows;\nFor compatibility with PostgreSQL, MySQL also supports the LIMIT row_count OFFSET offset\nsyntax.\nIf LIMIT occurs within a parenthesized query expression and also is applied in the outer query, the\nresults are undefined and may change in a future version of MySQL.\n• The SELECT ... INTO form of SELECT enables the query result to be written to a file or stored in\nvariables. For more information, see Section 15.2.13.1, “SELECT ... INTO Statement”.\n•      If you use FOR UPDATE with a storage engine that uses page or row locks, rows examined by the\nquery are write-locked until the end of the current transaction.\nYou cannot use FOR UPDATE as part of the SELECT in a statement such as CREATE TABLE\nnew_table SELECT ... FROM old_table .... (If you attempt to do so, the statement is\nrejected with the error Can't update table 'old_table' while 'new_table' is being\ncreated.)\nFOR SHARE and LOCK IN SHARE MODE set shared locks that permit other transactions to read\nthe examined rows but not to update or delete them. FOR SHARE and LOCK IN SHARE MODE are\nequivalent. However, FOR SHARE, like FOR UPDATE, supports NOWAIT, SKIP LOCKED, and OF\ntbl_name options. FOR SHARE is a replacement for LOCK IN SHARE MODE, but LOCK IN SHARE\nMODE remains available for backward compatibility.\nNOWAIT causes a FOR UPDATE or FOR SHARE query to execute immediately, returning an error if a\nrow lock cannot be obtained due to a lock held by another transaction.\nSKIP LOCKED causes a FOR UPDATE or FOR SHARE query to execute immediately, excluding rows\nfrom the result set that are locked by another transaction.\nNOWAIT and SKIP LOCKED options are unsafe for statement-based replication.\nNote\nQueries that skip locked rows return an inconsistent view of the data. SKIP\nLOCKED is therefore not suitable for general transactional work. However,\nit may be used to avoid lock contention when multiple sessions access the\nsame queue-like table.\nOF tbl_name applies FOR UPDATE and FOR SHARE queries to named tables. For example:\nSELECT * FROM t1, t2 FOR SHARE OF t1 FOR UPDATE OF t2;\nAll tables referenced by the query block are locked when OF tbl_name is omitted. Consequently,\nusing a locking clause without OF tbl_name in combination with another locking clause returns an\nerror. Specifying the same table in multiple locking clauses returns an error. If an alias is specified\nas the table name in the SELECT statement, a locking clause may only use the alias. If the SELECT\nstatement does not specify an alias explicitly, the locking clause may only specify the actual table\nname.\nFor more information about FOR UPDATE and FOR SHARE, see Section 17.7.2.4, “Locking\nReads”. For additional information about NOWAIT and SKIP LOCKED options, see Locking Read\nConcurrency with NOWAIT and SKIP LOCKED.\nFollowing the SELECT keyword, you can use a number of modifiers that affect the operation of the\nstatement. HIGH_PRIORITY, STRAIGHT_JOIN, and modifiers beginning with SQL_ are MySQL\nextensions to standard SQL.\n• The ALL and DISTINCT modifiers specify whether duplicate rows should be returned. ALL (the\ndefault) specifies that all matching rows should be returned, including duplicates. DISTINCT\nspecifies removal of duplicate rows from the result set. It is an error to specify both modifiers.\nDISTINCTROW is a synonym for DISTINCT.\nDISTINCT can be used with a query that also uses WITH ROLLUP.\n• HIGH_PRIORITY gives the SELECT higher priority than a statement that updates a table. You should\nuse this only for queries that are very fast and must be done at once. A SELECT HIGH_PRIORITY\nquery that is issued while the table is locked for reading runs even if there is an update statement\nwaiting for the table to be free. This affects only storage engines that use only table-level locking\n(such as MyISAM, MEMORY, and MERGE).\nHIGH_PRIORITY cannot be used with SELECT statements that are part of a UNION.\n• STRAIGHT_JOIN forces the optimizer to join the tables in the order in which they are listed in the\nFROM clause. You can use this to speed up a query if the optimizer joins the tables in nonoptimal\norder. STRAIGHT_JOIN also can be used in the table_references list. See Section 15.2.13.2,\n“JOIN Clause”.\nSTRAIGHT_JOIN does not apply to any table that the optimizer treats as a const or system table.\nSuch a table produces a single row, is read during the optimization phase of query execution, and\nreferences to its columns are replaced with the appropriate column values before query execution\nproceeds. These tables appear first in the query plan displayed by EXPLAIN. See Section 10.8.1,\n“Optimizing Queries with EXPLAIN”. This exception may not apply to const or system tables that\nare used on the NULL-complemented side of an outer join (that is, the right-side table of a LEFT\nJOIN or the left-side table of a RIGHT JOIN.\n• SQL_BIG_RESULT or SQL_SMALL_RESULT can be used with GROUP BY or DISTINCT to tell\nthe optimizer that the result set has many rows or is small, respectively. For SQL_BIG_RESULT,\nMySQL directly uses disk-based temporary tables if they are created, and prefers sorting to using\na temporary table with a key on the GROUP BY elements. For SQL_SMALL_RESULT, MySQL uses\nin-memory temporary tables to store the resulting table instead of using sorting. This should not\nnormally be needed.\n• SQL_BUFFER_RESULT forces the result to be put into a temporary table. This helps MySQL free the\ntable locks early and helps in cases where it takes a long time to send the result set to the client.\nThis modifier can be used only for top-level SELECT statements, not for subqueries or following\nUNION.\n• SQL_CALC_FOUND_ROWS tells MySQL to calculate how many rows there would be in the result\nset, disregarding any LIMIT clause. The number of rows can then be retrieved with SELECT\nFOUND_ROWS(). See Section 14.15, “Information Functions”.\nNote\nThe SQL_CALC_FOUND_ROWS query modifier and accompanying\nFOUND_ROWS() function are deprecated; expect them to be removed in\na future version of MySQL. See the description of FOUND_ROWS() for\ninformation about an alternative strategy.\n• The SQL_CACHE and SQL_NO_CACHE modifiers were used with the query cache prior to MySQL\n9.1. The query cache was removed in MySQL 9.1. The SQL_CACHE modifier was removed as\nwell. SQL_NO_CACHE is deprecated, and has no effect; expect it to be removed in a future MySQL\nrelease.\n15.2.13.1 SELECT ... INTO Statement\nThe SELECT ... INTO form of SELECT enables a query result to be stored in variables or written to a\nfile:\n• SELECT ... INTO var_list selects column values and stores them into variables.\n• SELECT ... INTO OUTFILE writes the selected rows to a file. Column and line terminators can be\nspecified to produce a specific output format.\n• SELECT ... INTO DUMPFILE writes a single row to a file without any formatting.\nA given SELECT statement can contain at most one INTO clause, although as shown by the SELECT\nsyntax description (see Section 15.2.13, “SELECT Statement”), the INTO can appear in different\npositions:\n• Before FROM. Example:\nSELECT * INTO @myvar FROM t1;\n• Before a trailing locking clause. Example:\nSELECT * FROM t1 INTO @myvar FOR UPDATE;\n• At the end of the SELECT. Example:\nSELECT * FROM t1 FOR UPDATE INTO @myvar;\nThe INTO position at the end of the statement is the preferred position. The position before a locking\nclause is deprecated; expect support for it to be removed in a future version of MySQL. In other words,\nINTO after FROM but not at the end of the SELECT produces a warning.\nAn INTO clause should not be used in a nested SELECT because such a SELECT must return its result\nto the outer context. There are also constraints on the use of INTO within UNION statements; see\nSection 15.2.18, “UNION Clause”.\nFor the INTO var_list variant:\n• var_list names a list of one or more variables, each of which can be a user-defined variable,\nstored procedure or function parameter, or stored program local variable. (Within a prepared\nSELECT ... INTO var_list statement, only user-defined variables are permitted; see\nSection 15.6.4.2, “Local Variable Scope and Resolution”.)\n• The selected values are assigned to the variables. The number of variables must match the number\nof columns. The query should return a single row. If the query returns no rows, a warning with error\ncode 1329 occurs (No data), and the variable values remain unchanged. If the query returns\nmultiple rows, error 1172 occurs (Result consisted of more than one row). If it is possible\nthat the statement may retrieve multiple rows, you can use LIMIT 1 to limit the result set to a single\nrow.\nSELECT id, data INTO @x, @y FROM test.t1 LIMIT 1;\nINTO var_list can also be used with a TABLE statement, subject to these restrictions:\n• The number of variables must match the number of columns in the table.\n• If the table contains more than one row, you must use LIMIT 1 to limit the result set to a single row.\nLIMIT 1 must precede the INTO keyword.\nAn example of such a statement is shown here:\nTABLE employees ORDER BY lname DESC LIMIT 1\n    INTO @id, @fname, @lname, @hired, @separated, @job_code, @store_id;\nYou can also select values from a VALUES statement that generates a single row into a set of user\nvariables. In this case, you must employ a table alias, and you must assign each value from the value\nlist to a variable. Each of the two statements shown here is equivalent to SET @x=2, @y=4, @z=8:\nSELECT * FROM (VALUES ROW(2,4,8)) AS t INTO @x,@y,@z;\nSELECT * FROM (VALUES ROW(2,4,8)) AS t(a,b,c) INTO @x,@y,@z;\nUser variable names are not case-sensitive. See Section 11.4, “User-Defined Variables”.\nThe SELECT ... INTO OUTFILE 'file_name' form of SELECT writes the selected rows to a\nfile. The file is created on the server host, so you must have the FILE privilege to use this syntax.\nfile_name cannot be an existing file, which among other things prevents files such as /etc/passwd\nand database tables from being modified. The character_set_filesystem system variable\ncontrols the interpretation of the file name.\nThe SELECT ... INTO OUTFILE statement is intended to enable dumping a table to a text file\non the server host. To create the resulting file on some other host, SELECT ... INTO OUTFILE\nnormally is unsuitable because there is no way to write a path to the file relative to the server host file\nsystem, unless the location of the file on the remote host can be accessed using a network-mapped\npath on the server host file system.\nAlternatively, if the MySQL client software is installed on the remote host, you can use a client\ncommand such as mysql -e \"SELECT ...\" > file_name to generate the file on that host.\nSELECT ... INTO OUTFILE is the complement of LOAD DATA. Column values are written\nconverted to the character set specified in the CHARACTER SET clause. If no such clause is present,\nvalues are dumped using the binary character set. In effect, there is no character set conversion.\nIf a result set contains columns in several character sets, so is the output data file, and it may not be\npossible to reload the file correctly.\nThe syntax for the export_options part of the statement consists of the same FIELDS and LINES\nclauses that are used with the LOAD DATA statement. For more detailed information about the FIELDS\nand LINES clauses, including their default values and permissible values, see Section 15.2.9, “LOAD\nDATA Statement”.\nFIELDS ESCAPED BY controls how to write special characters. If the FIELDS ESCAPED BY\ncharacter is not empty, it is used when necessary to avoid ambiguity as a prefix that precedes following\ncharacters on output:\n• The FIELDS ESCAPED BY character\n• The FIELDS [OPTIONALLY] ENCLOSED BY character\n• The first character of the FIELDS TERMINATED BY and LINES TERMINATED BY values\n• ASCII NUL (the zero-valued byte; what is actually written following the escape character is ASCII 0,\nnot a zero-valued byte)\nThe FIELDS TERMINATED BY, ENCLOSED BY, ESCAPED BY, or LINES TERMINATED BY\ncharacters must be escaped so that you can read the file back in reliably. ASCII NUL is escaped to\nmake it easier to view with some pagers.\nThe resulting file need not conform to SQL syntax, so nothing else need be escaped.\nIf the FIELDS ESCAPED BY character is empty, no characters are escaped and NULL is output as\nNULL, not \\N. It is probably not a good idea to specify an empty escape character, particularly if field\nvalues in your data contain any of the characters in the list just given.\nINTO OUTFILE can also be used with a TABLE statement when you want to dump all columns of a\ntable into a text file. In this case, the ordering and number of rows can be controlled using ORDER BY\nand LIMIT; these clauses must precede INTO OUTFILE. TABLE ... INTO OUTFILE supports\nthe same export_options as does SELECT ... INTO OUTFILE, and it is subject to the same\nrestrictions on writing to the file system. An example of such a statement is shown here:\nTABLE employees ORDER BY lname LIMIT 1000\n    INTO OUTFILE '/tmp/employee_data_1.txt'\n    FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"', ESCAPED BY '\\'\n    LINES TERMINATED BY '\\n';\nYou can also use SELECT ... INTO OUTFILE with a VALUES statement to write values directly into\na file. An example is shown here:\nSELECT * FROM (VALUES ROW(1,2,3),ROW(4,5,6),ROW(7,8,9)) AS t\n    INTO OUTFILE '/tmp/select-values.txt';\nYou must use a table alias; column aliases are also supported, and can optionally be used to write\nvalues only from desired columns. You can also use any or all of the export options supported by\nSELECT ... INTO OUTFILE to format the output to the file.\nHere is an example that produces a file in the comma-separated values (CSV) format used by many\nprograms:\nSELECT a,b,a+b INTO OUTFILE '/tmp/result.txt'\n  FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"'\n  LINES TERMINATED BY '\\n'\n  FROM test_table;\nIf you use INTO DUMPFILE instead of INTO OUTFILE, MySQL writes only one row into the file,\nwithout any column or line termination and without performing any escape processing. This is useful for\nselecting a BLOB value and storing it in a file.\nTABLE also supports INTO DUMPFILE. If the table contains more than one row, you must also use\nLIMIT 1 to limit the output to a single row. INTO DUMPFILE can also be used with SELECT *\nFROM (VALUES ROW()[, ...]) AS table_alias [LIMIT 1]. See Section 15.2.19, “VALUES\nStatement”.\nNote\nAny file created by INTO OUTFILE or INTO DUMPFILE is owned by the\noperating system user under whose account mysqld runs. (You should never\nrun mysqld as root for this and other reasons.) The umask for file creation is\n0640; you must have sufficient access privileges to manipulate the file contents.\nIf the secure_file_priv system variable is set to a nonempty directory\nname, the file to be written must be located in that directory.\nIn the context of SELECT ... INTO statements that occur as part of events executed by the Event\nScheduler, diagnostics messages (not only errors, but also warnings) are written to the error log,\nand, on Windows, to the application event log. For additional information, see Section 27.5.5, “Event\nScheduler Status”.\nSupport is provided for periodic synchronization of output files written to by SELECT INTO OUTFILE\nand SELECT INTO DUMPFILE, enabled by setting the select_into_disk_sync server system\nvariable introduced in that version. Output buffer size and optional delay can be set using, respectively,\nselect_into_buffer_size and select_into_disk_sync_delay. For more information, see\nthe descriptions of these system variables.\n15.2.13.2 JOIN Clause\nMySQL supports the following JOIN syntax for the table_references part of SELECT statements\nand multiple-table DELETE and UPDATE statements:\ntable_references:\n    escaped_table_reference [, escaped_table_reference] ...\nescaped_table_reference: {\n    table_reference\n  | { OJ table_reference }\n}\ntable_reference: {\n    table_factor\n  | joined_table\n}\ntable_factor: {\n    tbl_name [PARTITION (partition_names)]\n        [[AS] alias] [index_hint_list]\n  | [LATERAL] table_subquery [AS] alias [(col_list)]\n  | ( table_references )\n}\njoined_table: {\n    table_reference {[INNER | CROSS] JOIN | STRAIGHT_JOIN} table_factor [join_specification]\n  | table_reference {LEFT|RIGHT} [OUTER] JOIN table_reference join_specification\n  | table_reference NATURAL [INNER | {LEFT|RIGHT} [OUTER]] JOIN table_factor\n}\njoin_specification: {\n    ON search_condition\n  | USING (join_column_list)\n}\njoin_column_list:\n    column_name[, column_name] ...\nindex_hint_list:\n    index_hint[ index_hint] ...\nindex_hint: {\n    USE {INDEX|KEY}\n      [FOR {JOIN|ORDER BY|GROUP BY}] ([index_list])\n  | {IGNORE|FORCE} {INDEX|KEY}\n      [FOR {JOIN|ORDER BY|GROUP BY}] (index_list)\n}\nindex_list:\n    index_name [, index_name] ...\nA table reference is also known as a join expression.\nA table reference (when it refers to a partitioned table) may contain a PARTITION clause, including a\nlist of comma-separated partitions, subpartitions, or both. This option follows the name of the table and\nprecedes any alias declaration. The effect of this option is that rows are selected only from the listed\npartitions or subpartitions. Any partitions or subpartitions not named in the list are ignored. For more\ninformation and examples, see Section 26.5, “Partition Selection”.\nThe syntax of table_factor is extended in MySQL in comparison with standard SQL. The standard\naccepts only table_reference, not a list of them inside a pair of parentheses.\nThis is a conservative extension if each comma in a list of table_reference items is considered as\nequivalent to an inner join. For example:\nSELECT * FROM t1 LEFT JOIN (t2, t3, t4)\n                 ON (t2.a = t1.a AND t3.b = t1.b AND t4.c = t1.c)\nis equivalent to:\nSELECT * FROM t1 LEFT JOIN (t2 CROSS JOIN t3 CROSS JOIN t4)\n                 ON (t2.a = t1.a AND t3.b = t1.b AND t4.c = t1.c)\nIn MySQL, JOIN, CROSS JOIN, and INNER JOIN are syntactic equivalents (they can replace each\nother). In standard SQL, they are not equivalent. INNER JOIN is used with an ON clause, CROSS\nJOIN is used otherwise.\nIn general, parentheses can be ignored in join expressions containing only inner join operations.\nMySQL also supports nested joins. See Section 10.2.1.8, “Nested Join Optimization”.\nIndex hints can be specified to affect how the MySQL optimizer makes use of indexes. For more\ninformation, see Section 10.9.4, “Index Hints”. Optimizer hints and the optimizer_switch system\nvariable are other ways to influence optimizer use of indexes. See Section 10.9.3, “Optimizer Hints”,\nand Section 10.9.2, “Switchable Optimizations”.\nThe following list describes general factors to take into account when writing joins:\n• A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name:\nSELECT t1.name, t2.salary\n  FROM employee AS t1 INNER JOIN info AS t2 ON t1.name = t2.name;\nSELECT t1.name, t2.salary\n  FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name;\n• A table_subquery is also known as a derived table or subquery in the FROM clause. See\nSection 15.2.15.8, “Derived Tables”. Such subqueries must include an alias to give the subquery\nresult a table name, and may optionally include a list of table column names in parentheses. A trivial\nexample follows:\nSELECT * FROM (SELECT 1, 2, 3) AS t1;\n• The maximum number of tables that can be referenced in a single join is 61. This includes a join\nhandled by merging derived tables and views in the FROM clause into the outer query block (see\nSection 10.2.2.4, “Optimizing Derived Tables, View References, and Common Table Expressions\nwith Merging or Materialization”).\n• INNER JOIN and , (comma) are semantically equivalent in the absence of a join condition: both\nproduce a Cartesian product between the specified tables (that is, each and every row in the first\ntable is joined to each and every row in the second table).\nHowever, the precedence of the comma operator is less than that of INNER JOIN, CROSS JOIN,\nLEFT JOIN, and so on. If you mix comma joins with the other join types when there is a join\ncondition, an error of the form Unknown column 'col_name' in 'on clause' may occur.\nInformation about dealing with this problem is given later in this section.\n• The search_condition used with ON is any conditional expression of the form that can be used in\na WHERE clause. Generally, the ON clause serves for conditions that specify how to join tables, and\nthe WHERE clause restricts which rows to include in the result set.\n• If there is no matching row for the right table in the ON or USING part in a LEFT JOIN, a row with all\ncolumns set to NULL is used for the right table. You can use this fact to find rows in a table that have\nno counterpart in another table:\nSELECT left_tbl.*\n  FROM left_tbl LEFT JOIN right_tbl ON left_tbl.id = right_tbl.id\n  WHERE right_tbl.id IS NULL;\nThis example finds all rows in left_tbl with an id value that is not present in right_tbl (that is,\nall rows in left_tbl with no corresponding row in right_tbl). See Section 10.2.1.9, “Outer Join\nOptimization”.\n• The USING(join_column_list) clause names a list of columns that must exist in both tables.\nIf tables a and b both contain columns c1, c2, and c3, the following join compares corresponding\ncolumns from the two tables:\na LEFT JOIN b USING (c1, c2, c3)\n• The NATURAL [LEFT] JOIN of two tables is defined to be semantically equivalent to an INNER\nJOIN or a LEFT JOIN with a USING clause that names all columns that exist in both tables.\n• RIGHT JOIN works analogously to LEFT JOIN. To keep code portable across databases, it is\nrecommended that you use LEFT JOIN instead of RIGHT JOIN.\n•   The { OJ ... } syntax shown in the join syntax description exists only for compatibility with\nODBC. The curly braces in the syntax should be written literally; they are not metasyntax as used\nelsewhere in syntax descriptions.\nSELECT left_tbl.*\n    FROM { OJ left_tbl LEFT OUTER JOIN right_tbl\n           ON left_tbl.id = right_tbl.id }\n    WHERE right_tbl.id IS NULL;\nYou can use other types of joins within { OJ ... }, such as INNER JOIN or RIGHT OUTER\nJOIN. This helps with compatibility with some third-party applications, but is not official ODBC\nsyntax.\n• STRAIGHT_JOIN is similar to JOIN, except that the left table is always read before the right table.\nThis can be used for those (few) cases for which the join optimizer processes the tables in a\nsuboptimal order.\nSome join examples:\nSELECT * FROM table1, table2;\nSELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.id;\nSELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id;\nSELECT * FROM table1 LEFT JOIN table2 USING (id);\nSELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id\n  LEFT JOIN table3 ON table2.id = table3.id;\nNatural joins and joins with USING, including outer join variants, are processed according to the\nSQL:2003 standard:\n• Redundant columns of a NATURAL join do not appear. Consider this set of statements:\nCREATE TABLE t1 (i INT, j INT);\nCREATE TABLE t2 (k INT, j INT);\nINSERT INTO t1 VALUES(1, 1);\nINSERT INTO t2 VALUES(1, 1);\nSELECT * FROM t1 NATURAL JOIN t2;\nSELECT * FROM t1 JOIN t2 USING (j);\nIn the first SELECT statement, column j appears in both tables and thus becomes a join column,\nso, according to standard SQL, it should appear only once in the output, not twice. Similarly, in the\nsecond SELECT statement, column j is named in the USING clause and should appear only once in\nthe output, not twice.\nThus, the statements produce this output:\n+------+------+------+\n| j    | i    | k    |\n+------+------+------+\n|    1 |    1 |    1 |\n+------+------+------+\n+------+------+------+\n| j    | i    | k    |\n+------+------+------+\n|    1 |    1 |    1 |\n+------+------+------+\nRedundant column elimination and column ordering occurs according to standard SQL, producing\nthis display order:\n• First, coalesced common columns of the two joined tables, in the order in which they occur in the\nfirst table\n• Second, columns unique to the first table, in order in which they occur in that table\n• Third, columns unique to the second table, in order in which they occur in that table\nThe single result column that replaces two common columns is defined using the coalesce\noperation. That is, for two t1.a and t2.a the resulting single join column a is defined as a =\nCOALESCE(t1.a, t2.a), where:\nCOALESCE(x, y) = (CASE WHEN x IS NOT NULL THEN x ELSE y END)\nIf the join operation is any other join, the result columns of the join consist of the concatenation of all\ncolumns of the joined tables.\nA consequence of the definition of coalesced columns is that, for outer joins, the coalesced column\ncontains the value of the non-NULL column if one of the two columns is always NULL. If neither or\nboth columns are NULL, both common columns have the same value, so it doesn't matter which one\nis chosen as the value of the coalesced column. A simple way to interpret this is to consider that\na coalesced column of an outer join is represented by the common column of the inner table of a\nJOIN. Suppose that the tables t1(a, b) and t2(a, c) have the following contents:\nt1    t2\n----  ----\n1 x   2 z\n2 y   3 w\nThen, for this join, column a contains the values of t1.a:\nmysql> SELECT * FROM t1 NATURAL LEFT JOIN t2;\n+------+------+------+\n| a    | b    | c    |\n+------+------+------+\n|    1 | x    | NULL |\n|    2 | y    | z    |\n+------+------+------+\nBy contrast, for this join, column a contains the values of t2.a.\nmysql> SELECT * FROM t1 NATURAL RIGHT JOIN t2;\n+------+------+------+\n| a    | c    | b    |\n+------+------+------+\n|    2 | z    | y    |\n|    3 | w    | NULL |\n+------+------+------+\nCompare those results to the otherwise equivalent queries with JOIN ... ON:\nmysql> SELECT * FROM t1 LEFT JOIN t2 ON (t1.a = t2.a);\n+------+------+------+------+\n| a    | b    | a    | c    |\n+------+------+------+------+\n|    1 | x    | NULL | NULL |\n|    2 | y    |    2 | z    |\n+------+------+------+------+\nmysql> SELECT * FROM t1 RIGHT JOIN t2 ON (t1.a = t2.a);\n+------+------+------+------+\n| a    | b    | a    | c    |\n+------+------+------+------+\n|    2 | y    |    2 | z    |\n| NULL | NULL |    3 | w    |\n+------+------+------+------+\n• A USING clause can be rewritten as an ON clause that compares corresponding columns. However,\nalthough USING and ON are similar, they are not quite the same. Consider the following two queries:\na LEFT JOIN b USING (c1, c2, c3)\na LEFT JOIN b ON a.c1 = b.c1 AND a.c2 = b.c2 AND a.c3 = b.c3\nWith respect to determining which rows satisfy the join condition, both joins are semantically\nidentical.\nWith respect to determining which columns to display for SELECT * expansion, the two joins are\nnot semantically identical. The USING join selects the coalesced value of corresponding columns,\nwhereas the ON join selects all columns from all tables. For the USING join, SELECT * selects these\nvalues:\nCOALESCE(a.c1, b.c1), COALESCE(a.c2, b.c2), COALESCE(a.c3, b.c3)\nFor the ON join, SELECT * selects these values:\na.c1, a.c2, a.c3, b.c1, b.c2, b.c3\nWith an inner join, COALESCE(a.c1, b.c1) is the same as either a.c1 or b.c1 because both\ncolumns have the same value. With an outer join (such as LEFT JOIN), one of the two columns can\nbe NULL. That column is omitted from the result.\n• An ON clause can refer only to its operands.\nExample:\nCREATE TABLE t1 (i1 INT);\nCREATE TABLE t2 (i2 INT);\nCREATE TABLE t3 (i3 INT);\nSELECT * FROM t1 JOIN t2 ON (i1 = i3) JOIN t3;\nThe statement fails with an Unknown column 'i3' in 'on clause' error because i3 is a\ncolumn in t3, which is not an operand of the ON clause. To enable the join to be processed, rewrite\nthe statement as follows:\nSELECT * FROM t1 JOIN t2 JOIN t3 ON (i1 = i3);\n• JOIN has higher precedence than the comma operator (,), so the join expression t1, t2\nJOIN t3 is interpreted as (t1, (t2 JOIN t3)), not as ((t1, t2) JOIN t3). This affects\nstatements that use an ON clause because that clause can refer only to columns in the operands of\nthe join, and the precedence affects interpretation of what those operands are.\nExample:\nCREATE TABLE t1 (i1 INT, j1 INT);\nCREATE TABLE t2 (i2 INT, j2 INT);\nCREATE TABLE t3 (i3 INT, j3 INT);\nINSERT INTO t1 VALUES(1, 1);\nINSERT INTO t2 VALUES(1, 1);\nINSERT INTO t3 VALUES(1, 1);\nSELECT * FROM t1, t2 JOIN t3 ON (t1.i1 = t3.i3);\nThe JOIN takes precedence over the comma operator, so the operands for the ON clause are t2 and\nt3. Because t1.i1 is not a column in either of the operands, the result is an Unknown column\n't1.i1' in 'on clause' error.\nTo enable the join to be processed, use either of these strategies:\n• Group the first two tables explicitly with parentheses so that the operands for the ON clause are\n(t1, t2) and t3:\nSELECT * FROM (t1, t2) JOIN t3 ON (t1.i1 = t3.i3);\n• Avoid the use of the comma operator and use JOIN instead:\nSELECT * FROM t1 JOIN t2 JOIN t3 ON (t1.i1 = t3.i3);\nThe same precedence interpretation also applies to statements that mix the comma operator with\nINNER JOIN, CROSS JOIN, LEFT JOIN, and RIGHT JOIN, all of which have higher precedence\nthan the comma operator.\n• A MySQL extension compared to the SQL:2003 standard is that MySQL permits you to qualify the\ncommon (coalesced) columns of NATURAL or USING joins, whereas the standard disallows that.",
    "15.2.14 Set Operations with UNION, INTERSECT, and EXCEPT": "15.2.14 Set Operations with UNION, INTERSECT, and EXCEPT\n• Result Set Column Names and Data Types\n• Set Operations with TABLE and VALUES Statements\n• Set Operations using DISTINCT and ALL\n• Set Operations with ORDER BY and LIMIT\n• Limitations of Set Operations\nSQL set operations combine the results of multiple query blocks into a single result. A query block,\nsometimes also known as a simple table, is any SQL statement that returns a result set, such as\nSELECT. MySQL 9.1 also supports TABLE and VALUES statements. See the individual descriptions of\nthese statements elsewhere in this chapter for additional information.\nThe SQL standard defines the following three set operations:\n• UNION: Combine all results from two query blocks into a single result, omitting any duplicates.\n• INTERSECT: Combine only those rows which the results of two query blocks have in common,\nomitting any duplicates.\n• EXCEPT: For two query blocks A and B, return all results from A which are not also present in B,\nomitting any duplicates.\n(Some database systems, such as Oracle, use MINUS for the name of this operator. This is not\nsupported in MySQL.)\nMySQL supports UNION, INTERSECT, and EXCEPT.\nEach of these set operators supports an ALL modifier. When the ALL keyword follows a set operator,\nthis causes duplicates to be included in the result. See the following sections covering the individual\noperators for more information and examples.\nAll three set operators also support a DISTINCT keyword, which suppresses duplicates in the result.\nSince this is the default behavior for set operators, it is usually not necessary to specify DISTINCT\nexplicitly.\nIn general, query blocks and set operations can be combined in any number and order. A greatly\nsimplified representation is shown here:\nquery_block [set_op query_block] [set_op query_block] ...\nquery_block:\n    SELECT | TABLE | VALUES\nset_op:\n    UNION | INTERSECT | EXCEPT\nThis can be represented more accurately, and in greater detail, like this:\nquery_expression:\n  [with_clause] /* WITH clause */ \n  query_expression_body\n  [order_by_clause] [limit_clause] [into_clause]\nquery_expression_body:\n    query_term\n |  query_expression_body UNION [ALL | DISTINCT] query_term\n |  query_expression_body EXCEPT [ALL | DISTINCT] query_term\nquery_term:\n    query_primary\n |  query_term INTERSECT [ALL | DISTINCT] query_primary\nquery_primary:\n    query_block\n |  '(' query_expression_body [order_by_clause] [limit_clause] [into_clause] ')'\nquery_block:   /* also known as a simple table */\n    query_specification                     /* SELECT statement */\n |  table_value_constructor                 /* VALUES statement */\n |  explicit_table                          /* TABLE statement  */\nYou should be aware that INTERSECT is evaluated before UNION or EXCEPT. This means that, for\nexample, TABLE x UNION TABLE y INTERSECT TABLE z is always evaluated as TABLE x\nUNION (TABLE y INTERSECT TABLE z). See Section 15.2.8, “INTERSECT Clause”, for more\ninformation.\nIn addition, you should keep in mind that, while the UNION and INTERSECT set operators are\ncommutative (ordering is not significant), EXCEPT is not (order of operands affects the outcome). In\nother words, all of the following statements are true:\n• TABLE x UNION TABLE y and TABLE y UNION TABLE x produce the same result, although\nthe ordering of the rows may differ. You can force them to be the same using ORDER BY; see Set\nOperations with ORDER BY and LIMIT.\n• TABLE x INTERSECT TABLE y and TABLE y INTERSECT TABLE x return the same result.\n• TABLE x EXCEPT TABLE y and TABLE y EXCEPT TABLE x do not yield the same result. See\nSection 15.2.4, “EXCEPT Clause”, for an example.\nMore information and examples can be found in the sections that follow.\nResult Set Column Names and Data Types\nThe column names for the result of a set operation are taken from the column names of the first query\nblock. Example:\nmysql> CREATE TABLE t1 (x INT, y INT);\nQuery OK, 0 rows affected (0.04 sec)\nmysql> INSERT INTO t1 VALUES ROW(4,-2), ROW(5,9);\nQuery OK, 2 rows affected (0.00 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\nmysql> CREATE TABLE t2 (a INT, b INT);\nQuery OK, 0 rows affected (0.04 sec)\nmysql> INSERT INTO t2 VALUES ROW(1,2), ROW(3,4);\nQuery OK, 2 rows affected (0.01 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\nmysql> TABLE t1 UNION TABLE t2;\n+------+------+\n| x    | y    |\n+------+------+\n|    4 |   -2 |\n|    5 |    9 |\n|    1 |    2 |\n|    3 |    4 |\n+------+------+\n4 rows in set (0.00 sec)\nmysql> TABLE t2 UNION TABLE t1;\n+------+------+\n| a    | b    |\n+------+------+\n|    1 |    2 |\n|    3 |    4 |\n|    4 |   -2 |\n|    5 |    9 |\n+------+------+\n4 rows in set (0.00 sec)\nThis is true for UNION, EXCEPT, and INTERSECT queries.\nSelected columns listed in corresponding positions of each query block should have the same data\ntype. For example, the first column selected by the first statement should have the same type as the\nfirst column selected by the other statements. If the data types of corresponding result columns do not\nmatch, the types and lengths of the columns in the result take into account the values retrieved by all of\nthe query blocks. For example, the column length in the result set is not constrained to the length of the\nvalue from the first statement, as shown here:\nmysql> SELECT REPEAT('a',1) UNION SELECT REPEAT('b',20);\n+----------------------+\n| REPEAT('a',1)        |\n+----------------------+\n| a                    |\n| bbbbbbbbbbbbbbbbbbbb |\n+----------------------+\nSet Operations with TABLE and VALUES Statements\nYou can also use a TABLE statement or VALUES statement wherever you can employ the equivalent\nSELECT statement. Assume that tables t1 and t2 are created and populated as shown here:\nCREATE TABLE t1 (x INT, y INT);\nINSERT INTO t1 VALUES ROW(4,-2),ROW(5,9);\nCREATE TABLE t2 (a INT, b INT);\nINSERT INTO t2 VALUES ROW(1,2),ROW(3,4);\nThe preceding being the case, and disregarding the column names in the output of the queries\nbeginning with VALUES, all of the following UNION queries yield the same result:\nSELECT * FROM t1 UNION SELECT * FROM t2;\nTABLE t1 UNION SELECT * FROM t2;\nVALUES ROW(4,-2), ROW(5,9) UNION SELECT * FROM t2;\nSELECT * FROM t1 UNION TABLE t2;\nTABLE t1 UNION TABLE t2;\nVALUES ROW(4,-2), ROW(5,9) UNION TABLE t2;\nSELECT * FROM t1 UNION VALUES ROW(4,-2),ROW(5,9);\nTABLE t1 UNION VALUES ROW(4,-2),ROW(5,9);\nVALUES ROW(4,-2), ROW(5,9) UNION VALUES ROW(4,-2),ROW(5,9);\nTo force the column names to be the same, wrap the query block on the left-hand side in a SELECT\nstatement, and use aliases, like this:\nmysql> SELECT * FROM (TABLE t2) AS t(x,y) UNION TABLE t1;\n+------+------+\n| x    | y    |\n+------+------+\n|    1 |    2 |\n|    3 |    4 |\n|    4 |   -2 |\n|    5 |    9 |\n+------+------+\n4 rows in set (0.00 sec)\nSet Operations using DISTINCT and ALL\nBy default, duplicate rows are removed from results of set operations. The optional DISTINCT keyword\nhas the same effect but makes it explicit. With the optional ALL keyword, duplicate-row removal does\nnot occur and the result includes all matching rows from all queries in the union.\nYou can mix ALL and DISTINCT in the same query. Mixed types are treated such that a set operation\nusing DISTINCT overrides any such operation using ALL to its left. A DISTINCT set can be produced\nexplicitly by using DISTINCT with UNION, INTERSECT, or EXCEPT, or implicitly by using the set\noperations with no following DISTINCT or ALL keyword.\nSet operations work the same way when one or more TABLE statements, VALUES statements, or both,\nare used to generate the set.\nSet Operations with ORDER BY and LIMIT\nTo apply an ORDER BY or LIMIT clause to an individual query block used as part of a union,\nintersection, or other set operation, parenthesize the query block, placing the clause inside the\nparentheses, like this:\n(SELECT a FROM t1 WHERE a=10 AND b=1 ORDER BY a LIMIT 10)\nUNION\n(SELECT a FROM t2 WHERE a=11 AND b=2 ORDER BY a LIMIT 10);\n(TABLE t1 ORDER BY x LIMIT 10) \nINTERSECT \n(TABLE t2 ORDER BY a LIMIT 10);\nUse of ORDER BY for individual query blocks or statements implies nothing about the order in which the\nrows appear in the final result because the rows produced by a set operation are by default unordered.\nTherefore, ORDER BY in this context typically is used in conjunction with LIMIT, to determine the\nsubset of the selected rows to retrieve, even though it does not necessarily affect the order of those\nrows in the final result. If ORDER BY appears without LIMIT within a query block, it is optimized away\nbecause it has no effect in any case.\nTo use an ORDER BY or LIMIT clause to sort or limit the entire result of a set operation, place the\nORDER BY or LIMIT after the last statement:\nSELECT a FROM t1\nEXCEPT\nSELECT a FROM t2 WHERE a=11 AND b=2\nORDER BY a LIMIT 10;\nTABLE t1\nUNION \nTABLE t2\nORDER BY a LIMIT 10;\nIf one or more individual statements make use of ORDER BY, LIMIT, or both, and, in addition, you wish\nto apply an ORDER BY, LIMIT, or both to the entire result, then each such individual statement must\nbe enclosed in parentheses.\n(SELECT a FROM t1 WHERE a=10 AND b=1)\nEXCEPT\n(SELECT a FROM t2 WHERE a=11 AND b=2)\nORDER BY a LIMIT 10;\n(TABLE t1 ORDER BY a LIMIT 10) \nUNION \nTABLE t2 \nORDER BY a LIMIT 10;\nA statement with no ORDER BY or LIMIT clause does need to be parenthesized; replacing TABLE t2\nwith (TABLE t2) in the second statement of the two just shown does not alter the result of the UNION.\nYou can also use ORDER BY and LIMIT with VALUES statements in set operations, as shown in this\nexample using the mysql client:\nmysql> VALUES ROW(4,-2), ROW(5,9), ROW(-1,3) \n    -> UNION \n    -> VALUES ROW(1,2), ROW(3,4), ROW(-1,3) \n    -> ORDER BY column_0 DESC LIMIT 3;\n+----------+----------+\n| column_0 | column_1 |\n+----------+----------+\n|        5 |        9 |\n|        4 |       -2 |\n|        3 |        4 |\n+----------+----------+\n3 rows in set (0.00 sec)\n(You should keep in mind that neither TABLE statements nor VALUES statements accept a WHERE\nclause.)\nThis kind of ORDER BY cannot use column references that include a table name (that is, names in\ntbl_name.col_name format). Instead, provide a column alias in the first query block, and refer to\nthe alias in the ORDER BY clause. (You can also refer to the column in the ORDER BY clause using its\ncolumn position, but such use of column positions is deprecated, and thus subject to eventual removal\nin a future MySQL release.)\nIf a column to be sorted is aliased, the ORDER BY clause must refer to the alias, not the column name.\nThe first of the following statements is permitted, but the second fails with an Unknown column 'a'\nin 'order clause' error:\n(SELECT a AS b FROM t) UNION (SELECT ...) ORDER BY b;\n(SELECT a AS b FROM t) UNION (SELECT ...) ORDER BY a;\nTo cause rows in a UNION result to consist of the sets of rows retrieved by each query block one after\nthe other, select an additional column in each query block to use as a sort column and add an ORDER\nBY clause that sorts on that column following the last query block:\n(SELECT 1 AS sort_col, col1a, col1b, ... FROM t1)\nUNION\n(SELECT 2, col2a, col2b, ... FROM t2) ORDER BY sort_col;\nTo maintain sort order within individual results, add a secondary column to the ORDER BY clause:\n(SELECT 1 AS sort_col, col1a, col1b, ... FROM t1)\nUNION\n(SELECT 2, col2a, col2b, ... FROM t2) ORDER BY sort_col, col1a;\nUse of an additional column also enables you to determine which query block each row comes from.\nExtra columns can provide other identifying information as well, such as a string that indicates a table\nname.\nLimitations of Set Operations\nSet operations in MySQL are subject to some limitations, which are described in the next few\nparagraphs.\nSet operations including SELECT statements have the following limitations:\n• HIGH_PRIORITY in the first SELECT has no effect. HIGH_PRIORITY in any subsequent SELECT\nproduces a syntax error.\n• Only the last SELECT statement can use an INTO clause. However, the entire UNION result is written\nto the INTO output destination.\nThese two UNION variants containing INTO are deprecated; you should expect support for them to be\nremoved in a future version of MySQL:\n• In the trailing query block of a query expression, use of INTO before FROM produces a warning.\nExample:\n... UNION SELECT * INTO OUTFILE 'file_name' FROM table_name;\n• In a parenthesized trailing block of a query expression, use of INTO (regardless of its position\nrelative to FROM) produces a warning. Example:\n... UNION (SELECT * INTO OUTFILE 'file_name' FROM table_name);\nThose variants are deprecated because they are confusing, as if they collect information from the\nnamed table rather than the entire query expression (the UNION).\nSet operations with an aggregate function in an ORDER BY clause are rejected with\nER_AGGREGATE_ORDER_FOR_UNION. Although the error name might suggest that this is exclusive to\nUNION queries, the preceding is also true for EXCEPT and INTERSECT queries, as shown here:\nmysql> TABLE t1 INTERSECT TABLE t2 ORDER BY MAX(x);\nERROR 3028 (HY000): Expression #1 of ORDER BY contains aggregate function and applies to a UNION, EXCEPT or\nA locking clause (such as FOR UPDATE or LOCK IN SHARE MODE) applies to the query block it\nfollows. This means that, in a SELECT statement used with set operations, a locking clause can be\nused only if the query block and locking clause are enclosed in parentheses.",
    "15.2.15 Subqueries": "15.2.15 Subqueries\nA subquery is a SELECT statement within another statement.\nAll subquery forms and operations that the SQL standard requires are supported, as well as a few\nfeatures that are MySQL-specific.\nHere is an example of a subquery:\nSELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);\nIn this example, SELECT * FROM t1 ... is the outer query (or outer statement), and (SELECT\ncolumn1 FROM t2) is the subquery. We say that the subquery is nested within the outer query, and\nin fact it is possible to nest subqueries within other subqueries, to a considerable depth. A subquery\nmust always appear within parentheses.\nThe main advantages of subqueries are:\n• They allow queries that are structured so that it is possible to isolate each part of a statement.\n• They provide alternative ways to perform operations that would otherwise require complex joins and\nunions.\n• Many people find subqueries more readable than complex joins or unions. Indeed, it was the\ninnovation of subqueries that gave people the original idea of calling the early SQL “Structured Query\nLanguage.”\nHere is an example statement that shows the major points about subquery syntax as specified by the\nSQL standard and supported in MySQL:\nDELETE FROM t1\nWHERE s11 > ANY\n (SELECT COUNT(*) /* no hint */ FROM t2\n  WHERE NOT EXISTS\n   (SELECT * FROM t3\n    WHERE ROW(5*t2.s1,77)=\n     (SELECT 50,11*s1 FROM t4 UNION SELECT 50,77 FROM\n      (SELECT * FROM t5) AS t5)));\nA subquery can return a scalar (a single value), a single row, a single column, or a table (one or more\nrows of one or more columns). These are called scalar, column, row, and table subqueries. Subqueries\nthat return a particular kind of result often can be used only in certain contexts, as described in the\nfollowing sections.\nThere are few restrictions on the type of statements in which subqueries can be used. A subquery can\ncontain many of the keywords or clauses that an ordinary SELECT can contain: DISTINCT, GROUP BY,\nORDER BY, LIMIT, joins, index hints, UNION constructs, comments, functions, and so on.\nTABLE and VALUES statements can be used in subqueries. Subqueries using VALUES are generally\nmore verbose versions of subqueries that can be rewritten more compactly using set notation, or with\nSELECT or TABLE syntax; assuming that table ts is created using the statement CREATE TABLE ts\nVALUES ROW(2), ROW(4), ROW(6), the statements shown here are all equivalent:\nSELECT * FROM tt\n    WHERE b > ANY (VALUES ROW(2), ROW(4), ROW(6));\nSELECT * FROM tt\n    WHERE b > ANY (SELECT * FROM ts);\nSELECT * FROM tt\n    WHERE b > ANY (TABLE ts);\nExamples of TABLE subqueries are shown in the sections that follow.\nA subquery's outer statement can be any one of: SELECT, INSERT, UPDATE, DELETE, SET, or DO.\nFor information about how the optimizer handles subqueries, see Section 10.2.2, “Optimizing\nSubqueries, Derived Tables, View References, and Common Table Expressions”. For a discussion of\nrestrictions on subquery use, including performance issues for certain forms of subquery syntax, see\nSection 15.2.15.12, “Restrictions on Subqueries”.\n15.2.15.1 The Subquery as Scalar Operand\nIn its simplest form, a subquery is a scalar subquery that returns a single value. A scalar subquery is a\nsimple operand, and you can use it almost anywhere a single column value or literal is legal, and you\ncan expect it to have those characteristics that all operands have: a data type, a length, an indication\nthat it can be NULL, and so on. For example:\nCREATE TABLE t1 (s1 INT, s2 CHAR(5) NOT NULL);\nINSERT INTO t1 VALUES(100, 'abcde');\nSELECT (SELECT s2 FROM t1);\nThe subquery in this SELECT returns a single value ('abcde') that has a data type of CHAR, a\nlength of 5, a character set and collation equal to the defaults in effect at CREATE TABLE time, and\nan indication that the value in the column can be NULL. Nullability of the value selected by a scalar\nsubquery is not copied because if the subquery result is empty, the result is NULL. For the subquery\njust shown, if t1 were empty, the result would be NULL even though s2 is NOT NULL.\nThere are a few contexts in which a scalar subquery cannot be used. If a statement permits only a\nliteral value, you cannot use a subquery. For example, LIMIT requires literal integer arguments, and\nLOAD DATA requires a literal string file name. You cannot use subqueries to supply these values.\nWhen you see examples in the following sections that contain the rather spartan construct (SELECT\ncolumn1 FROM t1), imagine that your own code contains much more diverse and complex\nconstructions.\nSuppose that we make two tables:\nCREATE TABLE t1 (s1 INT);\nINSERT INTO t1 VALUES (1);\nCREATE TABLE t2 (s1 INT);\nINSERT INTO t2 VALUES (2);\nThen perform a SELECT:\nSELECT (SELECT s1 FROM t2) FROM t1;\nThe result is 2 because there is a row in t2 containing a column s1 that has a value of 2.\nThe preceding query can also be written like this, using TABLE:\nSELECT (TABLE t2) FROM t1;\nA scalar subquery can be part of an expression, but remember the parentheses, even if the subquery is\nan operand that provides an argument for a function. For example:\nSELECT UPPER((SELECT s1 FROM t1)) FROM t2;\nThe same result can be obtained using SELECT UPPER((TABLE t1)) FROM t2.\n15.2.15.2 Comparisons Using Subqueries\nThe most common use of a subquery is in the form:\nnon_subquery_operand comparison_operator (subquery)\nWhere comparison_operator is one of these operators:\n=  >  <  >=  <=  <>  !=  <=>\nFor example:\n... WHERE 'a' = (SELECT column1 FROM t1)\nMySQL also permits this construct:\nnon_subquery_operand LIKE (subquery)\nAt one time the only legal place for a subquery was on the right side of a comparison, and you might\nstill find some old DBMSs that insist on this.\nHere is an example of a common-form subquery comparison that you cannot do with a join. It finds all\nthe rows in table t1 for which the column1 value is equal to a maximum value in table t2:\nSELECT * FROM t1\n  WHERE column1 = (SELECT MAX(column2) FROM t2);\nHere is another example, which again is impossible with a join because it involves aggregating for one\nof the tables. It finds all rows in table t1 containing a value that occurs twice in a given column:\nSELECT * FROM t1 AS t\n  WHERE 2 = (SELECT COUNT(*) FROM t1 WHERE t1.id = t.id);\nFor a comparison of the subquery to a scalar, the subquery must return a scalar. For a comparison of\nthe subquery to a row constructor, the subquery must be a row subquery that returns a row with the\nsame number of values as the row constructor. See Section 15.2.15.5, “Row Subqueries”.\n15.2.15.3 Subqueries with ANY, IN, or SOME\nSyntax:\noperand comparison_operator ANY (subquery)\noperand IN (subquery)\noperand comparison_operator SOME (subquery)\nWhere comparison_operator is one of these operators:\n=  >  <  >=  <=  <>  !=\nThe ANY keyword, which must follow a comparison operator, means “return TRUE if the comparison is\nTRUE for ANY of the values in the column that the subquery returns.” For example:\nSELECT s1 FROM t1 WHERE s1 > ANY (SELECT s1 FROM t2);\nSuppose that there is a row in table t1 containing (10). The expression is TRUE if table t2 contains\n(21,14,7) because there is a value 7 in t2 that is less than 10. The expression is FALSE if table\nt2 contains (20,10), or if table t2 is empty. The expression is unknown (that is, NULL) if table t2\ncontains (NULL,NULL,NULL).\nWhen used with a subquery, the word IN is an alias for = ANY. Thus, these two statements are the\nsame:\nSELECT s1 FROM t1 WHERE s1 = ANY (SELECT s1 FROM t2);\nSELECT s1 FROM t1 WHERE s1 IN    (SELECT s1 FROM t2);\nIN and = ANY are not synonyms when used with an expression list. IN can take an expression list, but\n= ANY cannot. See Section 14.4.2, “Comparison Functions and Operators”.\nNOT IN is not an alias for <> ANY, but for <> ALL. See Section 15.2.15.4, “Subqueries with ALL”.\nThe word SOME is an alias for ANY. Thus, these two statements are the same:\nSELECT s1 FROM t1 WHERE s1 <> ANY  (SELECT s1 FROM t2);\nSELECT s1 FROM t1 WHERE s1 <> SOME (SELECT s1 FROM t2);\nUse of the word SOME is rare, but this example shows why it might be useful. To most people, the\nEnglish phrase “a is not equal to any b” means “there is no b which is equal to a,” but that is not what is\nmeant by the SQL syntax. The syntax means “there is some b to which a is not equal.” Using <> SOME\ninstead helps ensure that everyone understands the true meaning of the query.\nYou can use TABLE in a scalar IN, ANY, or SOME subquery provided the table contains only a single\ncolumn. If t2 has only one column, the statements shown previously in this section can be written as\nshown here, in each case substituting TABLE t2 for SELECT s1 FROM t2:\nSELECT s1 FROM t1 WHERE s1 > ANY (TABLE t2);\nSELECT s1 FROM t1 WHERE s1 = ANY (TABLE t2);\nSELECT s1 FROM t1 WHERE s1 IN (TABLE t2);\nSELECT s1 FROM t1 WHERE s1 <> ANY  (TABLE t2);\nSELECT s1 FROM t1 WHERE s1 <> SOME (TABLE t2);\n15.2.15.4 Subqueries with ALL\nSyntax:\noperand comparison_operator ALL (subquery)\nThe word ALL, which must follow a comparison operator, means “return TRUE if the comparison is\nTRUE for ALL of the values in the column that the subquery returns.” For example:\nSELECT s1 FROM t1 WHERE s1 > ALL (SELECT s1 FROM t2);\nSuppose that there is a row in table t1 containing (10). The expression is TRUE if table t2 contains\n(-5,0,+5) because 10 is greater than all three values in t2. The expression is FALSE if table t2\ncontains (12,6,NULL,-100) because there is a single value 12 in table t2 that is greater than 10.\nThe expression is unknown (that is, NULL) if table t2 contains (0,NULL,1).\nFinally, the expression is TRUE if table t2 is empty. So, the following expression is TRUE when table t2\nis empty:\nSELECT * FROM t1 WHERE 1 > ALL (SELECT s1 FROM t2);\nBut this expression is NULL when table t2 is empty:\nSELECT * FROM t1 WHERE 1 > (SELECT s1 FROM t2);\nIn addition, the following expression is NULL when table t2 is empty:\nSELECT * FROM t1 WHERE 1 > ALL (SELECT MAX(s1) FROM t2);\nIn general, tables containing NULL values and empty tables are “edge cases.” When writing\nsubqueries, always consider whether you have taken those two possibilities into account.\nNOT IN is an alias for <> ALL. Thus, these two statements are the same:\nSELECT s1 FROM t1 WHERE s1 <> ALL (SELECT s1 FROM t2);\nSELECT s1 FROM t1 WHERE s1 NOT IN (SELECT s1 FROM t2);\nAs with IN, ANY, and SOME, you can use TABLE with ALL and NOT IN provided that the following two\nconditions are met:\n• The table in the subquery contains only one column\n• The subquery does not depend on a column expression\nFor example, assuming that table t2 consists of a single column, the last two statements shown\npreviously can be written using TABLE t2 like this:\nSELECT s1 FROM t1 WHERE s1 <> ALL (TABLE t2);\nSELECT s1 FROM t1 WHERE s1 NOT IN (TABLE t2);\nA query such as SELECT * FROM t1 WHERE 1 > ALL (SELECT MAX(s1) FROM t2); cannot be\nwritten using TABLE t2 because the subquery depends on a column expression.\n15.2.15.5 Row Subqueries\nScalar or column subqueries return a single value or a column of values. A row subquery is a subquery\nvariant that returns a single row and can thus return more than one column value. Legal operators for\nrow subquery comparisons are:\n=  >  <  >=  <=  <>  !=  <=>\nHere are two examples:\nSELECT * FROM t1\n  WHERE (col1,col2) = (SELECT col3, col4 FROM t2 WHERE id = 10);\nSELECT * FROM t1\n  WHERE ROW(col1,col2) = (SELECT col3, col4 FROM t2 WHERE id = 10);\nFor both queries, if the table t2 contains a single row with id = 10, the subquery returns a single\nrow. If this row has col3 and col4 values equal to the col1 and col2 values of any rows in t1, the\nWHERE expression is TRUE and each query returns those t1 rows. If the t2 row col3 and col4 values\nare not equal the col1 and col2 values of any t1 row, the expression is FALSE and the query returns\nan empty result set. The expression is unknown (that is, NULL) if the subquery produces no rows. An\nerror occurs if the subquery produces multiple rows because a row subquery can return at most one\nrow.\nFor information about how each operator works for row comparisons, see Section 14.4.2, “Comparison\nFunctions and Operators”.\nThe expressions (1,2) and ROW(1,2) are sometimes called row constructors. The two are\nequivalent. The row constructor and the row returned by the subquery must contain the same number\nof values.\nA row constructor is used for comparisons with subqueries that return two or more columns. When\na subquery returns a single column, this is regarded as a scalar value and not as a row, so a row\nconstructor cannot be used with a subquery that does not return at least two columns. Thus, the\nfollowing query fails with a syntax error:\nSELECT * FROM t1 WHERE ROW(1) = (SELECT column1 FROM t2)\nRow constructors are legal in other contexts. For example, the following two statements are\nsemantically equivalent (and are handled in the same way by the optimizer):\nSELECT * FROM t1 WHERE (column1,column2) = (1,1);\nSELECT * FROM t1 WHERE column1 = 1 AND column2 = 1;\nThe following query answers the request, “find all rows in table t1 that also exist in table t2”:\nSELECT column1,column2,column3\n  FROM t1\n  WHERE (column1,column2,column3) IN\n         (SELECT column1,column2,column3 FROM t2);\nFor more information about the optimizer and row constructors, see Section 10.2.1.22, “Row\nConstructor Expression Optimization”\n15.2.15.6 Subqueries with EXISTS or NOT EXISTS\nIf a subquery returns any rows at all, EXISTS subquery is TRUE, and NOT EXISTS subquery is\nFALSE. For example:\nSELECT column1 FROM t1 WHERE EXISTS (SELECT * FROM t2);\nTraditionally, an EXISTS subquery starts with SELECT *, but it could begin with SELECT 5 or SELECT\ncolumn1 or anything at all. MySQL ignores the SELECT list in such a subquery, so it makes no\ndifference.\nFor the preceding example, if t2 contains any rows, even rows with nothing but NULL values, the\nEXISTS condition is TRUE. This is actually an unlikely example because a [NOT] EXISTS subquery\nalmost always contains correlations. Here are some more realistic examples:\n• What kind of store is present in one or more cities?\nSELECT DISTINCT store_type FROM stores\n  WHERE EXISTS (SELECT * FROM cities_stores\n                WHERE cities_stores.store_type = stores.store_type);\n• What kind of store is present in no cities?\nSELECT DISTINCT store_type FROM stores\n  WHERE NOT EXISTS (SELECT * FROM cities_stores\n                    WHERE cities_stores.store_type = stores.store_type);\n• What kind of store is present in all cities?\nSELECT DISTINCT store_type FROM stores\n  WHERE NOT EXISTS (\n    SELECT * FROM cities WHERE NOT EXISTS (\n      SELECT * FROM cities_stores\n       WHERE cities_stores.city = cities.city\n       AND cities_stores.store_type = stores.store_type));\nThe last example is a double-nested NOT EXISTS query. That is, it has a NOT EXISTS clause within\na NOT EXISTS clause. Formally, it answers the question “does a city exist with a store that is not in\nStores”? But it is easier to say that a nested NOT EXISTS answers the question “is x TRUE for all y?”\nYou can also use NOT EXISTS or NOT EXISTS with TABLE in the subquery, like this:\nSELECT column1 FROM t1 WHERE EXISTS (TABLE t2);\nThe results are the same as when using SELECT * with no WHERE clause in the subquery.\n15.2.15.7 Correlated Subqueries\nA correlated subquery is a subquery that contains a reference to a table that also appears in the outer\nquery. For example:\nSELECT * FROM t1\n  WHERE column1 = ANY (SELECT column1 FROM t2\n                       WHERE t2.column2 = t1.column2);\nNotice that the subquery contains a reference to a column of t1, even though the subquery's FROM\nclause does not mention a table t1. So, MySQL looks outside the subquery, and finds t1 in the outer\nquery.\nSuppose that table t1 contains a row where column1 = 5 and column2 = 6; meanwhile, table\nt2 contains a row where column1 = 5 and column2 = 7. The simple expression ... WHERE\ncolumn1 = ANY (SELECT column1 FROM t2) would be TRUE, but in this example, the WHERE\nclause within the subquery is FALSE (because (5,6) is not equal to (5,7)), so the expression as a\nwhole is FALSE.\nScoping rule: MySQL evaluates from inside to outside. For example:\nSELECT column1 FROM t1 AS x\n  WHERE x.column1 = (SELECT column1 FROM t2 AS x\n    WHERE x.column1 = (SELECT column1 FROM t3\n      WHERE x.column2 = t3.column1));\nIn this statement, x.column2 must be a column in table t2 because SELECT column1 FROM t2\nAS x ... renames t2. It is not a column in table t1 because SELECT column1 FROM t1 ... is\nan outer query that is farther out.\nThe optimizer can transform a correlated scalar subquery to a derived table when the\nsubquery_to_derived flag of the optimizer_switch variable is enabled. Consider the query\nshown here:\nSELECT * FROM t1 \n    WHERE ( SELECT a FROM t2 \n              WHERE t2.a=t1.a ) > 0;\nTo avoid materializing several times for a given derived table, we can instead materialize—once\n—a derived table which adds a grouping on the join column from the table referenced in the inner\nquery (t2.a) and then an outer join on the lifted predicate (t1.a = derived.a) in order to select\nthe correct group to match up with the outer row. (If the subquery already has an explicit grouping,\nthe extra grouping is added to the end of the grouping list.) The query previously shown can thus be\nrewritten like this:\nSELECT t1.* FROM t1 \n    LEFT OUTER JOIN\n        (SELECT a, COUNT(*) AS ct FROM t2 GROUP BY a) AS derived\n    ON  t1.a = derived.a \n        AND \n        REJECT_IF(\n            (ct > 1),\n            \"ERROR 1242 (21000): Subquery returns more than 1 row\"\n            )\n    WHERE derived.a > 0;\nIn the rewritten query, REJECT_IF() represents an internal function which tests a given condition\n(here, the comparison ct > 1) and raises a given error (in this case, ER_SUBQUERY_NO_1_ROW) if the\ncondition is true. This reflects the cardinality check that the optimizer performs as part of evaluating the\nJOIN or WHERE clause, prior to evaluating any lifted predicate, which is done only if the subquery does\nnot return more than one row.\nThis type of transformation can be performed, provided the following conditions are met:\n• The subquery can be part of a SELECT list, WHERE condition, or HAVING condition, but cannot be\npart of a JOIN condition, and cannot contain an OFFSET clause. The subquery may contain LIMIT\n1 but no other LIMIT clause; it must use a literal 1, and no other value, placeholder (?), or variable.\nIn addition, the subquery cannot contain any set operations such as UNION.\n• The WHERE clause may contain one or more predicates, combined with AND. If the WHERE clause\ncontains an OR clause, it cannot be transformed. At least one of the WHERE clause predicates must\nbe eligible for transformation, and none of them may reject transformation.\n• To be eligible for transformation, a WHERE clause predicate must be an equality predicate in\nwhich each operand should be a simple column reference. No other predicates—including other\ncomparison predicates—are eligible for transformation. The predicate must employ the equality\noperator = for making the comparison; the null-safe <=> operator is not supported in this context.\n• A WHERE clause predicate that contains only inner references is not eligible for transformation,\nsince it can be evaluated before the grouping. A WHERE clause predicate that contains only outer\nreferences is eligible for transformation, even though it can be lifted up to the outer query block. This\nis made possible by adding a cardinality check without grouping in the derived table.\n• To be eligible, a WHERE clause predicate must have one operand that contains only inner references\nand one operand that contains only outer references. If the predicate is not eligible due to this rule,\ntransformation of the query is rejected.\n• A correlated column can be present only in the subquery's WHERE clause (and not in the SELECT list,\na JOIN or ORDER BY clause, a GROUP BY list, or a HAVING clause). Nor can there be any correlated\ncolumn inside a derived table in the subquery's FROM list.\n• A correlated column can not be contained in an aggregate function's list of arguments.\n• A correlated column must be resolved in the query block directly containing the subquery being\nconsidered for transformation.\n• A correlated column cannot be present in a nested scalar subquery in the WHERE clause.\n• The subquery cannot contain any window functions, and must not contain any aggregate function\nwhich aggregates in a query block outer to the subquery. A COUNT() aggregate function, if\ncontained in the SELECT list element of the subquery, must be at the topmost level, and cannot be\npart of an expression.\nSee also Section 15.2.15.8, “Derived Tables”.\n15.2.15.8 Derived Tables\nThis section discusses general characteristics of derived tables. For information about lateral derived\ntables preceded by the LATERAL keyword, see Section 15.2.15.9, “Lateral Derived Tables”.\nA derived table is an expression that generates a table within the scope of a query FROM clause. For\nexample, a subquery in a SELECT statement FROM clause is a derived table:\nSELECT ... FROM (subquery) [AS] tbl_name ...\nThe JSON_TABLE() function generates a table and provides another way to create a derived table:\nSELECT * FROM JSON_TABLE(arg_list) [AS] tbl_name ...\nThe [AS] tbl_name clause is mandatory because every table in a FROM clause must have a name.\nAny columns in the derived table must have unique names. Alternatively, tbl_name may be followed\nby a parenthesized list of names for the derived table columns:\nSELECT ... FROM (subquery) [AS] tbl_name (col_list) ...\nThe number of column names must be the same as the number of table columns.\nFor the sake of illustration, assume that you have this table:\nCREATE TABLE t1 (s1 INT, s2 CHAR(5), s3 FLOAT);\nHere is how to use a subquery in the FROM clause, using the example table:\nINSERT INTO t1 VALUES (1,'1',1.0);\nINSERT INTO t1 VALUES (2,'2',2.0);\nSELECT sb1,sb2,sb3\n  FROM (SELECT s1 AS sb1, s2 AS sb2, s3*2 AS sb3 FROM t1) AS sb\n  WHERE sb1 > 1;\nResult:\n+------+------+------+\n| sb1  | sb2  | sb3  |\n+------+------+------+\n|    2 | 2    |    4 |\n+------+------+------+\nHere is another example: Suppose that you want to know the average of a set of sums for a grouped\ntable. This does not work:\nSELECT AVG(SUM(column1)) FROM t1 GROUP BY column1;\nHowever, this query provides the desired information:\nSELECT AVG(sum_column1)\n  FROM (SELECT SUM(column1) AS sum_column1\n        FROM t1 GROUP BY column1) AS t1;\nNotice that the column name used within the subquery (sum_column1) is recognized in the outer\nquery.\nThe column names for a derived table come from its select list:\nmysql> SELECT * FROM (SELECT 1, 2, 3, 4) AS dt;\n+---+---+---+---+\n| 1 | 2 | 3 | 4 |\n+---+---+---+---+\n| 1 | 2 | 3 | 4 |\n+---+---+---+---+\nTo provide column names explicitly, follow the derived table name with a parenthesized list of column\nnames:\nmysql> SELECT * FROM (SELECT 1, 2, 3, 4) AS dt (a, b, c, d);\n+---+---+---+---+\n| a | b | c | d |\n+---+---+---+---+\n| 1 | 2 | 3 | 4 |\n+---+---+---+---+\nA derived table can return a scalar, column, row, or table.\nDerived tables are subject to these restrictions:\n• A derived table cannot contain references to other tables of the same SELECT (use a LATERAL\nderived table for that; see Section 15.2.15.9, “Lateral Derived Tables”).\nThe optimizer determines information about derived tables in such a way that EXPLAIN does not need\nto materialize them. See Section 10.2.2.4, “Optimizing Derived Tables, View References, and Common\nTable Expressions with Merging or Materialization”.\nIt is possible under certain circumstances that using EXPLAIN SELECT modifies table data. This can\noccur if the outer query accesses any tables and an inner query invokes a stored function that changes\none or more rows of a table. Suppose that there are two tables t1 and t2 in database d1, and a stored\nfunction f1 that modifies t2, created as shown here:\nCREATE DATABASE d1;\nUSE d1;\nCREATE TABLE t1 (c1 INT);\nCREATE TABLE t2 (c1 INT);\nCREATE FUNCTION f1(p1 INT) RETURNS INT\n  BEGIN\n    INSERT INTO t2 VALUES (p1);\n    RETURN p1;\n  END;\nReferencing the function directly in an EXPLAIN SELECT has no effect on t2, as shown here:\nmysql> SELECT * FROM t2;\nEmpty set (0.02 sec)\nmysql> EXPLAIN SELECT f1(5)\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: NULL\n   partitions: NULL\n         type: NULL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: NULL\n     filtered: NULL\n        Extra: No tables used\n1 row in set (0.01 sec)\nmysql> SELECT * FROM t2;\nEmpty set (0.01 sec)\nThis is because the SELECT statement did not reference any tables, as can be seen in the table and\nExtra columns of the output. This is also true of the following nested SELECT:\nmysql> EXPLAIN SELECT NOW() AS a1, (SELECT f1(5)) AS a2\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: PRIMARY\n        table: NULL\n         type: NULL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: NULL\n     filtered: NULL\n        Extra: No tables used\n1 row in set, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS;\n+-------+------+------------------------------------------+\n| Level | Code | Message                                  |\n+-------+------+------------------------------------------+\n| Note  | 1249 | Select 2 was reduced during optimization |\n+-------+------+------------------------------------------+\n1 row in set (0.00 sec)\nmysql> SELECT * FROM t2;\nEmpty set (0.00 sec)\nHowever, if the outer SELECT references any tables, the optimizer executes the statement in the\nsubquery as well, with the result that t2 is modified:\nmysql> EXPLAIN SELECT * FROM t1 AS a1, (SELECT f1(5)) AS a2\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: PRIMARY\n        table: <derived2>\n   partitions: NULL\n         type: system\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: 1\n     filtered: 100.00\n        Extra: NULL\n*************************** 2. row ***************************\n           id: 1\n  select_type: PRIMARY\n        table: a1\n   partitions: NULL\n         type: ALL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: 1\n     filtered: 100.00\n        Extra: NULL\n*************************** 3. row ***************************\n           id: 2\n  select_type: DERIVED\n        table: NULL\n   partitions: NULL\n         type: NULL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: NULL\n     filtered: NULL\n        Extra: No tables used\n3 rows in set (0.00 sec)\nmysql> SELECT * FROM t2;\n+------+\n| c1   |\n+------+\n|    5 |\n+------+\n1 row in set (0.00 sec)\nThe derived table optimization can also be employed with many correlated (scalar) subqueries. For\nmore information and examples, see Section 15.2.15.7, “Correlated Subqueries”.\n15.2.15.9 Lateral Derived Tables\nA derived table cannot normally refer to (depend on) columns of preceding tables in the same FROM\nclause. A derived table may be defined as a lateral derived table to specify that such references are\npermitted.\nNonlateral derived tables are specified using the syntax discussed in Section 15.2.15.8, “Derived\nTables”. The syntax for a lateral derived table is the same as for a nonlateral derived table except that\nthe keyword LATERAL is specified before the derived table specification. The LATERAL keyword must\nprecede each table to be used as a lateral derived table.\nLateral derived tables are subject to these restrictions:\n• A lateral derived table can occur only in a FROM clause, either in a list of tables separated with\ncommas or in a join specification (JOIN, INNER JOIN, CROSS JOIN, LEFT [OUTER] JOIN, or\nRIGHT [OUTER] JOIN).\n• If a lateral derived table is in the right operand of a join clause and contains a reference to the left\noperand, the join operation must be an INNER JOIN, CROSS JOIN, or LEFT [OUTER] JOIN.\nIf the table is in the left operand and contains a reference to the right operand, the join operation\nmust be an INNER JOIN, CROSS JOIN, or RIGHT [OUTER] JOIN.\n• If a lateral derived table references an aggregate function, the function's aggregation query cannot\nbe the one that owns the FROM clause in which the lateral derived table occurs.\n• In accordance with the SQL standard, MySQL always treats a join with a table function such as\nJSON_TABLE() as though LATERAL had been used. Since the LATERAL keyword is implicit, it is not\nallowed before JSON_TABLE(); this is also according to the SQL standard.\nThe following discussion shows how lateral derived tables make possible certain SQL operations that\ncannot be done with nonlateral derived tables or that require less-efficient workarounds.\nSuppose that we want to solve this problem: Given a table of people in a sales force (where each row\ndescribes a member of the sales force), and a table of all sales (where each row describes a sale:\nsalesperson, customer, amount, date), determine the size and customer of the largest sale for each\nsalesperson. This problem can be approached two ways.\nFirst approach to solving the problem: For each salesperson, calculate the maximum sale size, and\nalso find the customer who provided this maximum. In MySQL, that can be done like this:\nSELECT\n  salesperson.name,\n  -- find maximum sale size for this salesperson\n  (SELECT MAX(amount) AS amount\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id)\n  AS amount,\n  -- find customer for this maximum size\n  (SELECT customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    AND all_sales.amount =\n         -- find maximum size, again\n         (SELECT MAX(amount) AS amount\n           FROM all_sales\n           WHERE all_sales.salesperson_id = salesperson.id))\n  AS customer_name\nFROM\n  salesperson;\nThat query is inefficient because it calculates the maximum size twice per salesperson (once in the first\nsubquery and once in the second).\nWe can try to achieve an efficiency gain by calculating the maximum once per salesperson and\n“caching” it in a derived table, as shown by this modified query:\nSELECT\n  salesperson.name,\n  max_sale.amount,\n  max_sale_customer.customer_name\nFROM\n  salesperson,\n  -- calculate maximum size, cache it in transient derived table max_sale\n  (SELECT MAX(amount) AS amount\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id)\n  AS max_sale,\n  -- find customer, reusing cached maximum size\n  (SELECT customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    AND all_sales.amount =\n        -- the cached maximum size\n        max_sale.amount)\n  AS max_sale_customer;\nHowever, the query is illegal in SQL-92 because derived tables cannot depend on other tables in the\nsame FROM clause. Derived tables must be constant over the query's duration, not contain references\nto columns of other FROM clause tables. As written, the query produces this error:\nERROR 1054 (42S22): Unknown column 'salesperson.id' in 'where clause'\nIn SQL:1999, the query becomes legal if the derived tables are preceded by the LATERAL keyword\n(which means “this derived table depends on previous tables on its left side”):\nSELECT\n  salesperson.name,\n  max_sale.amount,\n  max_sale_customer.customer_name\nFROM\n  salesperson,\n  -- calculate maximum size, cache it in transient derived table max_sale\n  LATERAL\n  (SELECT MAX(amount) AS amount\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id)\n  AS max_sale,\n  -- find customer, reusing cached maximum size\n  LATERAL\n  (SELECT customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    AND all_sales.amount =\n        -- the cached maximum size\n        max_sale.amount)\n  AS max_sale_customer;\nA lateral derived table need not be constant and is brought up to date each time a new row from a\npreceding table on which it depends is processed by the top query.\nSecond approach to solving the problem: A different solution could be used if a subquery in the\nSELECT list could return multiple columns:\nSELECT\n  salesperson.name,\n  -- find maximum size and customer at same time\n  (SELECT amount, customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    ORDER BY amount DESC LIMIT 1)\nFROM\n  salesperson;\nThat is efficient but illegal. It does not work because such subqueries can return only a single column:\nERROR 1241 (21000): Operand should contain 1 column(s)\nOne attempt at rewriting the query is to select multiple columns from a derived table:\nSELECT\n  salesperson.name,\n  max_sale.amount,\n  max_sale.customer_name\nFROM\n  salesperson,\n  -- find maximum size and customer at same time\n  (SELECT amount, customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    ORDER BY amount DESC LIMIT 1)\n  AS max_sale;\nHowever, that also does not work. The derived table is dependent on the salesperson table and thus\nfails without LATERAL:\nERROR 1054 (42S22): Unknown column 'salesperson.id' in 'where clause'\nAdding the LATERAL keyword makes the query legal:\nSELECT\n  salesperson.name,\n  max_sale.amount,\n  max_sale.customer_name\nFROM\n  salesperson,\n  -- find maximum size and customer at same time\n  LATERAL\n  (SELECT amount, customer_name\n    FROM all_sales\n    WHERE all_sales.salesperson_id = salesperson.id\n    ORDER BY amount DESC LIMIT 1)\n  AS max_sale;\nIn short, LATERAL is the efficient solution to all drawbacks in the two approaches just discussed.\n15.2.15.10 Subquery Errors\nThere are some errors that apply only to subqueries. This section describes them.\n• Unsupported subquery syntax:\nERROR 1235 (ER_NOT_SUPPORTED_YET)\nSQLSTATE = 42000\nMessage = \"This version of MySQL doesn't yet support\n'LIMIT & IN/ALL/ANY/SOME subquery'\"\nThis means that MySQL does not support statements like the following:\nSELECT * FROM t1 WHERE s1 IN (SELECT s2 FROM t2 ORDER BY s1 LIMIT 1)\n• Incorrect number of columns from subquery:\nERROR 1241 (ER_OPERAND_COL)\nSQLSTATE = 21000\nMessage = \"Operand should contain 1 column(s)\"\nThis error occurs in cases like this:\nSELECT (SELECT column1, column2 FROM t2) FROM t1;\nYou may use a subquery that returns multiple columns, if the purpose is row comparison. In other\ncontexts, the subquery must be a scalar operand. See Section 15.2.15.5, “Row Subqueries”.\n• Incorrect number of rows from subquery:\nERROR 1242 (ER_SUBSELECT_NO_1_ROW)\nSQLSTATE = 21000\nMessage = \"Subquery returns more than 1 row\"\nThis error occurs for statements where the subquery must return at most one row but returns multiple\nrows. Consider the following example:\nSELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);\nIf SELECT column1 FROM t2 returns just one row, the previous query works. If the subquery\nreturns more than one row, error 1242 occurs. In that case, the query should be rewritten as:\nSELECT * FROM t1 WHERE column1 = ANY (SELECT column1 FROM t2);\n• Incorrectly used table in subquery:\nError 1093 (ER_UPDATE_TABLE_USED)\nSQLSTATE = HY000\nMessage = \"You can't specify target table 'x'\nfor update in FROM clause\"\nThis error occurs in cases such as the following, which attempts to modify a table and select from the\nsame table in the subquery:\nUPDATE t1 SET column2 = (SELECT MAX(column1) FROM t1);\nYou can use a common table expression or derived table to work around this. See\nSection 15.2.15.12, “Restrictions on Subqueries”.\nAll of the errors described in this section also apply when using TABLE in subqueries.\nFor transactional storage engines, the failure of a subquery causes the entire statement to fail. For\nnontransactional storage engines, data modifications made before the error was encountered are\npreserved.\n15.2.15.11 Optimizing Subqueries\nDevelopment is ongoing, so no optimization tip is reliable for the long term. The following list provides\nsome interesting tricks that you might want to play with. See also Section 10.2.2, “Optimizing\nSubqueries, Derived Tables, View References, and Common Table Expressions”.\n• Move clauses from outside to inside the subquery. For example, use this query:\nSELECT * FROM t1\n  WHERE s1 IN (SELECT s1 FROM t1 UNION ALL SELECT s1 FROM t2);\nInstead of this query:\nSELECT * FROM t1\n  WHERE s1 IN (SELECT s1 FROM t1) OR s1 IN (SELECT s1 FROM t2);\nFor another example, use this query:\nSELECT (SELECT column1 + 5 FROM t1) FROM t2;\nInstead of this query:\nSELECT (SELECT column1 FROM t1) + 5 FROM t2;\n15.2.15.12 Restrictions on Subqueries\n• In general, you cannot modify a table and select from the same table in a subquery. For example,\nthis limitation applies to statements of the following forms:\nDELETE FROM t WHERE ... (SELECT ... FROM t ...);\nUPDATE t ... WHERE col = (SELECT ... FROM t ...);\n{INSERT|REPLACE} INTO t (SELECT ... FROM t ...);\nException: The preceding prohibition does not apply if for the modified table you are using a\nderived table and that derived table is materialized rather than merged into the outer query. (See\nSection 10.2.2.4, “Optimizing Derived Tables, View References, and Common Table Expressions\nwith Merging or Materialization”.) Example:\nUPDATE t ... WHERE col = (SELECT * FROM (SELECT ... FROM t...) AS dt ...);\nHere the result from the derived table is materialized as a temporary table, so the relevant rows in t\nhave already been selected by the time the update to t takes place.\nIn general, you may be able to influence the optimizer to materialize a derived table by adding a\nNO_MERGE optimizer hint. See Section 10.9.3, “Optimizer Hints”.\n• Row comparison operations are only partially supported:\n• For expr [NOT] IN subquery, expr can be an n-tuple (specified using row constructor\nsyntax) and the subquery can return rows of n-tuples. The permitted syntax is therefore more\nspecifically expressed as row_constructor [NOT] IN table_subquery\n• For expr op {ALL|ANY|SOME} subquery, expr must be a scalar value and the subquery\nmust be a column subquery; it cannot return multiple-column rows.\nIn other words, for a subquery that returns rows of n-tuples, this is supported:\n(expr_1, ..., expr_n) [NOT] IN table_subquery\nBut this is not supported:\n(expr_1, ..., expr_n) op {ALL|ANY|SOME} subquery\nThe reason for supporting row comparisons for IN but not for the others is that IN is implemented by\nrewriting it as a sequence of = comparisons and AND operations. This approach cannot be used for\nALL, ANY, or SOME.\n• MySQL does not support LIMIT in subqueries for certain subquery operators:\nmysql> SELECT * FROM t1\n       WHERE s1 IN (SELECT s2 FROM t2 ORDER BY s1 LIMIT 1);\nERROR 1235 (42000): This version of MySQL doesn't yet support\n 'LIMIT & IN/ALL/ANY/SOME subquery'\nSee Section 15.2.15.10, “Subquery Errors”.\n• MySQL permits a subquery to refer to a stored function that has data-modifying side effects such as\ninserting rows into a table. For example, if f() inserts rows, the following query can modify data:\nSELECT ... WHERE x IN (SELECT f() ...);\nThis behavior is an extension to the SQL standard. In MySQL, it can produce nondeterministic\nresults because f() might be executed a different number of times for different executions of a given\nquery depending on how the optimizer chooses to handle it.\nFor statement-based or mixed-format replication, one implication of this indeterminism is that such a\nquery can produce different results on the source and its replicas.",
    "15.2.16 TABLE Statement": "15.2.16 TABLE Statement\nTABLE is a DML statement which returns rows and columns of the named table.\nTABLE table_name \n    [ORDER BY column_name] \n    [LIMIT number [OFFSET number]]\n    [INTO OUTFILE 'file_name'\n        [{FIELDS | COLUMNS}\n            [TERMINATED BY 'string']\n            [[OPTIONALLY] ENCLOSED BY 'char']\n            [ESCAPED BY 'char']\n        ]\n        [LINES\n            [STARTING BY 'string']\n            [TERMINATED BY 'string']\n        ]\n    | INTO DUMPFILE 'file_name'\n    | INTO var_name [, var_name] ...]\nThe TABLE statement in some ways acts like SELECT. Given the existence of a table named t, the\nfollowing two statements produce identical output:\nTABLE t;\nSELECT * FROM t;\nYou can order and limit the number of rows produced by TABLE using ORDER BY and LIMIT clauses,\nrespectively. These function identically to the same clauses when used with SELECT (including an\noptional OFFSET clause with LIMIT), as you can see here:\nmysql> TABLE t;\n+----+----+\n| a  | b  |\n+----+----+\n|  1 |  2 |\n|  6 |  7 |\n|  9 |  5 |\n| 10 | -4 |\n| 11 | -1 |\n| 13 |  3 |\n| 14 |  6 |\n+----+----+\n7 rows in set (0.00 sec)\nmysql> TABLE t ORDER BY b;\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | -4 |\n| 11 | -1 |\n|  1 |  2 |\n| 13 |  3 |\n|  9 |  5 |\n| 14 |  6 |\n|  6 |  7 |\n+----+----+\n7 rows in set (0.00 sec)\nmysql> TABLE t LIMIT 3;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 2 |\n| 6 | 7 |\n| 9 | 5 |\n+---+---+\n3 rows in set (0.00 sec)\nmysql> TABLE t ORDER BY b LIMIT 3;\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | -4 |\n| 11 | -1 |\n|  1 |  2 |\n+----+----+\n3 rows in set (0.00 sec)\nmysql> TABLE t ORDER BY b LIMIT 3 OFFSET 2;\n+----+----+\n| a  | b  |\n+----+----+\n|  1 |  2 |\n| 13 |  3 |\n|  9 |  5 |\n+----+----+\n3 rows in set (0.00 sec)\nTABLE differs from SELECT in two key respects:\n• TABLE always displays all columns of the table.\nException: The output of TABLE does not include invisible columns. See Section 15.1.20.10,\n“Invisible Columns”.\n• TABLE does not allow for any arbitrary filtering of rows; that is, TABLE does not support any WHERE\nclause.\nFor limiting which table columns are returned, filtering rows beyond what can be accomplished using\nORDER BY and LIMIT, or both, use SELECT.\nTABLE can be used with temporary tables.\nTABLE can also be used in place of SELECT in a number of other constructs, including those listed\nhere:\n• With set operators such as UNION, as shown here:\nmysql> TABLE t1;\n+---+----+\n| a | b  |\n+---+----+\n| 2 | 10 |\n| 5 |  3 |\n| 7 |  8 |\n+---+----+\n3 rows in set (0.00 sec)\nmysql> TABLE t2;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 2 |\n| 3 | 4 |\n| 6 | 7 |\n+---+---+\n3 rows in set (0.00 sec)\nmysql> TABLE t1 UNION TABLE t2;\n+---+----+\n| a | b  |\n+---+----+\n| 2 | 10 |\n| 5 |  3 |\n| 7 |  8 |\n| 1 |  2 |\n| 3 |  4 |\n| 6 |  7 |\n+---+----+\n6 rows in set (0.00 sec)\nThe UNION just shown is equivalent to the following statement:\nmysql> SELECT * FROM t1 UNION SELECT * FROM t2;\n+---+----+\n| a | b  |\n+---+----+\n| 2 | 10 |\n| 5 |  3 |\n| 7 |  8 |\n| 1 |  2 |\n| 3 |  4 |\n| 6 |  7 |\n+---+----+\n6 rows in set (0.00 sec)\nTABLE can also be used together in set operations with SELECT statements, VALUES statements, or\nboth. See Section 15.2.18, “UNION Clause”, Section 15.2.4, “EXCEPT Clause”, and Section 15.2.8,\n“INTERSECT Clause”, for more information and examples. See also Section 15.2.14, “Set\nOperations with UNION, INTERSECT, and EXCEPT”.\n• With INTO to populate user variables, and with INTO OUTFILE or INTO DUMPFILE to write table\ndata to a file. See Section 15.2.13.1, “SELECT ... INTO Statement”, for more specific information and\nexamples.\n• In many cases where you can employ subqueries. Given any table t1 with a column named a, and a\nsecond table t2 having a single column, statements such as the following are possible:\nSELECT * FROM t1 WHERE a IN (TABLE t2);\nAssuming that the single column of table t1 is named x, the preceding is equivalent to each of the\nstatements shown here (and produces exactly the same result in either case):\nSELECT * FROM t1 WHERE a IN (SELECT x FROM t2);\nSELECT * FROM t1 WHERE a IN (SELECT * FROM t2);\nSee Section 15.2.15, “Subqueries”, for more information.\n• With INSERT and REPLACE statements, where you would otherwise use SELECT *. See\nSection 15.2.7.1, “INSERT ... SELECT Statement”, for more information and examples.\n• TABLE can also be used in many cases in place of the SELECT in CREATE TABLE ... SELECT\nor CREATE VIEW ... SELECT. See the descriptions of these statements for more information and\nexamples.",
    "15.2.17 UPDATE Statement": "15.2.17 UPDATE Statement\nUPDATE is a DML statement that modifies rows in a table.\nAn UPDATE statement can start with a WITH clause to define common table expressions accessible\nwithin the UPDATE. See Section 15.2.20, “WITH (Common Table Expressions)”.\nSingle-table syntax:\nUPDATE [LOW_PRIORITY] [IGNORE] table_reference\n    SET assignment_list\n    [WHERE where_condition]\n    [ORDER BY ...]\n    [LIMIT row_count]\nvalue:\n    {expr | DEFAULT}\nassignment:\n    col_name = value\nassignment_list:\n    assignment [, assignment] ...\nMultiple-table syntax:\nUPDATE [LOW_PRIORITY] [IGNORE] table_references\n    SET assignment_list\n    [WHERE where_condition]\nFor the single-table syntax, the UPDATE statement updates columns of existing rows in the named\ntable with new values. The SET clause indicates which columns to modify and the values they should\nbe given. Each value can be given as an expression, or the keyword DEFAULT to set a column\nexplicitly to its default value. The WHERE clause, if given, specifies the conditions that identify which\nrows to update. With no WHERE clause, all rows are updated. If the ORDER BY clause is specified, the\nrows are updated in the order that is specified. The LIMIT clause places a limit on the number of rows\nthat can be updated.\nFor the multiple-table syntax, UPDATE updates rows in each table named in table_references that\nsatisfy the conditions. Each matching row is updated once, even if it matches the conditions multiple\ntimes. For multiple-table syntax, ORDER BY and LIMIT cannot be used.\nFor partitioned tables, both the single-single and multiple-table forms of this statement support the use\nof a PARTITION clause as part of a table reference. This option takes a list of one or more partitions\nor subpartitions (or both). Only the partitions (or subpartitions) listed are checked for matches, and\na row that is not in any of these partitions or subpartitions is not updated, whether it satisfies the\nwhere_condition or not.\nNote\nUnlike the case when using PARTITION with an INSERT or REPLACE\nstatement, an otherwise valid UPDATE ... PARTITION statement is\nconsidered successful even if no rows in the listed partitions (or subpartitions)\nmatch the where_condition.\nFor more information and examples, see Section 26.5, “Partition Selection”.\nwhere_condition is an expression that evaluates to true for each row to be updated. For expression\nsyntax, see Section 11.5, “Expressions”.\ntable_references and where_condition are specified as described in Section 15.2.13,\n“SELECT Statement”.\nYou need the UPDATE privilege only for columns referenced in an UPDATE that are actually updated.\nYou need only the SELECT privilege for any columns that are read but not modified.\nThe UPDATE statement supports the following modifiers:\n• With the LOW_PRIORITY modifier, execution of the UPDATE is delayed until no other clients are\nreading from the table. This affects only storage engines that use only table-level locking (such as\nMyISAM, MEMORY, and MERGE).\n• With the IGNORE modifier, the update statement does not abort even if errors occur during the\nupdate. Rows for which duplicate-key conflicts occur on a unique key value are not updated. Rows\nupdated to values that would cause data conversion errors are updated to the closest valid values\ninstead. For more information, see The Effect of IGNORE on Statement Execution.\nUPDATE IGNORE statements, including those having an ORDER BY clause, are flagged as unsafe\nfor statement-based replication. (This is because the order in which the rows are updated determines\nwhich rows are ignored.) Such statements produce a warning in the error log when using statement-\nbased mode and are written to the binary log using the row-based format when using MIXED mode.\n(Bug #11758262, Bug #50439) See Section 19.2.1.3, “Determination of Safe and Unsafe Statements in\nBinary Logging”, for more information.\nIf you access a column from the table to be updated in an expression, UPDATE uses the current value\nof the column. For example, the following statement sets col1 to one more than its current value:\nUPDATE t1 SET col1 = col1 + 1;\nThe second assignment in the following statement sets col2 to the current (updated) col1 value, not\nthe original col1 value. The result is that col1 and col2 have the same value. This behavior differs\nfrom standard SQL.\nUPDATE t1 SET col1 = col1 + 1, col2 = col1;\nSingle-table UPDATE assignments are generally evaluated from left to right. For multiple-table updates,\nthere is no guarantee that assignments are carried out in any particular order.\nIf you set a column to the value it currently has, MySQL notices this and does not update it.\nIf you update a column that has been declared NOT NULL by setting to NULL, an error occurs if strict\nSQL mode is enabled; otherwise, the column is set to the implicit default value for the column data type\nand the warning count is incremented. The implicit default value is 0 for numeric types, the empty string\n('') for string types, and the “zero” value for date and time types. See Section 13.6, “Data Type Default\nValues”.\nIf a generated column is updated explicitly, the only permitted value is DEFAULT. For information about\ngenerated columns, see Section 15.1.20.8, “CREATE TABLE and Generated Columns”.\nUPDATE returns the number of rows that were actually changed. The mysql_info() C API function\nreturns the number of rows that were matched and updated and the number of warnings that occurred\nduring the UPDATE.\nYou can use LIMIT row_count to restrict the scope of the UPDATE. A LIMIT clause is a rows-\nmatched restriction. The statement stops as soon as it has found row_count rows that satisfy the\nWHERE clause, whether or not they actually were changed.\nIf an UPDATE statement includes an ORDER BY clause, the rows are updated in the order specified\nby the clause. This can be useful in certain situations that might otherwise result in an error. Suppose\nthat a table t contains a column id that has a unique index. The following statement could fail with a\nduplicate-key error, depending on the order in which rows are updated:\nUPDATE t SET id = id + 1;\nFor example, if the table contains 1 and 2 in the id column and 1 is updated to 2 before 2 is updated\nto 3, an error occurs. To avoid this problem, add an ORDER BY clause to cause the rows with larger id\nvalues to be updated before those with smaller values:\nUPDATE t SET id = id + 1 ORDER BY id DESC;\nYou can also perform UPDATE operations covering multiple tables. However, you cannot use ORDER\nBY or LIMIT with a multiple-table UPDATE. The table_references clause lists the tables involved in\nthe join. Its syntax is described in Section 15.2.13.2, “JOIN Clause”. Here is an example:\nUPDATE items,month SET items.price=month.price\nWHERE items.id=month.id;\nThe preceding example shows an inner join that uses the comma operator, but multiple-table UPDATE\nstatements can use any type of join permitted in SELECT statements, such as LEFT JOIN.\nIf you use a multiple-table UPDATE statement involving InnoDB tables for which there are foreign key\nconstraints, the MySQL optimizer might process tables in an order that differs from that of their parent/\nchild relationship. In this case, the statement fails and rolls back. Instead, update a single table and\nrely on the ON UPDATE capabilities that InnoDB provides to cause the other tables to be modified\naccordingly. See Section 15.1.20.5, “FOREIGN KEY Constraints”.\nYou cannot update a table and select directly from the same table in a subquery. You can work around\nthis by using a multi-table update in which one of the tables is derived from the table that you actually\nwish to update, and referring to the derived table using an alias. Suppose you wish to update a table\nnamed items which is defined using the statement shown here:\nCREATE TABLE items (\n    id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    wholesale DECIMAL(6,2) NOT NULL DEFAULT 0.00,\n    retail DECIMAL(6,2) NOT NULL DEFAULT 0.00,\n    quantity BIGINT NOT NULL DEFAULT 0\n);\nTo reduce the retail price of any items for which the markup is 30% or greater and of which you have\nfewer than one hundred in stock, you might try to use an UPDATE statement such as the one following,\nwhich uses a subquery in the WHERE clause. As shown here, this statement does not work:\nmysql> UPDATE items\n     > SET retail = retail * 0.9\n     > WHERE id IN\n     >     (SELECT id FROM items\n     >         WHERE retail / wholesale >= 1.3 AND quantity > 100);\nERROR 1093 (HY000): You can't specify target table 'items' for update in FROM clause\nInstead, you can employ a multi-table update in which the subquery is moved into the list of tables to\nbe updated, using an alias to reference it in the outermost WHERE clause, like this:\nUPDATE items,\n       (SELECT id FROM items\n        WHERE id IN\n            (SELECT id FROM items\n             WHERE retail / wholesale >= 1.3 AND quantity < 100))\n        AS discounted\nSET items.retail = items.retail * 0.9\nWHERE items.id = discounted.id;\nBecause the optimizer tries by default to merge the derived table discounted into the outermost\nquery block, this works only if you force materialization of the derived table. You can do this by setting\nthe derived_merge flag of the optimizer_switch system variable to off before running the\nupdate, or by using the NO_MERGE optimizer hint, as shown here:\nUPDATE /*+ NO_MERGE(discounted) */ items,\n       (SELECT id FROM items\n        WHERE retail / wholesale >= 1.3 AND quantity < 100)\n        AS discounted\n    SET items.retail = items.retail * 0.9\n    WHERE items.id = discounted.id;\nThe advantage of using the optimizer hint in such a case is that it applies only within the query block\nwhere it is used, so that it is not necessary to change the value of optimizer_switch again after\nexecuting the UPDATE.\nAnother possibility is to rewrite the subquery so that it does not use IN or EXISTS, like this:\nUPDATE items,\n       (SELECT id, retail / wholesale AS markup, quantity FROM items)\n       AS discounted\n    SET items.retail = items.retail * 0.9\n    WHERE discounted.markup >= 1.3\n    AND discounted.quantity < 100\n    AND items.id = discounted.id;\nIn this case, the subquery is materialized by default rather than merged, so it is not necessary to\ndisable merging of the derived table.",
    "15.2.18 UNION Clause": "15.2.18 UNION Clause\nquery_expression_body UNION [ALL | DISTINCT] query_block\n    [UNION [ALL | DISTINCT] query_expression_body]\n    [...]\nquery_expression_body:\n    See Section 15.2.14, “Set Operations with UNION, INTERSECT, and EXCEPT”\nUNION combines the result from multiple query blocks into a single result set. This example uses\nSELECT statements:\nmysql> SELECT 1, 2;\n+---+---+\n| 1 | 2 |\n+---+---+\n| 1 | 2 |\n+---+---+\nmysql> SELECT 'a', 'b';\n+---+---+\n| a | b |\n+---+---+\n| a | b |\n+---+---+\nmysql> SELECT 1, 2 UNION SELECT 'a', 'b';\n+---+---+\n| 1 | 2 |\n+---+---+\n| 1 | 2 |\n| a | b |\n+---+---+",
    "15.2.19 VALUES Statement": "15.2.19 VALUES Statement\nVALUES is a DML statement which returns a set of one or more rows as a table. In other words, it is a\ntable value constructor which also functions as a standalone SQL statement.\nVALUES row_constructor_list [ORDER BY column_designator] [LIMIT number]\nrow_constructor_list:\n    ROW(value_list)[, ROW(value_list)][, ...]\nvalue_list:\n    value[, value][, ...]\ncolumn_designator:\n    column_index\nThe VALUES statement consists of the VALUES keyword followed by a list of one or more row\nconstructors, separated by commas. A row constructor consists of the ROW() row constructor clause\nwith a value list of one or more scalar values enclosed in the parentheses. A value can be a literal of\nany MySQL data type or an expression that resolves to a scalar value.\nROW() cannot be empty (but each of the supplied scalar values can be NULL). Each ROW() in the\nsame VALUES statement must have the same number of values in its value list.\nThe DEFAULT keyword is not supported by VALUES and causes a syntax error, except when it is used\nto supply values in an INSERT statement.\nThe output of VALUES is a table:\nmysql> VALUES ROW(1,-2,3), ROW(5,7,9), ROW(4,6,8);\n+----------+----------+----------+\n| column_0 | column_1 | column_2 |\n+----------+----------+----------+\n|        1 |       -2 |        3 |\n|        5 |        7 |        9 |\n|        4 |        6 |        8 |\n+----------+----------+----------+\n3 rows in set (0.00 sec)\nThe columns of the table output from VALUES have the implicitly named columns column_0,\ncolumn_1, column_2, and so on, always beginning with 0. This fact can be used to order the rows\nby column using an optional ORDER BY clause in the same way that this clause works with a SELECT\nstatement, as shown here:\nmysql> VALUES ROW(1,-2,3), ROW(5,7,9), ROW(4,6,8) ORDER BY column_1;\n+----------+----------+----------+\n| column_0 | column_1 | column_2 |\n+----------+----------+----------+\n|        1 |       -2 |        3 |\n|        4 |        6 |        8 |\n|        5 |        7 |        9 |\n+----------+----------+----------+\n3 rows in set (0.00 sec)\nVALUES statement also supports a LIMIT clause for limiting the number of rows in the output.\nThe VALUES statement is permissive regarding data types of column values; you can mix types within\nthe same column, as shown here:\nmysql> VALUES ROW(\"q\", 42, '2019-12-18'),\n    ->     ROW(23, \"abc\", 98.6),\n    ->     ROW(27.0002, \"Mary Smith\", '{\"a\": 10, \"b\": 25}');\n+----------+------------+--------------------+\n| column_0 | column_1   | column_2           |\n+----------+------------+--------------------+\n| q        | 42         | 2019-12-18         |\n| 23       | abc        | 98.6               |\n| 27.0002  | Mary Smith | {\"a\": 10, \"b\": 25} |\n+----------+------------+--------------------+\n3 rows in set (0.00 sec)\nImportant\nVALUES with one or more instances of ROW() acts as a table value constructor;\nalthough it can be used to supply values in an INSERT or REPLACE statement,\ndo not confuse it with the VALUES keyword that is also used for this purpose.\nYou should also not confuse it with the VALUES() function that refers to column\nvalues in INSERT ... ON DUPLICATE KEY UPDATE.\nYou should also bear in mind that ROW() is a row value constructor (see\nSection 15.2.15.5, “Row Subqueries”), whereas VALUES ROW() is a table value\nconstructor; the two cannot be used interchangeably.\nVALUES can be used in many cases where you could employ SELECT, including those listed here:\n• With UNION, as shown here:\nmysql> SELECT 1,2 UNION SELECT 10,15;\n+----+----+\n| 1  | 2  |\n+----+----+\n|  1 |  2 |\n| 10 | 15 |\n+----+----+\n2 rows in set (0.00 sec)\nmysql> VALUES ROW(1,2) UNION VALUES ROW(10,15);\n+----------+----------+\n| column_0 | column_1 |\n+----------+----------+\n|        1 |        2 |\n|       10 |       15 |\n+----------+----------+\n2 rows in set (0.00 sec)\nYou can union together constructed tables having more than one row, like this:\nmysql> VALUES ROW(1,2), ROW(3,4), ROW(5,6)\n     >     UNION VALUES ROW(10,15),ROW(20,25);\n+----------+----------+\n| column_0 | column_1 |\n+----------+----------+\n|        1 |        2 |\n|        3 |        4 |\n|        5 |        6 |\n|       10 |       15 |\n|       20 |       25 |\n+----------+----------+\n5 rows in set (0.00 sec)\nYou can also (and it is usually preferable to) omit UNION altogether in such cases and use a single\nVALUES statement, like this:\nmysql> VALUES ROW(1,2), ROW(3,4), ROW(5,6), ROW(10,15), ROW(20,25);\n+----------+----------+\n| column_0 | column_1 |\n+----------+----------+\n|        1 |        2 |\n|        3 |        4 |\n|        5 |        6 |\n|       10 |       15 |\n|       20 |       25 |\n+----------+----------+\nVALUES can also be used in unions with SELECT statements, TABLE statements, or both.\nThe constructed tables in the UNION must contain the same number of columns, just as if you were\nusing SELECT. See Section 15.2.18, “UNION Clause”, for further examples.\nYou can use EXCEPT and INTERSECT with VALUES in much the same way as UNION, as shown\nhere:\nmysql> VALUES ROW(1,2), ROW(3,4), ROW(5,6)\n    ->   INTERSECT \n    -> VALUES ROW(10,15), ROW(20,25), ROW(3,4);\n+----------+----------+\n| column_0 | column_1 |\n+----------+----------+\n|        3 |        4 |\n+----------+----------+\n1 row in set (0.00 sec)\n \nmysql> VALUES ROW(1,2), ROW(3,4), ROW(5,6)\n    ->   EXCEPT \n    -> VALUES ROW(10,15), ROW(20,25), ROW(3,4);\n+----------+----------+\n| column_0 | column_1 |\n+----------+----------+\n|        1 |        2 |\n|        5 |        6 |\n+----------+----------+\n2 rows in set (0.00 sec)\nSee Section 15.2.4, “EXCEPT Clause”, and Section 15.2.8, “INTERSECT Clause”, for more\ninformation.\n• In joins. See Section 15.2.13.2, “JOIN Clause”, for more information and examples.\n• In place of VALUES() in an INSERT or REPLACE statement, in which case its semantics differ\nslightly from what is described here. See Section 15.2.7, “INSERT Statement”, for details.\n• In place of the source table in CREATE TABLE ... SELECT and CREATE VIEW ... SELECT.\nSee the descriptions of these statements for more information and examples.",
    "15.2.20 WITH (Common Table Expressions)": "15.2.20 WITH (Common Table Expressions)\nA common table expression (CTE) is a named temporary result set that exists within the scope of a\nsingle statement and that can be referred to later within that statement, possibly multiple times. The\nfollowing discussion describes how to write statements that use CTEs.\n• Common Table Expressions\n• Recursive Common Table Expressions\n• Limiting Common Table Expression Recursion\n• Recursive Common Table Expression Examples\n• Common Table Expressions Compared to Similar Constructs\nFor information about CTE optimization, see Section 10.2.2.4, “Optimizing Derived Tables, View\nReferences, and Common Table Expressions with Merging or Materialization”.\nCommon Table Expressions\nTo specify common table expressions, use a WITH clause that has one or more comma-separated\nsubclauses. Each subclause provides a subquery that produces a result set, and associates a name\nwith the subquery. The following example defines CTEs named cte1 and cte2 in the WITH clause,\nand refers to them in the top-level SELECT that follows the WITH clause:\nWITH\n  cte1 AS (SELECT a, b FROM table1),\n  cte2 AS (SELECT c, d FROM table2)\nSELECT b, d FROM cte1 JOIN cte2\nWHERE cte1.a = cte2.c;\nIn the statement containing the WITH clause, each CTE name can be referenced to access the\ncorresponding CTE result set.\nA CTE name can be referenced in other CTEs, enabling CTEs to be defined based on other CTEs.\nA CTE can refer to itself to define a recursive CTE. Common applications of recursive CTEs include\nseries generation and traversal of hierarchical or tree-structured data.\nCommon table expressions are an optional part of the syntax for DML statements. They are defined\nusing a WITH clause:\nwith_clause:\n    WITH [RECURSIVE]\n        cte_name [(col_name [, col_name] ...)] AS (subquery)\n        [, cte_name [(col_name [, col_name] ...)] AS (subquery)] ...\ncte_name names a single common table expression and can be used as a table reference in the\nstatement containing the WITH clause.\nThe subquery part of AS (subquery) is called the “subquery of the CTE” and is what produces the\nCTE result set. The parentheses following AS are required.\nA common table expression is recursive if its subquery refers to its own name. The RECURSIVE\nkeyword must be included if any CTE in the WITH clause is recursive. For more information, see\nRecursive Common Table Expressions.\nDetermination of column names for a given CTE occurs as follows:\n• If a parenthesized list of names follows the CTE name, those names are the column names:\nWITH cte (col1, col2) AS\n(\n  SELECT 1, 2\n  UNION ALL\n  SELECT 3, 4\n)\nSELECT col1, col2 FROM cte;\nThe number of names in the list must be the same as the number of columns in the result set.\n• Otherwise, the column names come from the select list of the first SELECT within the AS\n(subquery) part:\nWITH cte AS\n(\n  SELECT 1 AS col1, 2 AS col2\n  UNION ALL\n  SELECT 3, 4\n)\nSELECT col1, col2 FROM cte;\nA WITH clause is permitted in these contexts:\n• At the beginning of SELECT, UPDATE, and DELETE statements.\nWITH ... SELECT ...\nWITH ... UPDATE ...\nWITH ... DELETE ...\n• At the beginning of subqueries (including derived table subqueries):\nSELECT ... WHERE id IN (WITH ... SELECT ...) ...\nSELECT * FROM (WITH ... SELECT ...) AS dt ...\n• Immediately preceding SELECT for statements that include a SELECT statement:\nINSERT ... WITH ... SELECT ...\nREPLACE ... WITH ... SELECT ...\nCREATE TABLE ... WITH ... SELECT ...\nCREATE VIEW ... WITH ... SELECT ...\nDECLARE CURSOR ... WITH ... SELECT ...\nEXPLAIN ... WITH ... SELECT ...\nOnly one WITH clause is permitted at the same level. WITH followed by WITH at the same level is not\npermitted, so this is illegal:\nWITH cte1 AS (...) WITH cte2 AS (...) SELECT ...\nTo make the statement legal, use a single WITH clause that separates the subclauses by a comma:\nWITH cte1 AS (...), cte2 AS (...) SELECT ...\nHowever, a statement can contain multiple WITH clauses if they occur at different levels:\nWITH cte1 AS (SELECT 1)\nSELECT * FROM (WITH cte2 AS (SELECT 2) SELECT * FROM cte2 JOIN cte1) AS dt;\nA WITH clause can define one or more common table expressions, but each CTE name must be\nunique to the clause. This is illegal:\nWITH cte1 AS (...), cte1 AS (...) SELECT ...\nTo make the statement legal, define the CTEs with unique names:\nWITH cte1 AS (...), cte2 AS (...) SELECT ...\nA CTE can refer to itself or to other CTEs:\n• A self-referencing CTE is recursive.\n• A CTE can refer to CTEs defined earlier in the same WITH clause, but not those defined later.\nThis constraint rules out mutually-recursive CTEs, where cte1 references cte2 and cte2\nreferences cte1. One of those references must be to a CTE defined later, which is not permitted.\n• A CTE in a given query block can refer to CTEs defined in query blocks at a more outer level, but not\nCTEs defined in query blocks at a more inner level.\nFor resolving references to objects with the same names, derived tables hide CTEs; and CTEs hide\nbase tables, TEMPORARY tables, and views. Name resolution occurs by searching for objects in the\nsame query block, then proceeding to outer blocks in turn while no object with the name is found.\nFor additional syntax considerations specific to recursive CTEs, see Recursive Common Table\nExpressions.\nRecursive Common Table Expressions\nA recursive common table expression is one having a subquery that refers to its own name. For\nexample:\nWITH RECURSIVE cte (n) AS\n(\n  SELECT 1\n  UNION ALL\n  SELECT n + 1 FROM cte WHERE n < 5\n)\nSELECT * FROM cte;\nWhen executed, the statement produces this result, a single column containing a simple linear\nsequence:\n+------+\n| n    |\n+------+\n|    1 |\n|    2 |\n|    3 |\n|    4 |\n|    5 |\n+------+\nA recursive CTE has this structure:\n• The WITH clause must begin with WITH RECURSIVE if any CTE in the WITH clause refers to itself. (If\nno CTE refers to itself, RECURSIVE is permitted but not required.)\nIf you forget RECURSIVE for a recursive CTE, this error is a likely result:\nERROR 1146 (42S02): Table 'cte_name' doesn't exist\n• The recursive CTE subquery has two parts, separated by UNION ALL or UNION [DISTINCT]:\nSELECT ...      -- return initial row set\nUNION ALL\nSELECT ...      -- return additional row sets\nThe first SELECT produces the initial row or rows for the CTE and does not refer to the CTE name.\nThe second SELECT produces additional rows and recurses by referring to the CTE name in its FROM\nclause. Recursion ends when this part produces no new rows. Thus, a recursive CTE consists of a\nnonrecursive SELECT part followed by a recursive SELECT part.\nEach SELECT part can itself be a union of multiple SELECT statements.\n• The types of the CTE result columns are inferred from the column types of the nonrecursive SELECT\npart only, and the columns are all nullable. For type determination, the recursive SELECT part is\nignored.\n• If the nonrecursive and recursive parts are separated by UNION DISTINCT, duplicate rows are\neliminated. This is useful for queries that perform transitive closures, to avoid infinite loops.\n• Each iteration of the recursive part operates only on the rows produced by the previous iteration.\nIf the recursive part has multiple query blocks, iterations of each query block are scheduled in\nunspecified order, and each query block operates on rows that have been produced either by its\nprevious iteration or by other query blocks since that previous iteration's end.\nThe recursive CTE subquery shown earlier has this nonrecursive part that retrieves a single row to\nproduce the initial row set:\nSELECT 1\nThe CTE subquery also has this recursive part:\nSELECT n + 1 FROM cte WHERE n < 5\nAt each iteration, that SELECT produces a row with a new value one greater than the value of n from\nthe previous row set. The first iteration operates on the initial row set (1) and produces 1+1=2; the\nsecond iteration operates on the first iteration's row set (2) and produces 2+1=3; and so forth. This\ncontinues until recursion ends, which occurs when n is no longer less than 5.\nIf the recursive part of a CTE produces wider values for a column than the nonrecursive part, it may\nbe necessary to widen the column in the nonrecursive part to avoid data truncation. Consider this\nstatement:\nWITH RECURSIVE cte AS\n(\n  SELECT 1 AS n, 'abc' AS str\n  UNION ALL\n  SELECT n + 1, CONCAT(str, str) FROM cte WHERE n < 3\n)\nSELECT * FROM cte;\nIn nonstrict SQL mode, the statement produces this output:\n+------+------+\n| n    | str  |\n+------+------+\n|    1 | abc  |\n|    2 | abc  |\n|    3 | abc  |\n+------+------+\nThe str column values are all 'abc' because the nonrecursive SELECT determines the column\nwidths. Consequently, the wider str values produced by the recursive SELECT are truncated.\nIn strict SQL mode, the statement produces an error:\nERROR 1406 (22001): Data too long for column 'str' at row 1\nTo address this issue, so that the statement does not produce truncation or errors, use CAST() in the\nnonrecursive SELECT to make the str column wider:\nWITH RECURSIVE cte AS\n(\n  SELECT 1 AS n, CAST('abc' AS CHAR(20)) AS str\n  UNION ALL\n  SELECT n + 1, CONCAT(str, str) FROM cte WHERE n < 3\n)\nSELECT * FROM cte;\nNow the statement produces this result, without truncation:\n+------+--------------+\n| n    | str          |\n+------+--------------+\n|    1 | abc          |\n|    2 | abcabc       |\n|    3 | abcabcabcabc |\n+------+--------------+\nColumns are accessed by name, not position, which means that columns in the recursive part can\naccess columns in the nonrecursive part that have a different position, as this CTE illustrates:\nWITH RECURSIVE cte AS\n(\n  SELECT 1 AS n, 1 AS p, -1 AS q\n  UNION ALL\n  SELECT n + 1, q * 2, p * 2 FROM cte WHERE n < 5\n)\nSELECT * FROM cte;\nBecause p in one row is derived from q in the previous row, and vice versa, the positive and negative\nvalues swap positions in each successive row of the output:\n+------+------+------+\n| n    | p    | q    |\n+------+------+------+\n|    1 |    1 |   -1 |\n|    2 |   -2 |    2 |\n|    3 |    4 |   -4 |\n|    4 |   -8 |    8 |\n|    5 |   16 |  -16 |\n+------+------+------+\nSome syntax constraints apply within recursive CTE subqueries:\n• The recursive SELECT part must not contain these constructs:\n• Aggregate functions such as SUM()\n• Window functions\n• GROUP BY\n• ORDER BY\n• DISTINCT\nThe recursive SELECT part of a recursive CTE can also use a LIMIT clause, along with an optional\nOFFSET clause. The effect on the result set is the same as when using LIMIT in the outermost\nSELECT, but is also more efficient, since using it with the recursive SELECT stops the generation of\nrows as soon as the requested number of them has been produced.\nThe prohibition on DISTINCT applies only to UNION members; UNION DISTINCT is permitted.\n• The recursive SELECT part must reference the CTE only once and only in its FROM clause, not in any\nsubquery. It can reference tables other than the CTE and join them with the CTE. If used in a join like\nthis, the CTE must not be on the right side of a LEFT JOIN.\nThese constraints come from the SQL standard, other than the MySQL-specific exclusions mentioned\npreviously.\nFor recursive CTEs, EXPLAIN output rows for recursive SELECT parts display Recursive in the\nExtra column.\nCost estimates displayed by EXPLAIN represent cost per iteration, which might differ considerably from\ntotal cost. The optimizer cannot predict the number of iterations because it cannot predict at what point\nthe WHERE clause becomes false.\nCTE actual cost may also be affected by result set size. A CTE that produces many rows may require\nan internal temporary table large enough to be converted from in-memory to on-disk format and may\nsuffer a performance penalty. If so, increasing the permitted in-memory temporary table size may\nimprove performance; see Section 10.4.4, “Internal Temporary Table Use in MySQL”.\nLimiting Common Table Expression Recursion\nIt is important for recursive CTEs that the recursive SELECT part include a condition to terminate\nrecursion. As a development technique to guard against a runaway recursive CTE, you can force\ntermination by placing a limit on execution time:\n• The cte_max_recursion_depth system variable enforces a limit on the number of recursion\nlevels for CTEs. The server terminates execution of any CTE that recurses more levels than the\nvalue of this variable.\n• The max_execution_time system variable enforces an execution timeout for SELECT statements\nexecuted within the current session.\n• The MAX_EXECUTION_TIME optimizer hint enforces a per-query execution timeout for the SELECT\nstatement in which it appears.\nSuppose that a recursive CTE is mistakenly written with no recursion execution termination condition:\nWITH RECURSIVE cte (n) AS\n(\n  SELECT 1\n  UNION ALL\n  SELECT n + 1 FROM cte\n)\nSELECT * FROM cte;\nBy default, cte_max_recursion_depth has a value of 1000, causing the CTE to terminate when it\nrecurses past 1000 levels. Applications can change the session value to adjust for their requirements:\nSET SESSION cte_max_recursion_depth = 10;      -- permit only shallow recursion\nSET SESSION cte_max_recursion_depth = 1000000; -- permit deeper recursion\nYou can also set the global cte_max_recursion_depth value to affect all sessions that begin\nsubsequently.\nFor queries that execute and thus recurse slowly or in contexts for which there is reason to set the\ncte_max_recursion_depth value very high, another way to guard against deep recursion is to set a\nper-session timeout. To do so, execute a statement like this prior to executing the CTE statement:\nSET max_execution_time = 1000; -- impose one second timeout\nAlternatively, include an optimizer hint within the CTE statement itself:\nWITH RECURSIVE cte (n) AS\n(\n  SELECT 1\n  UNION ALL\n  SELECT n + 1 FROM cte\n)\nSELECT /*+ SET_VAR(cte_max_recursion_depth = 1M) */ * FROM cte;\nWITH RECURSIVE cte (n) AS\n(\n  SELECT 1\n  UNION ALL\n  SELECT n + 1 FROM cte\n)\nSELECT /*+ MAX_EXECUTION_TIME(1000) */ * FROM cte;\nYou can also use LIMIT within the recursive query to impose a maximum number of rows to be\nreturned to the outermost SELECT, for example:\nWITH RECURSIVE cte (n) AS\n(\n  SELECT 1\n  UNION ALL\n  SELECT n + 1 FROM cte LIMIT 10000\n)\nSELECT * FROM cte;\nYou can do this in addition to or instead of setting a time limit. Thus, the following CTE terminates after\nreturning ten thousand rows or running for one second (1000 milliseconds), whichever occurs first:\nWITH RECURSIVE cte (n) AS\n(\n  SELECT 1\n  UNION ALL\n  SELECT n + 1 FROM cte LIMIT 10000\n)\nSELECT /*+ MAX_EXECUTION_TIME(1000) */ * FROM cte;\nIf a recursive query without an execution time limit enters an infinite loop, you can terminate it from\nanother session using KILL QUERY. Within the session itself, the client program used to run the query\nmight provide a way to kill the query. For example, in mysql, typing Control+C interrupts the current\nstatement.\nRecursive Common Table Expression Examples\nAs mentioned previously, recursive common table expressions (CTEs) are frequently used for series\ngeneration and traversing hierarchical or tree-structured data. This section shows some simple\nexamples of these techniques.\n• Fibonacci Series Generation\n• Date Series Generation\n• Hierarchical Data Traversal\nFibonacci Series Generation\nA Fibonacci series begins with the two numbers 0 and 1 (or 1 and 1) and each number after that is\nthe sum of the previous two numbers. A recursive common table expression can generate a Fibonacci\nseries if each row produced by the recursive SELECT has access to the two previous numbers from the\nseries. The following CTE generates a 10-number series using 0 and 1 as the first two numbers:\nWITH RECURSIVE fibonacci (n, fib_n, next_fib_n) AS\n(\n  SELECT 1, 0, 1\n  UNION ALL\n  SELECT n + 1, next_fib_n, fib_n + next_fib_n\n    FROM fibonacci WHERE n < 10\n)\nSELECT * FROM fibonacci;\nThe CTE produces this result:\n+------+-------+------------+\n| n    | fib_n | next_fib_n |\n+------+-------+------------+\n|    1 |     0 |          1 |\n|    2 |     1 |          1 |\n|    3 |     1 |          2 |\n|    4 |     2 |          3 |\n|    5 |     3 |          5 |\n|    6 |     5 |          8 |\n|    7 |     8 |         13 |\n|    8 |    13 |         21 |\n|    9 |    21 |         34 |\n|   10 |    34 |         55 |\n+------+-------+------------+\nHow the CTE works:\n• n is a display column to indicate that the row contains the n-th Fibonacci number. For example, the\n8th Fibonacci number is 13.\n• The fib_n column displays Fibonacci number n.\n• The next_fib_n column displays the next Fibonacci number after number n. This column provides\nthe next series value to the next row, so that row can produce the sum of the two previous series\nvalues in its fib_n column.\n• Recursion ends when n reaches 10. This is an arbitrary choice, to limit the output to a small set of\nrows.\nThe preceding output shows the entire CTE result. To select just part of it, add an appropriate WHERE\nclause to the top-level SELECT. For example, to select the 8th Fibonacci number, do this:\nmysql> WITH RECURSIVE fibonacci ...\n       ...\n       SELECT fib_n FROM fibonacci WHERE n = 8;\n+-------+\n| fib_n |\n+-------+\n|    13 |\n+-------+\nDate Series Generation\nA common table expression can generate a series of successive dates, which is useful for generating\nsummaries that include a row for all dates in the series, including dates not represented in the\nsummarized data.\nSuppose that a table of sales numbers contains these rows:\nmysql> SELECT * FROM sales ORDER BY date, price;\n+------------+--------+\n| date       | price  |\n+------------+--------+\n| 2017-01-03 | 100.00 |\n| 2017-01-03 | 200.00 |\n| 2017-01-06 |  50.00 |\n| 2017-01-08 |  10.00 |\n| 2017-01-08 |  20.00 |\n| 2017-01-08 | 150.00 |\n| 2017-01-10 |   5.00 |\n+------------+--------+\nThis query summarizes the sales per day:\nmysql> SELECT date, SUM(price) AS sum_price\n       FROM sales\n       GROUP BY date\n       ORDER BY date;\n+------------+-----------+\n| date       | sum_price |\n+------------+-----------+\n| 2017-01-03 |    300.00 |\n| 2017-01-06 |     50.00 |\n| 2017-01-08 |    180.00 |\n| 2017-01-10 |      5.00 |\n+------------+-----------+\nHowever, that result contains “holes” for dates not represented in the range of dates spanned by\nthe table. A result that represents all dates in the range can be produced using a recursive CTE to\ngenerate that set of dates, joined with a LEFT JOIN to the sales data.\nHere is the CTE to generate the date range series:\nWITH RECURSIVE dates (date) AS\n(\n  SELECT MIN(date) FROM sales\n  UNION ALL\n  SELECT date + INTERVAL 1 DAY FROM dates\n  WHERE date + INTERVAL 1 DAY <= (SELECT MAX(date) FROM sales)\n)\nSELECT * FROM dates;\nThe CTE produces this result:\n+------------+\n| date       |\n+------------+\n| 2017-01-03 |\n| 2017-01-04 |\n| 2017-01-05 |\n| 2017-01-06 |\n| 2017-01-07 |\n| 2017-01-08 |\n| 2017-01-09 |\n| 2017-01-10 |\n+------------+\nHow the CTE works:\n• The nonrecursive SELECT produces the lowest date in the date range spanned by the sales table.\n• Each row produced by the recursive SELECT adds one day to the date produced by the previous\nrow.\n• Recursion ends after the dates reach the highest date in the date range spanned by the sales table.\nJoining the CTE with a LEFT JOIN against the sales table produces the sales summary with a row\nfor each date in the range:\nWITH RECURSIVE dates (date) AS\n(\n  SELECT MIN(date) FROM sales\n  UNION ALL\n  SELECT date + INTERVAL 1 DAY FROM dates\n  WHERE date + INTERVAL 1 DAY <= (SELECT MAX(date) FROM sales)\n)\nSELECT dates.date, COALESCE(SUM(price), 0) AS sum_price\nFROM dates LEFT JOIN sales ON dates.date = sales.date\nGROUP BY dates.date\nORDER BY dates.date;\nThe output looks like this:\n+------------+-----------+\n| date       | sum_price |\n+------------+-----------+\n| 2017-01-03 |    300.00 |\n| 2017-01-04 |      0.00 |\n| 2017-01-05 |      0.00 |\n| 2017-01-06 |     50.00 |\n| 2017-01-07 |      0.00 |\n| 2017-01-08 |    180.00 |\n| 2017-01-09 |      0.00 |\n| 2017-01-10 |      5.00 |\n+------------+-----------+\nSome points to note:\n• Are the queries inefficient, particularly the one with the MAX() subquery executed for each row in the\nrecursive SELECT? EXPLAIN shows that the subquery containing MAX() is evaluated only once and\nthe result is cached.\n• The use of COALESCE() avoids displaying NULL in the sum_price column on days for which no\nsales data occur in the sales table.\nHierarchical Data Traversal\nRecursive common table expressions are useful for traversing data that forms a hierarchy. Consider\nthese statements that create a small data set that shows, for each employee in a company, the\nemployee name and ID number, and the ID of the employee's manager. The top-level employee (the\nCEO), has a manager ID of NULL (no manager).\nCREATE TABLE employees (\n  id         INT PRIMARY KEY NOT NULL,\n  name       VARCHAR(100) NOT NULL,\n  manager_id INT NULL,\n  INDEX (manager_id),\nFOREIGN KEY (manager_id) REFERENCES employees (id)\n);\nINSERT INTO employees VALUES\n(333, \"Yasmina\", NULL),  # Yasmina is the CEO (manager_id is NULL)\n(198, \"John\", 333),      # John has ID 198 and reports to 333 (Yasmina)\n(692, \"Tarek\", 333),\n(29, \"Pedro\", 198),\n(4610, \"Sarah\", 29),\n(72, \"Pierre\", 29),\n(123, \"Adil\", 692);\nThe resulting data set looks like this:\nmysql> SELECT * FROM employees ORDER BY id;\n+------+---------+------------+\n| id   | name    | manager_id |\n+------+---------+------------+\n|   29 | Pedro   |        198 |\n|   72 | Pierre  |         29 |\n|  123 | Adil    |        692 |\n|  198 | John    |        333 |\n|  333 | Yasmina |       NULL |\n|  692 | Tarek   |        333 |\n| 4610 | Sarah   |         29 |\n+------+---------+------------+\nTo produce the organizational chart with the management chain for each employee (that is, the path\nfrom CEO to employee), use a recursive CTE:\nWITH RECURSIVE employee_paths (id, name, path) AS\n(\n  SELECT id, name, CAST(id AS CHAR(200))\n    FROM employees\n    WHERE manager_id IS NULL\n  UNION ALL\n  SELECT e.id, e.name, CONCAT(ep.path, ',', e.id)\n    FROM employee_paths AS ep JOIN employees AS e\n      ON ep.id = e.manager_id\n)\nSELECT * FROM employee_paths ORDER BY path;\nThe CTE produces this output:\n+------+---------+-----------------+\n| id   | name    | path            |\n+------+---------+-----------------+\n|  333 | Yasmina | 333             |\n|  198 | John    | 333,198         |\n|   29 | Pedro   | 333,198,29      |\n| 4610 | Sarah   | 333,198,29,4610 |\n|   72 | Pierre  | 333,198,29,72   |\n|  692 | Tarek   | 333,692         |\n|  123 | Adil    | 333,692,123     |\n+------+---------+-----------------+\nHow the CTE works:\n• The nonrecursive SELECT produces the row for the CEO (the row with a NULL manager ID).\nThe path column is widened to CHAR(200) to ensure that there is room for the longer path values\nproduced by the recursive SELECT.\n• Each row produced by the recursive SELECT finds all employees who report directly to an employee\nproduced by a previous row. For each such employee, the row includes the employee ID and name,\nand the employee management chain. The chain is the manager's chain, with the employee ID\nadded to the end.\n• Recursion ends when employees have no others who report to them.\nTo find the path for a specific employee or employees, add a WHERE clause to the top-level SELECT.\nFor example, to display the results for Tarek and Sarah, modify that SELECT like this:\nmysql> WITH RECURSIVE ...\n       ...\n       SELECT * FROM employees_extended\n       WHERE id IN (692, 4610)\n       ORDER BY path;\n+------+-------+-----------------+\n| id   | name  | path            |\n+------+-------+-----------------+\n| 4610 | Sarah | 333,198,29,4610 |\n|  692 | Tarek | 333,692         |\n+------+-------+-----------------+\nCommon Table Expressions Compared to Similar Constructs\nCommon table expressions (CTEs) are similar to derived tables in some ways:\n• Both constructs are named.\n• Both constructs exist for the scope of a single statement.\nBecause of these similarities, CTEs and derived tables often can be used interchangeably. As a trivial\nexample, these statements are equivalent:\nWITH cte AS (SELECT 1) SELECT * FROM cte;\nSELECT * FROM (SELECT 1) AS dt;\nHowever, CTEs have some advantages over derived tables:\n• A derived table can be referenced only a single time within a query. A CTE can be referenced\nmultiple times. To use multiple instances of a derived table result, you must derive the result multiple\ntimes.\n• A CTE can be self-referencing (recursive).\n• One CTE can refer to another.\n• A CTE may be easier to read when its definition appears at the beginning of the statement rather\nthan embedded within it.\nCTEs are similar to tables created with CREATE [TEMPORARY] TABLE but need not be defined or\ndropped explicitly. For a CTE, you need no privileges to create tables.",
    "15.3 Transactional and Locking Statements": "15.3 Transactional and Locking Statements\nMySQL supports local transactions (within a given client session) through statements such as SET\nautocommit, START TRANSACTION, COMMIT, and ROLLBACK. See Section 15.3.1, “START\nTRANSACTION, COMMIT, and ROLLBACK Statements”. XA transaction support enables MySQL to\nparticipate in distributed transactions as well. See Section 15.3.8, “XA Transactions”.",
    "15.3.1 START TRANSACTION, COMMIT, and ROLLBACK Statements": "15.3.1 START TRANSACTION, COMMIT, and ROLLBACK Statements\nSTART TRANSACTION\n    [transaction_characteristic [, transaction_characteristic] ...]\ntransaction_characteristic: {\n    WITH CONSISTENT SNAPSHOT\n  | READ WRITE\n  | READ ONLY\n}\nBEGIN [WORK]\nCOMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE]\nROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE]\nSET autocommit = {0 | 1}\nThese statements provide control over use of transactions:\n• START TRANSACTION or BEGIN start a new transaction.\n• COMMIT commits the current transaction, making its changes permanent.\n• ROLLBACK rolls back the current transaction, canceling its changes.\n• SET autocommit disables or enables the default autocommit mode for the current session.\nBy default, MySQL runs with autocommit mode enabled. This means that, when not otherwise inside a\ntransaction, each statement is atomic, as if it were surrounded by START TRANSACTION and COMMIT.\nYou cannot use ROLLBACK to undo the effect; however, if an error occurs during statement execution,\nthe statement is rolled back.\nTo disable autocommit mode implicitly for a single series of statements, use the START TRANSACTION\nstatement:\nSTART TRANSACTION;\nSELECT @A:=SUM(salary) FROM table1 WHERE type=1;\nUPDATE table2 SET summary=@A WHERE type=1;\nCOMMIT;\nWith START TRANSACTION, autocommit remains disabled until you end the transaction with COMMIT\nor ROLLBACK. The autocommit mode then reverts to its previous state.\nSTART TRANSACTION permits several modifiers that control transaction characteristics. To specify\nmultiple modifiers, separate them by commas.\n• The WITH CONSISTENT SNAPSHOT modifier starts a consistent read for storage engines\nthat are capable of it. This applies only to InnoDB. The effect is the same as issuing a START\nTRANSACTION followed by a SELECT from any InnoDB table. See Section 17.7.2.3, “Consistent\nNonlocking Reads”. The WITH CONSISTENT SNAPSHOT modifier does not change the current\ntransaction isolation level, so it provides a consistent snapshot only if the current isolation level\nis one that permits a consistent read. The only isolation level that permits a consistent read is\nREPEATABLE READ. For all other isolation levels, the WITH CONSISTENT SNAPSHOT clause is\nignored. A warning is generated when the WITH CONSISTENT SNAPSHOT clause is ignored.\n• The READ WRITE and READ ONLY modifiers set the transaction access mode. They permit\nor prohibit changes to tables used in the transaction. The READ ONLY restriction prevents the\ntransaction from modifying or locking both transactional and nontransactional tables that are visible\nto other transactions; the transaction can still modify or lock temporary tables.\nMySQL enables extra optimizations for queries on InnoDB tables when the transaction is known to\nbe read-only. Specifying READ ONLY ensures these optimizations are applied in cases where the\nread-only status cannot be determined automatically. See Section 10.5.3, “Optimizing InnoDB Read-\nOnly Transactions” for more information.\nIf no access mode is specified, the default mode applies. Unless the default has been changed, it is\nread/write. It is not permitted to specify both READ WRITE and READ ONLY in the same statement.\nIn read-only mode, it remains possible to change tables created with the TEMPORARY keyword using\nDML statements. Changes made with DDL statements are not permitted, just as with permanent\ntables.\nFor additional information about transaction access mode, including ways to change the default\nmode, see Section 15.3.7, “SET TRANSACTION Statement”.\nIf the read_only system variable is enabled, explicitly starting a transaction with START\nTRANSACTION READ WRITE requires the CONNECTION_ADMIN privilege (or the deprecated SUPER\nprivilege).\nImportant\nMany APIs used for writing MySQL client applications (such as JDBC) provide\ntheir own methods for starting transactions that can (and sometimes should) be\nused instead of sending a START TRANSACTION statement from the client. See\nChapter 31, Connectors and APIs, or the documentation for your API, for more\ninformation.\nTo disable autocommit mode explicitly, use the following statement:\nSET autocommit=0;\nAfter disabling autocommit mode by setting the autocommit variable to zero, changes to transaction-\nsafe tables (such as those for InnoDB or NDB) are not made permanent immediately. You must use\nCOMMIT to store your changes to disk or ROLLBACK to ignore the changes.\nautocommit is a session variable and must be set for each session. To disable autocommit mode for\neach new connection, see the description of the autocommit system variable at Section 7.1.8, “Server\nSystem Variables”.\nBEGIN and BEGIN WORK are supported as aliases of START TRANSACTION for initiating a transaction.\nSTART TRANSACTION is standard SQL syntax, is the recommended way to start an ad-hoc\ntransaction, and permits modifiers that BEGIN does not.\nThe BEGIN statement differs from the use of the BEGIN keyword that starts a BEGIN ... END\ncompound statement. The latter does not begin a transaction. See Section 15.6.1, “BEGIN ... END\nCompound Statement”.\nNote\nWithin all stored programs (stored procedures and functions, triggers, and\nevents), the parser treats BEGIN [WORK] as the beginning of a BEGIN ...\nEND block. Begin a transaction in this context with START TRANSACTION\ninstead.\nThe optional WORK keyword is supported for COMMIT and ROLLBACK, as are the CHAIN and RELEASE\nclauses. CHAIN and RELEASE can be used for additional control over transaction completion. The\nvalue of the completion_type system variable determines the default completion behavior. See\nSection 7.1.8, “Server System Variables”.\nThe AND CHAIN clause causes a new transaction to begin as soon as the current one ends, and the\nnew transaction has the same isolation level as the just-terminated transaction. The new transaction\nalso uses the same access mode (READ WRITE or READ ONLY) as the just-terminated transaction.\nThe RELEASE clause causes the server to disconnect the current client session after terminating the\ncurrent transaction. Including the NO keyword suppresses CHAIN or RELEASE completion, which can\nbe useful if the completion_type system variable is set to cause chaining or release completion by\ndefault.\nBeginning a transaction causes any pending transaction to be committed. See Section 15.3.3,\n“Statements That Cause an Implicit Commit”, for more information.\nBeginning a transaction also causes table locks acquired with LOCK TABLES to be released, as though\nyou had executed UNLOCK TABLES. Beginning a transaction does not release a global read lock\nacquired with FLUSH TABLES WITH READ LOCK.\nFor best results, transactions should be performed using only tables managed by a single transaction-\nsafe storage engine. Otherwise, the following problems can occur:\n• If you use tables from more than one transaction-safe storage engine (such as InnoDB), and the\ntransaction isolation level is not SERIALIZABLE, it is possible that when one transaction commits,\nanother ongoing transaction that uses the same tables sees only some of the changes made by\nthe first transaction. That is, the atomicity of transactions is not guaranteed with mixed engines\nand inconsistencies can result. (If mixed-engine transactions are infrequent, you can use SET\nTRANSACTION ISOLATION LEVEL to set the isolation level to SERIALIZABLE on a per-transaction\nbasis as necessary.)\n• If you use tables that are not transaction-safe within a transaction, changes to those tables are\nstored at once, regardless of the status of autocommit mode.\n• If you issue a ROLLBACK statement after updating a nontransactional table within a transaction, an\nER_WARNING_NOT_COMPLETE_ROLLBACK warning occurs. Changes to transaction-safe tables are\nrolled back, but not changes to nontransaction-safe tables.\nEach transaction is stored in the binary log in one chunk, upon COMMIT. Transactions that are rolled\nback are not logged. (Exception: Modifications to nontransactional tables cannot be rolled back. If a\ntransaction that is rolled back includes modifications to nontransactional tables, the entire transaction\nis logged with a ROLLBACK statement at the end to ensure that modifications to the nontransactional\ntables are replicated.) See Section 7.4.4, “The Binary Log”.\nYou can change the isolation level or access mode for transactions with the SET TRANSACTION\nstatement. See Section 15.3.7, “SET TRANSACTION Statement”.\nRolling back can be a slow operation that may occur implicitly without the user having explicitly asked\nfor it (for example, when an error occurs). Because of this, SHOW PROCESSLIST displays Rolling\nback in the State column for the session, not only for explicit rollbacks performed with the ROLLBACK\nstatement but also for implicit rollbacks.\nNote\nIn MySQL 9.1, BEGIN, COMMIT, and ROLLBACK are not affected by --\nreplicate-do-db or --replicate-ignore-db rules.\nWhen InnoDB performs a complete rollback of a transaction, all locks set by the transaction are\nreleased. If a single SQL statement within a transaction rolls back as a result of an error, such as a\nduplicate key error, locks set by the statement are preserved while the transaction remains active. This\nhappens because InnoDB stores row locks in a format such that it cannot know afterward which lock\nwas set by which statement.\nIf a SELECT statement within a transaction calls a stored function, and a statement within the stored\nfunction fails, that statement rolls back. If ROLLBACK is executed for the transaction subsequently, the\nentire transaction rolls back.",
    "15.3.2 Statements That Cannot Be Rolled Back": "15.3.2 Statements That Cannot Be Rolled Back\nSome statements cannot be rolled back. In general, these include data definition language (DDL)\nstatements, such as those that create or drop databases, those that create, drop, or alter tables or\nstored routines.\nYou should design your transactions not to include such statements. If you issue a statement early in\na transaction that cannot be rolled back, and then another statement later fails, the full effect of the\ntransaction cannot be rolled back in such cases by issuing a ROLLBACK statement.",
    "15.3.3 Statements That Cause an Implicit Commit": "15.3.3 Statements That Cause an Implicit Commit\nThe statements listed in this section (and any synonyms for them) implicitly end any transaction active\nin the current session, as if you had done a COMMIT before executing the statement.\nMost of these statements also cause an implicit commit after executing. The intent is to handle\neach such statement in its own special transaction. Transaction-control and locking statements are\nexceptions: If an implicit commit occurs before execution, another does not occur after.\n• Data definition language (DDL) statements that define or modify database objects. ALTER\nEVENT, ALTER FUNCTION, ALTER PROCEDURE, ALTER SERVER, ALTER TABLE, ALTER\nTABLESPACE, ALTER VIEW, CREATE DATABASE, CREATE EVENT, CREATE FUNCTION, CREATE\nINDEX, CREATE PROCEDURE, CREATE ROLE, CREATE SERVER, CREATE SPATIAL REFERENCE\nSYSTEM, CREATE TABLE, CREATE TABLESPACE, CREATE TRIGGER, CREATE VIEW, DROP\nDATABASE, DROP EVENT, DROP FUNCTION, DROP INDEX, DROP PROCEDURE, DROP ROLE,\nDROP SERVER, DROP SPATIAL REFERENCE SYSTEM, DROP TABLE, DROP TABLESPACE, DROP\nTRIGGER, DROP VIEW, INSTALL PLUGIN, RENAME TABLE, TRUNCATE TABLE, UNINSTALL\nPLUGIN.\nCREATE TABLE and DROP TABLE statements do not commit a transaction if the TEMPORARY\nkeyword is used. (This does not apply to other operations on temporary tables such as ALTER\nTABLE and CREATE INDEX, which do cause a commit.) However, although no implicit commit\noccurs, neither can the statement be rolled back, which means that the use of such statements\ncauses transactional atomicity to be violated. For example, if you use CREATE TEMPORARY TABLE\nand then roll back the transaction, the table remains in existence.\nThe CREATE TABLE statement in InnoDB is processed as a single transaction. This means that\na ROLLBACK from the user does not undo CREATE TABLE statements the user made during that\ntransaction.\nCREATE TABLE ... SELECT causes an implicit commit before and after the statement is\nexecuted when you are creating nontemporary tables. (No commit occurs for CREATE TEMPORARY\nTABLE ... SELECT.)\n• Statements that implicitly use or modify tables in the mysql database. ALTER USER, CREATE\nUSER, DROP USER, GRANT, RENAME USER, REVOKE, SET PASSWORD.\n• Transaction-control and locking statements. BEGIN, LOCK TABLES, SET autocommit = 1 (if\nthe value is not already 1), START TRANSACTION, UNLOCK TABLES.\nUNLOCK TABLES commits a transaction only if any tables currently have been locked with LOCK\nTABLES to acquire nontransactional table locks. A commit does not occur for UNLOCK TABLES\nfollowing FLUSH TABLES WITH READ LOCK because the latter statement does not acquire table-\nlevel locks.\nTransactions cannot be nested. This is a consequence of the implicit commit performed for any\ncurrent transaction when you issue a START TRANSACTION statement or one of its synonyms.\nStatements that cause an implicit commit cannot be used in an XA transaction while the transaction\nis in an ACTIVE state.\nThe BEGIN statement differs from the use of the BEGIN keyword that starts a BEGIN ... END\ncompound statement. The latter does not cause an implicit commit. See Section 15.6.1, “BEGIN ...\nEND Compound Statement”.\n• Data loading statements. LOAD DATA. LOAD DATA causes an implicit commit only for tables using\nthe NDB storage engine.\n• Administrative statements. ANALYZE TABLE, CACHE INDEX, CHECK TABLE, FLUSH, LOAD\nINDEX INTO CACHE, OPTIMIZE TABLE, REPAIR TABLE, RESET (but not RESET PERSIST).\n• Replication control statements. START REPLICA, STOP REPLICA, RESET REPLICA, CHANGE\nREPLICATION SOURCE TO.",
    "15.3.4 SAVEPOINT, ROLLBACK TO SAVEPOINT, and RELEASE": "15.3.4 SAVEPOINT, ROLLBACK TO SAVEPOINT, and RELEASE\nSAVEPOINT Statements\nSAVEPOINT identifier\nROLLBACK [WORK] TO [SAVEPOINT] identifier\nRELEASE SAVEPOINT identifier\nInnoDB supports the SQL statements SAVEPOINT, ROLLBACK TO SAVEPOINT, RELEASE\nSAVEPOINT and the optional WORK keyword for ROLLBACK.\nThe SAVEPOINT statement sets a named transaction savepoint with a name of identifier. If the\ncurrent transaction has a savepoint with the same name, the old savepoint is deleted and a new one is\nset.\nThe ROLLBACK TO SAVEPOINT statement rolls back a transaction to the named savepoint without\nterminating the transaction. Modifications that the current transaction made to rows after the savepoint\nwas set are undone in the rollback, but InnoDB does not release the row locks that were stored in\nmemory after the savepoint. (For a new inserted row, the lock information is carried by the transaction\nID stored in the row; the lock is not separately stored in memory. In this case, the row lock is released\nin the undo.) Savepoints that were set at a later time than the named savepoint are deleted.\nIf the ROLLBACK TO SAVEPOINT statement returns the following error, it means that no savepoint with\nthe specified name exists:\nERROR 1305 (42000): SAVEPOINT identifier does not exist\nThe RELEASE SAVEPOINT statement removes the named savepoint from the set of savepoints of the\ncurrent transaction. No commit or rollback occurs. It is an error if the savepoint does not exist.\nAll savepoints of the current transaction are deleted if you execute a COMMIT, or a ROLLBACK that does\nnot name a savepoint.\nA new savepoint level is created when a stored function is invoked or a trigger is activated. The\nsavepoints on previous levels become unavailable and thus do not conflict with savepoints on the new\nlevel. When the function or trigger terminates, any savepoints it created are released and the previous\nsavepoint level is restored.",
    "15.3.5 LOCK INSTANCE FOR BACKUP and UNLOCK INSTANCE Statements": "15.3.5 LOCK INSTANCE FOR BACKUP and UNLOCK INSTANCE Statements\nLOCK INSTANCE FOR BACKUP\nUNLOCK INSTANCE\nLOCK INSTANCE FOR BACKUP acquires an instance-level backup lock that permits DML during an\nonline backup while preventing operations that could result in an inconsistent snapshot.\nExecuting the LOCK INSTANCE FOR BACKUP statement requires the BACKUP_ADMIN privilege. The\nBACKUP_ADMIN privilege is automatically granted to users with the RELOAD privilege when performing\nan in-place upgrade to MySQL 9.1 from an earlier version.\nMultiple sessions can hold a backup lock simultaneously.\nUNLOCK INSTANCE releases a backup lock held by the current session. A backup lock held by a\nsession is also released if the session is terminated.\nLOCK INSTANCE FOR BACKUP prevents files from being created, renamed, or removed. REPAIR\nTABLE TRUNCATE TABLE, OPTIMIZE TABLE, and account management statements are blocked. See\nSection 15.7.1, “Account Management Statements”. Operations that modify InnoDB files that are not\nrecorded in the InnoDB redo log are also blocked.\nLOCK INSTANCE FOR BACKUP permits DDL operations that only affect user-created temporary\ntables. In effect, files that belong to user-created temporary tables can be created, renamed, or\nremoved while a backup lock is held. Creation of binary log files is also permitted.\nPURGE BINARY LOGS cannot be issued while a LOCK INSTANCE FOR BACKUP statement is in effect\nfor the instance, because it contravenes the rules of the backup lock by removing files from the server.\nA backup lock acquired by LOCK INSTANCE FOR BACKUP is independent of transactional locks\nand locks taken by FLUSH TABLES tbl_name [, tbl_name] ... WITH READ LOCK, and the\nfollowing sequences of statements are permitted:\nLOCK INSTANCE FOR BACKUP;\nFLUSH TABLES tbl_name [, tbl_name] ... WITH READ LOCK;\nUNLOCK TABLES;\nUNLOCK INSTANCE;\nFLUSH TABLES tbl_name [, tbl_name] ... WITH READ LOCK;\nLOCK INSTANCE FOR BACKUP;\nUNLOCK INSTANCE;\nUNLOCK TABLES;\nThe lock_wait_timeout setting defines the amount of time that a LOCK INSTANCE FOR BACKUP\nstatement waits to acquire a lock before giving up.",
    "15.3.6 LOCK TABLES and UNLOCK TABLES Statements": "15.3.6 LOCK TABLES and UNLOCK TABLES Statements\nLOCK {TABLE | TABLES}\n    tbl_name [[AS] alias] lock_type\n    [, tbl_name [[AS] alias] lock_type] ...\nlock_type: {\n    READ [LOCAL]\n  | WRITE\n}\nUNLOCK {TABLE | TABLES}\nMySQL enables client sessions to acquire table locks explicitly for the purpose of cooperating with\nother sessions for access to tables, or to prevent other sessions from modifying tables during periods\nwhen a session requires exclusive access to them. A session can acquire or release locks only for\nitself. One session cannot acquire locks for another session or release locks held by another session.\nLocks may be used to emulate transactions or to get more speed when updating tables. This is\nexplained in more detail in Table-Locking Restrictions and Conditions.\nLOCK TABLES explicitly acquires table locks for the current client session. Table locks can be acquired\nfor base tables or views. You must have the LOCK TABLES privilege, and the SELECT privilege for\neach object to be locked.\nFor view locking, LOCK TABLES adds all base tables used in the view to the set of tables to be locked\nand locks them automatically. For tables underlying any view being locked, LOCK TABLES checks\nthat the view definer (for SQL SECURITY DEFINER views) or invoker (for all views) has the proper\nprivileges on the tables.\nIf you lock a table explicitly with LOCK TABLES, any tables used in triggers are also locked implicitly, as\ndescribed in LOCK TABLES and Triggers.\nIf you lock a table explicitly with LOCK TABLES, any tables related by a foreign key constraint are\nopened and locked implicitly. For foreign key checks, a shared read-only lock (LOCK TABLES READ) is\ntaken on related tables. For cascading updates, a shared-nothing write lock (LOCK TABLES WRITE) is\ntaken on related tables that are involved in the operation.\nUNLOCK TABLES explicitly releases any table locks held by the current session. LOCK TABLES\nimplicitly releases any table locks held by the current session before acquiring new locks.\nAnother use for UNLOCK TABLES is to release the global read lock acquired with the FLUSH\nTABLES WITH READ LOCK statement, which enables you to lock all tables in all databases. See\nSection 15.7.8.3, “FLUSH Statement”. (This is a very convenient way to get backups if you have a file\nsystem such as Veritas that can take snapshots in time.)\nLOCK TABLE is a synonym for LOCK TABLES; UNLOCK TABLE is a synonym for UNLOCK TABLES.\nA table lock protects only against inappropriate reads or writes by other sessions. A session holding\na WRITE lock can perform table-level operations such as DROP TABLE or TRUNCATE TABLE. For\nsessions holding a READ lock, DROP TABLE and TRUNCATE TABLE operations are not permitted.\nThe following discussion applies only to non-TEMPORARY tables. LOCK TABLES is permitted (but\nignored) for a TEMPORARY table. The table can be accessed freely by the session within which it was\ncreated, regardless of what other locking may be in effect. No lock is necessary because no other\nsession can see the table.\n• Table Lock Acquisition\n• Table Lock Release\n• Interaction of Table Locking and Transactions\n• LOCK TABLES and Triggers\n• Table-Locking Restrictions and Conditions\nTable Lock Acquisition\nTo acquire table locks within the current session, use the LOCK TABLES statement, which acquires\nmetadata locks (see Section 10.11.4, “Metadata Locking”).\nThe following lock types are available:\nREAD [LOCAL] lock:\n• The session that holds the lock can read the table (but not write it).\n• Multiple sessions can acquire a READ lock for the table at the same time.\n• Other sessions can read the table without explicitly acquiring a READ lock.\n• The LOCAL modifier enables nonconflicting INSERT statements (concurrent inserts) by other\nsessions to execute while the lock is held. (See Section 10.11.3, “Concurrent Inserts”.) However,\nREAD LOCAL cannot be used if you are going to manipulate the database using processes external\nto the server while you hold the lock. For InnoDB tables, READ LOCAL is the same as READ.\nWRITE lock:\n• The session that holds the lock can read and write the table.\n• Only the session that holds the lock can access the table. No other session can access it until the\nlock is released.\n• Lock requests for the table by other sessions block while the WRITE lock is held.\nWRITE locks normally have higher priority than READ locks to ensure that updates are processed\nas soon as possible. This means that if one session obtains a READ lock and then another session\nrequests a WRITE lock, subsequent READ lock requests wait until the session that requested the WRITE\nlock has obtained the lock and released it. (An exception to this policy can occur for small values of the\nmax_write_lock_count system variable; see Section 10.11.4, “Metadata Locking”.)\nIf the LOCK TABLES statement must wait due to locks held by other sessions on any of the tables, it\nblocks until all locks can be acquired.\nA session that requires locks must acquire all the locks that it needs in a single LOCK TABLES\nstatement. While the locks thus obtained are held, the session can access only the locked tables.\nFor example, in the following sequence of statements, an error occurs for the attempt to access t2\nbecause it was not locked in the LOCK TABLES statement:\nmysql> LOCK TABLES t1 READ;\nmysql> SELECT COUNT(*) FROM t1;\n+----------+\n| COUNT(*) |\n+----------+\n|        3 |\n+----------+\nmysql> SELECT COUNT(*) FROM t2;\nERROR 1100 (HY000): Table 't2' was not locked with LOCK TABLES\nTables in the INFORMATION_SCHEMA database are an exception. They can be accessed without being\nlocked explicitly even while a session holds table locks obtained with LOCK TABLES.\nYou cannot refer to a locked table multiple times in a single query using the same name. Use aliases\ninstead, and obtain a separate lock for the table and each alias:\nmysql> LOCK TABLE t WRITE, t AS t1 READ;\nmysql> INSERT INTO t SELECT * FROM t;\nERROR 1100: Table 't' was not locked with LOCK TABLES\nmysql> INSERT INTO t SELECT * FROM t AS t1;\nThe error occurs for the first INSERT because there are two references to the same name for a locked\ntable. The second INSERT succeeds because the references to the table use different names.\nIf your statements refer to a table by means of an alias, you must lock the table using that same alias. It\ndoes not work to lock the table without specifying the alias:\nmysql> LOCK TABLE t READ;\nmysql> SELECT * FROM t AS myalias;\nERROR 1100: Table 'myalias' was not locked with LOCK TABLES\nConversely, if you lock a table using an alias, you must refer to it in your statements using that alias:\nmysql> LOCK TABLE t AS myalias READ;\nmysql> SELECT * FROM t;\nERROR 1100: Table 't' was not locked with LOCK TABLES\nmysql> SELECT * FROM t AS myalias;\nTable Lock Release\nWhen the table locks held by a session are released, they are all released at the same time. A session\ncan release its locks explicitly, or locks may be released implicitly under certain conditions.\n• A session can release its locks explicitly with UNLOCK TABLES.\n• If a session issues a LOCK TABLES statement to acquire a lock while already holding locks, its\nexisting locks are released implicitly before the new locks are granted.\n• If a session begins a transaction (for example, with START TRANSACTION), an implicit UNLOCK\nTABLES is performed, which causes existing locks to be released. (For additional information\nabout the interaction between table locking and transactions, see Interaction of Table Locking and\nTransactions.)\nIf the connection for a client session terminates, whether normally or abnormally, the server implicitly\nreleases all table locks held by the session (transactional and nontransactional). If the client\nreconnects, the locks are no longer in effect. In addition, if the client had an active transaction, the\nserver rolls back the transaction upon disconnect, and if reconnect occurs, the new session begins with\nautocommit enabled. For this reason, clients may wish to disable auto-reconnect. With auto-reconnect\nin effect, the client is not notified if reconnect occurs but any table locks or current transaction are lost.\nWith auto-reconnect disabled, if the connection drops, an error occurs for the next statement issued.\nThe client can detect the error and take appropriate action such as reacquiring the locks or redoing the\ntransaction. See Automatic Reconnection Control.\nNote\nIf you use ALTER TABLE on a locked table, it may become unlocked. For\nexample, if you attempt a second ALTER TABLE operation, the result may be\nan error Table 'tbl_name' was not locked with LOCK TABLES.\nTo handle this, lock the table again prior to the second alteration. See also\nSection B.3.6.1, “Problems with ALTER TABLE”.\nInteraction of Table Locking and Transactions\nLOCK TABLES and UNLOCK TABLES interact with the use of transactions as follows:\n• LOCK TABLES is not transaction-safe and implicitly commits any active transaction before attempting\nto lock the tables.\n• UNLOCK TABLES implicitly commits any active transaction, but only if LOCK TABLES has been used\nto acquire table locks. For example, in the following set of statements, UNLOCK TABLES releases the\nglobal read lock but does not commit the transaction because no table locks are in effect:\nFLUSH TABLES WITH READ LOCK;\nSTART TRANSACTION;\nSELECT ... ;\nUNLOCK TABLES;\n• Beginning a transaction (for example, with START TRANSACTION) implicitly commits any current\ntransaction and releases existing table locks.\n• FLUSH TABLES WITH READ LOCK acquires a global read lock and not table locks, so it is not\nsubject to the same behavior as LOCK TABLES and UNLOCK TABLES with respect to table locking\nand implicit commits. For example, START TRANSACTION does not release the global read lock.\nSee Section 15.7.8.3, “FLUSH Statement”.\n• Other statements that implicitly cause transactions to be committed do not release existing table\nlocks. For a list of such statements, see Section 15.3.3, “Statements That Cause an Implicit Commit”.\n• The correct way to use LOCK TABLES and UNLOCK TABLES with transactional tables, such as\nInnoDB tables, is to begin a transaction with SET autocommit = 0 (not START TRANSACTION)\nfollowed by LOCK TABLES, and to not call UNLOCK TABLES until you commit the transaction\nexplicitly. For example, if you need to write to table t1 and read from table t2, you can do this:\nSET autocommit=0;\nLOCK TABLES t1 WRITE, t2 READ, ...;\n... do something with tables t1 and t2 here ...\nCOMMIT;\nUNLOCK TABLES;\nWhen you call LOCK TABLES, InnoDB internally takes its own table lock, and MySQL takes its own\ntable lock. InnoDB releases its internal table lock at the next commit, but for MySQL to release its\ntable lock, you have to call UNLOCK TABLES. You should not have autocommit = 1, because then\nInnoDB releases its internal table lock immediately after the call of LOCK TABLES, and deadlocks\ncan very easily happen. InnoDB does not acquire the internal table lock at all if autocommit = 1,\nto help old applications avoid unnecessary deadlocks.\n• ROLLBACK does not release table locks.\nLOCK TABLES and Triggers\nIf you lock a table explicitly with LOCK TABLES, any tables used in triggers are also locked implicitly:\n• The locks are taken as the same time as those acquired explicitly with the LOCK TABLES statement.\n• The lock on a table used in a trigger depends on whether the table is used only for reading. If so, a\nread lock suffices. Otherwise, a write lock is used.\n• If a table is locked explicitly for reading with LOCK TABLES, but needs to be locked for writing\nbecause it might be modified within a trigger, a write lock is taken rather than a read lock. (That is, an\nimplicit write lock needed due to the table's appearance within a trigger causes an explicit read lock\nrequest for the table to be converted to a write lock request.)\nSuppose that you lock two tables, t1 and t2, using this statement:\nLOCK TABLES t1 WRITE, t2 READ;\nIf t1 or t2 have any triggers, tables used within the triggers are also locked. Suppose that t1 has a\ntrigger defined like this:\nCREATE TRIGGER t1_a_ins AFTER INSERT ON t1 FOR EACH ROW\nBEGIN\n  UPDATE t4 SET count = count+1\n      WHERE id = NEW.id AND EXISTS (SELECT a FROM t3);\n  INSERT INTO t2 VALUES(1, 2);\nEND;\nThe result of the LOCK TABLES statement is that t1 and t2 are locked because they appear in the\nstatement, and t3 and t4 are locked because they are used within the trigger:\n• t1 is locked for writing per the WRITE lock request.\n• t2 is locked for writing, even though the request is for a READ lock. This occurs because t2 is\ninserted into within the trigger, so the READ request is converted to a WRITE request.\n• t3 is locked for reading because it is only read from within the trigger.\n• t4 is locked for writing because it might be updated within the trigger.\nTable-Locking Restrictions and Conditions\nYou can safely use KILL to terminate a session that is waiting for a table lock. See Section 15.7.8.4,\n“KILL Statement”.\nLOCK TABLES and UNLOCK TABLES cannot be used within stored programs.\nTables in the performance_schema database cannot be locked with LOCK TABLES, except the\nsetup_xxx tables.\nThe scope of a lock generated by LOCK TABLES is a single MySQL server. It is not compatible with\nNDB Cluster, which has no way of enforcing an SQL-level lock across multiple instances of mysqld.\nYou can enforce locking in an API application instead. See Section 25.2.7.10, “Limitations Relating to\nMultiple NDB Cluster Nodes”, for more information.\nThe following statements are prohibited while a LOCK TABLES statement is in effect: CREATE TABLE,\nCREATE TABLE ... LIKE, CREATE VIEW, DROP VIEW, and DDL statements on stored functions\nand procedures and events.\nFor some operations, system tables in the mysql database must be accessed. For example, the HELP\nstatement requires the contents of the server-side help tables, and CONVERT_TZ() might need to read\nthe time zone tables. The server implicitly locks the system tables for reading as necessary so that you\nneed not lock them explicitly. These tables are treated as just described:\nmysql.help_category\nmysql.help_keyword\nmysql.help_relation\nmysql.help_topic\nmysql.time_zone\nmysql.time_zone_leap_second\nmysql.time_zone_name\nmysql.time_zone_transition\nmysql.time_zone_transition_type\nIf you want to explicitly place a WRITE lock on any of those tables with a LOCK TABLES statement, the\ntable must be the only one locked; no other table can be locked with the same statement.\nNormally, you do not need to lock tables, because all single UPDATE statements are atomic; no other\nsession can interfere with any other currently executing SQL statement. However, there are a few\ncases when locking tables may provide an advantage:\n• If you are going to run many operations on a set of MyISAM tables, it is much faster to lock the tables\nyou are going to use. Locking MyISAM tables speeds up inserting, updating, or deleting on them\nbecause MySQL does not flush the key cache for the locked tables until UNLOCK TABLES is called.\nNormally, the key cache is flushed after each SQL statement.\nThe downside to locking the tables is that no session can update a READ-locked table (including the\none holding the lock) and no session can access a WRITE-locked table other than the one holding\nthe lock.\n• If you are using tables for a nontransactional storage engine, you must use LOCK TABLES if you\nwant to ensure that no other session modifies the tables between a SELECT and an UPDATE. The\nexample shown here requires LOCK TABLES to execute safely:\nLOCK TABLES trans READ, customer WRITE;\nSELECT SUM(value) FROM trans WHERE customer_id=some_id;\nUPDATE customer\n  SET total_value=sum_from_previous_statement\n  WHERE customer_id=some_id;\nUNLOCK TABLES;\nWithout LOCK TABLES, it is possible that another session might insert a new row in the trans table\nbetween execution of the SELECT and UPDATE statements.\nYou can avoid using LOCK TABLES in many cases by using relative updates (UPDATE customer\nSET value=value+new_value) or the LAST_INSERT_ID() function.\nYou can also avoid locking tables in some cases by using the user-level advisory lock functions\nGET_LOCK() and RELEASE_LOCK(). These locks are saved in a hash table in the server and\nimplemented with pthread_mutex_lock() and pthread_mutex_unlock() for high speed. See\nSection 14.14, “Locking Functions”.\nSee Section 10.11.1, “Internal Locking Methods”, for more information on locking policy.",
    "15.3.7 SET TRANSACTION Statement": "15.3.7 SET TRANSACTION Statement\nSET [GLOBAL | SESSION] TRANSACTION\n    transaction_characteristic [, transaction_characteristic] ...\ntransaction_characteristic: {\n    ISOLATION LEVEL level\n  | access_mode\n}\nlevel: {\n     REPEATABLE READ\n   | READ COMMITTED\n   | READ UNCOMMITTED\n   | SERIALIZABLE\n}\naccess_mode: {\n     READ WRITE\n   | READ ONLY\n}\nThis statement specifies transaction characteristics. It takes a list of one or more characteristic values\nseparated by commas. Each characteristic value sets the transaction isolation level or access mode.\nThe isolation level is used for operations on InnoDB tables. The access mode specifies whether\ntransactions operate in read/write or read-only mode.\nIn addition, SET TRANSACTION can include an optional GLOBAL or SESSION keyword to indicate the\nscope of the statement.\n• Transaction Isolation Levels\n• Transaction Access Mode\n• Transaction Characteristic Scope\nTransaction Isolation Levels\nTo set the transaction isolation level, use an ISOLATION LEVEL level clause. It is not permitted to\nspecify multiple ISOLATION LEVEL clauses in the same SET TRANSACTION statement.\nThe default isolation level is REPEATABLE READ. Other permitted values are READ COMMITTED,\nREAD UNCOMMITTED, and SERIALIZABLE. For information about these isolation levels, see\nSection 17.7.2.1, “Transaction Isolation Levels”.\nTransaction Access Mode\nTo set the transaction access mode, use a READ WRITE or READ ONLY clause. It is not permitted to\nspecify multiple access-mode clauses in the same SET TRANSACTION statement.\nBy default, a transaction takes place in read/write mode, with both reads and writes permitted to tables\nused in the transaction. This mode may be specified explicitly using SET TRANSACTION with an\naccess mode of READ WRITE.\nIf the transaction access mode is set to READ ONLY, changes to tables are prohibited. This may enable\nstorage engines to make performance improvements that are possible when writes are not permitted.\nIn read-only mode, it remains possible to change tables created with the TEMPORARY keyword using\nDML statements. Changes made with DDL statements are not permitted, just as with permanent\ntables.\nThe READ WRITE and READ ONLY access modes also may be specified for an individual transaction\nusing the START TRANSACTION statement.\nTransaction Characteristic Scope\nYou can set transaction characteristics globally, for the current session, or for the next transaction only:\n• With the GLOBAL keyword:\n• The statement applies globally for all subsequent sessions.\n• Existing sessions are unaffected.\n• With the SESSION keyword:\n• The statement applies to all subsequent transactions performed within the current session.\n• The statement is permitted within transactions, but does not affect the current ongoing transaction.\n• If executed between transactions, the statement overrides any preceding statement that sets the\nnext-transaction value of the named characteristics.\n• Without any SESSION or GLOBAL keyword:\n• The statement applies only to the next single transaction performed within the session.\n• Subsequent transactions revert to using the session value of the named characteristics.\n• The statement is not permitted within transactions:\nmysql> START TRANSACTION;\nQuery OK, 0 rows affected (0.02 sec)\nmysql> SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;\nERROR 1568 (25001): Transaction characteristics can't be changed\nwhile a transaction is in progress\nA change to global transaction characteristics requires the CONNECTION_ADMIN privilege (or the\ndeprecated SUPER privilege). Any session is free to change its session characteristics (even in\nthe middle of a transaction), or the characteristics for its next transaction (prior to the start of that\ntransaction).\nTo set the global isolation level at server startup, use the --transaction-isolation=level\noption on the command line or in an option file. Values of level for this option use dashes rather than\nspaces, so the permissible values are READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ,\nor SERIALIZABLE.\nSimilarly, to set the global transaction access mode at server startup, use the --transaction-\nread-only option. The default is OFF (read/write mode) but the value can be set to ON for a mode of\nread only.\nFor example, to set the isolation level to REPEATABLE READ and the access mode to READ WRITE,\nuse these lines in the [mysqld] section of an option file:\n[mysqld]\ntransaction-isolation = REPEATABLE-READ\ntransaction-read-only = OFF\nAt runtime, characteristics at the global, session, and next-transaction scope levels can be set\nindirectly using the SET TRANSACTION statement, as described previously. They can also be\nset directly using the SET statement to assign values to the transaction_isolation and\ntransaction_read_only system variables:\n• SET TRANSACTION permits optional GLOBAL and SESSION keywords for setting transaction\ncharacteristics at different scope levels.\n• The SET statement for assigning values to the transaction_isolation and\ntransaction_read_only system variables has syntaxes for setting these variables at different\nscope levels.\nThe following tables show the characteristic scope level set by each SET TRANSACTION and variable-\nassignment syntax.\nTable 15.9 SET TRANSACTION Syntax for Transaction Characteristics\nSyntax\nAffected Characteristic Scope\nSET GLOBAL TRANSACTION\ntransaction_characteristic\nGlobal\nSET SESSION TRANSACTION\ntransaction_characteristic\nSession\nSET TRANSACTION\ntransaction_characteristic\nNext transaction only\nTable 15.10 SET Syntax for Transaction Characteristics\nSyntax\nAffected Characteristic Scope\nSET GLOBAL var_name = value\nGlobal\nSET @@GLOBAL.var_name = value\nGlobal\nSET PERSIST var_name = value\nGlobal\nSET @@PERSIST.var_name = value\nGlobal\nSET PERSIST_ONLY var_name = value\nNo runtime effect\nSET @@PERSIST_ONLY.var_name = value\nNo runtime effect\nSET SESSION var_name = value\nSession\nSyntax\nAffected Characteristic Scope\nSET @@SESSION.var_name = value\nSession\nSET var_name = value\nSession\nSET @@var_name = value\nNext transaction only\nIt is possible to check the global and session values of transaction characteristics at runtime:\nSELECT @@GLOBAL.transaction_isolation, @@GLOBAL.transaction_read_only;\nSELECT @@SESSION.transaction_isolation, @@SESSION.transaction_read_only;",
    "15.3.8 XA Transactions": "15.3.8 XA Transactions\nSupport for XA transactions is available for the InnoDB storage engine. The MySQL XA\nimplementation is based on the X/Open CAE document Distributed Transaction Processing:\nThe XA Specification. This document is published by The Open Group and available at http://\nwww.opengroup.org/public/pubs/catalog/c193.htm. Limitations of the current XA implementation are\ndescribed in Section 15.3.8.3, “Restrictions on XA Transactions”.\nOn the client side, there are no special requirements. The XA interface to a MySQL server consists of\nSQL statements that begin with the XA keyword. MySQL client programs must be able to send SQL\nstatements and to understand the semantics of the XA statement interface. They do not need be linked\nagainst a recent client library. Older client libraries also work.\nAmong the MySQL Connectors, MySQL Connector/J 5.0.0 and higher supports XA directly, by means\nof a class interface that handles the XA SQL statement interface for you.\nXA supports distributed transactions, that is, the ability to permit multiple separate transactional\nresources to participate in a global transaction. Transactional resources often are RDBMSs but may be\nother kinds of resources.\nA global transaction involves several actions that are transactional in themselves, but that all must\neither complete successfully as a group, or all be rolled back as a group. In essence, this extends ACID\nproperties “up a level” so that multiple ACID transactions can be executed in concert as components of\na global operation that also has ACID properties. (As with nondistributed transactions, SERIALIZABLE\nmay be preferred if your applications are sensitive to read phenomena. REPEATABLE READ may not\nbe sufficient for distributed transactions.)\nSome examples of distributed transactions:\n• An application may act as an integration tool that combines a messaging service with an RDBMS.\nThe application makes sure that transactions dealing with message sending, retrieval, and\nprocessing that also involve a transactional database all happen in a global transaction. You can\nthink of this as “transactional email.”\n• An application performs actions that involve different database servers, such as a MySQL server\nand an Oracle server (or multiple MySQL servers), where actions that involve multiple servers must\nhappen as part of a global transaction, rather than as separate transactions local to each server.\n• A bank keeps account information in an RDBMS and distributes and receives money through\nautomated teller machines (ATMs). It is necessary to ensure that ATM actions are correctly reflected\nin the accounts, but this cannot be done with the RDBMS alone. A global transaction manager\nintegrates the ATM and database resources to ensure overall consistency of financial transactions.\nApplications that use global transactions involve one or more Resource Managers and a Transaction\nManager:\n• A Resource Manager (RM) provides access to transactional resources. A database server is one\nkind of resource manager. It must be possible to either commit or roll back transactions managed by\nthe RM.\n• A Transaction Manager (TM) coordinates the transactions that are part of a global transaction. It\ncommunicates with the RMs that handle each of these transactions. The individual transactions\nwithin a global transaction are “branches” of the global transaction. Global transactions and their\nbranches are identified by a naming scheme described later.\nThe MySQL implementation of XA enables a MySQL server to act as a Resource Manager that\nhandles XA transactions within a global transaction. A client program that connects to the MySQL\nserver acts as the Transaction Manager.\nTo carry out a global transaction, it is necessary to know which components are involved, and\nbring each component to a point when it can be committed or rolled back. Depending on what each\ncomponent reports about its ability to succeed, they must all commit or roll back as an atomic group.\nThat is, either all components must commit, or all components must roll back. To manage a global\ntransaction, it is necessary to take into account that any component or the connecting network might\nfail.\nThe process for executing a global transaction uses two-phase commit (2PC). This takes place after\nthe actions performed by the branches of the global transaction have been executed.\n1. In the first phase, all branches are prepared. That is, they are told by the TM to get ready to\ncommit. Typically, this means each RM that manages a branch records the actions for the branch in\nstable storage. The branches indicate whether they are able to do this, and these results are used\nfor the second phase.\n2. In the second phase, the TM tells the RMs whether to commit or roll back. If all branches indicated\nwhen they were prepared that they were able to commit, all branches are told to commit. If any\nbranch indicated when it was prepared that it was not able to commit, all branches are told to roll\nback.\nIn some cases, a global transaction might use one-phase commit (1PC). For example, when a\nTransaction Manager finds that a global transaction consists of only one transactional resource (that is,\na single branch), that resource can be told to prepare and commit at the same time.\n15.3.8.1 XA Transaction SQL Statements\nTo perform XA transactions in MySQL, use the following statements:\nXA {START|BEGIN} xid [JOIN|RESUME]\nXA END xid [SUSPEND [FOR MIGRATE]]\nXA PREPARE xid\nXA COMMIT xid [ONE PHASE]\nXA ROLLBACK xid\nXA RECOVER [CONVERT XID]\nFor XA START, the JOIN and RESUME clauses are recognized but have no effect.\nFor XA END the SUSPEND [FOR MIGRATE] clause is recognized but has no effect.\nEach XA statement begins with the XA keyword, and most of them require an xid value. An xid is\nan XA transaction identifier. It indicates which transaction the statement applies to. xid values are\nsupplied by the client, or generated by the MySQL server. An xid value has from one to three parts:\nxid: gtrid [, bqual [, formatID ]]\ngtrid is a global transaction identifier, bqual is a branch qualifier, and formatID is a number that\nidentifies the format used by the gtrid and bqual values. As indicated by the syntax, bqual and\nformatID are optional. The default bqual value is '' if not given. The default formatID value is 1 if\nnot given.\ngtrid and bqual must be string literals, each up to 64 bytes (not characters) long. gtrid and bqual\ncan be specified in several ways. You can use a quoted string ('ab'), hex string (X'6162', 0x6162),\nor bit value (b'nnnn').\nformatID is an unsigned integer.\nThe gtrid and bqual values are interpreted in bytes by the MySQL server's underlying XA support\nroutines. However, while an SQL statement containing an XA statement is being parsed, the server\nworks with some specific character set. To be safe, write gtrid and bqual as hex strings.\nxid values typically are generated by the Transaction Manager. Values generated by one TM must\nbe different from values generated by other TMs. A given TM must be able to recognize its own xid\nvalues in a list of values returned by the XA RECOVER statement.\nXA START xid starts an XA transaction with the given xid value. Each XA transaction must have a\nunique xid value, so the value must not currently be used by another XA transaction. Uniqueness is\nassessed using the gtrid and bqual values. All following XA statements for the XA transaction must\nbe specified using the same xid value as that given in the XA START statement. If you use any of\nthose statements but specify an xid value that does not correspond to some existing XA transaction,\nan error occurs.\nXA START, XA BEGIN, XA END, XA COMMIT, and XA ROLLBACK statements are not filtered by the\ndefault database when the server is running with --replicate-do-db or --replicate-ignore-\ndb.\nOne or more XA transactions can be part of the same global transaction. All XA transactions within\na given global transaction must use the same gtrid value in the xid value. For this reason, gtrid\nvalues must be globally unique so that there is no ambiguity about which global transaction a given\nXA transaction is part of. The bqual part of the xid value must be different for each XA transaction\nwithin a global transaction. (The requirement that bqual values be different is a limitation of the current\nMySQL XA implementation. It is not part of the XA specification.)\nThe XA RECOVER statement returns information for those XA transactions on the MySQL server that\nare in the PREPARED state. (See Section 15.3.8.2, “XA Transaction States”.) The output includes a row\nfor each such XA transaction on the server, regardless of which client started it.\nXA RECOVER requires the XA_RECOVER_ADMIN privilege. This privilege requirement prevents users\nfrom discovering the XID values for outstanding prepared XA transactions other than their own. It does\nnot affect normal commit or rollback of an XA transaction because the user who started it knows its\nXID.\nXA RECOVER output rows look like this (for an example xid value consisting of the parts 'abc',\n'def', and 7):\nmysql> XA RECOVER;\n+----------+--------------+--------------+--------+\n| formatID | gtrid_length | bqual_length | data   |\n+----------+--------------+--------------+--------+\n|        7 |            3 |            3 | abcdef |\n+----------+--------------+--------------+--------+\nThe output columns have the following meanings:\n• formatID is the formatID part of the transaction xid\n• gtrid_length is the length in bytes of the gtrid part of the xid\n• bqual_length is the length in bytes of the bqual part of the xid\n• data is the concatenation of the gtrid and bqual parts of the xid\nXID values may contain nonprintable characters. XA RECOVER permits an optional CONVERT XID\nclause so that clients can request XID values in hexadecimal.\n15.3.8.2 XA Transaction States\nAn XA transaction progresses through the following states:\n1. Use XA START to start an XA transaction and put it in the ACTIVE state.\n2. For an ACTIVE XA transaction, issue the SQL statements that make up the transaction, and then\nissue an XA END statement. XA END puts the transaction in the IDLE state.\n3. For an IDLE XA transaction, you can issue either an XA PREPARE statement or an XA\nCOMMIT ... ONE PHASE statement:\n• XA PREPARE puts the transaction in the PREPARED state. An XA RECOVER statement at this\npoint includes the transaction's xid value in its output, because XA RECOVER lists all XA\ntransactions that are in the PREPARED state.\n• XA COMMIT ... ONE PHASE prepares and commits the transaction. The xid value is not listed\nby XA RECOVER because the transaction terminates.\n4. For a PREPARED XA transaction, you can issue an XA COMMIT statement to commit and terminate\nthe transaction, or XA ROLLBACK to roll back and terminate the transaction.\nHere is a simple XA transaction that inserts a row into a table as part of a global transaction:\nmysql> XA START 'xatest';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> INSERT INTO mytable (i) VALUES(10);\nQuery OK, 1 row affected (0.04 sec)\nmysql> XA END 'xatest';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> XA PREPARE 'xatest';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> XA COMMIT 'xatest';\nQuery OK, 0 rows affected (0.00 sec)\nMySQL 9.1 supports detached XA transactions, enabled by the xa_detach_on_prepare system\nvariable (ON by default). Detached transactions are disconnected from the current session following\nexecution of XA PREPARE (and can be committed or rolled back by another connection). This means\nthat the current session is free to start a new local transaction or XA transaction without having to wait\nfor the prepared XA transaction to be committed or rolled back.\nWhen XA transactions are detached, a connection has no special knowledge of any XA transaction\nthat it has prepared. If the current session tries to commit or roll back a given XA transaction (even one\nwhich it prepared) after another connection has already done so, the attempt is rejected with an invalid\nXID error (ER_XAER_NOTA) since the requested xid no longer exists.\nNote\nDetached XA transactions cannot use temporary tables.\nWhen detached XA transactions are disabled (xa_detach_on_prepare set to OFF), an XA\ntransaction remains connected until it is committed or rolled back by the originating connection.\nDisabling detached XA transactions is not recommended for a MySQL server instance used in group\nreplication; see Server Instance Configuration, for more information.\nIf an XA transaction is in the ACTIVE state, you cannot issue any statements that cause an implicit\ncommit. That would violate the XA contract because you could not roll back the XA transaction. Trying\nto execute such a statement raises the following error:\nERROR 1399 (XAE07): XAER_RMFAIL: The command cannot be executed\nwhen global transaction is in the ACTIVE state\nStatements to which the preceding remark applies are listed at Section 15.3.3, “Statements That Cause\nan Implicit Commit”.\n15.3.8.3 Restrictions on XA Transactions\nXA transaction support is limited to the InnoDB storage engine.\nFor “external XA,” a MySQL server acts as a Resource Manager and client programs act as\nTransaction Managers. For “Internal XA”, storage engines within a MySQL server act as RMs, and\nthe server itself acts as a TM. Internal XA support is limited by the capabilities of individual storage\nengines. Internal XA is required for handling XA transactions that involve more than one storage\nengine. The implementation of internal XA requires that a storage engine support two-phase commit at\nthe table handler level, and currently this is true only for InnoDB.\nFor XA START, the JOIN and RESUME clauses are recognized but have no effect.\nFor XA END the SUSPEND [FOR MIGRATE] clause is recognized but has no effect.\nThe requirement that the bqual part of the xid value be different for each XA transaction within\na global transaction is a limitation of the current MySQL XA implementation. It is not part of the XA\nspecification.\nAn XA transaction is written to the binary log in two parts. When XA PREPARE is issued, the first part\nof the transaction up to XA PREPARE is written using an initial GTID. A XA_prepare_log_event\nis used to identify such transactions in the binary log. When XA COMMIT or XA ROLLBACK\nis issued, a second part of the transaction containing only the XA COMMIT or XA ROLLBACK\nstatement is written using a second GTID. Note that the initial part of the transaction, identified by\nXA_prepare_log_event, is not necessarily followed by its XA COMMIT or XA ROLLBACK, which\ncan cause interleaved binary logging of any two XA transactions. The two parts of the XA transaction\ncan even appear in different binary log files. This means that an XA transaction in PREPARED state is\nnow persistent until an explicit XA COMMIT or XA ROLLBACK statement is issued, ensuring that XA\ntransactions are compatible with replication.\nOn a replica, immediately after the XA transaction is prepared, it is detached from the replication\napplier thread, and can be committed or rolled back by any thread on the replica. This means that\nthe same XA transaction can appear in the events_transactions_current table with different\nstates on different threads. The events_transactions_current table displays the current status\nof the most recent monitored transaction event on the thread, and does not update this status when the\nthread is idle. So the XA transaction can still be displayed in the PREPARED state for the original applier\nthread, after it has been processed by another thread. To positively identify XA transactions that are\nstill in the PREPARED state and need to be recovered, use the XA RECOVER statement rather than the\nPerformance Schema transaction tables.\nThe following restrictions exist for using XA transactions:\n• The use of replication filters or binary log filters in combination with XA transactions is not\nsupported. Filtering of tables could cause an XA transaction to be empty on a replica, and empty XA\ntransactions are not supported. Also, with the replica's connection metadata repository and applier\nmetadata repository stored in InnoDB tables (the default), the internal state of the data engine\ntransaction is changed following a filtered XA transaction, and can become inconsistent with the\nreplication transaction context state.\nThe error ER_XA_REPLICATION_FILTERS is logged whenever an XA transaction is impacted by a\nreplication filter, whether or not the transaction was empty as a result. If the transaction is not empty,\nthe replica is able to continue running, but you should take steps to discontinue the use of replication\nfilters with XA transactions in order to avoid potential issues. If the transaction is empty, the replica\nstops. In that event, the replica might be in an undetermined state in which the consistency of the\nreplication process might be compromised. In particular, the gtid_executed set on a replica of\nthe replica might be inconsistent with that on the source. To resolve this situation, isolate the source\nand stop all replication, then check GTID consistency across the replication topology. Undo the XA\ntransaction that generated the error message, then restart replication.\n• XA transactions are considered unsafe for statement-based replication. If two XA transactions\ncommitted in parallel on the source are being prepared on the replica in the inverse order, locking\ndependencies can occur that cannot be safely resolved, and it is possible for replication to fail with\ndeadlock on the replica. This situation can occur for a single-threaded or multithreaded replica.\nWhen binlog_format=STATEMENT is set, a warning is issued for DML statements inside XA\ntransactions. When binlog_format=MIXED or binlog_format=ROW is set, DML statements\ninside XA transactions are logged using row-based replication, and the potential issue is not present.\n• You should be aware that, when the same transaction XID is used to execute XA transactions\nsequentially and a break occurs during the processing of XA COMMIT ... ONE PHASE, it may no\nlonger be possible to synchronize the state between the binary log and the storage engine. This can\noccur if the series of events just described takes place after this transaction has been prepared in the\nstorage engine, while the XA COMMIT statement is still executing. This is a known issue.",
    "15.4 Replication Statements": "15.4 Replication Statements\nReplication can be controlled through the SQL interface using the statements described in this section.\nStatements are split into a group which controls source servers, a group which controls replica servers,\nand a group which can be applied to any replication servers.",
    "15.4.1 SQL Statements for Controlling Source Servers": "15.4.1 SQL Statements for Controlling Source Servers\nThis section discusses statements for managing replication source servers. Section 15.4.2, “SQL\nStatements for Controlling Replica Servers”, discusses statements for managing replica servers.\nIn addition to the statements described here, the following SHOW statements are used with source\nservers in replication. For information about these statements, see Section 15.7.7, “SHOW\nStatements”.\n• SHOW BINARY LOGS\n• SHOW BINLOG EVENTS\n• SHOW BINARY LOG STATUS\n• SHOW REPLICAS\n15.4.1.1 PURGE BINARY LOGS Statement\nPURGE BINARY LOGS {\n    TO 'log_name'\n  | BEFORE datetime_expr\n}\nThe binary log is a set of files that contain information about data modifications made by the MySQL\nserver. The log consists of a set of binary log files, plus an index file (see Section 7.4.4, “The Binary\nLog”).\nThe PURGE BINARY LOGS statement deletes all the binary log files listed in the log index file prior to\nthe specified log file name or date. Deleted log files also are removed from the list recorded in the index\nfile, so that the given log file becomes the first in the list.\nPURGE BINARY LOGS requires the BINLOG_ADMIN privilege. This statement has no effect if the\nserver was not started with the --log-bin option to enable binary logging.\nExamples:\nPURGE BINARY LOGS TO 'mysql-bin.010';\nPURGE BINARY LOGS BEFORE '2019-04-02 22:46:26';\nThe BEFORE variant's datetime_expr argument should evaluate to a DATETIME value (a value in\n'YYYY-MM-DD hh:mm:ss' format).\nPURGE BINARY LOGS is safe to run while replicas are replicating. You need not stop them. If you have\nan active replica that currently is reading one of the log files you are trying to delete, this statement\ndoes not delete the log file that is in use or any log files later than that one, but it deletes any earlier\nlog files. A warning message is issued in this situation. However, if a replica is not connected and you\nhappen to purge one of the log files it has yet to read, the replica cannot replicate after it reconnects.\nPURGE BINARY LOGS cannot be issued while a LOCK INSTANCE FOR BACKUP statement is in effect\nfor the instance, because it contravenes the rules of the backup lock by removing files from the server.\nTo safely purge binary log files, follow this procedure:\n1. On each replica, use SHOW REPLICA STATUS to check which log file it is reading.\n2. Obtain a listing of the binary log files on the source with SHOW BINARY LOGS.\n3. Determine the earliest log file among all the replicas. This is the target file. If all the replicas are up\nto date, this is the last log file on the list.\n4. Make a backup of all the log files you are about to delete. (This step is optional, but always\nadvisable.)\n5. Purge all log files up to but not including the target file.\nPURGE BINARY LOGS TO and PURGE BINARY LOGS BEFORE both fail with an error when binary log\nfiles listed in the .index file had been removed from the system by some other means (such as using\nrm on Linux). (Bug #18199, Bug #18453) To handle such errors, edit the .index file (which is a simple\ntext file) manually to ensure that it lists only the binary log files that are actually present, then run again\nthe PURGE BINARY LOGS statement that failed.\nBinary log files are automatically removed after the server's binary log expiration period. Removal\nof the files can take place at startup and when the binary log is flushed. The default binary\nlog expiration period is 30 days. You can specify an alternative expiration period using the\nbinlog_expire_logs_seconds system variable. If you are using replication, you should specify an\nexpiration period that is no lower than the maximum amount of time your replicas might lag behind the\nsource.\n15.4.1.2 RESET BINARY LOGS AND GTIDS Statement\nRESET BINARY LOGS AND GTIDS [TO binary_log_file_index_number]\nWarning\nUse this statement with caution to ensure you do not lose any wanted binary log\nfile data and GTID execution history.\nRESET BINARY LOGS AND GTIDS requires the RELOAD privilege.\nFor a server where binary logging is enabled (log_bin is ON), RESET BINARY LOGS AND GTIDS\ndeletes all existing binary log files and resets the binary log index file, resetting the server to its state\nbefore binary logging was started. A new empty binary log file is created so that binary logging can be\nrestarted.\nFor a server where GTIDs are in use (gtid_mode is ON), issuing RESET BINARY LOGS AND GTIDS\nresets the GTID execution history. The value of the gtid_purged system variable is set to an empty\nstring (''), the global value (but not the session value) of the gtid_executed system variable is set\nto an empty string, and the mysql.gtid_executed table is cleared (see mysql.gtid_executed Table).\nIf the GTID-enabled server has binary logging enabled, RESET BINARY LOGS AND GTIDS also\nresets the binary log as described above. Note that RESET BINARY LOGS AND GTIDS is the method\nto reset the GTID execution history even if the GTID-enabled server is a replica where binary logging\nis disabled; RESET REPLICA has no effect on the GTID execution history. For more information on\nresetting the GTID execution history, see Resetting the GTID Execution History.\nIssuing RESET BINARY LOGS AND GTIDS without the optional TO clause deletes all binary log files\nlisted in the index file, resets the binary log index file to be empty, and creates a new binary log file\nstarting at 1. Use the optional TO clause to start the binary log file index from a number other than 1\nafter the reset.\nCheck that you are using a reasonable value for the index number. If you enter an incorrect value, you\ncan correct this by issuing another RESET BINARY LOGS AND GTIDS statement with or without the\nTO clause. If you do not correct a value that is out of range, the server cannot be restarted.\nThe following example demonstrates TO clause usage:\nRESET BINARY LOGS AND GTIDS TO 1234;\nSHOW BINARY LOGS;\n+-------------------+-----------+-----------+\n| Log_name          | File_size | Encrypted |\n+-------------------+-----------+-----------+\n| source-bin.001234 |       154 | No        |\n+-------------------+-----------+-----------+\nImportant\nThe effects of RESET BINARY LOGS AND GTIDS without the TO clause differ\nfrom those of PURGE BINARY LOGS in 2 key ways:\n1. RESET BINARY LOGS AND GTIDS removes all binary log files that are\nlisted in the index file, leaving only a single, empty binary log file with a\nnumeric suffix of .000001, whereas the numbering is not reset by PURGE\nBINARY LOGS.\n2. RESET BINARY LOGS AND GTIDS is not intended to be used while any\nreplicas are running. The behavior of RESET BINARY LOGS AND GTIDS\nwhen used while replicas are running is undefined (and thus unsupported),\nwhereas PURGE BINARY LOGS may be safely used while replicas are\nrunning.\nSee also Section 15.4.1.1, “PURGE BINARY LOGS Statement”.\nRESET BINARY LOGS AND GTIDS without the TO clause can prove useful when you first set up a\nsource and replica, so that you can verify the setup as follows:\n1. Start the source and replica, and start replication (see Section 19.1.2, “Setting Up Binary Log File\nPosition Based Replication”).\n2. Execute a few test queries on the source.\n3. Check that the queries were replicated to the replica.\n4. When replication is running correctly, issue STOP REPLICA followed by RESET REPLICA (both on\nthe replica), then verify that no unwanted data from the test queries exists on the replica. Following\nthis, issue RESET BINARY LOGS AND GTIDS (also on the replica) to remove binary logs and and\nassociated transaction IDs.\n5. Remove the unwanted data from the source, then issue RESET BINARY LOGS AND GTIDS to\npurge any binary log entries and identifiers associated with it.\nAfter verifying the setup, resetting the source and replica and ensuring that no unwanted data or binary\nlog files generated by testing remain on the source or replica, you can start the replica and begin\nreplicating.\n15.4.1.3 SET sql_log_bin Statement\nSET sql_log_bin = {OFF|ON}\nThe sql_log_bin variable controls whether logging to the binary log is enabled for the current\nsession (assuming that the binary log itself is enabled). The default value is ON. To disable or enable\nbinary logging for the current session, set the session sql_log_bin variable to OFF or ON.\nSet this variable to OFF for a session to temporarily disable binary logging while making changes to the\nsource that you do not want replicated to the replica.\nSetting the session value of this system variable is a restricted operation. The session user must\nhave privileges sufficient to set restricted session variables. See Section 7.1.9.1, “System Variable\nPrivileges”.\nIt is not possible to set the session value of sql_log_bin within a transaction or subquery.\nSetting this variable to OFF prevents new GTIDs from being assigned to transactions in the binary log.\nIf you are using GTIDs for replication, this means that even when binary logging is later enabled again,\nthe GTIDs written into the log from this point do not account for any transactions that occurred in the\nmeantime, so in effect those transactions are lost.\nmysqldump adds a SET @@SESSION.sql_log_bin=0 statement to a dump file from a server where\nGTIDs are in use, which disables binary logging while the dump file is being reloaded. The statement\nprevents new GTIDs from being generated and assigned to the transactions in the dump file as they\nare executed, so that the original GTIDs for the transactions are used.",
    "15.4.2 SQL Statements for Controlling Replica Servers": "15.4.2 SQL Statements for Controlling Replica Servers\nThis section discusses statements for managing replica servers. Section 15.4.1, “SQL Statements for\nControlling Source Servers”, discusses statements for managing source servers.\nIn addition to the statements described here, SHOW REPLICA STATUS and SHOW RELAYLOG EVENTS\nare also used with replicas. For information about these statements, see Section 15.7.7.34, “SHOW\nREPLICA STATUS Statement”, and Section 15.7.7.33, “SHOW RELAYLOG EVENTS Statement”.\n15.4.2.1 CHANGE REPLICATION FILTER Statement\nCHANGE REPLICATION FILTER filter[, filter]\n [, ...] [FOR CHANNEL channel]\nfilter: {\n    REPLICATE_DO_DB = (db_list)\n  | REPLICATE_IGNORE_DB = (db_list)\n  | REPLICATE_DO_TABLE = (tbl_list)\n  | REPLICATE_IGNORE_TABLE = (tbl_list)\n  | REPLICATE_WILD_DO_TABLE = (wild_tbl_list)\n  | REPLICATE_WILD_IGNORE_TABLE = (wild_tbl_list)\n  | REPLICATE_REWRITE_DB = (db_pair_list)\n}\ndb_list:\n    db_name[, db_name][, ...]\ntbl_list:\n    db_name.table_name[, db_name.table_name][, ...]\nwild_tbl_list:\n    'db_pattern.table_pattern'[, 'db_pattern.table_pattern'][, ...]\ndb_pair_list:\n    (db_pair)[, (db_pair)][, ...]\ndb_pair:\n    from_db, to_db\nCHANGE REPLICATION FILTER sets one or more replication filtering rules on the replica in the same\nway as starting the replica mysqld with replication filtering options such as --replicate-do-db or\n--replicate-wild-ignore-table. Filters set using this statement differ from those set using the\nserver options in two key respects:\n1. The statement does not require restarting the server to take effect, only that the replication SQL\nthread be stopped using STOP REPLICA SQL_THREAD first (and restarted with START REPLICA\nSQL_THREAD afterwards).\n2. The effects of the statement are not persistent; any filters set using CHANGE REPLICATION\nFILTER are lost following a restart of the replica mysqld.\nCHANGE REPLICATION FILTER requires the REPLICATION_SLAVE_ADMIN privilege (or the\ndeprecated SUPER privilege).\nUse the FOR CHANNEL channel clause to make a replication filter specific to a replication channel,\nfor example on a multi-source replica. Filters applied without a specific FOR CHANNEL clause are\nconsidered global filters, meaning that they are applied to all replication channels.\nNote\nGlobal replication filters cannot be set on a MySQL server instance that is\nconfigured for Group Replication, because filtering transactions on some\nservers would make the group unable to reach agreement on a consistent state.\nChannel specific replication filters can be set on replication channels that are\nnot directly involved with Group Replication, such as where a group member\nalso acts as a replica to a source that is outside the group. They cannot be set\non the group_replication_applier or group_replication_recovery\nchannels.\nThe following list shows the CHANGE REPLICATION FILTER options and how they relate to --\nreplicate-* server options:\n• REPLICATE_DO_DB: Include updates based on database name. Equivalent to --replicate-do-\ndb.\n• REPLICATE_IGNORE_DB: Exclude updates based on database name. Equivalent to --replicate-\nignore-db.\n• REPLICATE_DO_TABLE: Include updates based on table name. Equivalent to --replicate-do-\ntable.\n• REPLICATE_IGNORE_TABLE: Exclude updates based on table name. Equivalent to --replicate-\nignore-table.\n• REPLICATE_WILD_DO_TABLE: Include updates based on wildcard pattern matching table name.\nEquivalent to --replicate-wild-do-table.\n• REPLICATE_WILD_IGNORE_TABLE: Exclude updates based on wildcard pattern matching table\nname. Equivalent to --replicate-wild-ignore-table.\n• REPLICATE_REWRITE_DB: Perform updates on replica after substituting new name on replica for\nspecified database on source. Equivalent to --replicate-rewrite-db.\nThe precise effects of REPLICATE_DO_DB and REPLICATE_IGNORE_DB filters are dependent on\nwhether statement-based or row-based replication is in effect. See Section 19.2.5, “How Servers\nEvaluate Replication Filtering Rules”, for more information.\nMultiple replication filtering rules can be created in a single CHANGE REPLICATION FILTER\nstatement by separating the rules with commas, as shown here:\nCHANGE REPLICATION FILTER\n    REPLICATE_DO_DB = (d1), REPLICATE_IGNORE_DB = (d2);\nIssuing the statement just shown is equivalent to starting the replica mysqld with the options --\nreplicate-do-db=d1 --replicate-ignore-db=d2.\nOn a multi-source replica, which uses multiple replication channels to process transaction from different\nsources, use the FOR CHANNEL channel clause to set a replication filter on a replication channel:\nCHANGE REPLICATION FILTER REPLICATE_DO_DB = (d1) FOR CHANNEL channel_1;\nThis enables you to create a channel specific replication filter to filter out selected data from a source.\nWhen a FOR CHANNEL clause is provided, the replication filter statement acts on that replication\nchannel, removing any existing replication filter which has the same filter type as the specified\nreplication filters, and replacing them with the specified filter. Filter types not explicitly listed in the\nstatement are not modified. If issued against a replication channel which is not configured, the\nstatement fails with an ER_SLAVE_CONFIGURATION error. If issued against Group Replication\nchannels, the statement fails with an ER_SLAVE_CHANNEL_OPERATION_NOT_ALLOWED error.\nOn a replica with multiple replication channels configured, issuing CHANGE REPLICATION FILTER\nwith no FOR CHANNEL clause configures the replication filter for every configured replication channel,\nand for the global replication filters. For every filter type, if the filter type is listed in the statement,\nthen any existing filter rules of that type are replaced by the filter rules specified in the most recently\nissued statement, otherwise the old value of the filter type is retained. For more information see\nSection 19.2.5.4, “Replication Channel Based Filters”.\nIf the same filtering rule is specified multiple times, only the last such rule is actually used.\nFor example, the two statements shown here have exactly the same effect, because the first\nREPLICATE_DO_DB rule in the first statement is ignored:\nCHANGE REPLICATION FILTER\n    REPLICATE_DO_DB = (db1, db2), REPLICATE_DO_DB = (db3, db4);\nCHANGE REPLICATION FILTER\n    REPLICATE_DO_DB = (db3, db4);\nCaution\nThis behavior differs from that of the --replicate-* filter options where\nspecifying the same option multiple times causes the creation of multiple filter\nrules.\nNames of tables and database not containing any special characters need not be quoted. Values used\nwith REPLICATION_WILD_TABLE and REPLICATION_WILD_IGNORE_TABLE are string expressions,\npossibly containing (special) wildcard characters, and so must be quoted. This is shown in the following\nexample statements:\nCHANGE REPLICATION FILTER\n    REPLICATE_WILD_DO_TABLE = ('db1.old%');\nCHANGE REPLICATION FILTER\n    REPLICATE_WILD_IGNORE_TABLE = ('db1.new%', 'db2.new%');\nValues used with REPLICATE_REWRITE_DB represent pairs of database names; each such value\nmust be enclosed in parentheses. The following statement rewrites statements occurring on database\ndb1 on the source to database db2 on the replica:\nCHANGE REPLICATION FILTER REPLICATE_REWRITE_DB = ((db1, db2));\nThe statement just shown contains two sets of parentheses, one enclosing the pair of database names,\nand the other enclosing the entire list. This is perhaps more easily seen in the following example, which\ncreates two rewrite-db rules, one rewriting database dbA to dbB, and one rewriting database dbC to\ndbD:\nCHANGE REPLICATION FILTER\n  REPLICATE_REWRITE_DB = ((dbA, dbB), (dbC, dbD));\nThe CHANGE REPLICATION FILTER statement replaces replication filtering rules only for\nthe filter types and replication channels affected by the statement, and leaves other rules and\nchannels unchanged. If you want to unset all filters of a given type, set the filter's value to an\nexplicitly empty list, as shown in this example, which removes all existing REPLICATE_DO_DB and\nREPLICATE_IGNORE_DB rules:\nCHANGE REPLICATION FILTER\n    REPLICATE_DO_DB = (), REPLICATE_IGNORE_DB = ();\nSetting a filter to empty in this way removes all existing rules, does not create any new ones, and does\nnot restore any rules set at mysqld startup using --replicate-* options on the command line or in\nthe configuration file.\nThe RESET REPLICA ALL statement removes channel specific replication filters that were set on\nchannels deleted by the statement. When the deleted channel or channels are recreated, any global\nreplication filters specified for the replica are copied to them, and no channel specific replication filters\nare applied.\nFor more information, see Section 19.2.5, “How Servers Evaluate Replication Filtering Rules”.\n15.4.2.2 CHANGE REPLICATION SOURCE TO Statement\nCHANGE REPLICATION SOURCE TO option [, option] ... [ channel_option ]\noption: {\n    SOURCE_BIND = 'interface_name'\n  | SOURCE_HOST = 'host_name'\n  | SOURCE_USER = 'user_name'\n  | SOURCE_PASSWORD = 'password'\n  | SOURCE_PORT = port_num\n  | PRIVILEGE_CHECKS_USER = {NULL | 'account'}\n  | REQUIRE_ROW_FORMAT = {0|1}\n  | REQUIRE_TABLE_PRIMARY_KEY_CHECK = {STREAM | ON | OFF | GENERATE}\n  | ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS = {OFF | LOCAL | uuid}\n  | SOURCE_LOG_FILE = 'source_log_name'\n  | SOURCE_LOG_POS = source_log_pos\n  | SOURCE_AUTO_POSITION = {0|1}\n  | RELAY_LOG_FILE = 'relay_log_name'\n  | RELAY_LOG_POS = relay_log_pos\n  | SOURCE_HEARTBEAT_PERIOD = interval\n  | SOURCE_CONNECT_RETRY = interval\n  | SOURCE_RETRY_COUNT = count\n  | SOURCE_CONNECTION_AUTO_FAILOVER = {0|1}\n  | SOURCE_DELAY = interval\n  | SOURCE_COMPRESSION_ALGORITHMS = 'algorithm[,algorithm][,algorithm]'\n  | SOURCE_ZSTD_COMPRESSION_LEVEL = level\n  | SOURCE_SSL = {0|1}\n  | SOURCE_SSL_CA = 'ca_file_name'\n  | SOURCE_SSL_CAPATH = 'ca_directory_name'\n  | SOURCE_SSL_CERT = 'cert_file_name'\n  | SOURCE_SSL_CRL = 'crl_file_name'\n  | SOURCE_SSL_CRLPATH = 'crl_directory_name'\n  | SOURCE_SSL_KEY = 'key_file_name'\n  | SOURCE_SSL_CIPHER = 'cipher_list'\n  | SOURCE_SSL_VERIFY_SERVER_CERT = {0|1}\n  | SOURCE_TLS_VERSION = 'protocol_list'\n  | SOURCE_TLS_CIPHERSUITES = 'ciphersuite_list'\n  | SOURCE_PUBLIC_KEY_PATH = 'key_file_name'\n  | GET_SOURCE_PUBLIC_KEY = {0|1}\n  | NETWORK_NAMESPACE = 'namespace'\n  | IGNORE_SERVER_IDS = (server_id_list),\n  | GTID_ONLY = {0|1}\n}\nchannel_option:\n    FOR CHANNEL channel\nserver_id_list:\n    [server_id [, server_id] ... ]\nCHANGE REPLICATION SOURCE TO changes the parameters that the replica server uses for\nconnecting to the source and reading data from the source. It also updates the contents of the\nreplication metadata repositories (see Section 19.2.4, “Relay Log and Replication Metadata\nRepositories”).\nCHANGE REPLICATION SOURCE TO requires the REPLICATION_SLAVE_ADMIN privilege (or the\ndeprecated SUPER privilege).\nOptions that you do not specify on a CHANGE REPLICATION SOURCE TO statement retain their value,\nexcept as indicated in the following discussion. In most cases, there is therefore no need to specify\noptions that do not change.\nValues used for SOURCE_HOST and other CHANGE REPLICATION SOURCE TO options are checked\nfor linefeed (\\n or 0x0A) characters. The presence of such characters in these values causes the\nstatement to fail with an error.\nThe optional FOR CHANNEL channel clause lets you name which replication channel the statement\napplies to. Providing a FOR CHANNEL channel clause applies the CHANGE REPLICATION SOURCE\nTO statement to a specific replication channel, and is used to add a new channel or modify an existing\nchannel. For example, to add a new channel called channel2:\nCHANGE REPLICATION SOURCE TO SOURCE_HOST=host1, SOURCE_PORT=3002 FOR CHANNEL 'channel2';\nIf no clause is named and no extra channels exist, a CHANGE REPLICATION SOURCE TO statement\napplies to the default channel, whose name is the empty string (\"\"). When you have set up multiple\nreplication channels, every CHANGE REPLICATION SOURCE TO statement must name a channel\nusing the FOR CHANNEL channel clause. See Section 19.2.2, “Replication Channels” for more\ninformation.\nFor some of the options of the CHANGE REPLICATION SOURCE TO statement, you must issue a\nSTOP REPLICA statement prior to issuing a CHANGE REPLICATION SOURCE TO statement (and\na START REPLICA statement afterwards). Sometimes, you only need to stop the replication SQL\n(applier) thread or the replication I/O (receiver) thread, not both:\n• When the applier thread is stopped, you can execute CHANGE REPLICATION SOURCE TO\nusing any combination that is otherwise allowed of RELAY_LOG_FILE, RELAY_LOG_POS, and\nSOURCE_DELAY options, even if the replication receiver thread is running. No other options may be\nused with this statement when the receiver thread is running.\n• When the receiver thread is stopped, you can execute CHANGE REPLICATION SOURCE TO\nusing any of the options for this statement (in any allowed combination) except RELAY_LOG_FILE,\nRELAY_LOG_POS, SOURCE_DELAY, or SOURCE_AUTO_POSITION = 1 even when the applier\nthread is running.\n• Both the receiver thread and the applier thread must be stopped before issuing a CHANGE\nREPLICATION SOURCE TO statement that employs SOURCE_AUTO_POSITION = 1, GTID_ONLY\n= 1, or ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS.\nYou can check the current state of the replication applier thread and replication receiver\nthread using SHOW REPLICA STATUS. Note that the Group Replication applier channel\n(group_replication_applier) has no receiver thread, only an applier thread.\nCHANGE REPLICATION SOURCE TO statements have a number of side-effects and interactions that\nyou should be aware of beforehand:\n• CHANGE REPLICATION SOURCE TO causes an implicit commit of an ongoing transaction. See\nSection 15.3.3, “Statements That Cause an Implicit Commit”.\n• CHANGE REPLICATION SOURCE TO causes the previous values for SOURCE_HOST,\nSOURCE_PORT, SOURCE_LOG_FILE, and SOURCE_LOG_POS to be written to the error log, along with\nother information about the replica's state prior to execution.\n• If you are using statement-based replication and temporary tables, it is possible for a CHANGE\nREPLICATION SOURCE TO statement following a STOP REPLICA statement to leave behind\ntemporary tables on the replica. A warning (ER_WARN_OPEN_TEMP_TABLES_MUST_BE_ZERO) is\nissued whenever this occurs. You can avoid this in such cases by making sure that the value of\nthe Replica_open_temp_tables system status variable is equal to 0 prior to executing such a\nCHANGE REPLICATION SOURCE TO statement.\n• When using a multithreaded replica (replica_parallel_workers > 0), stopping the replica can\ncause gaps in the sequence of transactions that have been executed from the relay log, regardless\nof whether the replica was stopped intentionally or otherwise. In MySQL 9.1, these can be resolved\nusing GTID auto-positioning.\nThe following options are available for CHANGE REPLICATION SOURCE TO statements:\n• ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS = {OFF | LOCAL | uuid}\nMakes the replication channel assign a GTID to replicated transactions that do not have\none, enabling replication from a source that does not use GTID-based replication, to a\nreplica that does. For a multi-source replica, you can have a mix of channels that use\nASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS, and channels that do not. The default is OFF,\nmeaning that the feature is not used.\nLOCAL assigns a GTID including the replica's own UUID (the server_uuid setting). uuid assigns\na GTID including the specified UUID, such as the server_uuid setting for the replication source\nserver. Using a nonlocal UUID lets you differentiate between transactions that originated on the\nreplica and transactions that originated on the source, and for a multi-source replica, between\ntransactions that originated on different sources. The UUID you choose only has significance for the\nreplica's own use. If any of the transactions sent by the source do have a GTID already, that GTID is\nretained.\nChannels specific to Group Replication cannot use\nASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS, but an asynchronous replication channel for\nanother source on a server instance that is a Group Replication group member can do so. In that\ncase, do not specify the Group Replication group name as the UUID for creating the GTIDs.\nTo set ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS to LOCAL or uuid, the replica must have\ngtid_mode=ON set, and this cannot be changed afterwards. This option is for use with a source that\nhas binary log file position based replication, so SOURCE_AUTO_POSITION=1 cannot be set for the\nchannel. Both the replication SQL thread and the replication I/O (receiver) thread must be stopped\nbefore setting this option.\nImportant\nA replica set up with ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS\non any channel cannot be promoted to replace the replication source\nserver in the event that a failover is required, and a backup taken from\nthe replica cannot be used to restore the replication source server. The\nsame restriction applies to replacing or restoring other replicas that use\nASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS on any channel.\nFor further restrictions and information, see Section 19.1.3.6, “Replication From a Source Without\nGTIDs to a Replica With GTIDs”.\n• GET_SOURCE_PUBLIC_KEY = {0|1}\nEnables RSA key pair-based password exchange by requesting the public key from the source. The\noption is disabled by default.\nThis option applies to replicas that authenticate with the caching_sha2_password authentication\nplugin. For connections by accounts that authenticate using this plugin, the source does not\nsend the public key unless requested, so it must be requested or specified in the client. If\nSOURCE_PUBLIC_KEY_PATH is given and specifies a valid public key file, it takes precedence over\nGET_SOURCE_PUBLIC_KEY. If you are using a replication user account that authenticates with the\ncaching_sha2_password plugin (the default), and you are not using a secure connection, you\nmust specify either this option or the SOURCE_PUBLIC_KEY_PATH option to provide the RSA public\nkey to the replica.\n• GTID_ONLY = {0|1}\nStops the replication channel persisting file names and file positions in the replication metadata\nrepositories. GTID_ONLY is disabled by default for asynchronous replication channels, but is enabled\nby default for Group Replication channels, for which it cannot be disabled.\nFor replication channels with this setting, in-memory file positions are still tracked, and file positions\ncan still be observed for debugging purposes in error messages and through interfaces such as\nSHOW REPLICA STATUS statements (where they are shown as being invalid if they are out of\ndate). However, the writes and reads required to persist and check the file positions are avoided in\nsituations where GTID-based replication does not actually require them, including the transaction\nqueuing and application process.\nThis option can be used only if both the replication SQL (applier) thread and replication I/O (receiver)\nthread are stopped. To set GTID_ONLY = 1 for a replication channel, GTIDs must be in use\non the server (gtid_mode = ON), and row-based binary logging must be in use on the source\n(statement-based replication is not supported). The options REQUIRE_ROW_FORMAT = 1 and\nSOURCE_AUTO_POSITION = 1 must be set for the replication channel.\nWhen GTID_ONLY = 1 is set, the replica uses replica_parallel_workers=1 if that system\nvariable is set to zero for the server, so it is always technically a multi-threaded applier. This\nis because a multi-threaded applier uses saved positions rather than the replication metadata\nrepositories to locate the start of a transaction that it needs to reapply.\nIf you disable GTID_ONLY after setting it, the existing relay logs are deleted and the existing known\nbinary log file positions are persisted, even if they are stale. The file positions for the binary log and\nrelay log in the replication metadata repositories might be invalid, and a warning is returned if this is\nthe case. Provided that SOURCE_AUTO_POSITION is still enabled, GTID auto-positioning is used to\nprovide the correct positioning.\nIf you also disable SOURCE_AUTO_POSITION, the file positions for the binary log and relay log in\nthe replication metadata repositories are used for positioning if they are valid. If they are marked\nas invalid, you must provide a valid binary log file name and position (SOURCE_LOG_FILE and\nSOURCE_LOG_POS). If you also provide a relay log file name and position (RELAY_LOG_FILE and\nRELAY_LOG_POS), the relay logs are preserved and the applier position is set to the stated position.\nGTID auto-skip ensures that any transactions already applied are skipped even if the eventual\napplier position is not correct.\n• IGNORE_SERVER_IDS = (server_id_list)\nMakes the replica ignore events originating from the specified servers. The option takes a comma-\nseparated list of 0 or more server IDs. Log rotation and deletion events from the servers are not\nignored, and are recorded in the relay log.\nIn circular replication, the originating server normally acts as the terminator of its own events, so that\nthey are not applied more than once. Thus, this option is useful in circular replication when one of the\nservers in the circle is removed. Suppose that you have a circular replication setup with 4 servers,\nhaving server IDs 1, 2, 3, and 4, and server 3 fails. When bridging the gap by starting replication from\nserver 2 to server 4, you can include IGNORE_SERVER_IDS = (3) in the CHANGE REPLICATION\nSOURCE TO statement that you issue on server 4 to tell it to use server 2 as its source instead of\nserver 3. Doing so causes it to ignore and not to propagate any statements that originated with the\nserver that is no longer in use.\nIf IGNORE_SERVER_IDS contains the server's own ID and the server was started with the --\nreplicate-same-server-id option enabled, an error results.\nThe source metadata repository and the output of SHOW REPLICA STATUS provide the list of\nservers that are currently ignored. For more information, see Section 19.2.4.2, “Replication Metadata\nRepositories”, and Section 15.7.7.34, “SHOW REPLICA STATUS Statement”.\nIf a CHANGE REPLICATION SOURCE TO statement is issued without IGNORE_SERVER_IDS, any\nexisting list is preserved. To clear the list of ignored servers, it is necessary to use the option with an\nempty list, like this:\nCHANGE REPLICATION SOURCE TO IGNORE_SERVER_IDS = ();\nRESET REPLICA ALL also clears IGNORE_SERVER_IDS.\nWhen global transaction identifiers (GTIDs) are used for replication, transactions that have already\nbeen applied are automatically ignored. Because of this, IGNORE_SERVER_IDS is not compatible\nwith gtid_mode=ON. If gtid_mode is ON, CHANGE REPLICATION SOURCE TO with a non-empty\nIGNORE_SERVER_IDS list is rejected with an error. Likewise, if any existing replication channel was\ncreated with a list of server IDs to be ignored, SET gtid_mode=ON is also rejected. Before starting\nGTID-based replication, check for and clear any ignored server ID lists on the servers involved; you\ncan do this by checking the output from SHOW REPLICA STATUS. In such cases, you can clear\nthe list by issuing CHANGE REPLICATION SOURCE TO with an empty list of server IDs as shown\npreviously.\n• NETWORK_NAMESPACE = 'namespace'\nThe network namespace to use for TCP/IP connections to the replication source server or, if the\nMySQL communication stack is in use, for Group Replication’s group communication connections.\nThe maximum length of the string value is 64 characters. If this option is omitted, connections\nfrom the replica use the default (global) namespace. On platforms that do not implement network\nnamespace support, failure occurs when the replica attempts to connect to the source. For\ninformation about network namespaces, see Section 7.1.14, “Network Namespace Support”.\n• PRIVILEGE_CHECKS_USER = {NULL | 'account'}\nNames a user account that supplies a security context for the specified channel. NULL, which is the\ndefault, means no security context is used.\nThe user name and host name for the user account must follow the syntax described in\nSection 8.2.4, “Specifying Account Names”, and the user must not be an anonymous user (with a\nblank user name) or the CURRENT_USER. The account must have the REPLICATION_APPLIER\nprivilege, plus the required privileges to execute the transactions replicated on the channel. For\ndetails of the privileges required by the account, see Section 19.3.3, “Replication Privilege Checks”.\nWhen you restart the replication channel, the privilege checks are applied from that point on. If you\ndo not specify a channel and no other channels exist, the statement is applied to the default channel.\nThe use of row-based binary logging is strongly recommended when PRIVILEGE_CHECKS_USER is\nset, and you can set REQUIRE_ROW_FORMAT to enforce this. For example, to start privilege checks\non the channel channel_1 on a running replica, issue the following statements:\nSTOP REPLICA FOR CHANNEL 'channel_1';\nCHANGE REPLICATION SOURCE TO\n    PRIVILEGE_CHECKS_USER = 'user'@'host',\n    REQUIRE_ROW_FORMAT = 1,\n    FOR CHANNEL 'channel_1';\nSTART REPLICA FOR CHANNEL 'channel_1';\n• RELAY_LOG_FILE = 'relay_log_file' , RELAY_LOG_POS = 'relay_log_pos'\nThe relay log file name, and the location in that file, at which the replication SQL thread begins\nreading from the replica's relay log the next time the thread starts. RELAY_LOG_FILE can use either\nan absolute or relative path, and uses the same base name as SOURCE_LOG_FILE. The maximum\nlength of the string value is 511 characters.\nA CHANGE REPLICATION SOURCE TO statement using RELAY_LOG_FILE, RELAY_LOG_POS,\nor both options can be executed on a running replica when the replication SQL (applier) thread is\nstopped. Relay logs are preserved if at least one of the replication applier thread and the replication\nI/O (receiver) thread is running. If both threads are stopped, all relay log files are deleted unless at\nleast one of RELAY_LOG_FILE or RELAY_LOG_POS is specified. For the Group Replication applier\nchannel (group_replication_applier), which only has an applier thread and no receiver\nthread, this is the case if the applier thread is stopped, but with that channel you cannot use the\nRELAY_LOG_FILE and RELAY_LOG_POS options.\n• REQUIRE_ROW_FORMAT = {0|1}\nPermits only row-based replication events to be processed by the replication channel. This\noption prevents the replication applier from taking actions such as creating temporary tables\nand executing LOAD DATA INFILE requests, which increases the security of the channel. The\nREQUIRE_ROW_FORMAT option is disabled by default for asynchronous replication channels, but it\nis enabled by default for Group Replication channels, and it cannot be disabled for them. For more\ninformation, see Section 19.3.3, “Replication Privilege Checks”.\n• REQUIRE_TABLE_PRIMARY_KEY_CHECK = {STREAM | ON | OFF | GENERATE}\nThis option lets a replica set its own policy for primary key checks, as follows:\n• ON: The replica sets sql_require_primary_key = ON; any replicated CREATE TABLE or\nALTER TABLE statement must result in a table that contains a primary key.\n• OFF: The replica sets sql_require_primary_key = OFF; no replicated CREATE TABLE or\nALTER TABLE statement is checked for the presence of a primary key.\n• STREAM: The replica uses whatever value of sql_require_primary_key is replicated from the\nsource for each transaction. This is the default value, and the default behavior.\n• GENERATE: Causes the replica to generate an invisible primary key for any InnoDB table that, as\nreplicated, lacks a primary key. See Section 15.1.20.11, “Generated Invisible Primary Keys”, for\nmore information.\nGENERATE is not compatible with Group Replication; you can use ON, OFF, or STREAM.\nA divergence based on the presence of a generated invisible primary key solely on a source or\nreplica table is supported by MySQL Replication as long as the source supports GIPKs and the\nreplica uses MySQL version 8.0.32 or later. If you use GIPKs on a replica with the source using an\nearlier version of MySQL, such divergences in schema, other than the extra GIPK on the replica, are\nnot supported and may result in replication errors.\nFor multisource replication, setting REQUIRE_TABLE_PRIMARY_KEY_CHECK to ON or OFF lets the\nreplica normalize behavior across replication channels for different sources, and to keep a consistent\nsetting for sql_require_primary_key. Using ON safeguards against the accidental loss of\nprimary keys when multiple sources update the same set of tables. Using OFF lets sources that can\nmanipulate primary keys to work alongside sources that cannot.\nIn the case of multiple replicas, when REQUIRE_TABLE_PRIMARY_KEY_CHECK is set to GENERATE,\nthe generated invisible primary key added by a given replica is independent of any such key added\non any other replica. This means that, if generated invisible primary keys are in use, the values in the\ngenerated primary key columns on different replicas are not guaranteed to be the same. This may be\nan issue when failing over to such a replica.\nWhen PRIVILEGE_CHECKS_USER is NULL (the default), the user account does not need\nadministration level privileges to set restricted session variables. Setting this option to a value other\nthan NULL means that, when REQUIRE_TABLE_PRIMARY_KEY_CHECK is ON, OFF, or GENERATE,\nthe user account does not require session administration level privileges to set restricted session\nvariables such as sql_require_primary_key, avoiding the need to grant the account such\nprivileges. For more information, see Section 19.3.3, “Replication Privilege Checks”.\n• SOURCE_AUTO_POSITION = {0|1}\nMakes the replica attempt to connect to the source using the auto-positioning feature of GTID-based\nreplication, rather than a binary log file based position. This option is used to start a replica using\nGTID-based replication. The default is 0, meaning that GTID auto-positioning and GTID-based\nreplication are not used. This option can be used with CHANGE REPLICATION SOURCE TO only if\nboth the replication SQL (applier) thread and replication I/O (receiver) thread are stopped.\nBoth the replica and the source must have GTIDs enabled (GTID_MODE=ON, ON_PERMISSIVE,\nor OFF_PERMISSIVE on the replica, and GTID_MODE=ON on the source). SOURCE_LOG_FILE,\nSOURCE_LOG_POS, RELAY_LOG_FILE, and RELAY_LOG_POS cannot be specified together with\nSOURCE_AUTO_POSITION = 1. If multi-source replication is enabled on the replica, you need to set\nthe SOURCE_AUTO_POSITION = 1 option for each applicable replication channel.\nWith SOURCE_AUTO_POSITION = 1 set, in the initial connection handshake, the replica sends a\nGTID set containing the transactions that it has already received, committed, or both. The source\nresponds by sending all transactions recorded in its binary log whose GTID is not included in the\nGTID set sent by the replica. This exchange ensures that the source only sends the transactions with\na GTID that the replica has not already recorded or committed. If the replica receives transactions\nfrom more than one source, as in the case of a diamond topology, the auto-skip function ensures\nthat the transactions are not applied twice. For details of how the GTID set sent by the replica is\ncomputed, see Section 19.1.3.3, “GTID Auto-Positioning”.\nIf any of the transactions that should be sent by the source have been purged from the source's\nbinary log, or added to the set of GTIDs in the gtid_purged system variable by another method,\nthe source sends the error ER_SOURCE_HAS_PURGED_REQUIRED_GTIDS to the replica, and\nreplication does not start. The GTIDs of the missing purged transactions are identified and listed\nin the source's error log in the warning message ER_FOUND_MISSING_GTIDS. Also, if during the\nexchange of transactions it is found that the replica has recorded or committed transactions with the\nsource's UUID in the GTID, but the source itself has not committed them, the source sends the error\nER_REPLICA_HAS_MORE_GTIDS_THAN_SOURCE to the replica and replication does not start. For\ninformation on how to handle these situations, see Section 19.1.3.3, “GTID Auto-Positioning”.\nYou can see whether replication is running with GTID auto-positioning enabled by checking the\nPerformance Schema replication_connection_status table or the output of SHOW REPLICA\nSTATUS. Disabling the SOURCE_AUTO_POSITION option again makes the replica revert to file-based\nreplication.\n• SOURCE_BIND = 'interface_name'\nDetermines which of the replica's network interfaces is chosen for connecting to the source, for use\non replicas that have multiple network interfaces. Specify the IP address of the network interface.\nThe maximum length of the string value is 255 characters.\nThe IP address configured with this option, if any, can be seen in the Source_Bind column\nof the output from SHOW REPLICA STATUS. In the source metadata repository table\nmysql.slave_master_info, the value can be seen as the Source_bind column. The ability to\nbind a replica to a specific network interface is also supported by NDB Cluster.\n• SOURCE_COMPRESSION_ALGORITHMS = 'algorithm[,algorithm][,algorithm]'\nSpecifies one, two, or three of the permitted compression algorithms for connections to the\nreplication source server, separated by commas. The maximum length of the string value is 99\ncharacters. The default value is uncompressed.\nThe available algorithms are zlib, zstd, and uncompressed, the same as for the\nprotocol_compression_algorithms system variable. The algorithms can be specified in any\norder, but it is not an order of preference - the algorithm negotiation process attempts to use zlib,\nthen zstd, then uncompressed, if they are specified.\nThe value of SOURCE_COMPRESSION_ALGORITHMS applies only if the\nreplica_compressed_protocol system variable is disabled. If\nreplica_compressed_protocol is enabled, it takes precedence over\nSOURCE_COMPRESSION_ALGORITHMS and connections to the source use zlib compression if\nboth source and replica support that algorithm. For more information, see Section 6.2.8, “Connection\nCompression Control”.\nBinary log transaction compression is activated by the binlog_transaction_compression\nsystem variable, and can also be used to save bandwidth. If you do this in combination with\nconnection compression, connection compression has less opportunity to act on the data, but can\nstill compress headers and those events and transaction payloads that are uncompressed. For more\ninformation on binary log transaction compression, see Section 7.4.4.5, “Binary Log Transaction\nCompression”.\n• SOURCE_CONNECT_RETRY = interval\nSpecifies the interval in seconds between the reconnection attempts that the replica makes after the\nconnection to the source times out. The default interval is 60.\nThe number of attempts is limited by the SOURCE_RETRY_COUNT option. If both the\ndefault settings are used, the replica waits 60 seconds between reconnection attempts\n(SOURCE_CONNECT_RETRY=60), and keeps attempting to reconnect at this rate for 10 minutes\n(SOURCE_RETRY_COUNT=10). These values are recorded in the source metadata repository and\nshown in the replication_connection_configuration Performance Schema table.\n• SOURCE_CONNECTION_AUTO_FAILOVER = {0|1}\nActivates the asynchronous connection failover mechanism for a replication channel if one or more\nalternative replication source servers are available (so when there are multiple MySQL servers or\ngroups of servers that share the replicated data). The default is 0, meaning that the mechanism\nis not activated. For full information and instructions to set up this feature, see Section 19.4.9.2,\n“Asynchronous Connection Failover for Replicas”.\nThe asynchronous connection failover mechanism takes over after the reconnection attempts\ncontrolled by SOURCE_CONNECT_RETRY and SOURCE_RETRY_COUNT are exhausted. It\nreconnects the replica to an alternative source chosen from a specified source list, which you\ncan manage using the functions asynchronous_connection_failover_add_source()\nand asynchronous_connection_failover_delete_source(). To add and remove\nmanaged groups of servers, use asynchronous_connection_failover_add_managed() and\nasynchronous_connection_failover_delete_managed() instead. For more information,\nsee Section 19.4.9, “Switching Sources and Replicas with Asynchronous Connection Failover”.\nImportant\n1. You can only set SOURCE_CONNECTION_AUTO_FAILOVER = 1 when\nGTID auto-positioning is in use (SOURCE_AUTO_POSITION = 1).\n2. When you set SOURCE_CONNECTION_AUTO_FAILOVER = 1, set\nSOURCE_RETRY_COUNT and SOURCE_CONNECT_RETRY to minimal\nnumbers that just allow a few retry attempts with the same source, in\ncase the connection failure is caused by a transient network outage.\nOtherwise the asynchronous connection failover mechanism cannot\nbe activated promptly. Suitable values are SOURCE_RETRY_COUNT=3\nand SOURCE_CONNECT_RETRY=10, which make the replica retry the\nconnection 3 times with 10-second intervals between.\n3. When you set SOURCE_CONNECTION_AUTO_FAILOVER = 1, the\nreplication metadata repositories must contain the credentials for a\nreplication user account that can be used to connect to all the servers\non the source list for the replication channel. The account must also\nhave SELECT permissions on the Performance Schema tables. These\ncredentials can be set using the CHANGE REPLICATION SOURCE TO\nstatement with the SOURCE_USER and SOURCE_PASSWORD options. For\nmore information, see Section 19.4.9, “Switching Sources and Replicas\nwith Asynchronous Connection Failover”.\n4. When you set SOURCE_CONNECTION_AUTO_FAILOVER = 1,\nasynchronous connection failover for replicas is automatically activated\nif this replication channel is on a Group Replication primary in a group\nin single-primary mode. With this function active, if the primary that is\nreplicating goes offline or into an error state, the new primary starts\nreplication on the same channel when it is elected. If you want to use the\nfunction, this replication channel must also be set up on all the secondary\nservers in the replication group, and on any new joining members. (If\nthe servers are provisioned using MySQL’s clone functionality, this all\nhappens automatically.) If you do not want to use the function, disable\nit by using the group_replication_disable_member_action()\nfunction to disable the Group Replication member action\nmysql_start_failover_channels_if_primary, which is enabled\nby default. For more information, see Section 19.4.9.2, “Asynchronous\nConnection Failover for Replicas”.\n• SOURCE_DELAY = interval\nSpecifies how many seconds behind the source the replica must lag. An event received from the\nsource is not executed until at least interval seconds later than its execution on the source.\ninterval must be a nonnegative integer in the range from 0 to 231−1. The default is 0. For more\ninformation, see Section 19.4.11, “Delayed Replication”.\nA CHANGE REPLICATION SOURCE TO statement using the SOURCE_DELAY option can be\nexecuted on a running replica when the replication SQL thread is stopped.\n• SOURCE_HEARTBEAT_PERIOD = interval\nControls the heartbeat interval, which stops the connection timeout occurring in the absence of data\nif the connection is still good. A heartbeat signal is sent to the replica after that number of seconds,\nand the waiting period is reset whenever the source's binary log is updated with an event. Heartbeats\nare therefore sent by the source only if there are no unsent events in the binary log file for a period\nlonger than this.\nThe heartbeat interval interval is a decimal value having the range 0 to 4294967 seconds\nand a resolution in milliseconds; the smallest nonzero value is 0.001. Setting interval\nto 0 disables heartbeats altogether. The heartbeat interval defaults to half the value of the\nreplica_net_timeout system variable. It is recorded in the source metadata repository and\nshown in the replication_connection_configuration Performance Schema table.\nThe replica_net_timeout system variable specifies the number of seconds that the replica\nwaits for either more data or a heartbeat signal from the source, before the replica considers\nthe connection broken, aborts the read, and tries to reconnect. The default value is 60 seconds\n(one minute). Note that a change to the value or default setting of replica_net_timeout\ndoes not automatically change the heartbeat interval, whether that has been set explicitly\nor is using a previously calculated default. A warning is issued if you set the global value\nof replica_net_timeout to a value less than that of the current heartbeat interval. If\nreplica_net_timeout is changed, you must also issue CHANGE REPLICATION SOURCE TO\nto adjust the heartbeat interval to an appropriate value so that the heartbeat signal occurs before\nthe connection timeout. If you do not do this, the heartbeat signal has no effect, and if no data is\nreceived from the source, the replica can make repeated reconnection attempts, creating zombie\ndump threads.\n• SOURCE_HOST = 'host_name'\nThe host name or IP address of the replication source server. The replica uses this to connect to the\nsource. The maximum length of the string value is 255 characters.\nIf you specify SOURCE_HOST or SOURCE_PORT, the replica assumes that the source server is\ndifferent from before (even if the option value is the same as its current value.) In this case,\nthe old values for the source's binary log file name and position are considered no longer\napplicable, so if you do not specify SOURCE_LOG_FILE and SOURCE_LOG_POS in the statement,\nSOURCE_LOG_FILE='' and SOURCE_LOG_POS=4 are silently appended to it.\nSetting SOURCE_HOST='' (that is, setting its value explicitly to an empty string) is not the same as\nnot setting SOURCE_HOST at all. Trying to set SOURCE_HOST to an empty string fails with an error.\n• SOURCE_LOG_FILE = 'source_log_name', SOURCE_LOG_POS = source_log_pos\nThe binary log file name, and the location in that file, at which the replication I/O (receiver) thread\nbegins reading from the source's binary log the next time the thread starts. Specify these options if\nyou are using binary log file position based replication.\nSOURCE_LOG_FILE must include the numeric suffix of a specific binary log file that is available on\nthe source server, for example, SOURCE_LOG_FILE='binlog.000145'. The maximum length of\nthe string value is 511 characters.\nSOURCE_LOG_POS is the numeric position for the replica to start reading in that file.\nSOURCE_LOG_POS=4 represents the start of the events in a binary log file.\nIf you specify either of SOURCE_LOG_FILE or SOURCE_LOG_POS, you cannot specify\nSOURCE_AUTO_POSITION = 1, which is for GTID-based replication.\nIf neither of SOURCE_LOG_FILE or SOURCE_LOG_POS is specified, the replica uses the last\ncoordinates of the replication SQL thread before CHANGE REPLICATION SOURCE TO was issued.\nThis ensures that there is no discontinuity in replication, even if the replication SQL (applier) thread\nwas late compared to the replication I/O (receiver) thread.\n• SOURCE_PASSWORD = 'password'\nThe password for the replication user account to use for connecting to the replication source server.\nThe maximum length of the string value is 32 characters. If you specify SOURCE_PASSWORD,\nSOURCE_USER is also required.\nThe password used for a replication user account in a CHANGE REPLICATION SOURCE TO\nstatement is limited to 32 characters in length. Trying to use a password of more than 32 characters\ncauses CHANGE REPLICATION SOURCE TO to fail.\nThe password is masked in MySQL Server’s logs, Performance Schema tables, and SHOW\nPROCESSLIST statements.\n• SOURCE_PORT = port_num\nThe TCP/IP port number that the replica uses to connect to the replication source server.\nNote\nReplication cannot use Unix socket files. You must be able to connect to the\nreplication source server using TCP/IP.\nIf you specify SOURCE_HOST or SOURCE_PORT, the replica assumes that the source server is\ndifferent from before (even if the option value is the same as its current value.) In this case,\nthe old values for the source's binary log file name and position are considered no longer\napplicable, so if you do not specify SOURCE_LOG_FILE and SOURCE_LOG_POS in the statement,\nSOURCE_LOG_FILE='' and SOURCE_LOG_POS=4 are silently appended to it.\n• SOURCE_PUBLIC_KEY_PATH = 'key_file_name'\nEnables RSA key pair-based password exchange by providing the path name to a file containing\na replica-side copy of the public key required by the source. The file must be in PEM format. The\nmaximum length of the string value is 511 characters.\nThis option applies to replicas that authenticate with the sha256_password or\ncaching_sha2_password authentication plugin. (For sha256_password,\nSOURCE_PUBLIC_KEY_PATH can be used only if MySQL was built using OpenSSL.) If you are\nusing a replication user account that authenticates with the caching_sha2_password plugin\n(the default), and you are not using a secure connection, you must specify either this option or the\nGET_SOURCE_PUBLIC_KEY=1 option to provide the RSA public key to the replica.\n• SOURCE_RETRY_COUNT = count\nSets the maximum number of reconnection attempts that the replica makes after the connection\nto the source times out, as determined by the replica_net_timeout system variable. If the\nreplica does need to reconnect, the first retry occurs immediately after the timeout. The default is 10\nattempts.\nThe interval between the attempts is specified by the SOURCE_CONNECT_RETRY option. If both\nthe default settings are used, the replica waits 60 seconds between reconnection attempts\n(SOURCE_CONNECT_RETRY=60), and keeps attempting to reconnect at this rate for 10 minutes\n(SOURCE_RETRY_COUNT=10). A setting of 0 for SOURCE_RETRY_COUNT means that there is no limit\non the number of reconnection attempts, so the replica keeps trying to reconnect indefinitely.\nThe values for SOURCE_CONNECT_RETRY and SOURCE_RETRY_COUNT are recorded in the source\nmetadata repository and shown in the replication_connection_configuration Performance\nSchema table. SOURCE_RETRY_COUNT supersedes the --master-retry-count server startup\noption.\n• SOURCE_SSL = {0|1}\nSpecify whether the replica encrypts the replication connection. The default is 0, meaning that the\nreplica does not encrypt the replication connection. If you set SOURCE_SSL=1, you can configure the\nencryption using the SOURCE_SSL_xxx and SOURCE_TLS_xxx options.\nSetting SOURCE_SSL=1 for a replication connection and then setting no further SOURCE_SSL_xxx\noptions corresponds to setting --ssl-mode=REQUIRED for the client, as described in Command\nOptions for Encrypted Connections. With SOURCE_SSL=1, the connection attempt only succeeds\nif an encrypted connection can be established. A replication connection does not fall back to an\nunencrypted connection, so there is no setting corresponding to the --ssl-mode=PREFERRED\nsetting for replication. If SOURCE_SSL=0 is set, this corresponds to --ssl-mode=DISABLED.\nImportant\nTo help prevent sophisticated man-in-the-middle attacks, it is important\nfor the replica to verify the server’s identity. You can specify additional\nSOURCE_SSL_xxx options to correspond to the settings --ssl-\nmode=VERIFY_CA and --ssl-mode=VERIFY_IDENTITY, which are a\nbetter choice than the default setting to help prevent this type of attack. With\nthese settings, the replica checks that the server’s certificate is valid, and\nchecks that the host name the replica is using matches the identity in the\nserver’s certificate. To implement one of these levels of verification, you must\nfirst ensure that the CA certificate for the server is reliably available to the\nreplica, otherwise availability issues will result. For this reason, they are not\nthe default setting.\n• SOURCE_SSL_xxx, SOURCE_TLS_xxx\nSpecify how the replica uses encryption and ciphers to secure the replication connection. These\noptions can be changed even on replicas that are compiled without SSL support. They are saved to\nthe source metadata repository, but are ignored if the replica does not have SSL support enabled.\nThe maximum length of the value for the string-valued SOURCE_SSL_xxx and SOURCE_TLS_xxx\noptions is 511 characters, with the exception of SOURCE_TLS_CIPHERSUITES, for which it is 4000\ncharacters.\nThe SOURCE_SSL_xxx and SOURCE_TLS_xxx options perform the same functions as the --\nssl-xxx and --tls-xxx client options described in Command Options for Encrypted Connections.\nThe correspondence between the two sets of options, and the use of the SOURCE_SSL_xxx and\nSOURCE_TLS_xxx options to set up a secure connection, is explained in Section 19.3.1, “Setting Up\nReplication to Use Encrypted Connections”.\n• SOURCE_USER = 'user_name'\nThe user name for the replication user account to use for connecting to the replication source server.\nThe maximum length of the string value is 96 characters.\nFor Group Replication, this account must exist on every member of the replication group. It is used\nfor distributed recovery if the XCom communication stack is in use for the group, and also used\nfor group communication connections if the MySQL communication stack is in use for the group.\nWith the MySQL communication stack, the account must have the GROUP_REPLICATION_STREAM\npermission.\nIt is possible to set an empty user name by specifying SOURCE_USER='', but the replication channel\ncannot be started with an empty user name. It is valid to set an empty SOURCE_USER user name\nand use the channel afterwards if you always provide user credentials using the START REPLICA\nstatement or START GROUP_REPLICATION statement that starts the replication channel. This\napproach means that the replication channel always needs operator intervention to restart, but the\nuser credentials are not recorded in the replication metadata repositories.\nImportant\nTo connect to the source using a replication user account that authenticates\nwith the caching_sha2_password plugin, you must either set up a secure\nconnection as described in Section 19.3.1, “Setting Up Replication to Use\nEncrypted Connections”, or enable the unencrypted connection to support\npassword exchange using an RSA key pair. The caching_sha2_password\nauthentication plugin is the default for new users (see Section 8.4.1.1,\n“Caching SHA-2 Pluggable Authentication”). If the user account that you\ncreate or use for replication uses this authentication plugin, and you are not\nusing a secure connection, you must enable RSA key pair-based password\nexchange for a successful connection. You can do this using either the\nSOURCE_PUBLIC_KEY_PATH option or the GET_SOURCE_PUBLIC_KEY=1\noption for this statement.\n• SOURCE_ZSTD_COMPRESSION_LEVEL = level\nThe compression level to use for connections to the replication source server that use the zstd\ncompression algorithm. The permitted levels are from 1 to 22, with larger values indicating increasing\nlevels of compression. The default level is 3.\nThe compression level setting has no effect on connections that do not use zstd compression. For\nmore information, see Section 6.2.8, “Connection Compression Control”.\nExamples\nCHANGE REPLICATION SOURCE TO is useful for setting up a replica when you have the\nsnapshot of the source and have recorded the source's binary log coordinates corresponding\nto the time of the snapshot. After loading the snapshot into the replica to synchronize it with the\nsource, you can run CHANGE REPLICATION SOURCE TO SOURCE_LOG_FILE='log_name',\nSOURCE_LOG_POS=log_pos on the replica to specify the coordinates at which the replica should\nbegin reading the source's binary log. The following example changes the source server the replica\nuses and establishes the source's binary log coordinates from which the replica begins reading:\nCHANGE REPLICATION SOURCE TO\n  SOURCE_HOST='source2.example.com',\n  SOURCE_USER='replication',\n  SOURCE_PASSWORD='password',\n  SOURCE_PORT=3306,\n  SOURCE_LOG_FILE='source2-bin.001',\n  SOURCE_LOG_POS=4,\n  SOURCE_CONNECT_RETRY=10;\nFor the procedure to switch an existing replica to a new source during failover, see Section 19.4.8,\n“Switching Sources During Failover”.\nWhen GTIDs are in use on the source and the replica, specify GTID auto-positioning instead of giving\nthe binary log file position, as in the following example. For full instructions to configure and start GTID-\nbased replication on new or stopped servers, online servers, or additional replicas, see Section 19.1.3,\n“Replication with Global Transaction Identifiers”.\nCHANGE REPLICATION SOURCE TO\n  SOURCE_HOST='source3.example.com',\n  SOURCE_USER='replication',\n  SOURCE_PASSWORD='password',\n  SOURCE_PORT=3306,\n  SOURCE_AUTO_POSITION = 1,\n  FOR CHANNEL \"source_3\";\nIn this example, multi-source replication is in use, and the CHANGE REPLICATION SOURCE TO\nstatement is applied to the replication channel \"source_3\" that connects the replica to the specified\nhost. For guidance on setting up multi-source replication, see Section 19.1.5, “MySQL Multi-Source\nReplication”.\nThe next example shows how to make the replica apply transactions from relay log files that you\nwant to repeat. To do this, the source need not be reachable. You can use CHANGE REPLICATION\nSOURCE TO to locate the relay log position where you want the replica to start reapplying transactions,\nand then start the SQL thread:\nCHANGE REPLICATION SOURCE TO\n  RELAY_LOG_FILE='replica-relay-bin.006',\n  RELAY_LOG_POS=4025;\nSTART REPLICA SQL_THREAD;\nCHANGE REPLICATION SOURCE TO can also be used to skip over transactions in the binary log that\nare causing replication to stop. The appropriate method to do this depends on whether GTIDs are in\nuse or not. For instructions to skip transactions using CHANGE REPLICATION SOURCE TO or another\nmethod, see Section 19.1.7.3, “Skipping Transactions”.\n15.4.2.3 RESET REPLICA Statement\nRESET REPLICA [ALL] [channel_option]\nchannel_option:\n    FOR CHANNEL channel\nRESET REPLICA makes the replica forget its position in the source's binary log.\nThis statement is meant to be used for a clean start; it clears the replication metadata repositories,\ndeletes all the relay log files, and starts a new relay log file. It also resets to 0 the replication delay\nspecified with the SOURCE_DELAY option of the CHANGE REPLICATION SOURCE TO statement.\nNote\nAll relay log files are deleted, even if they have not been completely executed\nby the replication SQL thread. (This is a condition likely to exist on a replica if\nyou have issued a STOP REPLICA statement or if the replica is highly loaded.)\nFor a server where GTIDs are in use (gtid_mode is ON), issuing RESET REPLICA has no effect\non the GTID execution history. The statement does not change the values of gtid_executed or\ngtid_purged, or the mysql.gtid_executed table. If you need to reset the GTID execution history,\nuse RESET BINARY LOGS AND GTIDS, even if the GTID-enabled server is a replica where binary\nlogging is disabled.\nRESET REPLICA requires the RELOAD privilege.\nTo use RESET REPLICA, the replication SQL thread and replication I/O (receiver) thread must be\nstopped, so on a running replica use STOP REPLICA before issuing RESET REPLICA. To use RESET\nREPLICA on a Group Replication group member, the member status must be OFFLINE, meaning that\nthe plugin is loaded but the member does not currently belong to any group. A group member can be\ntaken offline by using a STOP GROUP REPLICATION statement.\nThe optional FOR CHANNEL channel clause enables you to name which replication channel the\nstatement applies to. Providing a FOR CHANNEL channel clause applies the RESET REPLICA\nstatement to a specific replication channel. Combining a FOR CHANNEL channel clause with the ALL\noption deletes the specified channel. If no channel is named and no extra channels exist, the statement\napplies to the default channel. Issuing a RESET REPLICA ALL statement without a FOR CHANNEL\nchannel clause when multiple replication channels exist deletes all replication channels and recreates\nonly the default channel. See Section 19.2.2, “Replication Channels” for more information.\nRESET REPLICA does not change any replication connection parameters, which include the source's\nhost name and port, the replication user account and its password, the PRIVILEGE_CHECKS_USER\naccount, the REQUIRE_ROW_FORMAT option, the REQUIRE_TABLE_PRIMARY_KEY_CHECK option,and\nthe ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS option. If you want to change any of the\nreplication connection parameters, you can do this using a CHANGE REPLICATION SOURCE TO\nstatement after the server starts. If you want to remove all of the replication connection parameters,\nuse RESET REPLICA ALL. RESET REPLICA ALL also clears the IGNORE_SERVER_IDS list set by\nCHANGE REPLICATION SOURCE TO. When you have used RESET REPLICA ALL, if you want to use\nthe instance as a replica again, you need to issue a CHANGE REPLICATION SOURCE TO statement\nafter the server start to specify new connection parameters.\nYou can set the GTID_ONLY option on the CHANGE REPLICATION SOURCE TO statement to stop a\nreplication channel from persisting file names and file positions in the replication metadata repositories.\nWhen you issue RESET REPLICA, the replication metadata repositories are synchronized. RESET\nREPLICA ALL deletes rather than updates the repositories, so they are synchronized implicitly.\nIn the event of an unexpected server exit or deliberate restart after issuing RESET REPLICA but before\nissuing START REPLICA, replication connection parameters are preserved in the crash-safe InnoDB\ntables mysql.slave_master_info and mysql.slave_relay_log_info as part of the RESET\nREPLICA operation. They are also retained in memory. In the event of an unexpected server exit or\ndeliberate restart after issuing RESET REPLICA but before issuing START REPLICA, the replication\nconnection parameters are retrieved from the tables and reapplied to the channel. This applies for both\nthe connection and applier metadata repositories.\nRESET REPLICA does not change any replication filter settings (such as --replicate-ignore-\ntable) for channels affected by the statement. However, RESET REPLICA ALL removes the\nreplication filters that were set on the channels deleted by the statement. When the deleted channel or\nchannels are recreated, any global replication filters specified for the replica are copied to them, and no\nchannel specific replication filters are applied. For more information see Section 19.2.5.4, “Replication\nChannel Based Filters”.\nRESET REPLICA causes an implicit commit of an ongoing transaction. See Section 15.3.3,\n“Statements That Cause an Implicit Commit”.\nIf the replication SQL thread was in the middle of replicating temporary tables when it was stopped, and\nRESET REPLICA is issued, these replicated temporary tables are deleted on the replica.\nNote\nWhen used on an NDB Cluster replica SQL node, RESET REPLICA clears the\nmysql.ndb_apply_status table. You should keep in mind when using this\nstatement that ndb_apply_status uses the NDB storage engine and so is\nshared by all SQL nodes attached to the cluster.\nYou can override this behavior by issuing SET GLOBAL\n@@ndb_clear_apply_status=OFF prior to executing RESET REPLICA,\nwhich keeps the replica from purging the ndb_apply_status table in such\ncases.\n15.4.2.4 START REPLICA Statement\nSTART REPLICA [thread_types] [until_option] [connection_options] [channel_option]\nthread_types:\n    [thread_type [, thread_type] ... ]\nthread_type:\n    IO_THREAD | SQL_THREAD\nuntil_option:\n    UNTIL {   {SQL_BEFORE_GTIDS | SQL_AFTER_GTIDS} = gtid_set\n          |   SOURCE_LOG_FILE = 'log_name', SOURCE_LOG_POS = log_pos\n          |   RELAY_LOG_FILE = 'log_name', RELAY_LOG_POS = log_pos\n          |   SQL_AFTER_MTS_GAPS  }\nconnection_options:\n    [USER='user_name'] [PASSWORD='user_pass'] [DEFAULT_AUTH='plugin_name'] [PLUGIN_DIR='plugin_dir']\nchannel_option:\n    FOR CHANNEL channel\ngtid_set:\n    uuid_set [, uuid_set] ...\n    | ''\nuuid_set:\n    uuid:interval[:interval]...\nuuid:\n    hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhhhhhh\nh:\n    [0-9,A-F]\ninterval:\n    n[-n]\n    (n >= 1)\nSTART REPLICA starts the replication threads, either together or separately.\nSTART REPLICA requires the REPLICATION_SLAVE_ADMIN privilege (or the deprecated SUPER\nprivilege). START REPLICA causes an implicit commit of an ongoing transaction. See Section 15.3.3,\n“Statements That Cause an Implicit Commit”.\nFor the thread type options, you can specify IO_THREAD, SQL_THREAD, both of these, or neither of\nthem. Only the threads that are started are affected by the statement.\n• START REPLICA with no thread type options starts all of the replication threads, and so does START\nREPLICA with both of the thread type options.\n• IO_THREAD starts the replication receiver thread, which reads events from the source server and\nstores them in the relay log.\n• SQL_THREAD starts the replication applier thread, which reads events from the relay log and\nexecutes them. A multithreaded replica (with replica_parallel_workers > 0) applies\ntransactions using a coordinator thread and multiple applier threads, and SQL_THREAD starts all of\nthese.\nImportant\nSTART REPLICA sends an acknowledgment to the user after all the replication\nthreads have started. However, the replication receiver thread might not\nyet have connected to the source successfully, or an applier thread might\nstop when applying an event right after starting. START REPLICA does\nnot continue to monitor the threads after they are started, so it does not\nwarn you if they subsequently stop or cannot connect. You must check the\nreplica's error log for error messages generated by the replication threads,\nor check that they are running satisfactorily with SHOW REPLICA STATUS.\nA successful START REPLICA statement causes SHOW REPLICA STATUS\nto show Replica_SQL_Running=Yes, but it might or might not show\nReplica_IO_Running=Yes, because Replica_IO_Running=Yes is\nonly shown if the receiver thread is both running and connected. For more\ninformation, see Section 19.1.7.1, “Checking Replication Status”.\nThe optional FOR CHANNEL channel clause enables you to name which replication channel the\nstatement applies to. Providing a FOR CHANNEL channel clause applies the START REPLICA\nstatement to a specific replication channel. If no clause is named and no extra channels exist, the\nstatement applies to the default channel. If a START REPLICA statement does not have a channel\ndefined when using multiple channels, this statement starts the specified threads for all channels. See\nSection 19.2.2, “Replication Channels” for more information.\nThe replication channels for Group Replication (group_replication_applier and\ngroup_replication_recovery) are managed automatically by the server instance. START\nREPLICA cannot be used at all with the group_replication_recovery channel, and should only\nbe used with the group_replication_applier channel when Group Replication is not running.\nThe group_replication_applier channel only has an applier thread and has no receiver thread,\nso it can be started if required by using the SQL_THREAD option without the IO_THREAD option.\nSTART REPLICA supports pluggable user-password authentication (see Section 8.2.17, “Pluggable\nAuthentication”) with the USER, PASSWORD, DEFAULT_AUTH and PLUGIN_DIR options, as described in\nthe following list. When you use these options, you must start the receiver thread (IO_THREAD option)\nor all the replication threads; you cannot start the replication applier thread (SQL_THREAD option)\nalone.\nUSER\nThe user name for the account. You must set this if PASSWORD is\nused. The option cannot be set to an empty or null string.\nPASSWORD\nThe password for the named user account.\nDEFAULT_AUTH\nThe name of the authentication plugin. The default is MySQL native\nauthentication.\nPLUGIN_DIR\nThe location of the authentication plugin.\nImportant\nThe password that you set using START REPLICA is masked when it is\nwritten to MySQL Server’s logs, Performance Schema tables, and SHOW\nPROCESSLIST statements. However, it is sent in plain text over the connection\nto the replica server instance. To protect the password in transit, use SSL/TLS\nencryption, an SSH tunnel, or another method of protecting the connection from\nunauthorized viewing, for the connection between the replica server instance\nand the client that you use to issue START REPLICA.\nThe UNTIL clause makes the replica start replication, then process transactions up to the point that\nyou specify in the UNTIL clause, then stop again. The UNTIL clause can be used to make a replica\nproceed until just before the point where you want to skip a transaction that is unwanted, and then skip\nthe transaction as described in Section 19.1.7.3, “Skipping Transactions”. To identify a transaction, you\ncan use mysqlbinlog with the source's binary log or the replica's relay log, or use a SHOW BINLOG\nEVENTS statement.\nYou can also use the UNTIL clause for debugging replication by processing transactions one at a time\nor in sections. If you are using the UNTIL clause to do this, start the replica with --skip-replica-\nstart to prevent the SQL thread from running when the replica server starts. Remove the option or\nsystem variable setting after the procedure is complete, so that it is not forgotten in the event of an\nunexpected server restart.\nThe SHOW REPLICA STATUS statement includes output fields that display the current values of the\nUNTIL condition. The UNTIL condition lasts for as long as the affected threads are still running, and is\nremoved when they stop.\nThe UNTIL clause operates on the replication applier thread (SQL_THREAD option). You can use the\nSQL_THREAD option or let the replica default to starting both threads. If you use the IO_THREAD option\nalone, the UNTIL clause is ignored because the applier thread is not started.\nThe point that you specify in the UNTIL clause can be any one (and only one) of the following options:\nSOURCE_LOG_FILE and\nSOURCE_LOG_POS\nThese options make the replication applier process transactions\nup to a position in its relay log, identified by the file name and file\nposition of the corresponding point in the binary log on the source\nserver. The applier thread finds the nearest transaction boundary at\nor after the specified position, finishes applying the transaction, and\nstops there. For compressed transaction payloads, specify the end\nposition of the compressed Transaction_payload_event.\nThese options can still be used when the GTID_ONLY option was\nset on the CHANGE REPLICATION SOURCE TO statement to stop\nthe replication channel from persisting file names and file positions\nin the replication metadata repositories. The file names and file\npositions are tracked in memory.\nRELAY_LOG_FILE and\nRELAY_LOG_POS\nThese options make the replication applier process transactions\nup to a position in the replica’s relay log, identified by the relay\nlog file name and a position in that file. The applier thread finds\nthe nearest transaction boundary at or after the specified position,\nfinishes applying the transaction, and stops there. For compressed\ntransaction payloads, specify the end position of the compressed\nTransaction_payload_event.\nThese options can still be used when the GTID_ONLY option was\nset on the CHANGE REPLICATION SOURCE TO statement to stop\nthe replication channel from persisting file names and file positions\nin the replication metadata repositories. The file names and file\npositions are tracked in memory.\nSQL_BEFORE_GTIDS\nThis option makes the replication applier start processing\ntransactions and stop when it encounters any transaction that is\nin the specified GTID set. The encountered transaction from the\nGTID set is not applied, and nor are any of the other transactions\nin the GTID set. The option takes a GTID set containing one or\nmore global transaction identifiers as an argument (see GTID\nSets). Transactions in a GTID set do not necessarily appear in the\nreplication stream in the order of their GTIDs, so the transaction\nbefore which the applier stops is not necessarily the earliest.\nSQL_AFTER_GTIDS\nThis option makes the replication applier start processing\ntransactions and stop when it has processed all of the transactions\nin a specified GTID set. The option takes a GTID set containing one\nor more global transaction identifiers as an argument (see GTID\nSets).\nWith SQL_AFTER_GTIDS, the replication threads stop after they\nhave processed all transactions in the GTID set. Transactions\nare processed in the order received, so it is possible that these\ninclude transactions which are not part of the GTID set, but which\nare received (and processed) before all transactions in the set\nhave been committed. For example, executing START REPLICA\nUNTIL SQL_AFTER_GTIDS = 3E11FA47-71CA-11E1-9E33-\nC80AA9429562:11-56 causes the replica to obtain (and process)\nall transactions from the source until all of the transactions having\nthe sequence numbers 11 through 56 have been processed, and\nthen to stop without processing any additional transactions after that\npoint has been reached.\nIn older versions of MySQL, this option could not be used with\nreplica_parallel_workers > 1. In MySQL 9.1, this is no\nlonger an issue, and SQL_AFTER_GTIDS can be used without\ncausing the replica to fall back into single-threaded mode.\nSQL_AFTER_MTS_GAPS\nFor a multithreaded replica only (with\nreplica_parallel_workers > 0), this option makes the replica\nprocess transactions up to the point where there are no more gaps\nin the sequence of transactions executed from the relay log. When\nusing a multithreaded replica, there is a chance of gaps occurring in\nthe following situations:\n• The coordinator thread is stopped.\n• An error occurs in the applier threads.\n• mysqld shuts down unexpectedly.\nWhen a replication channel has gaps, the replica’s database is in\na state that might never have existed on the source. The replica\ntracks the gaps internally and disallows CHANGE REPLICATION\nSOURCE TO statements that would remove the gap information if\nthey executed.\nAll replicas are multithreaded by default. When\nreplica_preserve_commit_order=ON on the replica\n(the default), gaps should not occur except in the specific\nsituations listed in the description for this variable. If\nreplica_preserve_commit_order is OFF, the commit order\nof transactions is not preserved, so the chance of gaps occurring is\nmuch larger.\nIf GTIDs are not in use and you need to change a failed\nmultithreaded replica to single-threaded mode, you can issue the\nfollowing series of statements, in the order shown:\nSTART REPLICA UNTIL SQL_AFTER_MTS_GAPS;\nSET @@GLOBAL.replica_parallel_workers = 0;\nSTART REPLICA SQL_THREAD;\n15.4.2.5 STOP REPLICA Statement\nSTOP REPLICA [thread_types] [channel_option]\nthread_types:\n    [thread_type [, thread_type] ... ]\nthread_type: IO_THREAD | SQL_THREAD\nchannel_option:\n    FOR CHANNEL channel\nStops the replication threads.\nSTOP REPLICA requires the REPLICATION_SLAVE_ADMIN privilege (or the deprecated SUPER\nprivilege). Recommended best practice is to execute STOP REPLICA on the replica before stopping\nthe replica server (see Section 7.1.19, “The Server Shutdown Process”, for more information).\nLike START REPLICA, this statement may be used with the IO_THREAD and SQL_THREAD options to\nname the replication thread or threads to be stopped. Note that the Group Replication applier channel\n(group_replication_applier) has no replication I/O (receiver) thread, only a replication SQL\n(applier) thread. Using the SQL_THREAD option therefore stops this channel completely.\nSTOP REPLICA causes an implicit commit of an ongoing transaction. See Section 15.3.3, “Statements\nThat Cause an Implicit Commit”.\ngtid_next must be set to AUTOMATIC before issuing this statement.\nYou can control how long STOP REPLICA waits before timing out by setting the system variable\nrpl_stop_replica_timeout. This can be used to avoid deadlocks between STOP REPLICA\nand other SQL statements using different client connections to the replica. When the timeout value\nis reached, the issuing client returns an error message and stops waiting, but the STOP REPLICA\ninstruction remains in effect. Once the replication threads are no longer busy, the STOP REPLICA\nstatement is executed and the replica stops.\nSome CHANGE REPLICATION SOURCE TO statements are allowed while the replica is running,\ndepending on the states of the replication threads. However, using STOP REPLICA prior to executing a\nCHANGE REPLICATION SOURCE TO statement in such cases is still supported. See Section 15.4.2.2,\n“CHANGE REPLICATION SOURCE TO Statement”, and Section 19.4.8, “Switching Sources During\nFailover”, for more information.\nThe optional FOR CHANNEL channel clause enables you to name which replication channel the\nstatement applies to. Providing a FOR CHANNEL channel clause applies the STOP REPLICA\nstatement to a specific replication channel. If no channel is named and no extra channels exist, the\nstatement applies to the default channel. If a STOP REPLICA statement does not name a channel\nwhen using multiple channels, this statement stops the specified threads for all channels. See\nSection 19.2.2, “Replication Channels” for more information.\nThe replication channels for Group Replication (group_replication_applier and\ngroup_replication_recovery) are managed automatically by the server instance. STOP\nREPLICA cannot be used at all with the group_replication_recovery channel, and should only\nbe used with the group_replication_applier channel when Group Replication is not running.\nThe group_replication_applier channel only has an applier thread and has no receiver thread,\nso it can be stopped if required by using the SQL_THREAD option without the IO_THREAD option.\nWhen the replica is multithreaded (replica_parallel_workers is a nonzero value), any gaps in\nthe sequence of transactions executed from the relay log are closed as part of stopping the worker\nthreads. If the replica is stopped unexpectedly (for example due to an error in a worker thread, or\nanother thread issuing KILL) while a STOP REPLICA statement is executing, the sequence of\nexecuted transactions from the relay log may become inconsistent. See Section 19.5.1.35, “Replication\nand Transaction Inconsistencies”, for more information.\nWhen the source is using the row-based binary logging format, you should execute STOP REPLICA\nor STOP REPLICA SQL_THREAD on the replica prior to shutting down the replica server if you are\nreplicating any tables that use a nontransactional storage engine. If the current replication event group\nhas modified one or more nontransactional tables, STOP REPLICA waits for up to 60 seconds for the\nevent group to complete, unless you issue a KILL QUERY or KILL CONNECTION statement for the\nreplication SQL thread. If the event group remains incomplete after the timeout, an error message is\nlogged.\nWhen the source is using the statement-based binary logging format, changing the source while it has\nopen temporary tables is potentially unsafe. This is one of the reasons why statement-based replication\nof temporary tables is not recommended. You can find out whether there are any temporary tables on\nthe replica by checking the value of Replica_open_temp_tables. When using statement-based\nreplication, this value should be 0 before executing CHANGE REPLICATION SOURCE TO. If there are\nany temporary tables open on the replica, issuing a CHANGE REPLICATION SOURCE TO statement\nafter issuing a STOP REPLICA causes an ER_WARN_OPEN_TEMP_TABLES_MUST_BE_ZERO warning.",
    "15.4.3 SQL Statements for Controlling Group Replication": "15.4.3 SQL Statements for Controlling Group Replication\nThis section provides information about the statements used for controlling group replication.\n15.4.3.1 START GROUP_REPLICATION Statement\n  START GROUP_REPLICATION\n          [USER='user_name']\n          [, PASSWORD='user_pass']\n          [, DEFAULT_AUTH='plugin_name']\nStarts group replication. This statement requires the GROUP_REPLICATION_ADMIN privilege (or\nthe deprecated SUPER privilege). If super_read_only=ON is set and the member should join as a\nprimary, super_read_only is set to OFF once Group Replication successfully starts.\nA server that participates in a group in single-primary mode should use skip_replica_start=ON.\nOtherwise, the server is not allowed to join a group as a secondary.\nYou can specify user credentials for distributed recovery in the START GROUP_REPLICATION\nstatement using the USER, PASSWORD, and DEFAULT_AUTH options, as follows:\n• USER: The replication user for distributed recovery. For instructions to set up this account, see\nSection 20.2.1.3, “User Credentials For Distributed Recovery”. You cannot specify an empty or null\nstring, or omit the USER option if PASSWORD is specified.\n• PASSWORD: The password for the replication user account. The password cannot be encrypted, but it\nis masked in the query log.\n• DEFAULT_AUTH: The name of the authentication plugin used for the replication user account. If you\ndo not specify this option, the caching_sha2_password plugin is assumed. This option acts as a\nhint to the server, and the donor for distributed recovery overrides it if a different plugin is associated\nwith the user account on that server. The authentication plugin used by default when you create user\naccounts in MySQL 9.1 is the caching SHA-2 authentication plugin (caching_sha2_password).\nSee Section 8.2.17, “Pluggable Authentication” for more information on authentication plugins.\nThese credentials are used for distributed recovery on the group_replication_recovery channel.\nWhen you specify user credentials on START GROUP_REPLICATION, the credentials are saved in\nmemory only, and are removed by a STOP GROUP_REPLICATION statement or server shutdown. You\nmust issue a START GROUP_REPLICATION statement to provide the credentials again. This method is\ntherefore not compatible with starting Group Replication automatically on server start, as specified by\nthe group_replication_start_on_boot system variable.\nUser credentials specified on START GROUP_REPLICATION take precedence over any user\ncredentials set for the group_replication_recovery channel using a CHANGE REPLICATION\nSOURCE TO. Note that user credentials set using these statements are stored in the replication\nmetadata repositories, and are used when START GROUP_REPLICATION is specified without\nuser credentials, including automatic starts if the group_replication_start_on_boot\nsystem variable is set to ON. To gain the security benefits of specifying user credentials on START\nGROUP_REPLICATION, ensure that group_replication_start_on_boot is set to OFF (the\ndefault is ON), and clear any user credentials previously set for the group_replication_recovery\nchannel, following the instructions in Section 20.6.3, “Securing Distributed Recovery Connections”.\nWhile a member is rejoining a replication group, its status can be displayed as OFFLINE or ERROR\nbefore the group completes the compatibility checks and accepts it as a member. When the member is\ncatching up with the group's transactions, its status is RECOVERING.\n15.4.3.2 STOP GROUP_REPLICATION Statement\nSTOP GROUP_REPLICATION\nStops Group Replication. This statement requires the GROUP_REPLICATION_ADMIN privilege (or\nthe deprecated SUPER privilege). As soon as you issue STOP GROUP_REPLICATION the member\nis set to super_read_only=ON, which ensures that no writes can be made to the member while\nGroup Replication stops. Any other asynchronous replication channels running on the member are also\nstopped. Any user credentials that you specified in the START GROUP_REPLICATION statement when\nstarting Group Replication on this member are removed from memory, and must be supplied when you\nstart Group Replication again.\nWarning\nUse this statement with extreme caution because it removes the server instance\nfrom the group, meaning it is no longer protected by Group Replication's\nconsistency guarantee mechanisms. To be completely safe, ensure that your\napplications can no longer connect to the instance before issuing this statement\nto avoid any chance of stale reads.\nThe STOP GROUP_REPLICATION statement stops asynchronous replication channels on the\ngroup member, but it does not implicitly commit transactions that are in progress on them like STOP\nREPLICA does. This is because on a Group Replication group member, an additional transaction\ncommitted during the shutdown operation would leave the member inconsistent with the group and\ncause an issue with rejoining. To avoid failed commits for transactions that are in progress while\nstopping Group Replication, the STOP GROUP_REPLICATION statement cannot be issued while a\nGTID is assigned as the value of the gtid_next system variable.\nThe group_replication_components_stop_timeout system variable specifies the time for\nwhich Group Replication waits for each of its modules to complete ongoing processes after this\nstatement is issued. The timeout is used to resolve situations in which Group Replication components\ncannot be stopped normally, which can happen if the member is expelled from the group while it is\nin an error state, or while a process such as MySQL Enterprise Backup is holding a global lock on\ntables on the member. In such situations, the member cannot stop the applier thread or complete the\ndistributed recovery process to rejoin. STOP GROUP_REPLICATION does not complete until either the\nsituation is resolved (for example, by the lock being released), or the component timeout expires and\nthe modules are shut down regardless of their status. The default value is 300 seconds; this means\nthat Group Replication components are stopped after 5 minutes if the situation is not resolved before\nthat time, allowing the member to be restarted and rejoin.",
    "15.5 Prepared Statements": "15.5 Prepared Statements\nMySQL 9.1 provides support for server-side prepared statements. This support takes advantage of\nthe efficient client/server binary protocol. Using prepared statements with placeholders for parameter\nvalues has the following benefits:\n• Less overhead for parsing the statement each time it is executed. Typically, database applications\nprocess large volumes of almost-identical statements, with only changes to literal or variable values\nin clauses such as WHERE for queries and deletes, SET for updates, and VALUES for inserts.\n• Protection against SQL injection attacks. The parameter values can contain unescaped SQL quote\nand delimiter characters.\nThe following sections provide an overview of the characteristics of prepared statements:\n• Prepared Statements in Application Programs\n• Prepared Statements in SQL Scripts\n• PREPARE, EXECUTE, and DEALLOCATE PREPARE Statements\n• SQL Syntax Permitted in Prepared Statements\nPrepared Statements in Application Programs\nYou can use server-side prepared statements through client programming interfaces, including the\nMySQL C API client library for C programs, MySQL Connector/J for Java programs, and MySQL\nConnector/NET for programs using .NET technologies. For example, the C API provides a set of\nfunction calls that make up its prepared statement API. See C API Prepared Statement Interface. Other\nlanguage interfaces can provide support for prepared statements that use the binary protocol by linking\nin the C client library, one example being the mysqli extension, available in PHP 5.0 and later.\nPrepared Statements in SQL Scripts\nAn alternative SQL interface to prepared statements is available. This interface is not as efficient as\nusing the binary protocol through a prepared statement API, but requires no programming because it is\navailable directly at the SQL level:\n• You can use it when no programming interface is available to you.\n• You can use it from any program that can send SQL statements to the server to be executed, such\nas the mysql client program.\n• You can use it even if the client is using an old version of the client library.\nSQL syntax for prepared statements is intended to be used for situations such as these:\n• To test how prepared statements work in your application before coding it.\n• To use prepared statements when you do not have access to a programming API that supports\nthem.\n• To interactively troubleshoot application issues with prepared statements.\n• To create a test case that reproduces a problem with prepared statements, so that you can file a bug\nreport.\nPREPARE, EXECUTE, and DEALLOCATE PREPARE Statements\nSQL syntax for prepared statements is based on three SQL statements:\n• PREPARE prepares a statement for execution (see Section 15.5.1, “PREPARE Statement”).\n• EXECUTE executes a prepared statement (see Section 15.5.2, “EXECUTE Statement”).\n• DEALLOCATE PREPARE releases a prepared statement (see Section 15.5.3, “DEALLOCATE\nPREPARE Statement”).\nThe following examples show two equivalent ways of preparing a statement that computes the\nhypotenuse of a triangle given the lengths of the two sides.\nThe first example shows how to create a prepared statement by using a string literal to supply the text\nof the statement:\nmysql> PREPARE stmt1 FROM 'SELECT SQRT(POW(?,2) + POW(?,2)) AS hypotenuse';\nmysql> SET @a = 3;\nmysql> SET @b = 4;\nmysql> EXECUTE stmt1 USING @a, @b;\n+------------+\n| hypotenuse |\n+------------+\n|          5 |\n+------------+\nmysql> DEALLOCATE PREPARE stmt1;\nThe second example is similar, but supplies the text of the statement as a user variable:\nmysql> SET @s = 'SELECT SQRT(POW(?,2) + POW(?,2)) AS hypotenuse';\nmysql> PREPARE stmt2 FROM @s;\nmysql> SET @a = 6;\nmysql> SET @b = 8;\nmysql> EXECUTE stmt2 USING @a, @b;\n+------------+\n| hypotenuse |\n+------------+\n|         10 |\n+------------+\nmysql> DEALLOCATE PREPARE stmt2;\nHere is an additional example that demonstrates how to choose the table on which to perform a query\nat runtime, by storing the name of the table as a user variable:\nmysql> USE test;\nmysql> CREATE TABLE t1 (a INT NOT NULL);\nmysql> INSERT INTO t1 VALUES (4), (8), (11), (32), (80);\nmysql> SET @table = 't1';\nmysql> SET @s = CONCAT('SELECT * FROM ', @table);\nmysql> PREPARE stmt3 FROM @s;\nmysql> EXECUTE stmt3;\n+----+\n| a  |\n+----+\n|  4 |\n|  8 |\n| 11 |\n| 32 |\n| 80 |\n+----+\nmysql> DEALLOCATE PREPARE stmt3;\nA prepared statement is specific to the session in which it was created. If you terminate a session\nwithout deallocating a previously prepared statement, the server deallocates it automatically.\nA prepared statement is also global to the session. If you create a prepared statement within a stored\nroutine, it is not deallocated when the stored routine ends.\nTo guard against too many prepared statements being created simultaneously, set the\nmax_prepared_stmt_count system variable. To prevent the use of prepared statements, set the\nvalue to 0.\nSQL Syntax Permitted in Prepared Statements\nThe following SQL statements can be used as prepared statements:\nALTER {INSTANCE | TABLE | USER}\nANALYZE\nCALL\nCHANGE {REPLICATION SOURCE TO | REPLICATION FILTER}\nCHECKSUM\nCOMMIT\n{CREATE | DROP} INDEX\n{CREATE | DROP | RENAME} DATABASE\n{CREATE | DROP | RENAME} TABLE\n{CREATE | DROP | RENAME} USER\nDEALLOCATE PREPARE\nDROP VIEW\nDELETE\nDO\nEXECUTE\nFLUSH\nGRANT {ROLE}\nINSERT\nINSTALL PLUGIN\nKILL\nOPTIMIZE\nPREPARE\nREPAIR TABLE\nREPLACE\nREPLICA {START | STOP}\nRESET\nREVOKE {ALL | ROLE}\nSELECT\nSET ROLE\nSHOW {BINLOG EVENTS | BINARY LOGS | BINARY LOG STATUS | CHARACTER SETS | COLLATIONS | DATABASES | ENGIN\n      ERRORS | EVENTS | FIELDS | FUNCTION CODE | FUNCTION STATUS | GRANTS | KEYS | OPEN TABLES |\n      PLUGINS | PRIVILEGES | PROCEDURE CODE | PROCEDURE STATUS | PROCESSLIST | PROFILE | PROFILES | \n      RELAYLOG EVENTS | REPLICAS | REPLICA STATUS | STATUS | PROCEDURE STATUS | TABLE STATUS | TABLES |\n      TRIGGERS | VARIABLES | WARNINGS}\nSHOW CREATE { DATABASE | EVENT | FUNCTION | PROCEDURE | TABLE | TRIGGER | USER | VIEW}\nTRUNCATE\nUNINSTALL PLUGIN\nUPDATE\nNote\nCREATE TABLE ... START TRANSACTION is not supported in prepared\nstatements.\nOther statements are not supported.\nFor compliance with the SQL standard, which states that diagnostics statements are not preparable,\nMySQL does not support the following as prepared statements:\n• SHOW COUNT(*) WARNINGS\n• SHOW COUNT(*) ERRORS\n• Statements containing any reference to the warning_count or error_count system variable.\nGenerally, statements not permitted in SQL prepared statements are also not permitted in stored\nprograms. Exceptions are noted in Section 27.9, “Restrictions on Stored Programs”.\nMetadata changes to tables or views referred to by prepared statements are detected and cause\nautomatic repreparation of the statement when it is next executed. For more information, see\nSection 10.10.3, “Caching of Prepared Statements and Stored Programs”.\nPlaceholders can be used for the arguments of the LIMIT clause when using prepared statements.\nSee Section 15.2.13, “SELECT Statement”.\nPlaceholders are not supported in prepared statements which contain event DDL. Attempting to use\na placeholder in such a statement is rejected by PREPARE with ERROR 6413 (HY000): Dynamic\nparameters can only be used in DML statements. Instead, you can do this in a reusable\nfashion is to assemble the text containing the event SQL in the body of a stored procedure, passing\nany variable parts of the SQL statement as IN parameters to the stored procedure; then you can\nprepare the assembled text with a PREPARE statement (also within the body of the stored procedure),\nthen invoke the procedure using the desired parameter values. See Section 15.1.13, “CREATE EVENT\nStatement”, for an example.\nIn prepared CALL statements used with PREPARE and EXECUTE, placeholder support for OUT and\nINOUT parameters is available beginning with MySQL 9.1. See Section 15.2.1, “CALL Statement”,\nfor an example and a workaround for earlier versions. Placeholders can be used for IN parameters\nregardless of version.\nSQL syntax for prepared statements cannot be used in nested fashion. That is, a statement passed to\nPREPARE cannot itself be a PREPARE, EXECUTE, or DEALLOCATE PREPARE statement.\nSQL syntax for prepared statements is distinct from using prepared statement API calls. For example,\nyou cannot use the mysql_stmt_prepare() C API function to prepare a PREPARE, EXECUTE, or\nDEALLOCATE PREPARE statement.\nSQL syntax for prepared statements can be used within stored procedures, but not in stored functions\nor triggers. However, a cursor cannot be used for a dynamic statement that is prepared and executed\nwith PREPARE and EXECUTE. The statement for a cursor is checked at cursor creation time, so the\nstatement cannot be dynamic.\nSQL syntax for prepared statements does not support multi-statements (that is, multiple statements\nwithin a single string separated by ; characters).\nTo write C programs that use the CALL SQL statement to execute stored procedures that contain\nprepared statements, the CLIENT_MULTI_RESULTS flag must be enabled. This is because each\nCALL returns a result to indicate the call status, in addition to any result sets that might be returned by\nstatements executed within the procedure.\nCLIENT_MULTI_RESULTS can be enabled when you call mysql_real_connect(),\neither explicitly by passing the CLIENT_MULTI_RESULTS flag itself, or implicitly by passing\nCLIENT_MULTI_STATEMENTS (which also enables CLIENT_MULTI_RESULTS). For additional\ninformation, see Section 15.2.1, “CALL Statement”.",
    "15.5.1 PREPARE Statement": "15.5.1 PREPARE Statement\nPREPARE stmt_name FROM preparable_stmt\nThe PREPARE statement prepares a SQL statement and assigns it a name, stmt_name, by which\nto refer to the statement later. The prepared statement is executed with EXECUTE and released with\nDEALLOCATE PREPARE. For examples, see Section 15.5, “Prepared Statements”.\nStatement names are not case-sensitive. preparable_stmt is either a string literal or a user variable\nthat contains the text of the SQL statement. The text must represent a single statement, not multiple\nstatements. Within the statement, ? characters can be used as parameter markers to indicate where\ndata values are to be bound to the query later when you execute it. The ? characters should not be\nenclosed within quotation marks, even if you intend to bind them to string values. Parameter markers\ncan be used only where data values should appear, not for SQL keywords, identifiers, and so forth.\nIf a prepared statement with the given name already exists, it is deallocated implicitly before the new\nstatement is prepared. This means that if the new statement contains an error and cannot be prepared,\nan error is returned and no statement with the given name exists.\nThe scope of a prepared statement is the session within which it is created, which as several\nimplications:\n• A prepared statement created in one session is not available to other sessions.\n• When a session ends, whether normally or abnormally, its prepared statements no longer exist. If\nauto-reconnect is enabled, the client is not notified that the connection was lost. For this reason,\nclients may wish to disable auto-reconnect. See Automatic Reconnection Control.\n• A prepared statement created within a stored program continues to exist after the program finishes\nexecuting and can be executed outside the program later.\n• A statement prepared in stored program context cannot refer to stored procedure or function\nparameters or local variables because they go out of scope when the program ends and would be\nunavailable were the statement to be executed later outside the program. As a workaround, refer\ninstead to user-defined variables, which also have session scope; see Section 11.4, “User-Defined\nVariables”.\nThe type of a parameter used in a prepared statement is determined when the statement is first\nprepared; it retains this type whenever EXECUTE is invoked for this prepared statement (unless the\nstatement is reprepared, as explained later in this section). Rules for determining a parameter's type\nare listed here:\n• A parameter which is an operand of a binary arithmetic operator has the same data type as the other\noperand.\n• If both operands of a binary arithmetic operator are parameters, the type of the parameters is\ndecided by the context of the operator.\n• If a parameter is the operand of a unary arithmetic operator, the parameter's type is decided by the\ncontext of the operator.\n• If an arithmetic operator has no type-determining context, the derived type for any parameters\ninvolved is DOUBLE PRECISION. This can happen, for example, when the parameter is a top-level\nnode in a SELECT list, or when it is part of a comparison operator.\n• A parameter which is an operand of a character string operator has the same derived type as the\naggregated type of the other operands. If all operands of the operator are parameters, the derived\ntype is VARCHAR; its collation is determined by the value of collation_connection.\n• A parameter which is an operand of a temporal operator has type DATETIME if the operator returns a\nDATETIME, TIME if the operator returns a TIME, and DATE if the operator returns a DATE.\n• A parameter which is an operand of a binary comparison operator has the same derived type as the\nother operand of the comparison.\n• A parameter that is an operand of a ternary comparison operator such as BETWEEN has the same\nderived type as the aggregated type of the other operands.\n• If all operands of a comparison operator are parameters, the derived type for each of them is\nVARCHAR, with collation determined by the value of collation_connection.\n• A parameter that is an output operand of any of CASE, COALESCE, IF, IFNULL, or NULLIF has the\nsame derived type as the aggregated type of the operator's other output operands.\n• If all output operands of any of CASE, COALESCE, IF, IFNULL, or NULLIF are parameters, or they\nare all NULL, the type of the parameter is decided by the context of the operator.\n• If the parameter is an operand of any of CASE, COALESCE(), IF, or IFNULL, and has no type-\ndetermining context, the derived type for each of the parameters involved is VARCHAR, and its\ncollation is determined by the value of collation_connection.\n• A parameter which is the operand of a CAST() has the same type as specified by the CAST().\n• If a parameter is an immediate member of a SELECT list that is not part of an INSERT statement,\nthe derived type of the parameter is VARCHAR, and its collation is determined by the value of\ncollation_connection.\n• If a parameter is an immediate member of a SELECT list that is part of an INSERT statement, the\nderived type of the parameter is the type of the corresponding column into which the parameter is\ninserted.\n• If a parameter is used as source for an assignment in a SET clause of an UPDATE statement or in the\nON DUPLICATE KEY UPDATE clause of an INSERT statement, the derived type of the parameter is\nthe type of the corresponding column which is updated by the SET or ON DUPLICATE KEY UPDATE\nclause.\n• If a parameter is an argument of a function, the derived type depends on the function's return type.\nFor some combinations of actual type and derived type, an automatic repreparation of the statement\nis triggered, to ensure closer compatibility with previous versions of MySQL. Repreparation does not\noccur if any of the following conditions are true:\n• NULL is used as the actual parameter value.\n• A parameter is an operand of a CAST(). (Instead, a cast to the derived type is attempted, and an\nexception raised if the cast fails.)\n• A parameter is a string. (In this case, an implicit CAST(? AS derived_type) is performed.)\n• The derived type and actual type of the parameter are both INTEGER and have the same sign.\n• The parameter's derived type is DECIMAL and its actual type is either DECIMAL or INTEGER.\n• The derived type is DOUBLE and the actual type is any numeric type.\n• Both the derived type and the actual type are string types.\n• If the derived type is temporal and the actual type is temporal. Exceptions: The derived type is TIME\nand the actual type is not TIME; the derived type is DATE and the actual type is not DATE.\n• The derived type is temporal and the actual type is numeric.\nFor cases other than those just listed, the statement is reprepared and the actual parameter types are\nused instead of the derived parameter types.\nThese rules also apply to a user variable referenced in a prepared statement.\nUsing a different data type for a given parameter or user variable within a prepared statement for\nexecutions of the statement subsequent to the first execution causes the statement to be reprepared.\nThis is less efficient; it may also lead to the parameter's (or variable's) actual type to vary, and thus for\nresults to be inconsistent, with subsequent executions of the prepared statement. For these reasons, it\nis advisable to use the same data type for a given parameter when re-executing a prepared statement.",
    "15.5.2 EXECUTE Statement": "15.5.2 EXECUTE Statement\nEXECUTE stmt_name\n    [USING @var_name [, @var_name] ...]\nAfter preparing a statement with PREPARE, you execute it with an EXECUTE statement that refers to\nthe prepared statement name. If the prepared statement contains any parameter markers, you must\nsupply a USING clause that lists user variables containing the values to be bound to the parameters.\nParameter values can be supplied only by user variables, and the USING clause must name exactly as\nmany variables as the number of parameter markers in the statement.\nYou can execute a given prepared statement multiple times, passing different variables to it or setting\nthe variables to different values before each execution.\nFor examples, see Section 15.5, “Prepared Statements”.",
    "15.5.3 DEALLOCATE PREPARE Statement": "15.5.3 DEALLOCATE PREPARE Statement\n{DEALLOCATE | DROP} PREPARE stmt_name\nTo deallocate a prepared statement produced with PREPARE, use a DEALLOCATE PREPARE statement\nthat refers to the prepared statement name. Attempting to execute a prepared statement after\ndeallocating it results in an error. If too many prepared statements are created and not deallocated by\neither the DEALLOCATE PREPARE statement or the end of the session, you might encounter the upper\nlimit enforced by the max_prepared_stmt_count system variable.\nFor examples, see Section 15.5, “Prepared Statements”.",
    "15.6 Compound Statement Syntax": "15.6 Compound Statement Syntax\nThis section describes the syntax for the BEGIN ... END compound statement and other statements\nthat can be used in the body of stored programs: Stored procedures and functions, triggers, and\nevents. These objects are defined in terms of SQL code that is stored on the server for later invocation\n(see Chapter 27, Stored Objects).\nA compound statement is a block that can contain other blocks; declarations for variables, condition\nhandlers, and cursors; and flow control constructs such as loops and conditional tests.",
    "15.6.1 BEGIN ... END Compound Statement": "15.6.1 BEGIN ... END Compound Statement\n[begin_label:] BEGIN\n    [statement_list]\nEND [end_label]\nBEGIN ... END syntax is used for writing compound statements, which can appear within stored\nprograms (stored procedures and functions, triggers, and events). A compound statement can contain\nmultiple statements, enclosed by the BEGIN and END keywords. statement_list represents\na list of one or more statements, each terminated by a semicolon (;) statement delimiter. The\nstatement_list itself is optional, so the empty compound statement (BEGIN END) is legal.\nBEGIN ... END blocks can be nested.\nUse of multiple statements requires that a client is able to send statement strings containing the ;\nstatement delimiter. In the mysql command-line client, this is handled with the delimiter command.\nChanging the ; end-of-statement delimiter (for example, to //) permit ; to be used in a program body.\nFor an example, see Section 27.1, “Defining Stored Programs”.\nA BEGIN ... END block can be labeled. See Section 15.6.2, “Statement Labels”.\nThe optional [NOT] ATOMIC clause is not supported. This means that no transactional savepoint is\nset at the start of the instruction block and the BEGIN clause used in this context has no effect on the\ncurrent transaction.\nNote\nWithin all stored programs, the parser treats BEGIN [WORK] as the beginning\nof a BEGIN ... END block. To begin a transaction in this context, use START\nTRANSACTION instead.",
    "15.6.2 Statement Labels": "15.6.2 Statement Labels\n[begin_label:] BEGIN\n    [statement_list]\nEND [end_label]\n[begin_label:] LOOP\n    statement_list\nEND LOOP [end_label]\n[begin_label:] REPEAT\n    statement_list\nUNTIL search_condition\nEND REPEAT [end_label]\n[begin_label:] WHILE search_condition DO\n    statement_list\nEND WHILE [end_label]\nLabels are permitted for BEGIN ... END blocks and for the LOOP, REPEAT, and WHILE statements.\nLabel use for those statements follows these rules:\n• begin_label must be followed by a colon.\n• begin_label can be given without end_label. If end_label is present, it must be the same as\nbegin_label.\n• end_label cannot be given without begin_label.\n• Labels at the same nesting level must be distinct.\n• Labels can be up to 16 characters long.\nTo refer to a label within the labeled construct, use an ITERATE or LEAVE statement. The following\nexample uses those statements to continue iterating or terminate the loop:\nCREATE PROCEDURE doiterate(p1 INT)\nBEGIN\n  label1: LOOP\n    SET p1 = p1 + 1;\n    IF p1 < 10 THEN ITERATE label1; END IF;\n    LEAVE label1;\n  END LOOP label1;\nEND;\nThe scope of a block label does not include the code for handlers declared within the block. For details,\nsee Section 15.6.7.2, “DECLARE ... HANDLER Statement”.",
    "15.6.3 DECLARE Statement": "15.6.3 DECLARE Statement\nThe DECLARE statement is used to define various items local to a program:\n• Local variables. See Section 15.6.4, “Variables in Stored Programs”.\n• Conditions and handlers. See Section 15.6.7, “Condition Handling”.\n• Cursors. See Section 15.6.6, “Cursors”.\nDECLARE is permitted only inside a BEGIN ... END compound statement and must be at its start,\nbefore any other statements.\nDeclarations must follow a certain order. Cursor declarations must appear before handler declarations.\nVariable and condition declarations must appear before cursor or handler declarations.",
    "15.6.4 Variables in Stored Programs": "15.6.4 Variables in Stored Programs\nSystem variables and user-defined variables can be used in stored programs, just as they can be\nused outside stored-program context. In addition, stored programs can use DECLARE to define local\nvariables, and stored routines (procedures and functions) can be declared to take parameters that\ncommunicate values between the routine and its caller.\n• To declare local variables, use the DECLARE statement, as described in Section 15.6.4.1, “Local\nVariable DECLARE Statement”.\n• Variables can be set directly with the SET statement. See Section 15.7.6.1, “SET Syntax for Variable\nAssignment”.\n• Results from queries can be retrieved into local variables using SELECT ... INTO var_list or\nby opening a cursor and using FETCH ... INTO var_list. See Section 15.2.13.1, “SELECT ...\nINTO Statement”, and Section 15.6.6, “Cursors”.\nFor information about the scope of local variables and how MySQL resolves ambiguous names, see\nSection 15.6.4.2, “Local Variable Scope and Resolution”.\nIt is not permitted to assign the value DEFAULT to stored procedure or function parameters or stored\nprogram local variables (for example with a SET var_name = DEFAULT statement). In MySQL 9.1,\nthis results in a syntax error.\n15.6.4.1 Local Variable DECLARE Statement\nDECLARE var_name [, var_name] ... type [DEFAULT value]\nThis statement declares local variables within stored programs. To provide a default value for a\nvariable, include a DEFAULT clause. The value can be specified as an expression; it need not be a\nconstant. If the DEFAULT clause is missing, the initial value is NULL.\nLocal variables are treated like stored routine parameters with respect to data type and overflow\nchecking. See Section 15.1.17, “CREATE PROCEDURE and CREATE FUNCTION Statements”.\nVariable declarations must appear before cursor or handler declarations.\nLocal variable names are not case-sensitive. Permissible characters and quoting rules are the same as\nfor other identifiers, as described in Section 11.2, “Schema Object Names”.\nThe scope of a local variable is the BEGIN ... END block within which it is declared. The variable can\nbe referred to in blocks nested within the declaring block, except those blocks that declare a variable\nwith the same name.\nFor examples of variable declarations, see Section 15.6.4.2, “Local Variable Scope and Resolution”.\n15.6.4.2 Local Variable Scope and Resolution\nThe scope of a local variable is the BEGIN ... END block within which it is declared. The variable can\nbe referred to in blocks nested within the declaring block, except those blocks that declare a variable\nwith the same name.\nBecause local variables are in scope only during stored program execution, references to them are not\npermitted in prepared statements created within a stored program. Prepared statement scope is the\ncurrent session, not the stored program, so the statement could be executed after the program ends, at\nwhich point the variables would no longer be in scope. For example, SELECT ... INTO local_var\ncannot be used as a prepared statement. This restriction also applies to stored procedure and function\nparameters. See Section 15.5.1, “PREPARE Statement”.\nA local variable should not have the same name as a table column. If an SQL statement, such as a\nSELECT ... INTO statement, contains a reference to a column and a declared local variable with\nthe same name, MySQL currently interprets the reference as the name of a variable. Consider the\nfollowing procedure definition:\nCREATE PROCEDURE sp1 (x VARCHAR(5))\nBEGIN\n  DECLARE xname VARCHAR(5) DEFAULT 'bob';\n  DECLARE newname VARCHAR(5);\n  DECLARE xid INT;\n  SELECT xname, id INTO newname, xid\n    FROM table1 WHERE xname = xname;\n  SELECT newname;\nEND;\nMySQL interprets xname in the SELECT statement as a reference to the xname variable rather than the\nxname column. Consequently, when the procedure sp1()is called, the newname variable returns the\nvalue 'bob' regardless of the value of the table1.xname column.\nSimilarly, the cursor definition in the following procedure contains a SELECT statement that refers\nto xname. MySQL interprets this as a reference to the variable of that name rather than a column\nreference.\nCREATE PROCEDURE sp2 (x VARCHAR(5))\nBEGIN\n  DECLARE xname VARCHAR(5) DEFAULT 'bob';\n  DECLARE newname VARCHAR(5);\n  DECLARE xid INT;\n  DECLARE done TINYINT DEFAULT 0;\n  DECLARE cur1 CURSOR FOR SELECT xname, id FROM table1;\n  DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;\n  OPEN cur1;\n  read_loop: LOOP\n    FETCH FROM cur1 INTO newname, xid;\n    IF done THEN LEAVE read_loop; END IF;\n    SELECT newname;\n  END LOOP;\n  CLOSE cur1;\nEND;\nSee also Section 27.9, “Restrictions on Stored Programs”.",
    "15.6.5 Flow Control Statements": "15.6.5 Flow Control Statements\nMySQL supports the IF, CASE, ITERATE, LEAVE LOOP, WHILE, and REPEAT constructs for flow\ncontrol within stored programs. It also supports RETURN within stored functions.\nMany of these constructs contain other statements, as indicated by the grammar specifications in the\nfollowing sections. Such constructs may be nested. For example, an IF statement might contain a\nWHILE loop, which itself contains a CASE statement.\nMySQL does not support FOR loops.\n15.6.5.1 CASE Statement\nCASE case_value\n    WHEN when_value THEN statement_list\n    [WHEN when_value THEN statement_list] ...\n    [ELSE statement_list]\nEND CASE\nOr:\nCASE\n    WHEN search_condition THEN statement_list\n    [WHEN search_condition THEN statement_list] ...\n    [ELSE statement_list]\nEND CASE\nThe CASE statement for stored programs implements a complex conditional construct.\nNote\nThere is also a CASE operator, which differs from the CASE statement described\nhere. See Section 14.5, “Flow Control Functions”. The CASE statement cannot\nhave an ELSE NULL clause, and it is terminated with END CASE instead of\nEND.\nFor the first syntax, case_value is an expression. This value is compared to the when_value\nexpression in each WHEN clause until one of them is equal. When an equal when_value is found, the\ncorresponding THEN clause statement_list executes. If no when_value is equal, the ELSE clause\nstatement_list executes, if there is one.\nThis syntax cannot be used to test for equality with NULL because NULL = NULL is false. See\nSection 5.3.4.6, “Working with NULL Values”.\nFor the second syntax, each WHEN clause search_condition expression is evaluated until\none is true, at which point its corresponding THEN clause statement_list executes. If no\nsearch_condition is equal, the ELSE clause statement_list executes, if there is one.\nIf no when_value or search_condition matches the value tested and the CASE statement contains\nno ELSE clause, a Case not found for CASE statement error results.\nEach statement_list consists of one or more SQL statements; an empty statement_list is not\npermitted.\nTo handle situations where no value is matched by any WHEN clause, use an ELSE containing an empty\nBEGIN ... END block, as shown in this example. (The indentation used here in the ELSE clause is for\npurposes of clarity only, and is not otherwise significant.)\nDELIMITER |\nCREATE PROCEDURE p()\n  BEGIN\n    DECLARE v INT DEFAULT 1;\n    CASE v\n      WHEN 2 THEN SELECT v;\n      WHEN 3 THEN SELECT 0;\n      ELSE\n        BEGIN\n        END;\n    END CASE;\n  END;\n  |\n15.6.5.2 IF Statement\nIF search_condition THEN statement_list\n    [ELSEIF search_condition THEN statement_list] ...\n    [ELSE statement_list]\nEND IF\nThe IF statement for stored programs implements a basic conditional construct.\nNote\nThere is also an IF() function, which differs from the IF statement described\nhere. See Section 14.5, “Flow Control Functions”. The IF statement can have\nTHEN, ELSE, and ELSEIF clauses, and it is terminated with END IF.\nIf a given search_condition evaluates to true, the corresponding THEN or ELSEIF clause\nstatement_list executes. If no search_condition matches, the ELSE clause statement_list\nexecutes.\nEach statement_list consists of one or more SQL statements; an empty statement_list is not\npermitted.\nAn IF ... END IF block, like all other flow-control blocks used within stored programs, must be\nterminated with a semicolon, as shown in this example:\nDELIMITER //\nCREATE FUNCTION SimpleCompare(n INT, m INT)\n  RETURNS VARCHAR(20)\n  BEGIN\n    DECLARE s VARCHAR(20);\n    IF n > m THEN SET s = '>';\n    ELSEIF n = m THEN SET s = '=';\n    ELSE SET s = '<';\n    END IF;\n    SET s = CONCAT(n, ' ', s, ' ', m);\n    RETURN s;\n  END //\nDELIMITER ;\nAs with other flow-control constructs, IF ... END IF blocks may be nested within other flow-control\nconstructs, including other IF statements. Each IF must be terminated by its own END IF followed\nby a semicolon. You can use indentation to make nested flow-control blocks more easily readable by\nhumans (although this is not required by MySQL), as shown here:\nDELIMITER //\nCREATE FUNCTION VerboseCompare (n INT, m INT)\n  RETURNS VARCHAR(50)\n  BEGIN\n    DECLARE s VARCHAR(50);\n    IF n = m THEN SET s = 'equals';\n    ELSE\n      IF n > m THEN SET s = 'greater';\n      ELSE SET s = 'less';\n      END IF;\n      SET s = CONCAT('is ', s, ' than');\n    END IF;\n    SET s = CONCAT(n, ' ', s, ' ', m, '.');\n    RETURN s;\n  END //\nDELIMITER ;\nIn this example, the inner IF is evaluated only if n is not equal to m.\n15.6.5.3 ITERATE Statement\nITERATE label\nITERATE can appear only within LOOP, REPEAT, and WHILE statements. ITERATE means “start the\nloop again.”\nFor an example, see Section 15.6.5.5, “LOOP Statement”.\n15.6.5.4 LEAVE Statement\nLEAVE label\nThis statement is used to exit the flow control construct that has the given label. If the label is for the\noutermost stored program block, LEAVE exits the program.\nLEAVE can be used within BEGIN ... END or loop constructs (LOOP, REPEAT, WHILE).\nFor an example, see Section 15.6.5.5, “LOOP Statement”.\n15.6.5.5 LOOP Statement\n[begin_label:] LOOP\n    statement_list\nEND LOOP [end_label]\nLOOP implements a simple loop construct, enabling repeated execution of the statement list, which\nconsists of one or more statements, each terminated by a semicolon (;) statement delimiter. The\nstatements within the loop are repeated until the loop is terminated. Usually, this is accomplished with a\nLEAVE statement. Within a stored function, RETURN can also be used, which exits the function entirely.\nNeglecting to include a loop-termination statement results in an infinite loop.\nA LOOP statement can be labeled. For the rules regarding label use, see Section 15.6.2, “Statement\nLabels”.\nExample:\nCREATE PROCEDURE doiterate(p1 INT)\nBEGIN\n  label1: LOOP\n    SET p1 = p1 + 1;\n    IF p1 < 10 THEN\n      ITERATE label1;\n    END IF;\n    LEAVE label1;\n  END LOOP label1;\n  SET @x = p1;\nEND;\n15.6.5.6 REPEAT Statement\n[begin_label:] REPEAT\n    statement_list\nUNTIL search_condition\nEND REPEAT [end_label]\nThe statement list within a REPEAT statement is repeated until the search_condition expression is\ntrue. Thus, a REPEAT always enters the loop at least once. statement_list consists of one or more\nstatements, each terminated by a semicolon (;) statement delimiter.\nA REPEAT statement can be labeled. For the rules regarding label use, see Section 15.6.2, “Statement\nLabels”.\nExample:\nmysql> delimiter //\nmysql> CREATE PROCEDURE dorepeat(p1 INT)\n       BEGIN\n         SET @x = 0;\n         REPEAT\n           SET @x = @x + 1;\n         UNTIL @x > p1 END REPEAT;\n       END\n       //\nQuery OK, 0 rows affected (0.00 sec)\nmysql> CALL dorepeat(1000)//\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @x//\n+------+\n| @x   |\n+------+\n| 1001 |\n+------+\n1 row in set (0.00 sec)\n15.6.5.7 RETURN Statement\nRETURN expr\nThe RETURN statement terminates execution of a stored function and returns the value expr to the\nfunction caller. There must be at least one RETURN statement in a stored function. There may be more\nthan one if the function has multiple exit points.\nThis statement is not used in stored procedures, triggers, or events. The LEAVE statement can be used\nto exit a stored program of those types.\n15.6.5.8 WHILE Statement\n[begin_label:] WHILE search_condition DO\n    statement_list\nEND WHILE [end_label]\nThe statement list within a WHILE statement is repeated as long as the search_condition\nexpression is true. statement_list consists of one or more SQL statements, each terminated by a\nsemicolon (;) statement delimiter.\nA WHILE statement can be labeled. For the rules regarding label use, see Section 15.6.2, “Statement\nLabels”.\nExample:\nCREATE PROCEDURE dowhile()\nBEGIN\n  DECLARE v1 INT DEFAULT 5;\n  WHILE v1 > 0 DO\n    ...\n    SET v1 = v1 - 1;\n  END WHILE;\nEND;",
    "15.6.6 Cursors": "15.6.6 Cursors\nMySQL supports cursors inside stored programs. The syntax is as in embedded SQL. Cursors have\nthese properties:\n• Asensitive: The server may or may not make a copy of its result table\n• Read only: Not updatable\n• Nonscrollable: Can be traversed only in one direction and cannot skip rows\nCursor declarations must appear before handler declarations and after variable and condition\ndeclarations.\nExample:\nCREATE PROCEDURE curdemo()\nBEGIN\n  DECLARE done INT DEFAULT FALSE;\n  DECLARE a CHAR(16);\n  DECLARE b, c INT;\n  DECLARE cur1 CURSOR FOR SELECT id,data FROM test.t1;\n  DECLARE cur2 CURSOR FOR SELECT i FROM test.t2;\n  DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;\n  OPEN cur1;\n  OPEN cur2;\n  read_loop: LOOP\n    FETCH cur1 INTO a, b;\n    FETCH cur2 INTO c;\n    IF done THEN\n      LEAVE read_loop;\n    END IF;\n    IF b < c THEN\n      INSERT INTO test.t3 VALUES (a,b);\n    ELSE\n      INSERT INTO test.t3 VALUES (a,c);\n    END IF;\n  END LOOP;\n  CLOSE cur1;\n  CLOSE cur2;\nEND;\n15.6.6.1 Cursor CLOSE Statement\nCLOSE cursor_name\nThis statement closes a previously opened cursor. For an example, see Section 15.6.6, “Cursors”.\nAn error occurs if the cursor is not open.\nIf not closed explicitly, a cursor is closed at the end of the BEGIN ... END block in which it was\ndeclared.\n15.6.6.2 Cursor DECLARE Statement\nDECLARE cursor_name CURSOR FOR select_statement\nThis statement declares a cursor and associates it with a SELECT statement that retrieves the rows to\nbe traversed by the cursor. To fetch the rows later, use a FETCH statement. The number of columns\nretrieved by the SELECT statement must match the number of output variables specified in the FETCH\nstatement.\nThe SELECT statement cannot have an INTO clause.\nCursor declarations must appear before handler declarations and after variable and condition\ndeclarations.\nA stored program may contain multiple cursor declarations, but each cursor declared in a given block\nmust have a unique name. For an example, see Section 15.6.6, “Cursors”.\nFor information available through SHOW statements, it is possible in many cases to obtain equivalent\ninformation by using a cursor with an INFORMATION_SCHEMA table.\n15.6.6.3 Cursor FETCH Statement\nFETCH [[NEXT] FROM] cursor_name INTO var_name [, var_name] ...\nThis statement fetches the next row for the SELECT statement associated with the specified cursor\n(which must be open), and advances the cursor pointer. If a row exists, the fetched columns are stored\nin the named variables. The number of columns retrieved by the SELECT statement must match the\nnumber of output variables specified in the FETCH statement.\nIf no more rows are available, a No Data condition occurs with SQLSTATE value '02000'. To detect\nthis condition, you can set up a handler for it (or for a NOT FOUND condition). For an example, see\nSection 15.6.6, “Cursors”.\nBe aware that another operation, such as a SELECT or another FETCH, may also cause the handler\nto execute by raising the same condition. If it is necessary to distinguish which operation raised the\ncondition, place the operation within its own BEGIN ... END block so that it can be associated with its\nown handler.\n15.6.6.4 Cursor OPEN Statement\nOPEN cursor_name\nThis statement opens a previously declared cursor. For an example, see Section 15.6.6, “Cursors”.\n15.6.6.5 Restrictions on Server-Side Cursors\nServer-side cursors are implemented in the C API using the mysql_stmt_attr_set() function. The\nsame implementation is used for cursors in stored routines. A server-side cursor enables a result set\nto be generated on the server side, but not transferred to the client except for those rows that the client\nrequests. For example, if a client executes a query but is only interested in the first row, the remaining\nrows are not transferred.\nIn MySQL, a server-side cursor is materialized into an internal temporary table. Initially, this is a\nMEMORY table, but is converted to a MyISAM table when its size exceeds the minimum value of the\nmax_heap_table_size and tmp_table_size system variables. The same restrictions apply\nto internal temporary tables created to hold the result set for a cursor as for other uses of internal\ntemporary tables. See Section 10.4.4, “Internal Temporary Table Use in MySQL”. One limitation of the\nimplementation is that for a large result set, retrieving its rows through a cursor might be slow.\nCursors are read only; you cannot use a cursor to update rows.\nUPDATE WHERE CURRENT OF and DELETE WHERE CURRENT OF are not implemented, because\nupdatable cursors are not supported.\nCursors are nonholdable (not held open after a commit).\nCursors are asensitive.\nCursors are nonscrollable.\nCursors are not named. The statement handler acts as the cursor ID.\nYou can have open only a single cursor per prepared statement. If you need several cursors, you must\nprepare several statements.\nYou cannot use a cursor for a statement that generates a result set if the statement is not supported\nin prepared mode. This includes statements such as CHECK TABLE, HANDLER READ, and SHOW\nBINLOG EVENTS.",
    "15.6.7 Condition Handling": "15.6.7 Condition Handling\nConditions may arise during stored program execution that require special handling, such as exiting the\ncurrent program block or continuing execution. Handlers can be defined for general conditions such as\nwarnings or exceptions, or for specific conditions such as a particular error code. Specific conditions\ncan be assigned names and referred to that way in handlers.\nTo name a condition, use the DECLARE ... CONDITION statement. To declare a handler, use the\nDECLARE ... HANDLER statement. See Section 15.6.7.1, “DECLARE ... CONDITION Statement”,\nand Section 15.6.7.2, “DECLARE ... HANDLER Statement”. For information about how the server\nchooses handlers when a condition occurs, see Section 15.6.7.6, “Scope Rules for Handlers”.\nTo raise a condition, use the SIGNAL statement. To modify condition information within a condition\nhandler, use RESIGNAL. See Section 15.6.7.1, “DECLARE ... CONDITION Statement”, and\nSection 15.6.7.2, “DECLARE ... HANDLER Statement”.\nTo retrieve information from the diagnostics area, use the GET DIAGNOSTICS statement (see\nSection 15.6.7.3, “GET DIAGNOSTICS Statement”). For information about the diagnostics area, see\nSection 15.6.7.7, “The MySQL Diagnostics Area”.\n15.6.7.1 DECLARE ... CONDITION Statement\nDECLARE condition_name CONDITION FOR condition_value\ncondition_value: {\n    mysql_error_code\n  | SQLSTATE [VALUE] sqlstate_value\n}\nThe DECLARE ... CONDITION statement declares a named error condition, associating a name with\na condition that needs specific handling. The name can be referred to in a subsequent DECLARE ...\nHANDLER statement (see Section 15.6.7.2, “DECLARE ... HANDLER Statement”).\nCondition declarations must appear before cursor or handler declarations.\nThe condition_value for DECLARE ... CONDITION indicates the specific condition or class of\nconditions to associate with the condition name. It can take the following forms:\n• mysql_error_code: An integer literal indicating a MySQL error code.\nDo not use MySQL error code 0 because that indicates success rather than an error condition. For a\nlist of MySQL error codes, see Server Error Message Reference.\n• SQLSTATE [VALUE] sqlstate_value: A 5-character string literal indicating an SQLSTATE value.\nDo not use SQLSTATE values that begin with '00' because those indicate success rather than an\nerror condition. For a list of SQLSTATE values, see Server Error Message Reference.\nCondition names referred to in SIGNAL or use RESIGNAL statements must be associated with\nSQLSTATE values, not MySQL error codes.\nUsing names for conditions can help make stored program code clearer. For example, this handler\napplies to attempts to drop a nonexistent table, but that is apparent only if you know that 1051 is the\nMySQL error code for “unknown table”:\nDECLARE CONTINUE HANDLER FOR 1051\n  BEGIN\n    -- body of handler\n  END;\nBy declaring a name for the condition, the purpose of the handler is more readily seen:\nDECLARE no_such_table CONDITION FOR 1051;\nDECLARE CONTINUE HANDLER FOR no_such_table\n  BEGIN\n    -- body of handler\n  END;\nHere is a named condition for the same condition, but based on the corresponding SQLSTATE value\nrather than the MySQL error code:\nDECLARE no_such_table CONDITION FOR SQLSTATE '42S02';\nDECLARE CONTINUE HANDLER FOR no_such_table\n  BEGIN\n    -- body of handler\n  END;\n15.6.7.2 DECLARE ... HANDLER Statement\nDECLARE handler_action HANDLER\n    FOR condition_value [, condition_value] ...\n    statement\nhandler_action: {\n    CONTINUE\n  | EXIT\n  | UNDO\n}\ncondition_value: {\n    mysql_error_code\n  | SQLSTATE [VALUE] sqlstate_value\n  | condition_name\n  | SQLWARNING\n  | NOT FOUND\n  | SQLEXCEPTION\n}\nThe DECLARE ... HANDLER statement specifies a handler that deals with one or more conditions.\nIf one of these conditions occurs, the specified statement executes. statement can be a simple\nstatement such as SET var_name = value, or a compound statement written using BEGIN and END\n(see Section 15.6.1, “BEGIN ... END Compound Statement”).\nHandler declarations must appear after variable or condition declarations.\nThe handler_action value indicates what action the handler takes after execution of the handler\nstatement:\n• CONTINUE: Execution of the current program continues.\n• EXIT: Execution terminates for the BEGIN ... END compound statement in which the handler is\ndeclared. This is true even if the condition occurs in an inner block.\n• UNDO: Not supported.\nThe condition_value for DECLARE ... HANDLER indicates the specific condition or class of\nconditions that activates the handler. It can take the following forms:\n• mysql_error_code: An integer literal indicating a MySQL error code, such as 1051 to specify\n“unknown table”:\nDECLARE CONTINUE HANDLER FOR 1051\n  BEGIN\n    -- body of handler\n  END;\nDo not use MySQL error code 0 because that indicates success rather than an error condition. For a\nlist of MySQL error codes, see Server Error Message Reference.\n• SQLSTATE [VALUE] sqlstate_value: A 5-character string literal indicating an SQLSTATE value,\nsuch as '42S01' to specify “unknown table”:\nDECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'\n  BEGIN\n    -- body of handler\n  END;\nDo not use SQLSTATE values that begin with '00' because those indicate success rather than an\nerror condition. For a list of SQLSTATE values, see Server Error Message Reference.\n• condition_name: A condition name previously specified with DECLARE ... CONDITION.\nA condition name can be associated with a MySQL error code or SQLSTATE value. See\nSection 15.6.7.1, “DECLARE ... CONDITION Statement”.\n• SQLWARNING: Shorthand for the class of SQLSTATE values that begin with '01'.\nDECLARE CONTINUE HANDLER FOR SQLWARNING\n  BEGIN\n    -- body of handler\n  END;\n• NOT FOUND: Shorthand for the class of SQLSTATE values that begin with '02'. This is relevant\nwithin the context of cursors and is used to control what happens when a cursor reaches the end of a\ndata set. If no more rows are available, a No Data condition occurs with SQLSTATE value '02000'.\nTo detect this condition, you can set up a handler for it or for a NOT FOUND condition.\nDECLARE CONTINUE HANDLER FOR NOT FOUND\n  BEGIN\n    -- body of handler\n  END;\nFor another example, see Section 15.6.6, “Cursors”. The NOT FOUND condition also occurs for\nSELECT ... INTO var_list statements that retrieve no rows.\n• SQLEXCEPTION: Shorthand for the class of SQLSTATE values that do not begin with '00', '01', or\n'02'.\nDECLARE CONTINUE HANDLER FOR SQLEXCEPTION\n  BEGIN\n    -- body of handler\n  END;\nFor information about how the server chooses handlers when a condition occurs, see Section 15.6.7.6,\n“Scope Rules for Handlers”.\nIf a condition occurs for which no handler has been declared, the action taken depends on the\ncondition class:\n• For SQLEXCEPTION conditions, the stored program terminates at the statement that raised the\ncondition, as if there were an EXIT handler. If the program was called by another stored program,\nthe calling program handles the condition using the handler selection rules applied to its own\nhandlers.\n• For SQLWARNING conditions, the program continues executing, as if there were a CONTINUE\nhandler.\n• For NOT FOUND conditions, if the condition was raised normally, the action is CONTINUE. If it was\nraised by SIGNAL or RESIGNAL, the action is EXIT.\nThe following example uses a handler for SQLSTATE '23000', which occurs for a duplicate-key error:\nmysql> CREATE TABLE test.t (s1 INT, PRIMARY KEY (s1));\nQuery OK, 0 rows affected (0.00 sec)\nmysql> delimiter //\nmysql> CREATE PROCEDURE handlerdemo ()\n       BEGIN\n         DECLARE CONTINUE HANDLER FOR SQLSTATE '23000' SET @x2 = 1;\n         SET @x = 1;\n         INSERT INTO test.t VALUES (1);\n         SET @x = 2;\n         INSERT INTO test.t VALUES (1);\n         SET @x = 3;\n       END;\n       //\nQuery OK, 0 rows affected (0.00 sec)\nmysql> CALL handlerdemo()//\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @x//\n    +------+\n    | @x   |\n    +------+\n    | 3    |\n    +------+\n    1 row in set (0.00 sec)\nNotice that @x is 3 after the procedure executes, which shows that execution continued to the end\nof the procedure after the error occurred. If the DECLARE ... HANDLER statement had not been\npresent, MySQL would have taken the default action (EXIT) after the second INSERT failed due to the\nPRIMARY KEY constraint, and SELECT @x would have returned 2.\nTo ignore a condition, declare a CONTINUE handler for it and associate it with an empty block. For\nexample:\nDECLARE CONTINUE HANDLER FOR SQLWARNING BEGIN END;\nThe scope of a block label does not include the code for handlers declared within the block. Therefore,\nthe statement associated with a handler cannot use ITERATE or LEAVE to refer to labels for blocks that\nenclose the handler declaration. Consider the following example, where the REPEAT block has a label\nof retry:\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE i INT DEFAULT 3;\n  retry:\n    REPEAT\n      BEGIN\n        DECLARE CONTINUE HANDLER FOR SQLWARNING\n          BEGIN\n            ITERATE retry;    # illegal\n          END;\n        IF i < 0 THEN\n          LEAVE retry;        # legal\n        END IF;\n        SET i = i - 1;\n      END;\n    UNTIL FALSE END REPEAT;\nEND;\nThe retry label is in scope for the IF statement within the block. It is not in scope for the CONTINUE\nhandler, so the reference there is invalid and results in an error:\nERROR 1308 (42000): LEAVE with no matching label: retry\nTo avoid references to outer labels in handlers, use one of these strategies:\n• To leave the block, use an EXIT handler. If no block cleanup is required, the BEGIN ... END\nhandler body can be empty:\nDECLARE EXIT HANDLER FOR SQLWARNING BEGIN END;\nOtherwise, put the cleanup statements in the handler body:\nDECLARE EXIT HANDLER FOR SQLWARNING\n  BEGIN\n    block cleanup statements\n  END;\n• To continue execution, set a status variable in a CONTINUE handler that can be checked in the\nenclosing block to determine whether the handler was invoked. The following example uses the\nvariable done for this purpose:\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE i INT DEFAULT 3;\n  DECLARE done INT DEFAULT FALSE;\n  retry:\n    REPEAT\n      BEGIN\n        DECLARE CONTINUE HANDLER FOR SQLWARNING\n          BEGIN\n            SET done = TRUE;\n          END;\n        IF done OR i < 0 THEN\n          LEAVE retry;\n        END IF;\n        SET i = i - 1;\n      END;\n    UNTIL FALSE END REPEAT;\nEND;\n15.6.7.3 GET DIAGNOSTICS Statement\nGET [CURRENT | STACKED] DIAGNOSTICS {\n    statement_information_item\n    [, statement_information_item] ...\n  | CONDITION condition_number\n    condition_information_item\n    [, condition_information_item] ...\n}\nstatement_information_item:\n    target = statement_information_item_name\ncondition_information_item:\n    target = condition_information_item_name\nstatement_information_item_name: {\n    NUMBER\n  | ROW_COUNT\n}\ncondition_information_item_name: {\n    CLASS_ORIGIN\n  | SUBCLASS_ORIGIN\n  | RETURNED_SQLSTATE\n  | MESSAGE_TEXT\n  | MYSQL_ERRNO\n  | CONSTRAINT_CATALOG\n  | CONSTRAINT_SCHEMA\n  | CONSTRAINT_NAME\n  | CATALOG_NAME\n  | SCHEMA_NAME\n  | TABLE_NAME\n  | COLUMN_NAME\n  | CURSOR_NAME\n}\ncondition_number, target:\n    (see following discussion)\nSQL statements produce diagnostic information that populates the diagnostics area. The GET\nDIAGNOSTICS statement enables applications to inspect this information. (You can also use SHOW\nWARNINGS or SHOW ERRORS to see conditions or errors.)\nNo special privileges are required to execute GET DIAGNOSTICS.\nThe keyword CURRENT means to retrieve information from the current diagnostics area. The keyword\nSTACKED means to retrieve information from the second diagnostics area, which is available only if\nthe current context is a condition handler. If neither keyword is given, the default is to use the current\ndiagnostics area.\nThe GET DIAGNOSTICS statement is typically used in a handler within a stored program. It is a\nMySQL extension that GET [CURRENT] DIAGNOSTICS is permitted outside handler context to check\nthe execution of any SQL statement. For example, if you invoke the mysql client program, you can\nenter these statements at the prompt:\nmysql> DROP TABLE test.no_such_table;\nERROR 1051 (42S02): Unknown table 'test.no_such_table'\nmysql> GET DIAGNOSTICS CONDITION 1\n         @p1 = RETURNED_SQLSTATE, @p2 = MESSAGE_TEXT;\nmysql> SELECT @p1, @p2;\n+-------+------------------------------------+\n| @p1   | @p2                                |\n+-------+------------------------------------+\n| 42S02 | Unknown table 'test.no_such_table' |\n+-------+------------------------------------+\nThis extension applies only to the current diagnostics area. It does not apply to the second diagnostics\narea because GET STACKED DIAGNOSTICS is permitted only if the current context is a condition\nhandler. If that is not the case, a GET STACKED DIAGNOSTICS when handler not active error\noccurs.\nFor a description of the diagnostics area, see Section 15.6.7.7, “The MySQL Diagnostics Area”. Briefly,\nit contains two kinds of information:\n• Statement information, such as the number of conditions that occurred or the affected-rows count.\n• Condition information, such as the error code and message. If a statement raises multiple conditions,\nthis part of the diagnostics area has a condition area for each one. If a statement raises no\nconditions, this part of the diagnostics area is empty.\nFor a statement that produces three conditions, the diagnostics area contains statement and condition\ninformation like this:\nStatement information:\n  row count\n  ... other statement information items ...\nCondition area list:\n  Condition area 1:\n    error code for condition 1\n    error message for condition 1\n    ... other condition information items ...\n  Condition area 2:\n    error code for condition 2:\n    error message for condition 2\n    ... other condition information items ...\n  Condition area 3:\n    error code for condition 3\n    error message for condition 3\n    ... other condition information items ...\nGET DIAGNOSTICS can obtain either statement or condition information, but not both in the same\nstatement:\n• To obtain statement information, retrieve the desired statement items into target variables. This\ninstance of GET DIAGNOSTICS assigns the number of available conditions and the rows-affected\ncount to the user variables @p1 and @p2:\nGET DIAGNOSTICS @p1 = NUMBER, @p2 = ROW_COUNT;\n• To obtain condition information, specify the condition number and retrieve the desired condition items\ninto target variables. This instance of GET DIAGNOSTICS assigns the SQLSTATE value and error\nmessage to the user variables @p3 and @p4:\nGET DIAGNOSTICS CONDITION 1\n  @p3 = RETURNED_SQLSTATE, @p4 = MESSAGE_TEXT;\nThe retrieval list specifies one or more target = item_name assignments, separated by commas.\nEach assignment names a target variable and either a statement_information_item_name or\ncondition_information_item_name designator, depending on whether the statement retrieves\nstatement or condition information.\nValid target designators for storing item information can be stored procedure or function parameters,\nstored program local variables declared with DECLARE, or user-defined variables.\nValid condition_number designators can be stored procedure or function parameters, stored\nprogram local variables declared with DECLARE, user-defined variables, system variables, or literals. A\ncharacter literal may include a _charset introducer. A warning occurs if the condition number is not\nin the range from 1 to the number of condition areas that have information. In this case, the warning is\nadded to the diagnostics area without clearing it.\nWhen a condition occurs, MySQL does not populate all condition items recognized by GET\nDIAGNOSTICS. For example:\nmysql> GET DIAGNOSTICS CONDITION 1\n         @p5 = SCHEMA_NAME, @p6 = TABLE_NAME;\nmysql> SELECT @p5, @p6;\n+------+------+\n| @p5  | @p6  |\n+------+------+\n|      |      |\n+------+------+\nIn standard SQL, if there are multiple conditions, the first condition relates to the SQLSTATE value\nreturned for the previous SQL statement. In MySQL, this is not guaranteed. To get the main error, you\ncannot do this:\nGET DIAGNOSTICS CONDITION 1 @errno = MYSQL_ERRNO;\nInstead, retrieve the condition count first, then use it to specify which condition number to inspect:\nGET DIAGNOSTICS @cno = NUMBER;\nGET DIAGNOSTICS CONDITION @cno @errno = MYSQL_ERRNO;\nFor information about permissible statement and condition information items, and which ones are\npopulated when a condition occurs, see Diagnostics Area Information Items.\nHere is an example that uses GET DIAGNOSTICS and an exception handler in stored procedure\ncontext to assess the outcome of an insert operation. If the insert was successful, the procedure uses\nGET DIAGNOSTICS to get the rows-affected count. This shows that you can use GET DIAGNOSTICS\nmultiple times to retrieve information about a statement as long as the current diagnostics area has not\nbeen cleared.\nCREATE PROCEDURE do_insert(value INT)\nBEGIN\n  -- Declare variables to hold diagnostics area information\n  DECLARE code CHAR(5) DEFAULT '00000';\n  DECLARE msg TEXT;\n  DECLARE nrows INT;\n  DECLARE result TEXT;\n  -- Declare exception handler for failed insert\n  DECLARE CONTINUE HANDLER FOR SQLEXCEPTION\n    BEGIN\n      GET DIAGNOSTICS CONDITION 1\n        code = RETURNED_SQLSTATE, msg = MESSAGE_TEXT;\n    END;\n  -- Perform the insert\n  INSERT INTO t1 (int_col) VALUES(value);\n  -- Check whether the insert was successful\n  IF code = '00000' THEN\n    GET DIAGNOSTICS nrows = ROW_COUNT;\n    SET result = CONCAT('insert succeeded, row count = ',nrows);\n  ELSE\n    SET result = CONCAT('insert failed, error = ',code,', message = ',msg);\n  END IF;\n  -- Say what happened\n  SELECT result;\nEND;\nSuppose that t1.int_col is an integer column that is declared as NOT NULL. The procedure\nproduces these results when invoked to insert non-NULL and NULL values, respectively:\nmysql> CALL do_insert(1);\n+---------------------------------+\n| result                          |\n+---------------------------------+\n| insert succeeded, row count = 1 |\n+---------------------------------+\nmysql> CALL do_insert(NULL);\n+-------------------------------------------------------------------------+\n| result                                                                  |\n+-------------------------------------------------------------------------+\n| insert failed, error = 23000, message = Column 'int_col' cannot be null |\n+-------------------------------------------------------------------------+\nWhen a condition handler activates, a push to the diagnostics area stack occurs:\n• The first (current) diagnostics area becomes the second (stacked) diagnostics area and a new\ncurrent diagnostics area is created as a copy of it.\n• GET [CURRENT] DIAGNOSTICS and GET STACKED DIAGNOSTICS can be used within the\nhandler to access the contents of the current and stacked diagnostics areas.\n• Initially, both diagnostics areas return the same result, so it is possible to get information from the\ncurrent diagnostics area about the condition that activated the handler, as long as you execute no\nstatements within the handler that change its current diagnostics area.\n• However, statements executing within the handler can modify the current diagnostics area, clearing\nand setting its contents according to the normal rules (see How the Diagnostics Area is Cleared and\nPopulated).\nA more reliable way to obtain information about the handler-activating condition is to use the\nstacked diagnostics area, which cannot be modified by statements executing within the handler\nexcept RESIGNAL. For information about when the current diagnostics area is set and cleared, see\nSection 15.6.7.7, “The MySQL Diagnostics Area”.\nThe next example shows how GET STACKED DIAGNOSTICS can be used within a handler to obtain\ninformation about the handled exception, even after the current diagnostics area has been modified by\nhandler statements.\nWithin a stored procedure p(), we attempt to insert two values into a table that contains a TEXT NOT\nNULL column. The first value is a non-NULL string and the second is NULL. The column prohibits NULL\nvalues, so the first insert succeeds but the second causes an exception. The procedure includes an\nexception handler that maps attempts to insert NULL into inserts of the empty string:\nDROP TABLE IF EXISTS t1;\nCREATE TABLE t1 (c1 TEXT NOT NULL);\nDROP PROCEDURE IF EXISTS p;\ndelimiter //\nCREATE PROCEDURE p ()\nBEGIN\n  -- Declare variables to hold diagnostics area information\n  DECLARE errcount INT;\n  DECLARE errno INT;\n  DECLARE msg TEXT;\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION\n  BEGIN\n    -- Here the current DA is nonempty because no prior statements\n    -- executing within the handler have cleared it\n    GET CURRENT DIAGNOSTICS CONDITION 1\n      errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;\n    SELECT 'current DA before mapped insert' AS op, errno, msg;\n    GET STACKED DIAGNOSTICS CONDITION 1\n      errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;\n    SELECT 'stacked DA before mapped insert' AS op, errno, msg;\n    -- Map attempted NULL insert to empty string insert\n    INSERT INTO t1 (c1) VALUES('');\n    -- Here the current DA should be empty (if the INSERT succeeded),\n    -- so check whether there are conditions before attempting to\n    -- obtain condition information\n    GET CURRENT DIAGNOSTICS errcount = NUMBER;\n    IF errcount = 0\n    THEN\n      SELECT 'mapped insert succeeded, current DA is empty' AS op;\n    ELSE\n      GET CURRENT DIAGNOSTICS CONDITION 1\n        errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;\n      SELECT 'current DA after mapped insert' AS op, errno, msg;\n    END IF ;\n    GET STACKED DIAGNOSTICS CONDITION 1\n      errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;\n    SELECT 'stacked DA after mapped insert' AS op, errno, msg;\n  END;\n  INSERT INTO t1 (c1) VALUES('string 1');\n  INSERT INTO t1 (c1) VALUES(NULL);\nEND;\n//\ndelimiter ;\nCALL p();\nSELECT * FROM t1;\nWhen the handler activates, a copy of the current diagnostics area is pushed to the diagnostics area\nstack. The handler first displays the contents of the current and stacked diagnostics areas, which are\nboth the same initially:\n+---------------------------------+-------+----------------------------+\n| op                              | errno | msg                        |\n+---------------------------------+-------+----------------------------+\n| current DA before mapped insert |  1048 | Column 'c1' cannot be null |\n+---------------------------------+-------+----------------------------+\n+---------------------------------+-------+----------------------------+\n| op                              | errno | msg                        |\n+---------------------------------+-------+----------------------------+\n| stacked DA before mapped insert |  1048 | Column 'c1' cannot be null |\n+---------------------------------+-------+----------------------------+\nStatements executing after the GET DIAGNOSTICS statements may reset the current diagnostics\narea. statements may reset the current diagnostics area. For example, the handler maps the NULL\ninsert to an empty-string insert and displays the result. The new insert succeeds and clears the current\ndiagnostics area, but the stacked diagnostics area remains unchanged and still contains information\nabout the condition that activated the handler:\n+----------------------------------------------+\n| op                                           |\n+----------------------------------------------+\n| mapped insert succeeded, current DA is empty |\n+----------------------------------------------+\n+--------------------------------+-------+----------------------------+\n| op                             | errno | msg                        |\n+--------------------------------+-------+----------------------------+\n| stacked DA after mapped insert |  1048 | Column 'c1' cannot be null |\n+--------------------------------+-------+----------------------------+\nWhen the condition handler ends, its current diagnostics area is popped from the stack and the stacked\ndiagnostics area becomes the current diagnostics area in the stored procedure.\nAfter the procedure returns, the table contains two rows. The empty row results from the attempt to\ninsert NULL that was mapped to an empty-string insert:\n+----------+\n| c1       |\n+----------+\n| string 1 |\n|          |\n+----------+\n15.6.7.4 RESIGNAL Statement\nRESIGNAL [condition_value]\n    [SET signal_information_item\n    [, signal_information_item] ...]\ncondition_value: {\n    SQLSTATE [VALUE] sqlstate_value\n  | condition_name\n}\nsignal_information_item:\n    condition_information_item_name = simple_value_specification\ncondition_information_item_name: {\n    CLASS_ORIGIN\n  | SUBCLASS_ORIGIN\n  | MESSAGE_TEXT\n  | MYSQL_ERRNO\n  | CONSTRAINT_CATALOG\n  | CONSTRAINT_SCHEMA\n  | CONSTRAINT_NAME\n  | CATALOG_NAME\n  | SCHEMA_NAME\n  | TABLE_NAME\n  | COLUMN_NAME\n  | CURSOR_NAME\n}\ncondition_name, simple_value_specification:\n    (see following discussion)\nRESIGNAL passes on the error condition information that is available during execution of a condition\nhandler within a compound statement inside a stored procedure or function, trigger, or event.\nRESIGNAL may change some or all information before passing it on. RESIGNAL is related to SIGNAL,\nbut instead of originating a condition as SIGNAL does, RESIGNAL relays existing condition information,\npossibly after modifying it.\nRESIGNAL makes it possible to both handle an error and return the error information. Otherwise, by\nexecuting an SQL statement within the handler, information that caused the handler's activation is\ndestroyed. RESIGNAL also can make some procedures shorter if a given handler can handle part of a\nsituation, then pass the condition “up the line” to another handler.\nNo privileges are required to execute the RESIGNAL statement.\nAll forms of RESIGNAL require that the current context be a condition handler. Otherwise, RESIGNAL is\nillegal and a RESIGNAL when handler not active error occurs.\nTo retrieve information from the diagnostics area, use the GET DIAGNOSTICS statement (see\nSection 15.6.7.3, “GET DIAGNOSTICS Statement”). For information about the diagnostics area, see\nSection 15.6.7.7, “The MySQL Diagnostics Area”.\n• RESIGNAL Overview\n• RESIGNAL Alone\n• RESIGNAL with New Signal Information\n• RESIGNAL with a Condition Value and Optional New Signal Information\n• RESIGNAL Requires Condition Handler Context\nRESIGNAL Overview\nFor condition_value and signal_information_item, the definitions and rules are the same\nfor RESIGNAL as for SIGNAL. For example, the condition_value can be an SQLSTATE value, and\nthe value can indicate errors, warnings, or “not found.” For additional information, see Section 15.6.7.5,\n“SIGNAL Statement”.\nThe RESIGNAL statement takes condition_value and SET clauses, both of which are optional. This\nleads to several possible uses:\n• RESIGNAL alone:\nRESIGNAL;\n• RESIGNAL with new signal information:\nRESIGNAL SET signal_information_item [, signal_information_item] ...;\n• RESIGNAL with a condition value and possibly new signal information:\nRESIGNAL condition_value\n    [SET signal_information_item [, signal_information_item] ...];\nThese use cases all cause changes to the diagnostics and condition areas:\n• A diagnostics area contains one or more condition areas.\n• A condition area contains condition information items, such as the SQLSTATE value, MYSQL_ERRNO,\nor MESSAGE_TEXT.\nThere is a stack of diagnostics areas. When a handler takes control, it pushes a diagnostics area to the\ntop of the stack, so there are two diagnostics areas during handler execution:\n• The first (current) diagnostics area, which starts as a copy of the last diagnostics area, but is\noverwritten by the first statement in the handler that changes the current diagnostics area.\n• The last (stacked) diagnostics area, which has the condition areas that were set up before the\nhandler took control.\nThe maximum number of condition areas in a diagnostics area is determined by the value of the\nmax_error_count system variable. See Diagnostics Area-Related System Variables.\nRESIGNAL Alone\nA simple RESIGNAL alone means “pass on the error with no change.” It restores the last diagnostics\narea and makes it the current diagnostics area. That is, it “pops” the diagnostics area stack.\nWithin a condition handler that catches a condition, one use for RESIGNAL alone is to perform some\nother actions, and then pass on without change the original condition information (the information that\nexisted before entry into the handler).\nExample:\nDROP TABLE IF EXISTS xx;\ndelimiter //\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION\n  BEGIN\n    SET @error_count = @error_count + 1;\n    IF @a = 0 THEN RESIGNAL; END IF;\n  END;\n  DROP TABLE xx;\nEND//\ndelimiter ;\nSET @error_count = 0;\nSET @a = 0;\nCALL p();\nSuppose that the DROP TABLE xx statement fails. The diagnostics area stack looks like this:\nDA 1. ERROR 1051 (42S02): Unknown table 'xx'\nThen execution enters the EXIT handler. It starts by pushing a diagnostics area to the top of the stack,\nwhich now looks like this:\nDA 1. ERROR 1051 (42S02): Unknown table 'xx'\nDA 2. ERROR 1051 (42S02): Unknown table 'xx'\nAt this point, the contents of the first (current) and second (stacked) diagnostics areas are the same.\nThe first diagnostics area may be modified by statements executing subsequently within the handler.\nUsually a procedure statement clears the first diagnostics area. BEGIN is an exception, it does not\nclear, it does nothing. SET is not an exception, it clears, performs the operation, and produces a result\nof “success.” The diagnostics area stack now looks like this:\nDA 1. ERROR 0000 (00000): Successful operation\nDA 2. ERROR 1051 (42S02): Unknown table 'xx'\nAt this point, if @a = 0, RESIGNAL pops the diagnostics area stack, which now looks like this:\nDA 1. ERROR 1051 (42S02): Unknown table 'xx'\nAnd that is what the caller sees.\nIf @a is not 0, the handler simply ends, which means that there is no more use for the current\ndiagnostics area (it has been “handled”), so it can be thrown away, causing the stacked diagnostics\narea to become the current diagnostics area again. The diagnostics area stack looks like this:\nDA 1. ERROR 0000 (00000): Successful operation\nThe details make it look complex, but the end result is quite useful: Handlers can execute without\ndestroying information about the condition that caused activation of the handler.\nRESIGNAL with New Signal Information\nRESIGNAL with a SET clause provides new signal information, so the statement means “pass on the\nerror with changes”:\nRESIGNAL SET signal_information_item [, signal_information_item] ...;\nAs with RESIGNAL alone, the idea is to pop the diagnostics area stack so that the original information\ngoes out. Unlike RESIGNAL alone, anything specified in the SET clause changes.\nExample:\nDROP TABLE IF EXISTS xx;\ndelimiter //\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION\n  BEGIN\n    SET @error_count = @error_count + 1;\n    IF @a = 0 THEN RESIGNAL SET MYSQL_ERRNO = 5; END IF;\n  END;\n  DROP TABLE xx;\nEND//\ndelimiter ;\nSET @error_count = 0;\nSET @a = 0;\nCALL p();\nRemember from the previous discussion that RESIGNAL alone results in a diagnostics area stack like\nthis:\nDA 1. ERROR 1051 (42S02): Unknown table 'xx'\nThe RESIGNAL SET MYSQL_ERRNO = 5 statement results in this stack instead, which is what the\ncaller sees:\nDA 1. ERROR 5 (42S02): Unknown table 'xx'\nIn other words, it changes the error number, and nothing else.\nThe RESIGNAL statement can change any or all of the signal information items, making the first\ncondition area of the diagnostics area look quite different.\nRESIGNAL with a Condition Value and Optional New Signal Information\nRESIGNAL with a condition value means “push a condition into the current diagnostics area.” If the SET\nclause is present, it also changes the error information.\nRESIGNAL condition_value\n    [SET signal_information_item [, signal_information_item] ...];\nThis form of RESIGNAL restores the last diagnostics area and makes it the current diagnostics area.\nThat is, it “pops” the diagnostics area stack, which is the same as what a simple RESIGNAL alone\nwould do. However, it also changes the diagnostics area depending on the condition value or signal\ninformation.\nExample:\nDROP TABLE IF EXISTS xx;\ndelimiter //\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION\n  BEGIN\n    SET @error_count = @error_count + 1;\n    IF @a = 0 THEN RESIGNAL SQLSTATE '45000' SET MYSQL_ERRNO=5; END IF;\n  END;\n  DROP TABLE xx;\nEND//\ndelimiter ;\nSET @error_count = 0;\nSET @a = 0;\nSET @@max_error_count = 2;\nCALL p();\nSHOW ERRORS;\nThis is similar to the previous example, and the effects are the same, except that if RESIGNAL\nhappens, the current condition area looks different at the end. (The reason the condition adds to rather\nthan replaces the existing condition is the use of a condition value.)\nThe RESIGNAL statement includes a condition value (SQLSTATE '45000'), so it adds a new\ncondition area, resulting in a diagnostics area stack that looks like this:\nDA 1. (condition 2) ERROR 1051 (42S02): Unknown table 'xx'\n      (condition 1) ERROR 5 (45000) Unknown table 'xx'\nThe result of CALL p() and SHOW ERRORS for this example is:\nmysql> CALL p();\nERROR 5 (45000): Unknown table 'xx'\nmysql> SHOW ERRORS;\n+-------+------+----------------------------------+\n| Level | Code | Message                          |\n+-------+------+----------------------------------+\n| Error | 1051 | Unknown table 'xx'               |\n| Error |    5 | Unknown table 'xx'               |\n+-------+------+----------------------------------+\nRESIGNAL Requires Condition Handler Context\nAll forms of RESIGNAL require that the current context be a condition handler. Otherwise, RESIGNAL is\nillegal and a RESIGNAL when handler not active error occurs. For example:\nmysql> CREATE PROCEDURE p () RESIGNAL;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> CALL p();\nERROR 1645 (0K000): RESIGNAL when handler not active\nHere is a more difficult example:\ndelimiter //\nCREATE FUNCTION f () RETURNS INT\nBEGIN\n  RESIGNAL;\n  RETURN 5;\nEND//\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION SET @a=f();\n  SIGNAL SQLSTATE '55555';\nEND//\ndelimiter ;\nCALL p();\nRESIGNAL occurs within the stored function f(). Although f() itself is invoked within the context\nof the EXIT handler, execution within f() has its own context, which is not handler context. Thus,\nRESIGNAL within f() results in a “handler not active” error.\n15.6.7.5 SIGNAL Statement\nSIGNAL condition_value\n    [SET signal_information_item\n    [, signal_information_item] ...]\ncondition_value: {\n    SQLSTATE [VALUE] sqlstate_value\n  | condition_name\n}\nsignal_information_item:\n    condition_information_item_name = simple_value_specification\ncondition_information_item_name: {\n    CLASS_ORIGIN\n  | SUBCLASS_ORIGIN\n  | MESSAGE_TEXT\n  | MYSQL_ERRNO\n  | CONSTRAINT_CATALOG\n  | CONSTRAINT_SCHEMA\n  | CONSTRAINT_NAME\n  | CATALOG_NAME\n  | SCHEMA_NAME\n  | TABLE_NAME\n  | COLUMN_NAME\n  | CURSOR_NAME\n}\ncondition_name, simple_value_specification:\n    (see following discussion)\nSIGNAL is the way to “return” an error. SIGNAL provides error information to a handler, to an outer\nportion of the application, or to the client. Also, it provides control over the error's characteristics (error\nnumber, SQLSTATE value, message). Without SIGNAL, it is necessary to resort to workarounds such\nas deliberately referring to a nonexistent table to cause a routine to return an error.\nNo privileges are required to execute the SIGNAL statement.\nTo retrieve information from the diagnostics area, use the GET DIAGNOSTICS statement (see\nSection 15.6.7.3, “GET DIAGNOSTICS Statement”). For information about the diagnostics area, see\nSection 15.6.7.7, “The MySQL Diagnostics Area”.\n• SIGNAL Overview\n• Signal Condition Information Items\n• Effect of Signals on Handlers, Cursors, and Statements\nSIGNAL Overview\nThe condition_value in a SIGNAL statement indicates the error value to be returned. It can be an\nSQLSTATE value (a 5-character string literal) or a condition_name that refers to a named condition\npreviously defined with DECLARE ... CONDITION (see Section 15.6.7.1, “DECLARE ... CONDITION\nStatement”).\nAn SQLSTATE value can indicate errors, warnings, or “not found.” The first two characters of the value\nindicate its error class, as discussed in Signal Condition Information Items. Some signal values cause\nstatement termination; see Effect of Signals on Handlers, Cursors, and Statements.\nThe SQLSTATE value for a SIGNAL statement should not start with '00' because such values indicate\nsuccess and are not valid for signaling an error. This is true whether the SQLSTATE value is specified\ndirectly in the SIGNAL statement or in a named condition referred to in the statement. If the value is\ninvalid, a Bad SQLSTATE error occurs.\nTo signal a generic SQLSTATE value, use '45000', which means “unhandled user-defined exception.”\nThe SIGNAL statement optionally includes a SET clause that contains multiple signal items, in a list\nof condition_information_item_name = simple_value_specification assignments,\nseparated by commas.\nEach condition_information_item_name may be specified only once in the SET clause.\nOtherwise, a Duplicate condition information item error occurs.\nValid simple_value_specification designators can be specified using stored procedure or\nfunction parameters, stored program local variables declared with DECLARE, user-defined variables,\nsystem variables, or literals. A character literal may include a _charset introducer.\nFor information about permissible condition_information_item_name values, see Signal\nCondition Information Items.\nThe following procedure signals an error or warning depending on the value of pval, its input\nparameter:\nCREATE PROCEDURE p (pval INT)\nBEGIN\n  DECLARE specialty CONDITION FOR SQLSTATE '45000';\n  IF pval = 0 THEN\n    SIGNAL SQLSTATE '01000';\n  ELSEIF pval = 1 THEN\n    SIGNAL SQLSTATE '45000'\n      SET MESSAGE_TEXT = 'An error occurred';\n  ELSEIF pval = 2 THEN\n    SIGNAL specialty\n      SET MESSAGE_TEXT = 'An error occurred';\n  ELSE\n    SIGNAL SQLSTATE '01000'\n      SET MESSAGE_TEXT = 'A warning occurred', MYSQL_ERRNO = 1000;\n    SIGNAL SQLSTATE '45000'\n      SET MESSAGE_TEXT = 'An error occurred', MYSQL_ERRNO = 1001;\n  END IF;\nEND;\nIf pval is 0, p() signals a warning because SQLSTATE values that begin with '01' are signals in the\nwarning class. The warning does not terminate the procedure, and can be seen with SHOW WARNINGS\nafter the procedure returns.\nIf pval is 1, p() signals an error and sets the MESSAGE_TEXT condition information item. The error\nterminates the procedure, and the text is returned with the error information.\nIf pval is 2, the same error is signaled, although the SQLSTATE value is specified using a named\ncondition in this case.\nIf pval is anything else, p() first signals a warning and sets the message text and error number\ncondition information items. This warning does not terminate the procedure, so execution continues\nand p() then signals an error. The error does terminate the procedure. The message text and error\nnumber set by the warning are replaced by the values set by the error, which are returned with the\nerror information.\nSIGNAL is typically used within stored programs, but it is a MySQL extension that it is permitted outside\nhandler context. For example, if you invoke the mysql client program, you can enter any of these\nstatements at the prompt:\nSIGNAL SQLSTATE '77777';\nCREATE TRIGGER t_bi BEFORE INSERT ON t\n  FOR EACH ROW SIGNAL SQLSTATE '77777';\nCREATE EVENT e ON SCHEDULE EVERY 1 SECOND\n  DO SIGNAL SQLSTATE '77777';\nSIGNAL executes according to the following rules:\nIf the SIGNAL statement indicates a particular SQLSTATE value, that value is used to signal the\ncondition specified. Example:\nCREATE PROCEDURE p (divisor INT)\nBEGIN\n  IF divisor = 0 THEN\n    SIGNAL SQLSTATE '22012';\n  END IF;\nEND;\nIf the SIGNAL statement uses a named condition, the condition must be declared in some scope that\napplies to the SIGNAL statement, and must be defined using an SQLSTATE value, not a MySQL error\nnumber. Example:\nCREATE PROCEDURE p (divisor INT)\nBEGIN\n  DECLARE divide_by_zero CONDITION FOR SQLSTATE '22012';\n  IF divisor = 0 THEN\n    SIGNAL divide_by_zero;\n  END IF;\nEND;\nIf the named condition does not exist in the scope of the SIGNAL statement, an Undefined\nCONDITION error occurs.\nIf SIGNAL refers to a named condition that is defined with a MySQL error number rather than\nan SQLSTATE value, a SIGNAL/RESIGNAL can only use a CONDITION defined with\nSQLSTATE error occurs. The following statements cause that error because the named condition is\nassociated with a MySQL error number:\nDECLARE no_such_table CONDITION FOR 1051;\nSIGNAL no_such_table;\nIf a condition with a given name is declared multiple times in different scopes, the declaration with the\nmost local scope applies. Consider the following procedure:\nCREATE PROCEDURE p (divisor INT)\nBEGIN\n  DECLARE my_error CONDITION FOR SQLSTATE '45000';\n  IF divisor = 0 THEN\n    BEGIN\n      DECLARE my_error CONDITION FOR SQLSTATE '22012';\n      SIGNAL my_error;\n    END;\n  END IF;\n  SIGNAL my_error;\nEND;\nIf divisor is 0, the first SIGNAL statement executes. The innermost my_error condition declaration\napplies, raising SQLSTATE '22012'.\nIf divisor is not 0, the second SIGNAL statement executes. The outermost my_error condition\ndeclaration applies, raising SQLSTATE '45000'.\nFor information about how the server chooses handlers when a condition occurs, see Section 15.6.7.6,\n“Scope Rules for Handlers”.\nSignals can be raised within exception handlers:\nCREATE PROCEDURE p ()\nBEGIN\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION\n  BEGIN\n    SIGNAL SQLSTATE VALUE '99999'\n      SET MESSAGE_TEXT = 'An error occurred';\n  END;\n  DROP TABLE no_such_table;\nEND;\nCALL p() reaches the DROP TABLE statement. There is no table named no_such_table, so the\nerror handler is activated. The error handler destroys the original error (“no such table”) and makes a\nnew error with SQLSTATE '99999' and message An error occurred.\nSignal Condition Information Items\nThe following table lists the names of diagnostics area condition information items that can be set\nin a SIGNAL (or RESIGNAL) statement. All items are standard SQL except MYSQL_ERRNO, which\nis a MySQL extension. For more information about these items see Section 15.6.7.7, “The MySQL\nDiagnostics Area”.\nItem Name             Definition\n---------             ----------\nCLASS_ORIGIN          VARCHAR(64)\nSUBCLASS_ORIGIN       VARCHAR(64)\nCONSTRAINT_CATALOG    VARCHAR(64)\nCONSTRAINT_SCHEMA     VARCHAR(64)\nCONSTRAINT_NAME       VARCHAR(64)\nCATALOG_NAME          VARCHAR(64)\nSCHEMA_NAME           VARCHAR(64)\nTABLE_NAME            VARCHAR(64)\nCOLUMN_NAME           VARCHAR(64)\nCURSOR_NAME           VARCHAR(64)\nMESSAGE_TEXT          VARCHAR(128)\nMYSQL_ERRNO           SMALLINT UNSIGNED\nThe character set for character items is UTF-8.\nIt is illegal to assign NULL to a condition information item in a SIGNAL statement.\nA SIGNAL statement always specifies an SQLSTATE value, either directly, or indirectly by referring to a\nnamed condition defined with an SQLSTATE value. The first two characters of an SQLSTATE value are\nits class, and the class determines the default value for the condition information items:\n• Class = '00' (success)\nIllegal. SQLSTATE values that begin with '00' indicate success and are not valid for SIGNAL.\n• Class = '01' (warning)\nMESSAGE_TEXT = 'Unhandled user-defined warning condition';\nMYSQL_ERRNO = ER_SIGNAL_WARN\n• Class = '02' (not found)\nMESSAGE_TEXT = 'Unhandled user-defined not found condition';\nMYSQL_ERRNO = ER_SIGNAL_NOT_FOUND\n• Class > '02' (exception)\nMESSAGE_TEXT = 'Unhandled user-defined exception condition';\nMYSQL_ERRNO = ER_SIGNAL_EXCEPTION\nFor legal classes, the other condition information items are set as follows:\nCLASS_ORIGIN = SUBCLASS_ORIGIN = '';\nCONSTRAINT_CATALOG = CONSTRAINT_SCHEMA = CONSTRAINT_NAME = '';\nCATALOG_NAME = SCHEMA_NAME = TABLE_NAME = COLUMN_NAME = '';\nCURSOR_NAME = '';\nThe error values that are accessible after SIGNAL executes are the SQLSTATE value raised by the\nSIGNAL statement and the MESSAGE_TEXT and MYSQL_ERRNO items. These values are available from\nthe C API:\n• mysql_sqlstate() returns the SQLSTATE value.\n• mysql_errno() returns the MYSQL_ERRNO value.\n• mysql_error() returns the MESSAGE_TEXT value.\nAt the SQL level, the output from SHOW WARNINGS and SHOW ERRORS indicates the MYSQL_ERRNO\nand MESSAGE_TEXT values in the Code and Message columns.\nTo retrieve information from the diagnostics area, use the GET DIAGNOSTICS statement (see\nSection 15.6.7.3, “GET DIAGNOSTICS Statement”). For information about the diagnostics area, see\nSection 15.6.7.7, “The MySQL Diagnostics Area”.\nEffect of Signals on Handlers, Cursors, and Statements\nSignals have different effects on statement execution depending on the signal class. The class\ndetermines how severe an error is. MySQL ignores the value of the sql_mode system variable; in\nparticular, strict SQL mode does not matter. MySQL also ignores IGNORE: The intent of SIGNAL is to\nraise a user-generated error explicitly, so a signal is never ignored.\nIn the following descriptions, “unhandled” means that no handler for the signaled SQLSTATE value has\nbeen defined with DECLARE ... HANDLER.\n• Class = '00' (success)\nIllegal. SQLSTATE values that begin with '00' indicate success and are not valid for SIGNAL.\n• Class = '01' (warning)\nThe value of the warning_count system variable goes up. SHOW WARNINGS shows the signal.\nSQLWARNING handlers catch the signal.\nWarnings cannot be returned from stored functions because the RETURN statement that causes the\nfunction to return clears the diagnostic area. The statement thus clears any warnings that may have\nbeen present there (and resets warning_count to 0).\n• Class = '02' (not found)\nNOT FOUND handlers catch the signal. There is no effect on cursors. If the signal is unhandled in a\nstored function, statements end.\n• Class > '02' (exception)\nSQLEXCEPTION handlers catch the signal. If the signal is unhandled in a stored function, statements\nend.\n• Class = '40'\nTreated as an ordinary exception.\n15.6.7.6 Scope Rules for Handlers\nA stored program may include handlers to be invoked when certain conditions occur within the\nprogram. The applicability of each handler depends on its location within the program definition and on\nthe condition or conditions that it handles:\n• A handler declared in a BEGIN ... END block is in scope only for the SQL statements following\nthe handler declarations in the block. If the handler itself raises a condition, it cannot handle that\ncondition, nor can any other handlers declared in the block. In the following example, handlers H1\nand H2 are in scope for conditions raised by statements stmt1 and stmt2. But neither H1 nor H2\nare in scope for conditions raised in the body of H1 or H2.\nBEGIN -- outer block\n  DECLARE EXIT HANDLER FOR ...;  -- handler H1\n  DECLARE EXIT HANDLER FOR ...;  -- handler H2\n  stmt1;\n  stmt2;\nEND;\n• A handler is in scope only for the block in which it is declared, and cannot be activated for conditions\noccurring outside that block. In the following example, handler H1 is in scope for stmt1 in the inner\nblock, but not for stmt2 in the outer block:\nBEGIN -- outer block\n  BEGIN -- inner block\n    DECLARE EXIT HANDLER FOR ...;  -- handler H1\n    stmt1;\n  END;\n  stmt2;\nEND;\n• A handler can be specific or general. A specific handler is for a MySQL error code, SQLSTATE value,\nor condition name. A general handler is for a condition in the SQLWARNING, SQLEXCEPTION, or NOT\nFOUND class. Condition specificity is related to condition precedence, as described later.\nMultiple handlers can be declared in different scopes and with different specificities. For example,\nthere might be a specific MySQL error code handler in an outer block, and a general SQLWARNING\nhandler in an inner block. Or there might be handlers for a specific MySQL error code and the general\nSQLWARNING class in the same block.\nWhether a handler is activated depends not only on its own scope and condition value, but on what\nother handlers are present. When a condition occurs in a stored program, the server searches for\napplicable handlers in the current scope (current BEGIN ... END block). If there are no applicable\nhandlers, the search continues outward with the handlers in each successive containing scope (block).\nWhen the server finds one or more applicable handlers at a given scope, it chooses among them\nbased on condition precedence:\n• A MySQL error code handler takes precedence over an SQLSTATE value handler.\n• An SQLSTATE value handler takes precedence over general SQLWARNING, SQLEXCEPTION, or NOT\nFOUND handlers.\n• An SQLEXCEPTION handler takes precedence over an SQLWARNING handler.\n• It is possible to have several applicable handlers with the same precedence. For example, a\nstatement could generate multiple warnings with different error codes, for each of which an\nerror-specific handler exists. In this case, the choice of which handler the server activates is\nnondeterministic, and may change depending on the circumstances under which the condition\noccurs.\nOne implication of the handler selection rules is that if multiple applicable handlers occur in different\nscopes, handlers with the most local scope take precedence over handlers in outer scopes, even over\nthose for more specific conditions.\nIf there is no appropriate handler when a condition occurs, the action taken depends on the class of the\ncondition:\n• For SQLEXCEPTION conditions, the stored program terminates at the statement that raised the\ncondition, as if there were an EXIT handler. If the program was called by another stored program,\nthe calling program handles the condition using the handler selection rules applied to its own\nhandlers.\n• For SQLWARNING conditions, the program continues executing, as if there were a CONTINUE\nhandler.\n• For NOT FOUND conditions, if the condition was raised normally, the action is CONTINUE. If it was\nraised by SIGNAL or RESIGNAL, the action is EXIT.\nThe following examples demonstrate how MySQL applies the handler selection rules.\nThis procedure contains two handlers, one for the specific SQLSTATE value ('42S02') that occurs for\nattempts to drop a nonexistent table, and one for the general SQLEXCEPTION class:\nCREATE PROCEDURE p1()\nBEGIN\n  DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'\n    SELECT 'SQLSTATE handler was activated' AS msg;\n  DECLARE CONTINUE HANDLER FOR SQLEXCEPTION\n    SELECT 'SQLEXCEPTION handler was activated' AS msg;\n  DROP TABLE test.t;\nEND;\nBoth handlers are declared in the same block and have the same scope. However, SQLSTATE\nhandlers take precedence over SQLEXCEPTION handlers, so if the table t is nonexistent, the DROP\nTABLE statement raises a condition that activates the SQLSTATE handler:\nmysql> CALL p1();\n+--------------------------------+\n| msg                            |\n+--------------------------------+\n| SQLSTATE handler was activated |\n+--------------------------------+\nThis procedure contains the same two handlers. But this time, the DROP TABLE statement and\nSQLEXCEPTION handler are in an inner block relative to the SQLSTATE handler:\nCREATE PROCEDURE p2()\nBEGIN -- outer block\n    DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'\n      SELECT 'SQLSTATE handler was activated' AS msg;\n  BEGIN -- inner block\n    DECLARE CONTINUE HANDLER FOR SQLEXCEPTION\n      SELECT 'SQLEXCEPTION handler was activated' AS msg;\n    DROP TABLE test.t; -- occurs within inner block\n  END;\nEND;\nIn this case, the handler that is more local to where the condition occurs takes precedence. The\nSQLEXCEPTION handler activates, even though it is more general than the SQLSTATE handler:\nmysql> CALL p2();\n+------------------------------------+\n| msg                                |\n+------------------------------------+\n| SQLEXCEPTION handler was activated |\n+------------------------------------+\nIn this procedure, one of the handlers is declared in a block inner to the scope of the DROP TABLE\nstatement:\nCREATE PROCEDURE p3()\nBEGIN -- outer block\n  DECLARE CONTINUE HANDLER FOR SQLEXCEPTION\n    SELECT 'SQLEXCEPTION handler was activated' AS msg;\n  BEGIN -- inner block\n    DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'\n      SELECT 'SQLSTATE handler was activated' AS msg;\n  END;\n  DROP TABLE test.t; -- occurs within outer block\nEND;\nOnly the SQLEXCEPTION handler applies because the other one is not in scope for the condition raised\nby the DROP TABLE:\nmysql> CALL p3();\n+------------------------------------+\n| msg                                |\n+------------------------------------+\n| SQLEXCEPTION handler was activated |\n+------------------------------------+\nIn this procedure, both handlers are declared in a block inner to the scope of the DROP TABLE\nstatement:\nCREATE PROCEDURE p4()\nBEGIN -- outer block\n  BEGIN -- inner block\n    DECLARE CONTINUE HANDLER FOR SQLEXCEPTION\n      SELECT 'SQLEXCEPTION handler was activated' AS msg;\n    DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'\n      SELECT 'SQLSTATE handler was activated' AS msg;\n  END;\n  DROP TABLE test.t; -- occurs within outer block\nEND;\nNeither handler applies because they are not in scope for the DROP TABLE. The condition raised by\nthe statement goes unhandled and terminates the procedure with an error:\nmysql> CALL p4();\nERROR 1051 (42S02): Unknown table 'test.t'\n15.6.7.7 The MySQL Diagnostics Area\nSQL statements produce diagnostic information that populates the diagnostics area. Standard SQL has\na diagnostics area stack, containing a diagnostics area for each nested execution context. Standard\nSQL also supports GET STACKED DIAGNOSTICS syntax for referring to the second diagnostics area\nduring condition handler execution.\nThe following discussion describes the structure of the diagnostics area in MySQL, the information\nitems recognized by MySQL, how statements clear and set the diagnostics area, and how diagnostics\nareas are pushed to and popped from the stack.\n• Diagnostics Area Structure\n• Diagnostics Area Information Items\n• How the Diagnostics Area is Cleared and Populated\n• How the Diagnostics Area Stack Works\n• Diagnostics Area-Related System Variables\nDiagnostics Area Structure\nThe diagnostics area contains two kinds of information:\n• Statement information, such as the number of conditions that occurred or the affected-rows count.\n• Condition information, such as the error code and message. If a statement raises multiple conditions,\nthis part of the diagnostics area has a condition area for each one. If a statement raises no\nconditions, this part of the diagnostics area is empty.\nFor a statement that produces three conditions, the diagnostics area contains statement and condition\ninformation like this:\nStatement information:\n  row count\n  ... other statement information items ...\nCondition area list:\n  Condition area 1:\n    error code for condition 1\n    error message for condition 1\n    ... other condition information items ...\n  Condition area 2:\n    error code for condition 2:\n    error message for condition 2\n    ... other condition information items ...\n  Condition area 3:\n    error code for condition 3\n    error message for condition 3\n    ... other condition information items ...\nDiagnostics Area Information Items\nThe diagnostics area contains statement and condition information items. Numeric items are integers.\nThe character set for character items is UTF-8. No item can be NULL. If a statement or condition item is\nnot set by a statement that populates the diagnostics area, its value is 0 or the empty string, depending\non the item data type.\nThe statement information part of the diagnostics area contains these items:\n• NUMBER: An integer indicating the number of condition areas that have information.\n• ROW_COUNT: An integer indicating the number of rows affected by the statement. ROW_COUNT has\nthe same value as the ROW_COUNT() function (see Section 14.15, “Information Functions”).\nThe condition information part of the diagnostics area contains a condition area for each condition.\nCondition areas are numbered from 1 to the value of the NUMBER statement condition item. If NUMBER\nis 0, there are no condition areas.\nEach condition area contains the items in the following list. All items are standard SQL except\nMYSQL_ERRNO, which is a MySQL extension. The definitions apply for conditions generated other than\nby a signal (that is, by a SIGNAL or RESIGNAL statement). For nonsignal conditions, MySQL populates\nonly those condition items not described as always empty. The effects of signals on the condition area\nare described later.\n• CLASS_ORIGIN: A string containing the class of the RETURNED_SQLSTATE value. If the\nRETURNED_SQLSTATE value begins with a class value defined in SQL standards document ISO\n9075-2 (section 24.1, SQLSTATE), CLASS_ORIGIN is 'ISO 9075'. Otherwise, CLASS_ORIGIN is\n'MySQL'.\n• SUBCLASS_ORIGIN: A string containing the subclass of the RETURNED_SQLSTATE value. If\nCLASS_ORIGIN is 'ISO 9075' or RETURNED_SQLSTATE ends with '000', SUBCLASS_ORIGIN is\n'ISO 9075'. Otherwise, SUBCLASS_ORIGIN is 'MySQL'.\n• RETURNED_SQLSTATE: A string that indicates the SQLSTATE value for the condition.\n• MESSAGE_TEXT: A string that indicates the error message for the condition.\n• MYSQL_ERRNO: An integer that indicates the MySQL error code for the condition.\n• CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME: Strings that indicate the\ncatalog, schema, and name for a violated constraint. They are always empty.\n• CATALOG_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME: Strings that indicate the catalog,\nschema, table, and column related to the condition. They are always empty.\n• CURSOR_NAME: A string that indicates the cursor name. This is always empty.\nFor the RETURNED_SQLSTATE, MESSAGE_TEXT, and MYSQL_ERRNO values for particular errors, see\nServer Error Message Reference.\nIf a SIGNAL (or RESIGNAL) statement populates the diagnostics area, its SET clause can assign to any\ncondition information item except RETURNED_SQLSTATE any value that is legal for the item data type.\nSIGNAL also sets the RETURNED_SQLSTATE value, but not directly in its SET clause. That value comes\nfrom the SIGNAL statement SQLSTATE argument.\nSIGNAL also sets statement information items. It sets NUMBER to 1. It sets ROW_COUNT to −1 for errors\nand 0 otherwise.\nHow the Diagnostics Area is Cleared and Populated\nNondiagnostic SQL statements populate the diagnostics area automatically, and its contents can be set\nexplicitly with the SIGNAL and RESIGNAL statements. The diagnostics area can be examined with GET\nDIAGNOSTICS to extract specific items, or with SHOW WARNINGS or SHOW ERRORS to see conditions\nor errors.\nSQL statements clear and set the diagnostics area as follows:\n• When the server starts executing a statement after parsing it, it clears the diagnostics area\nfor nondiagnostic statements. Diagnostic statements do not clear the diagnostics area. These\nstatements are diagnostic:\n• GET DIAGNOSTICS\n• SHOW ERRORS\n• SHOW WARNINGS\n• If a statement raises a condition, the diagnostics area is cleared of conditions that belong to earlier\nstatements. The exception is that conditions raised by GET DIAGNOSTICS and RESIGNAL are\nadded to the diagnostics area without clearing it.\nThus, even a statement that does not normally clear the diagnostics area when it begins executing\nclears it if the statement raises a condition.\nThe following example shows the effect of various statements on the diagnostics area, using SHOW\nWARNINGS to display information about conditions stored there.\nThis DROP TABLE statement clears the diagnostics area and populates it when the condition occurs:\nmysql> DROP TABLE IF EXISTS test.no_such_table;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\nmysql> SHOW WARNINGS;\n+-------+------+------------------------------------+\n| Level | Code | Message                            |\n+-------+------+------------------------------------+\n| Note  | 1051 | Unknown table 'test.no_such_table' |\n+-------+------+------------------------------------+\n1 row in set (0.00 sec)\nThis SET statement generates an error, so it clears and populates the diagnostics area:\nmysql> SET @x = @@x;\nERROR 1193 (HY000): Unknown system variable 'x'\nmysql> SHOW WARNINGS;\n+-------+------+-----------------------------+\n| Level | Code | Message                     |\n+-------+------+-----------------------------+\n| Error | 1193 | Unknown system variable 'x' |\n+-------+------+-----------------------------+\n1 row in set (0.00 sec)\nThe previous SET statement produced a single condition, so 1 is the only valid condition number\nfor GET DIAGNOSTICS at this point. The following statement uses a condition number of 2, which\nproduces a warning that is added to the diagnostics area without clearing it:\nmysql> GET DIAGNOSTICS CONDITION 2 @p = MESSAGE_TEXT;\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS;\n+-------+------+------------------------------+\n| Level | Code | Message                      |\n+-------+------+------------------------------+\n| Error | 1193 | Unknown system variable 'xx' |\n| Error | 1753 | Invalid condition number     |\n+-------+------+------------------------------+\n2 rows in set (0.00 sec)\nNow there are two conditions in the diagnostics area, so the same GET DIAGNOSTICS statement\nsucceeds:\nmysql> GET DIAGNOSTICS CONDITION 2 @p = MESSAGE_TEXT;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @p;\n+--------------------------+\n| @p                       |\n+--------------------------+\n| Invalid condition number |\n+--------------------------+\n1 row in set (0.01 sec)\nHow the Diagnostics Area Stack Works\nWhen a push to the diagnostics area stack occurs, the first (current) diagnostics area becomes the\nsecond (stacked) diagnostics area and a new current diagnostics area is created as a copy of it.\nDiagnostics areas are pushed to and popped from the stack under the following circumstances:\n• Execution of a stored program\nA push occurs before the program executes and a pop occurs afterward. If the stored program ends\nwhile handlers are executing, there can be more than one diagnostics area to pop; this occurs due to\nan exception for which there are no appropriate handlers or due to RETURN in the handler.\nAny warning or error conditions in the popped diagnostics areas then are added to the current\ndiagnostics area, except that, for triggers, only errors are added. When the stored program ends, the\ncaller sees these conditions in its current diagnostics area.\n• Execution of a condition handler within a stored program\nWhen a push occurs as a result of condition handler activation, the stacked diagnostics area is the\narea that was current within the stored program prior to the push. The new now-current diagnostics\narea is the handler's current diagnostics area. GET [CURRENT] DIAGNOSTICS and GET STACKED\nDIAGNOSTICS can be used within the handler to access the contents of the current (handler) and\nstacked (stored program) diagnostics areas. Initially, they return the same result, but statements\nexecuting within the handler modify the current diagnostics area, clearing and setting its contents\naccording to the normal rules (see How the Diagnostics Area is Cleared and Populated). The\nstacked diagnostics area cannot be modified by statements executing within the handler except\nRESIGNAL.\nIf the handler executes successfully, the current (handler) diagnostics area is popped and the\nstacked (stored program) diagnostics area again becomes the current diagnostics area. Conditions\nadded to the handler diagnostics area during handler execution are added to the current diagnostics\narea.\n• Execution of RESIGNAL\nThe RESIGNAL statement passes on the error condition information that is available during execution\nof a condition handler within a compound statement inside a stored program. RESIGNAL may\nchange some or all information before passing it on, modifying the diagnostics stack as described in\nSection 15.6.7.4, “RESIGNAL Statement”.\nDiagnostics Area-Related System Variables\nCertain system variables control or are related to some aspects of the diagnostics area:\n• max_error_count controls the number of condition areas in the diagnostics area. If more\nconditions than this occur, MySQL silently discards information for the excess conditions. (Conditions\nadded by RESIGNAL are always added, with older conditions being discarded as necessary to make\nroom.)\n• warning_count indicates the number of conditions that occurred. This includes errors, warnings,\nand notes. Normally, NUMBER and warning_count are the same. However, as the number of\nconditions generated exceeds max_error_count, the value of warning_count continues to\nrise whereas NUMBER remains capped at max_error_count because no additional conditions are\nstored in the diagnostics area.\n• error_count indicates the number of errors that occurred. This value includes “not found” and\nexception conditions, but excludes warnings and notes. Like warning_count, its value can exceed\nmax_error_count.\n• If the sql_notes system variable is set to 0, notes are not stored and do not increment\nwarning_count.\nExample: If max_error_count is 10, the diagnostics area can contain a maximum of 10 condition\nareas. Suppose that a statement raises 20 conditions, 12 of which are errors. In that case, the\ndiagnostics area contains the first 10 conditions, NUMBER is 10, warning_count is 20, and\nerror_count is 12.\nChanges to the value of max_error_count have no effect until the next attempt to modify the\ndiagnostics area. If the diagnostics area contains 10 condition areas and max_error_count is set to\n5, that has no immediate effect on the size or content of the diagnostics area.\n15.6.7.8 Condition Handling and OUT or INOUT Parameters\nIf a stored procedure exits with an unhandled exception, modified values of OUT and INOUT\nparameters are not propagated back to the caller.\nIf an exception is handled by a CONTINUE or EXIT handler that contains a RESIGNAL statement,\nexecution of RESIGNAL pops the Diagnostics Area stack, thus signalling the exception (that is, the\ninformation that existed before entry into the handler). If the exception is an error, the values of OUT\nand INOUT parameters are not propagated back to the caller.",
    "15.6.8 Restrictions on Condition Handling": "15.6.8 Restrictions on Condition Handling\nSIGNAL, RESIGNAL, and GET DIAGNOSTICS are not permissible as prepared statements. For\nexample, this statement is invalid:\nPREPARE stmt1 FROM 'SIGNAL SQLSTATE \"02000\"';\nSQLSTATE values in class '04' are not treated specially. They are handled the same as other\nexceptions.\nIn standard SQL, the first condition relates to the SQLSTATE value returned for the previous SQL\nstatement. In MySQL, this is not guaranteed, so to get the main error, you cannot do this:\nGET DIAGNOSTICS CONDITION 1 @errno = MYSQL_ERRNO;\nInstead, do this:\nGET DIAGNOSTICS @cno = NUMBER;\nGET DIAGNOSTICS CONDITION @cno @errno = MYSQL_ERRNO;",
    "15.7 Database Administration Statements": "15.7 Database Administration Statements",
    "15.7.1 Account Management Statements": "15.7.1 Account Management Statements\nMySQL account information is stored in the tables of the mysql system schema. This database and\nthe access control system are discussed extensively in Chapter 7, MySQL Server Administration,\nwhich you should consult for additional details.\nImportant\nSome MySQL releases introduce changes to the grant tables to add new\nprivileges or features. To make sure that you can take advantage of any new\ncapabilities, update your grant tables to the current structure whenever you\nupgrade MySQL. See Chapter 3, Upgrading MySQL.\nWhen the read_only system variable is enabled, account-management statements require the\nCONNECTION_ADMIN privilege (or the deprecated SUPER privilege), in addition to any other required\nprivileges. This is because they modify tables in the mysql system schema.\nAccount management statements are atomic and crash safe. For more information, see Section 15.1.1,\n“Atomic Data Definition Statement Support”.\n15.7.1.1 ALTER USER Statement\nALTER USER [IF EXISTS]\n    user [auth_option] [, user [auth_option]] ...\n    [REQUIRE {NONE | tls_option [[AND] tls_option] ...}]\n    [WITH resource_option [resource_option] ...]\n    [password_option | lock_option] ...\n    [COMMENT 'comment_string' | ATTRIBUTE 'json_object']\nALTER USER [IF EXISTS]\n    USER() user_func_auth_option\nALTER USER [IF EXISTS]\n    user [registration_option]\nALTER USER [IF EXISTS]\n    USER() [registration_option]\nALTER USER [IF EXISTS]\n    user DEFAULT ROLE\n    {NONE | ALL | role [, role ] ...}\nuser:\n    (see Section 8.2.4, “Specifying Account Names”)\nauth_option: {\n    IDENTIFIED BY 'auth_string'\n        [REPLACE 'current_auth_string']\n        [RETAIN CURRENT PASSWORD]\n  | IDENTIFIED BY RANDOM PASSWORD\n        [REPLACE 'current_auth_string']\n        [RETAIN CURRENT PASSWORD]\n  | IDENTIFIED WITH auth_plugin\n  | IDENTIFIED WITH auth_plugin BY 'auth_string'\n        [REPLACE 'current_auth_string']\n        [RETAIN CURRENT PASSWORD]\n  | IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD\n        [REPLACE 'current_auth_string']\n        [RETAIN CURRENT PASSWORD]\n  | IDENTIFIED WITH auth_plugin AS 'auth_string'\n  | DISCARD OLD PASSWORD\n  | ADD factor factor_auth_option [ADD factor factor_auth_option]\n  | MODIFY factor factor_auth_option [MODIFY factor factor_auth_option]\n  | DROP factor [DROP factor]\n}\nuser_func_auth_option: {\n    IDENTIFIED BY 'auth_string'\n        [REPLACE 'current_auth_string']\n        [RETAIN CURRENT PASSWORD]\n  | DISCARD OLD PASSWORD\n}\nfactor_auth_option: {\n    IDENTIFIED BY 'auth_string'\n  | IDENTIFIED BY RANDOM PASSWORD\n  | IDENTIFIED WITH auth_plugin BY 'auth_string'\n  | IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD\n  | IDENTIFIED WITH auth_plugin AS 'auth_string'\n}\nregistration_option: {\n    factor INITIATE REGISTRATION\n  | factor FINISH REGISTRATION SET CHALLENGE_RESPONSE AS 'auth_string'\n  | factor UNREGISTER\n}\nfactor: {2 | 3} FACTOR\ntls_option: {\n   SSL\n | X509\n | CIPHER 'cipher'\n | ISSUER 'issuer'\n | SUBJECT 'subject'\n}\nresource_option: {\n    MAX_QUERIES_PER_HOUR count\n  | MAX_UPDATES_PER_HOUR count\n  | MAX_CONNECTIONS_PER_HOUR count\n  | MAX_USER_CONNECTIONS count\n}\npassword_option: {\n    PASSWORD EXPIRE [DEFAULT | NEVER | INTERVAL N DAY]\n  | PASSWORD HISTORY {DEFAULT | N}\n  | PASSWORD REUSE INTERVAL {DEFAULT | N DAY}\n  | PASSWORD REQUIRE CURRENT [DEFAULT | OPTIONAL]\n  | FAILED_LOGIN_ATTEMPTS N\n  | PASSWORD_LOCK_TIME {N | UNBOUNDED}\n}\nlock_option: {\n    ACCOUNT LOCK\n  | ACCOUNT UNLOCK\n}\nThe ALTER USER statement modifies MySQL accounts. It enables authentication, role, SSL/TLS,\nresource-limit, password-management, comment, and attribute properties to be modified for existing\naccounts. It can also be used to lock and unlock accounts.\nIn most cases, ALTER USER requires the global CREATE USER privilege, or the UPDATE privilege for\nthe mysql system schema. The exceptions are:\n• Any client who connects to the server using a nonanonymous account can change the password for\nthat account. (In particular, you can change your own password.) To see which account the server\nauthenticated you as, invoke the CURRENT_USER() function:\nSELECT CURRENT_USER();\n• For DEFAULT ROLE syntax, ALTER USER requires these privileges:\n• Setting the default roles for another user requires the global CREATE USER privilege, or the\nUPDATE privilege for the mysql.default_roles system table.\n• Setting the default roles for yourself requires no special privileges, as long as the roles you want\nas the default have been granted to you.\n• Statements that modify secondary passwords require these privileges:\n• The APPLICATION_PASSWORD_ADMIN privilege is required to use the RETAIN CURRENT\nPASSWORD or DISCARD OLD PASSWORD clause for ALTER USER statements that apply to your\nown account. The privilege is required to manipulate your own secondary password because most\nusers require only one password.\n• If an account is to be permitted to manipulate secondary passwords for all accounts, it requires the\nCREATE USER privilege rather than APPLICATION_PASSWORD_ADMIN.\nWhen the read_only system variable is enabled, ALTER USER additionally requires the\nCONNECTION_ADMIN privilege (or the deprecated SUPER privilege).\nThese additional privilege considerations also apply:\n• The authentication_policy system variable places certain constraints on how the\nauthentication-related clauses of ALTER USER statements may be used; for details,\nsee the description of that variable. These constraints do not apply if you have the\nAUTHENTICATION_POLICY_ADMIN privilege.\n• To modify an account that uses passwordless authentication, you must have the\nPASSWORDLESS_USER_ADMIN privilege.\nBy default, an error occurs if you try to modify a user that does not exist. If the IF EXISTS clause is\ngiven, the statement produces a warning for each named user that does not exist, rather than an error.\nImportant\nUnder some circumstances, ALTER USER may be recorded in server logs or\non the client side in a history file such as ~/.mysql_history, which means\nthat cleartext passwords may be read by anyone having read access to that\ninformation. For information about the conditions under which this occurs for the\nserver logs and how to control it, see Section 8.1.2.3, “Passwords and Logging”.\nFor similar information about client-side logging, see Section 6.5.1.3, “mysql\nClient Logging”.\nThere are several aspects to the ALTER USER statement, described under the following topics:\n• ALTER USER Overview\n• ALTER USER Authentication Options\n• ALTER USER Multifactor Authentication Options\n• ALTER USER Registration Options\n• ALTER USER Role Options\n• ALTER USER SSL/TLS Options\n• ALTER USER Resource-Limit Options\n• ALTER USER Password-Management Options\n• ALTER USER Comment and Attribute Options\n• ALTER USER Account-Locking Options\n• ALTER USER Binary Logging\nALTER USER Overview\nFor each affected account, ALTER USER modifies the corresponding row in the mysql.user system\ntable to reflect the properties specified in the statement. Unspecified properties retain their current\nvalues.\nEach account name uses the format described in Section 8.2.4, “Specifying Account Names”.\nThe host name part of the account name, if omitted, defaults to '%'. It is also possible to specify\nCURRENT_USER or CURRENT_USER() to refer to the account associated with the current session.\nIn one case only, the account may be specified with the USER() function:\nALTER USER USER() IDENTIFIED BY 'auth_string';\nThis syntax enables changing your own password without naming your account literally. (The syntax\nalso supports the REPLACE, RETAIN CURRENT PASSWORD, and DISCARD OLD PASSWORD clauses\ndescribed at ALTER USER Authentication Options.)\nFor ALTER USER syntax that permits an auth_option value to follow a user value, auth_option\nindicates how the account authenticates by specifying an account authentication plugin, credentials\n(for example, a password), or both. Each auth_option value applies only to the account named\nimmediately preceding it.\nFollowing the user specifications, the statement may include options for SSL/TLS, resource-limit,\npassword-management, and locking properties. All such options are global to the statement and apply\nto all accounts named in the statement.\nExample: Change an account's password and expire it. As a result, the user must connect with the\nnamed password and choose a new one at the next connection:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED BY 'new_password' PASSWORD EXPIRE;\nExample: Modify an account to use the caching_sha2_password authentication plugin and the\ngiven password. Require that a new password be chosen every 180 days, and enable failed-login\ntracking, such that three consecutive incorrect passwords cause temporary account locking for two\ndays:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED WITH caching_sha2_password BY 'new_password'\n  PASSWORD EXPIRE INTERVAL 180 DAY\n  FAILED_LOGIN_ATTEMPTS 3 PASSWORD_LOCK_TIME 2;\nExample: Lock or unlock an account:\nALTER USER 'jeffrey'@'localhost' ACCOUNT LOCK;\nALTER USER 'jeffrey'@'localhost' ACCOUNT UNLOCK;\nExample: Require an account to connect using SSL and establish a limit of 20 connections per hour:\nALTER USER 'jeffrey'@'localhost'\n  REQUIRE SSL WITH MAX_CONNECTIONS_PER_HOUR 20;\nExample: Alter multiple accounts, specifying some per-account properties and some global properties:\nALTER USER\n  'jeffrey'@'localhost'\n    IDENTIFIED BY 'jeffrey_new_password',\n  'jeanne'@'localhost',\n  'josh'@'localhost'\n    IDENTIFIED BY 'josh_new_password'\n    REPLACE 'josh_current_password'\n    RETAIN CURRENT PASSWORD\n  REQUIRE SSL WITH MAX_USER_CONNECTIONS 2\n  PASSWORD HISTORY 5;\nThe IDENTIFIED BY value following jeffrey applies only to its immediately preceding account, so\nit changes the password to 'jeffrey_new_password' only for jeffrey. For jeanne, there is no\nper-account value (thus leaving the password unchanged). For josh, IDENTIFIED BY establishes\na new password ('josh_new_password'), REPLACE is specified to verify that the user issuing the\nALTER USER statement knows the current password ('josh_current_password'), and that current\npassword is also retained as the account secondary password. (As a result, josh can connect with\neither the primary or secondary password.)\nThe remaining properties apply globally to all accounts named in the statement, so for both accounts:\n• Connections are required to use SSL.\n• The account can be used for a maximum of two simultaneous connections.\n• Password changes cannot reuse any of the five most recent passwords.\nExample: Discard the secondary password for josh, leaving the account with only its primary\npassword:\nALTER USER 'josh'@'localhost' DISCARD OLD PASSWORD;\nIn the absence of a particular type of option, the account remains unchanged in that respect. For\nexample, with no locking option, the locking state of the account is not changed.\nALTER USER Authentication Options\nAn account name may be followed by an auth_option authentication option that specifies the\naccount authentication plugin, credentials, or both. It may also include a password-verification clause\nthat specifies the account current password to be replaced, and clauses that manage whether an\naccount has a secondary password.\nNote\nClauses for random password generation, password verification, and secondary\npasswords apply only to accounts that use an authentication plugin that stores\ncredentials internally to MySQL. For accounts that use a plugin that performs\nauthentication against a credentials system that is external to MySQL, password\nmanagement must be handled externally against that system as well. For more\ninformation about internal credentials storage, see Section 8.2.15, “Password\nManagement”.\n• auth_plugin names an authentication plugin. The plugin name can be a quoted string literal or an\nunquoted name. Plugin names are stored in the plugin column of the mysql.user system table.\nFor auth_option syntax that does not specify an authentication plugin, the server assigns the\ndefault plugin, determined as described in The Default Authentication Plugin. For descriptions of\neach plugin, see Section 8.4.1, “Authentication Plugins”.\n• Credentials that are stored internally are stored in the mysql.user system table. An\n'auth_string' value or RANDOM PASSWORD specifies account credentials, either as a cleartext\n(unencrypted) string or hashed in the format expected by the authentication plugin associated with\nthe account, respectively:\n• For syntax that uses BY 'auth_string', the string is cleartext and is passed to the\nauthentication plugin for possible hashing. The result returned by the plugin is stored in the\nmysql.user table. A plugin may use the value as specified, in which case no hashing occurs.\n• For syntax that uses BY RANDOM PASSWORD, MySQL generates a random password and as\ncleartext and passes it to the authentication plugin for possible hashing. The result returned by the\nplugin is stored in the mysql.user table. A plugin may use the value as specified, in which case\nno hashing occurs.\nRandomly generated passwords have the characteristics described in Random Password\nGeneration.\n• For syntax that uses AS 'auth_string', the string is assumed to be already in the format the\nauthentication plugin requires, and is stored as is in the mysql.user table. If a plugin requires a\nhashed value, the value must be already hashed in a format appropriate for the plugin; otherwise,\nthe value cannot be used by the plugin and correct authentication of client connections does not\noccur.\nA hashed string can be either a string literal or a hexadecimal value. The latter corresponds to\nthe type of value displayed by SHOW CREATE USER for password hashes containing unprintable\ncharacters when the print_identified_with_as_hex system variable is enabled.\n• If an authentication plugin performs no hashing of the authentication string, the BY\n'auth_string' and AS 'auth_string' clauses have the same effect: The authentication\nstring is stored as is in the mysql.user system table.\n• The REPLACE 'current_auth_string' clause performs password verification. If given:\n• REPLACE specifies the account current password to be replaced, as a cleartext (unencrypted)\nstring.\n• The clause must be given if password changes for the account are required to specify the current\npassword, as verification that the user attempting to make the change actually knows the current\npassword.\n• The clause is optional if password changes for the account may but need not specify the current\npassword.\n• The statement fails if the clause is given but does not match the current password, even if the\nclause is optional.\n• REPLACE can be specified only when changing the account password for the current user.\nFor more information about password verification by specifying the current password, see\nSection 8.2.15, “Password Management”.\n• The RETAIN CURRENT PASSWORD and DISCARD OLD PASSWORD clauses implement dual-\npassword capability. Both are optional, but if given, have the following effects:\n• RETAIN CURRENT PASSWORD retains an account current password as its secondary password,\nreplacing any existing secondary password. The new password becomes the primary password,\nbut clients can use the account to connect to the server using either the primary or secondary\npassword. (Exception: If the new password specified by the ALTER USER statement is empty, the\nsecondary password becomes empty as well, even if RETAIN CURRENT PASSWORD is given.)\n• If you specify RETAIN CURRENT PASSWORD for an account that has an empty primary password,\nthe statement fails.\n• If an account has a secondary password and you change its primary password without specifying\nRETAIN CURRENT PASSWORD, the secondary password remains unchanged.\n• If you change the authentication plugin assigned to the account, the secondary password\nis discarded. If you change the authentication plugin and also specify RETAIN CURRENT\nPASSWORD, the statement fails.\n• DISCARD OLD PASSWORD discards the secondary password, if one exists. The account retains\nonly its primary password, and clients can use the account to connect to the server only with the\nprimary password.\nFor more information about use of dual passwords, see Section 8.2.15, “Password Management”.\nALTER USER permits these auth_option syntaxes:\n• IDENTIFIED BY 'auth_string' [REPLACE 'current_auth_string'] [RETAIN\nCURRENT PASSWORD]\nSets the account authentication plugin to the default plugin, passes the cleartext 'auth_string'\nvalue to the plugin for possible hashing, and stores the result in the account row in the mysql.user\nsystem table.\nThe REPLACE clause, if given, specifies the account current password, as described previously in\nthis section.\nThe RETAIN CURRENT PASSWORD clause, if given, causes the account current password to be\nretained as its secondary password, as described previously in this section.\n• IDENTIFIED BY RANDOM PASSWORD [REPLACE 'current_auth_string'] [RETAIN\nCURRENT PASSWORD]\nSets the account authentication plugin to the default plugin, generates a random password, passes\nthe cleartext password value to the plugin for possible hashing, and stores the result in the account\nrow in the mysql.user system table. The statement also returns the cleartext password in a result\nset to make it available to the user or application executing the statement. For details about the result\nset and characteristics of randomly generated passwords, see Random Password Generation.\nThe REPLACE clause, if given, specifies the account current password, as described previously in\nthis section.\nThe RETAIN CURRENT PASSWORD clause, if given, causes the account current password to be\nretained as its secondary password, as described previously in this section.\n• IDENTIFIED WITH auth_plugin\nSets the account authentication plugin to auth_plugin, clears the credentials to the empty string\n(the credentials are associated with the old authentication plugin, not the new one), and stores the\nresult in the account row in the mysql.user system table.\nIn addition, the password is marked expired. The user must choose a new one when next\nconnecting.\n• IDENTIFIED WITH auth_plugin BY 'auth_string' [REPLACE\n'current_auth_string'] [RETAIN CURRENT PASSWORD]\nSets the account authentication plugin to auth_plugin, passes the cleartext 'auth_string'\nvalue to the plugin for possible hashing, and stores the result in the account row in the mysql.user\nsystem table.\nThe REPLACE clause, if given, specifies the account current password, as described previously in\nthis section.\nThe RETAIN CURRENT PASSWORD clause, if given, causes the account current password to be\nretained as its secondary password, as described previously in this section.\n• IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD [REPLACE\n'current_auth_string'] [RETAIN CURRENT PASSWORD]\nSets the account authentication plugin to auth_plugin, generates a random password, passes the\ncleartext password value to the plugin for possible hashing, and stores the result in the account row\nin the mysql.user system table. The statement also returns the cleartext password in a result set to\nmake it available to the user or application executing the statement. For details about the result set\nand characteristics of randomly generated passwords, see Random Password Generation.\nThe REPLACE clause, if given, specifies the account current password, as described previously in\nthis section.\nThe RETAIN CURRENT PASSWORD clause, if given, causes the account current password to be\nretained as its secondary password, as described previously in this section.\n• IDENTIFIED WITH auth_plugin AS 'auth_string'\nSets the account authentication plugin to auth_plugin and stores the 'auth_string' value as is\nin the mysql.user account row. If the plugin requires a hashed string, the string is assumed to be\nalready hashed in the format the plugin requires.\n• DISCARD OLD PASSWORD\nDiscards the account secondary password, if there is one, as described previously in this section.\nExample: Specify the password as cleartext; the default plugin is used:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED BY 'password';\nExample: Specify the authentication plugin, along with a cleartext password value:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED WITH sha2_password\n             BY 'password';\nExample: Like the preceding example, but in addition, specify the current password as a cleartext value\nto satisfy any account requirement that the user making the change knows that password:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED WITH sha2_password\n             BY 'password'\n             REPLACE 'current_password';\nThe preceding statement fails unless the current user is jeffrey because REPLACE is permitted only\nfor changes to the current user's password.\nExample: Establish a new primary password and retain the existing password as the secondary\npassword:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED BY 'new_password'\n  RETAIN CURRENT PASSWORD;\nExample: Discard the secondary password, leaving the account with only its primary password:\nALTER USER 'jeffery'@'localhost' DISCARD OLD PASSWORD;\nExample: Specify the authentication plugin, along with a hashed password value:\nALTER USER 'jeffrey'@'localhost'\n  IDENTIFIED WITH caching_sha2_password\n             AS '*6C8989366EAF75BB670AD8EA7A7FC1176A95CEF4';\nFor additional information about setting passwords and authentication plugins, see Section 8.2.14,\n“Assigning Account Passwords”, and Section 8.2.17, “Pluggable Authentication”.\nALTER USER Multifactor Authentication Options\nALTER USER has ADD, MODIFY, and DROP clauses that enable authentication factors to be added,\nmodified, or dropped. In each case, the clause specifies an operation to perform on one authentication\nfactor, and optionally an operation on another authentication factor. For each operation, the factor\nitem specifies the FACTOR keyword preceded by the number 2 or 3 to indicate whether the operation\napplies to the second or third authentication factor. (1 is not permitted in this context. To act on the first\nauthentication factor, use the syntax described in ALTER USER Authentication Options.)\nALTER USER multifactor authentication clause constraints are defined by the\nauthentication_policy system variable. For example, the authentication_policy setting\ncontrols the number of authentication factors that accounts may have, and for each factor, which\nauthentication methods are permitted. See Configuring the Multifactor Authentication Policy.\nWhen ALTER USER adds, modifies, or drops second and third factors in a single statement, operations\nare executed sequentially, but if any operation in the sequence fails the entire ALTER USER statement\nfails.\nFor ADD, each named factor must not already exist or it cannot be added. For MODIFY and DROP, each\nnamed factor must exist to be modified or dropped. If a second and third factor are defined, dropping\nthe second factor causes the third factor to take its place as the second factor.\nThis statement drops authentication factors 2 and 3, which has the effect of converting the account\nfrom 3FA to 1FA:\nALTER USER 'user' DROP 2 FACTOR 3 FACTOR;\nFor additional ADD, MODIFY, and DROP examples, see Getting Started with Multifactor Authentication.\nFor information about factor-specific rules that determine the default authentication plugin for\nauthentication clauses that do not name a plugin, see The Default Authentication Plugin.\nALTER USER Registration Options\nALTER USER has clauses that enable FIDO/FIDO2 devices to be registered and unregistered. For\nmore information, see Using WebAuthn Authentication, Device Unregistration for WebAuthn, and the\nmysql client --register-factor option description.\nThe mysql client --register-factor option, used for FIDO/FIDO2 device registration, causes\nthe mysql client to generate and execute INITIATE REGISTRATION and FINISH REGISTRATION\nstatements. These statements are not intended for manual execution.\nALTER USER Role Options\nALTER USER ... DEFAULT ROLE defines which roles become active when the user connects to\nthe server and authenticates, or when the user executes the SET ROLE DEFAULT statement during a\nsession.\nALTER USER ... DEFAULT ROLE is alternative syntax for SET DEFAULT ROLE (see\nSection 15.7.1.9, “SET DEFAULT ROLE Statement”). However, ALTER USER can set the default for\nonly a single user, whereas SET DEFAULT ROLE can set the default for multiple users. On the other\nhand, you can specify CURRENT_USER as the user name for the ALTER USER statement, whereas you\ncannot for SET DEFAULT ROLE.\nEach user account name uses the format described previously.\nEach role name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nALTER USER 'joe'@'10.0.0.1' DEFAULT ROLE administrator, developer;\nThe host name part of the role name, if omitted, defaults to '%'.\nThe clause following the DEFAULT ROLE keywords permits these values:\n• NONE: Set the default to NONE (no roles).\n• ALL: Set the default to all roles granted to the account.\n• role [, role ] ...: Set the default to the named roles, which must exist and be granted to the\naccount at the time ALTER USER ... DEFAULT ROLE is executed.\nALTER USER SSL/TLS Options\nMySQL can check X.509 certificate attributes in addition to the usual authentication that is based on\nthe user name and credentials. For background information on the use of SSL/TLS with MySQL, see\nSection 8.3, “Using Encrypted Connections”.\nTo specify SSL/TLS-related options for a MySQL account, use a REQUIRE clause that specifies one or\nmore tls_option values.\nOrder of REQUIRE options does not matter, but no option can be specified twice. The AND keyword is\noptional between REQUIRE options.\nALTER USER permits these tls_option values:\n• NONE\nIndicates that all accounts named by the statement have no SSL or X.509 requirements.\nUnencrypted connections are permitted if the user name and password are valid. Encrypted\nconnections can be used, at the client's option, if the client has the proper certificate and key files.\nALTER USER 'jeffrey'@'localhost' REQUIRE NONE;\nClients attempt to establish a secure connection by default. For clients that have REQUIRE NONE,\nthe connection attempt falls back to an unencrypted connection if a secure connection cannot\nbe established. To require an encrypted connection, a client need specify only the --ssl-\nmode=REQUIRED option; the connection attempt fails if a secure connection cannot be established.\n• SSL\nTells the server to permit only encrypted connections for all accounts named by the statement.\nALTER USER 'jeffrey'@'localhost' REQUIRE SSL;\nClients attempt to establish a secure connection by default. For accounts that have REQUIRE SSL,\nthe connection attempt fails if a secure connection cannot be established.\n• X509\nFor all accounts named by the statement, requires that clients present a valid certificate, but the\nexact certificate, issuer, and subject do not matter. The only requirement is that it should be possible\nto verify its signature with one of the CA certificates. Use of X.509 certificates always implies\nencryption, so the SSL option is unnecessary in this case.\nALTER USER 'jeffrey'@'localhost' REQUIRE X509;\nFor accounts with REQUIRE X509, clients must specify the --ssl-key and --ssl-cert options\nto connect. (It is recommended but not required that --ssl-ca also be specified so that the public\ncertificate provided by the server can be verified.) This is true for ISSUER and SUBJECT as well\nbecause those REQUIRE options imply the requirements of X509.\n• ISSUER 'issuer'\nFor all accounts named by the statement, requires that clients present a valid X.509 certificate issued\nby CA 'issuer'. If a client presents a certificate that is valid but has a different issuer, the server\nrejects the connection. Use of X.509 certificates always implies encryption, so the SSL option is\nunnecessary in this case.\nALTER USER 'jeffrey'@'localhost'\n  REQUIRE ISSUER '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL/CN=CA/emailAddress=ca@example.com';\nBecause ISSUER implies the requirements of X509, clients must specify the --ssl-key and --\nssl-cert options to connect. (It is recommended but not required that --ssl-ca also be specified\nso that the public certificate provided by the server can be verified.)\n• SUBJECT 'subject'\nFor all accounts named by the statement, requires that clients present a valid X.509 certificate\ncontaining the subject subject. If a client presents a certificate that is valid but has a different\nsubject, the server rejects the connection. Use of X.509 certificates always implies encryption, so the\nSSL option is unnecessary in this case.\nALTER USER 'jeffrey'@'localhost'\n  REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL demo client certificate/\n    CN=client/emailAddress=client@example.com';\nMySQL does a simple string comparison of the 'subject' value to the value in the certificate, so\nlettercase and component ordering must be given exactly as present in the certificate.\nBecause SUBJECT implies the requirements of X509, clients must specify the --ssl-key and --\nssl-cert options to connect. (It is recommended but not required that --ssl-ca also be specified\nso that the public certificate provided by the server can be verified.)\n• CIPHER 'cipher'\nFor all accounts named by the statement, requires a specific cipher method for encrypting\nconnections. This option is needed to ensure that ciphers and key lengths of sufficient strength are\nused. Encryption can be weak if old algorithms using short encryption keys are used.\nALTER USER 'jeffrey'@'localhost'\n  REQUIRE CIPHER 'EDH-RSA-DES-CBC3-SHA';\nThe SUBJECT, ISSUER, and CIPHER options can be combined in the REQUIRE clause:\nALTER USER 'jeffrey'@'localhost'\n  REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL demo client certificate/\n    CN=client/emailAddress=client@example.com'\n  AND ISSUER '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL/CN=CA/emailAddress=ca@example.com'\n  AND CIPHER 'EDH-RSA-DES-CBC3-SHA';\nALTER USER Resource-Limit Options\nIt is possible to place limits on use of server resources by an account, as discussed in Section 8.2.21,\n“Setting Account Resource Limits”. To do so, use a WITH clause that specifies one or more\nresource_option values.\nOrder of WITH options does not matter, except that if a given resource limit is specified multiple times,\nthe last instance takes precedence.\nALTER USER permits these resource_option values:\n• MAX_QUERIES_PER_HOUR count, MAX_UPDATES_PER_HOUR count,\nMAX_CONNECTIONS_PER_HOUR count\nFor all accounts named by the statement, these options restrict how many queries, updates, and\nconnections to the server are permitted to each account during any given one-hour period. If count\nis 0 (the default), this means that there is no limitation for the account.\n• MAX_USER_CONNECTIONS count\nFor all accounts named by the statement, restricts the maximum number of simultaneous\nconnections to the server by each account. A nonzero count specifies the limit for the account\nexplicitly. If count is 0 (the default), the server determines the number of simultaneous connections\nfor the account from the global value of the max_user_connections system variable. If\nmax_user_connections is also zero, there is no limit for the account.\nExample:\nALTER USER 'jeffrey'@'localhost'\n  WITH MAX_QUERIES_PER_HOUR 500 MAX_UPDATES_PER_HOUR 100;\nALTER USER Password-Management Options\nALTER USER supports several password_option values for password management:\n• Password expiration options: You can expire an account password manually and establish its\npassword expiration policy. Policy options do not expire the password. Instead, they determine how\nthe server applies automatic expiration to the account based on password age, which is assessed\nfrom the date and time of the most recent account password change.\n• Password reuse options: You can restrict password reuse based on number of password changes,\ntime elapsed, or both.\n• Password verification-required options: You can indicate whether attempts to change an account\npassword must specify the current password, as verification that the user attempting to make the\nchange actually knows the current password.\n• Incorrect-password failed-login tracking options: You can cause the server to track failed login\nattempts and temporarily lock accounts for which too many consecutive incorrect passwords are\ngiven. The required number of failures and the lock time are configurable.\nThis section describes the syntax for password-management options. For information about\nestablishing policy for password management, see Section 8.2.15, “Password Management”.\nIf multiple password-management options of a given type are specified, the last one takes precedence.\nFor example, PASSWORD EXPIRE DEFAULT PASSWORD EXPIRE NEVER is the same as PASSWORD\nEXPIRE NEVER.\nNote\nExcept for the options that pertain to failed-login tracking, password-\nmanagement options apply only to accounts that use an authentication plugin\nthat stores credentials internally to MySQL. For accounts that use a plugin that\nperforms authentication against a credentials system that is external to MySQL,\npassword management must be handled externally against that system as well.\nFor more information about internal credentials storage, see Section 8.2.15,\n“Password Management”.\nA client has an expired password if the account password was expired manually or the password\nage is considered greater than its permitted lifetime per the automatic expiration policy. In this case,\nthe server either disconnects the client or restricts the operations permitted to it (see Section 8.2.16,\n“Server Handling of Expired Passwords”). Operations performed by a restricted client result in an error\nuntil the user establishes a new account password.\nNote\nAlthough it is possible to “reset” an expired password by setting it to its\ncurrent value, it is preferable, as a matter of good policy, to choose a different\npassword. DBAs can enforce non-reuse by establishing an appropriate\npassword-reuse policy. See Password Reuse Policy.\nALTER USER permits these password_option values for controlling password expiration:\n• PASSWORD EXPIRE\nImmediately marks the password expired for all accounts named by the statement.\nALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE;\n• PASSWORD EXPIRE DEFAULT\nSets all accounts named by the statement so that the global expiration policy applies, as specified by\nthe default_password_lifetime system variable.\nALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;\n• PASSWORD EXPIRE NEVER\nThis expiration option overrides the global policy for all accounts named by the statement. For each,\nit disables password expiration so that the password never expires.\nALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;\n• PASSWORD EXPIRE INTERVAL N DAY\nThis expiration option overrides the global policy for all accounts named by the statement. For each,\nit sets the password lifetime to N days. The following statement requires the password to be changed\nevery 180 days:\nALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 180 DAY;\nALTER USER permits these password_option values for controlling reuse of previous passwords\nbased on required minimum number of password changes:\n• PASSWORD HISTORY DEFAULT\nSets all accounts named by the statement so that the global policy about password history\nlength applies, to prohibit reuse of passwords before the number of changes specified by the\npassword_history system variable.\nALTER USER 'jeffrey'@'localhost' PASSWORD HISTORY DEFAULT;\n• PASSWORD HISTORY N\nThis history-length option overrides the global policy for all accounts named by the statement. For\neach, it sets the password history length to N passwords, to prohibit reusing any of the N most\nrecently chosen passwords. The following statement prohibits reuse of any of the previous 6\npasswords:\nALTER USER 'jeffrey'@'localhost' PASSWORD HISTORY 6;\nALTER USER permits these password_option values for controlling reuse of previous passwords\nbased on time elapsed:\n• PASSWORD REUSE INTERVAL DEFAULT\nSets all statements named by the account so that the global policy about time elapsed\napplies, to prohibit reuse of passwords newer than the number of days specified by the\npassword_reuse_interval system variable.\nALTER USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL DEFAULT;\n• PASSWORD REUSE INTERVAL N DAY\nThis time-elapsed option overrides the global policy for all accounts named by the statement. For\neach, it sets the password reuse interval to N days, to prohibit reuse of passwords newer than that\nmany days. The following statement prohibits password reuse for 360 days:\nALTER USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL 360 DAY;\nALTER USER permits these password_option values for controlling whether attempts to change an\naccount password must specify the current password, as verification that the user attempting to make\nthe change actually knows the current password:\n• PASSWORD REQUIRE CURRENT\nThis verification option overrides the global policy for all accounts named by the statement. For each,\nit requires that password changes specify the current password.\nALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT;\n• PASSWORD REQUIRE CURRENT OPTIONAL\nThis verification option overrides the global policy for all accounts named by the statement. For each,\nit does not require that password changes specify the current password. (The current password may\nbut need not be given.)\nALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT OPTIONAL;\n• PASSWORD REQUIRE CURRENT DEFAULT\nSets all statements named by the account so that the global policy about password verification\napplies, as specified by the password_require_current system variable.\nALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT DEFAULT;\nALTER USER permits these password_option values for controlling failed-login tracking:\n• FAILED_LOGIN_ATTEMPTS N\nWhether to track account login attempts that specify an incorrect password. N must be a number\nfrom 0 to 32767. A value of 0 disables failed-login tracking. Values greater than 0 indicate how many\nconsecutive password failures cause temporary account locking (if PASSWORD_LOCK_TIME is also\nnonzero).\n• PASSWORD_LOCK_TIME {N | UNBOUNDED}\nHow long to lock the account after too many consecutive login attempts provide an incorrect\npassword. N must be a number from 0 to 32767, or UNBOUNDED. A value of 0 disables temporary\naccount locking. Values greater than 0 indicate how long to lock the account in days. A value of\nUNBOUNDED causes the account locking duration to be unbounded; once locked, the account\nremains in a locked state until unlocked. For information about the conditions under which unlocking\noccurs, see Failed-Login Tracking and Temporary Account Locking.\nFor failed-login tracking and temporary locking to occur, an account's FAILED_LOGIN_ATTEMPTS and\nPASSWORD_LOCK_TIME options both must be nonzero. The following statement modifies an account\nsuch that it remains locked for two days after four consecutive password failures:\nALTER USER 'jeffrey'@'localhost'\n  FAILED_LOGIN_ATTEMPTS 4 PASSWORD_LOCK_TIME 2;\nALTER USER Comment and Attribute Options\nMySQL 9.1 supports user comments and user attributes, as described in Section 15.7.1.3, “CREATE\nUSER Statement”. These can be modified employing ALTER USER by means of the COMMENT\nand ATTRIBUTE options, respectively. You cannot specify both options in the same ALTER USER\nstatement; attempting to do so results in a syntax error.\nThe user comment and user attribute are stored in the Information Schema USER_ATTRIBUTES table\nas a JSON object; the user comment is stored as the value for a comment key in the ATTRIBUTE\ncolumn of this table, as shown later in this discussion. The COMMENT text can be any arbitrary\nquoted text, and replaces any existing user comment. The ATTRIBUTE value must be the valid\nstring representation of a JSON object. This is merged with any existing user attribute as if the\nJSON_MERGE_PATCH() function had been used on the existing user attribute and the new one; for any\nkeys that are re-used, the new value overwrites the old one, as shown here:\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->     WHERE USER='bill' AND HOST='localhost';\n+------+-----------+----------------+\n| USER | HOST      | ATTRIBUTE      |\n+------+-----------+----------------+\n| bill | localhost | {\"foo\": \"bar\"} |\n+------+-----------+----------------+\n1 row in set (0.11 sec)\nmysql> ALTER USER 'bill'@'localhost' ATTRIBUTE '{\"baz\": \"faz\", \"foo\": \"moo\"}';\nQuery OK, 0 rows affected (0.22 sec)\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->     WHERE USER='bill' AND HOST='localhost';\n+------+-----------+------------------------------+\n| USER | HOST      | ATTRIBUTE                    |\n+------+-----------+------------------------------+\n| bill | localhost | {\"baz\": \"faz\", \"foo\": \"moo\"} |\n+------+-----------+------------------------------+\n1 row in set (0.00 sec)\nTo remove a key and its value from the user attribute, set the key to JSON null (must be lowercase\nand unquoted), like this:\nmysql> ALTER USER 'bill'@'localhost' ATTRIBUTE '{\"foo\": null}';\nQuery OK, 0 rows affected (0.08 sec)\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->     WHERE USER='bill' AND HOST='localhost';\n+------+-----------+----------------+\n| USER | HOST      | ATTRIBUTE      |\n+------+-----------+----------------+\n| bill | localhost | {\"baz\": \"faz\"} |\n+------+-----------+----------------+\n1 row in set (0.00 sec)\nTo set an existing user comment to an empty string, use ALTER USER ... COMMENT ''. This\nleaves an empty comment value in the USER_ATTRIBUTES table; to remove the user comment\ncompletely, use ALTER USER ... ATTRIBUTE ... with the value for the column key set to JSON\nnull (unquoted, in lower case). This is illustrated by the following sequence of SQL statements:\nmysql> ALTER USER 'bill'@'localhost' COMMENT 'Something about Bill';\nQuery OK, 0 rows affected (0.06 sec)\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->     WHERE USER='bill' AND HOST='localhost';\n+------+-----------+---------------------------------------------------+\n| USER | HOST      | ATTRIBUTE                                         |\n+------+-----------+---------------------------------------------------+\n| bill | localhost | {\"baz\": \"faz\", \"comment\": \"Something about Bill\"} |\n+------+-----------+---------------------------------------------------+\n1 row in set (0.00 sec)\nmysql> ALTER USER 'bill'@'localhost' COMMENT '';\nQuery OK, 0 rows affected (0.09 sec)\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->     WHERE USER='bill' AND HOST='localhost';\n+------+-----------+-------------------------------+\n| USER | HOST      | ATTRIBUTE                     |\n+------+-----------+-------------------------------+\n| bill | localhost | {\"baz\": \"faz\", \"comment\": \"\"} |\n+------+-----------+-------------------------------+\n1 row in set (0.00 sec)\nmysql> ALTER USER 'bill'@'localhost' ATTRIBUTE '{\"comment\": null}';\nQuery OK, 0 rows affected (0.07 sec)\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->     WHERE USER='bill' AND HOST='localhost';\n+------+-----------+----------------+\n| USER | HOST      | ATTRIBUTE      |\n+------+-----------+----------------+\n| bill | localhost | {\"baz\": \"faz\"} |\n+------+-----------+----------------+\n1 row in set (0.00 sec)\nALTER USER Account-Locking Options\nMySQL supports account locking and unlocking using the ACCOUNT LOCK and ACCOUNT UNLOCK\noptions, which specify the locking state for an account. For additional discussion, see Section 8.2.20,\n“Account Locking”.\nIf multiple account-locking options are specified, the last one takes precedence.\nALTER USER ... ACCOUNT UNLOCK unlocks any account named by the statement that is\ntemporarily locked due to too many failed logins. See Section 8.2.15, “Password Management”.\nALTER USER Binary Logging\nALTER USER is written to the binary log if it succeeds, but not if it fails; in that case, rollback occurs\nand no changes are made. A statement written to the binary log includes all named users. If the IF\nEXISTS clause is given, this includes even users that do not exist and were not altered.\nIf the original statement changes the credentials for a user, the statement written to the binary log\nspecifies the applicable authentication plugin for that user, determined as follows:\n• The plugin named in the original statement, if one was specified.\n• Otherwise, the plugin associated with the user account if the user exists, or the default authentication\nplugin if the user does not exist. (If the statement written to the binary log must specify a particular\nauthentication plugin for a user, include it in the original statement.)\nIf the server adds the default authentication plugin for any users in the statement written to the binary\nlog, it writes a warning to the error log naming those users.\nIf the original statement specifies the FAILED_LOGIN_ATTEMPTS or PASSWORD_LOCK_TIME option,\nthe statement written to the binary log includes the option.\nALTER USER statements with clauses that support multifactor authentication (MFA) are written to\nthe binary log with the exception of ALTER USER user factor INITIATE REGISTRATION\nstatements.\n• ALTER USER user factor FINISH REGISTRATION SET CHALLENGE_RESPONSE AS\n'auth_string' statements are written to the binary log as ALTER USER user MODIFY factor\nIDENTIFIED WITH authentication_webauthn AS webauthn_hash_string;\n• In a replication context, the replication user requires PASSWORDLESS_USER_ADMIN privilege\nto execute ALTER USER ... MODIFY operations on accounts configured for passwordless\nauthentication using the authentication_webauthn plugin.\n15.7.1.2 CREATE ROLE Statement\nCREATE ROLE [IF NOT EXISTS] role [, role ] ...\nCREATE ROLE creates one or more roles, which are named collections of privileges. To use this\nstatement, you must have the global CREATE ROLE or CREATE USER privilege. When the read_only\nsystem variable is enabled, CREATE ROLE additionally requires the CONNECTION_ADMIN privilege (or\nthe deprecated SUPER privilege).\nA role when created is locked, has no password, and is assigned the default authentication plugin.\n(These role attributes can be changed later with the ALTER USER statement, by users who have the\nglobal CREATE USER privilege.)\nCREATE ROLE either succeeds for all named roles or rolls back and has no effect if any error occurs.\nBy default, an error occurs if you try to create a role that already exists. If the IF NOT EXISTS clause\nis given, the statement produces a warning for each named role that already exists, rather than an\nerror.\nThe statement is written to the binary log if it succeeds, but not if it fails; in that case, rollback occurs\nand no changes are made. A statement written to the binary log includes all named roles. If the IF\nNOT EXISTS clause is given, this includes even roles that already exist and were not created.\nEach role name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nCREATE ROLE 'admin', 'developer';\nCREATE ROLE 'webapp'@'localhost';\nThe host name part of the role name, if omitted, defaults to '%'.\nFor role usage examples, see Section 8.2.10, “Using Roles”.\n15.7.1.3 CREATE USER Statement\nCREATE USER [IF NOT EXISTS]\n    user [auth_option] [, user [auth_option]] ...\n    DEFAULT ROLE role [, role ] ...\n    [REQUIRE {NONE | tls_option [[AND] tls_option] ...}]\n    [WITH resource_option [resource_option] ...]\n    [password_option | lock_option] ...\n    [COMMENT 'comment_string' | ATTRIBUTE 'json_object']\nuser:\n    (see Section 8.2.4, “Specifying Account Names”)\nauth_option: {\n    IDENTIFIED BY 'auth_string' [AND 2fa_auth_option]\n  | IDENTIFIED BY RANDOM PASSWORD [AND 2fa_auth_option]\n  | IDENTIFIED WITH auth_plugin [AND 2fa_auth_option]\n  | IDENTIFIED WITH auth_plugin BY 'auth_string' [AND 2fa_auth_option]\n  | IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD [AND 2fa_auth_option]\n  | IDENTIFIED WITH auth_plugin AS 'auth_string' [AND 2fa_auth_option]\n  | IDENTIFIED WITH auth_plugin [initial_auth_option]\n}\n2fa_auth_option: {\n    IDENTIFIED BY 'auth_string' [AND 3fa_auth_option]\n  | IDENTIFIED BY RANDOM PASSWORD [AND 3fa_auth_option]\n  | IDENTIFIED WITH auth_plugin [AND 3fa_auth_option]\n  | IDENTIFIED WITH auth_plugin BY 'auth_string' [AND 3fa_auth_option]\n  | IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD [AND 3fa_auth_option]\n  | IDENTIFIED WITH auth_plugin AS 'auth_string' [AND 3fa_auth_option]\n}\n3fa_auth_option: {\n    IDENTIFIED BY 'auth_string'\n  | IDENTIFIED BY RANDOM PASSWORD\n  | IDENTIFIED WITH auth_plugin\n  | IDENTIFIED WITH auth_plugin BY 'auth_string'\n  | IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD\n  | IDENTIFIED WITH auth_plugin AS 'auth_string'\n}\ninitial_auth_option: {\n    INITIAL AUTHENTICATION IDENTIFIED BY {RANDOM PASSWORD | 'auth_string'}\n  | INITIAL AUTHENTICATION IDENTIFIED WITH auth_plugin AS 'auth_string'\n}\ntls_option: {\n   SSL\n | X509\n | CIPHER 'cipher'\n | ISSUER 'issuer'\n | SUBJECT 'subject'\n}\nresource_option: {\n    MAX_QUERIES_PER_HOUR count\n  | MAX_UPDATES_PER_HOUR count\n  | MAX_CONNECTIONS_PER_HOUR count\n  | MAX_USER_CONNECTIONS count\n}\npassword_option: {\n    PASSWORD EXPIRE [DEFAULT | NEVER | INTERVAL N DAY]\n  | PASSWORD HISTORY {DEFAULT | N}\n  | PASSWORD REUSE INTERVAL {DEFAULT | N DAY}\n  | PASSWORD REQUIRE CURRENT [DEFAULT | OPTIONAL]\n  | FAILED_LOGIN_ATTEMPTS N\n  | PASSWORD_LOCK_TIME {N | UNBOUNDED}\n}\nlock_option: {\n    ACCOUNT LOCK\n  | ACCOUNT UNLOCK\n}\nThe CREATE USER statement creates new MySQL accounts. It enables authentication, role, SSL/TLS,\nresource-limit, password-management, comment, and attribute properties to be established for new\naccounts. It also controls whether accounts are initially locked or unlocked.\nTo use CREATE USER, you must have the global CREATE USER privilege, or the INSERT privilege\nfor the mysql system schema. When the read_only system variable is enabled, CREATE USER\nadditionally requires the CONNECTION_ADMIN privilege (or the deprecated SUPER privilege).\nThese additional privilege considerations also apply:\n• The authentication_policy system variable places certain constraints on how the\nauthentication-related clauses of CREATE USER statements may be used; for details,\nsee the description of that variable. These constraints do not apply if you have the\nAUTHENTICATION_POLICY_ADMIN privilege.\n• To create an account that uses passwordless authentication, you must have the\nPASSWORDLESS_USER_ADMIN privilege.\nCREATE USER fails with an error if any account to be created is named as the DEFINER attribute\nfor any stored object. (That is, the statement fails if creating an account would cause the account\nto adopt a currently orphaned stored object.) To perform the operation anyway, you must have\nthe SET_ANY_DEFINER or ALLOW_NONEXISTENT_DEFINER privilege; in this case, the statement\nsucceeds with a warning rather than failing with an error. To perform the user-creation operation\nwithout either of these, drop the orphan objects, create the account and grant its privileges, and then\nre-create the dropped objects. For additional information, including how to identify which objects name\na given account as the DEFINER attribute, see Orphan Stored Objects.\nCREATE USER either succeeds for all named users or rolls back and has no effect if any error occurs.\nBy default, an error occurs if you try to create a user that already exists. If the IF NOT EXISTS clause\nis given, the statement produces a warning for each named user that already exists, rather than an\nerror.\nImportant\nUnder some circumstances, CREATE USER may be recorded in server logs or\non the client side in a history file such as ~/.mysql_history, which means\nthat cleartext passwords may be read by anyone having read access to that\ninformation. For information about the conditions under which this occurs for the\nserver logs and how to control it, see Section 8.1.2.3, “Passwords and Logging”.\nFor similar information about client-side logging, see Section 6.5.1.3, “mysql\nClient Logging”.\nThere are several aspects to the CREATE USER statement, described under the following topics:\n• CREATE USER Overview\n• CREATE USER Authentication Options\n• CREATE USER Multifactor Authentication Options\n• CREATE USER Role Options\n• CREATE USER SSL/TLS Options\n• CREATE USER Resource-Limit Options\n• CREATE USER Password-Management Options\n• CREATE USER Comment and Attribute Options\n• CREATE USER Account-Locking Options\n• CREATE USER Binary Logging\nCREATE USER Overview\nFor each account, CREATE USER creates a new row in the mysql.user system table. The account\nrow reflects the properties specified in the statement. Unspecified properties are set to their default\nvalues:\n• Authentication: The default authentication plugin (determined as described in The Default\nAuthentication Plugin), and empty credentials\n• Default role: NONE\n• SSL/TLS: NONE\n• Resource limits: Unlimited\n• Password management: PASSWORD EXPIRE DEFAULT PASSWORD HISTORY DEFAULT\nPASSWORD REUSE INTERVAL DEFAULT PASSWORD REQUIRE CURRENT DEFAULT; failed-login\ntracking and temporary account locking are disabled\n• Account locking: ACCOUNT UNLOCK\nAn account when first created has no privileges and the default role NONE. To assign privileges or roles\nto this account, use one or more GRANT statements.\nEach account name uses the format described in Section 8.2.4, “Specifying Account Names”. For\nexample:\nCREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';\nThe host name part of the account name, if omitted, defaults to '%'. You should be aware\nthat, while MySQL 9.1 treats grants made to such a user as though they had been granted to\n'user'@'localhost', this behavior is deprecated, and thus subject to removal in a future version of\nMySQL.\nEach user value naming an account may be followed by an optional auth_option value that\nindicates how the account authenticates. These values enable account authentication plugins and\ncredentials (for example, a password) to be specified. Each auth_option value applies only to the\naccount named immediately preceding it.\nFollowing the user specifications, the statement may include options for SSL/TLS, resource-limit,\npassword-management, and locking properties. All such options are global to the statement and apply\nto all accounts named in the statement.\nExample: Create an account that uses the default authentication plugin and the given password. Mark\nthe password expired so that the user must choose a new one at the first connection to the server:\nCREATE USER 'jeffrey'@'localhost'\n  IDENTIFIED BY 'new_password' PASSWORD EXPIRE;\nExample: Create an account that uses the caching_sha2_password authentication plugin and the\ngiven password. Require that a new password be chosen every 180 days, and enable failed-login\ntracking, such that three consecutive incorrect passwords cause temporary account locking for two\ndays:\nCREATE USER 'jeffrey'@'localhost'\n  IDENTIFIED WITH caching_sha2_password BY 'new_password'\n  PASSWORD EXPIRE INTERVAL 180 DAY\n  FAILED_LOGIN_ATTEMPTS 3 PASSWORD_LOCK_TIME 2;\nExample: Create multiple accounts, specifying some per-account properties and some global\nproperties:\nCREATE USER\n  'jeffrey'@'localhost' IDENTIFIED WITH caching_sha2_password\n                                BY 'new_password1',\n  'jeanne'@'localhost' IDENTIFIED WITH caching_sha2_password\n                                BY 'new_password2'\n  REQUIRE X509 WITH MAX_QUERIES_PER_HOUR 60\n  PASSWORD HISTORY 5\n  ACCOUNT LOCK;\nEach auth_option value (IDENTIFIED WITH ... BY in this case) applies only to the account\nnamed immediately preceding it, so each account uses the immediately following authentication plugin\nand password.\nThe remaining properties apply globally to all accounts named in the statement, so for both accounts:\n• Connections must be made using a valid X.509 certificate.\n• Up to 60 queries per hour are permitted.\n• Password changes cannot reuse any of the five most recent passwords.\n• The account is locked initially, so effectively it is a placeholder and cannot be used until an\nadministrator unlocks it.\nCREATE USER Authentication Options\nAn account name may be followed by an auth_option authentication option that specifies the\naccount authentication plugin, credentials, or both.\nNote\nMySQL 9.1 supports multifactor authentication (MFA), such that accounts\ncan have up to three authentication methods. That is, accounts can use two-\nfactor authentication (2FA) or three-factor authentication (3FA). The syntax and\nsemantics of auth_option remain unchanged, but auth_option may be\nfollowed by specifications for additional authentication methods. This section\ndescribes auth_option. For details about the optional MFA-related following\nclauses, see CREATE USER Multifactor Authentication Options.\nNote\nClauses for random password generation apply only to accounts that use an\nauthentication plugin that stores credentials internally to MySQL. For accounts\nthat use a plugin that performs authentication against a credentials system\nthat is external to MySQL, password management must be handled externally\nagainst that system as well. For more information about internal credentials\nstorage, see Section 8.2.15, “Password Management”.\n• auth_plugin names an authentication plugin. The plugin name can be a quoted string literal or an\nunquoted name. Plugin names are stored in the plugin column of the mysql.user system table.\nFor auth_option syntax that does not specify an authentication plugin, the server assigns the\ndefault plugin, determined as described in The Default Authentication Plugin. For descriptions of\neach plugin, see Section 8.4.1, “Authentication Plugins”.\n• Credentials that are stored internally are stored in the mysql.user system table. An\n'auth_string' value or RANDOM PASSWORD specifies account credentials, either as a cleartext\n(unencrypted) string or hashed in the format expected by the authentication plugin associated with\nthe account, respectively:\n• For syntax that uses BY 'auth_string', the string is cleartext and is passed to the\nauthentication plugin for possible hashing. The result returned by the plugin is stored in the\nmysql.user table. A plugin may use the value as specified, in which case no hashing occurs.\n• For syntax that uses BY RANDOM PASSWORD, MySQL generates a random password and as\ncleartext and passes it to the authentication plugin for possible hashing. The result returned by the\nplugin is stored in the mysql.user table. A plugin may use the value as specified, in which case\nno hashing occurs.\nRandomly generated passwords have the characteristics described in Random Password\nGeneration.\n• For syntax that uses AS 'auth_string', the string is assumed to be already in the format the\nauthentication plugin requires, and is stored as is in the mysql.user table. If a plugin requires a\nhashed value, the value must be already hashed in a format appropriate for the plugin; otherwise,\nthe value cannot be used by the plugin and correct authentication of client connections does not\noccur.\nA hashed string can be either a string literal or a hexadecimal value. The latter corresponds to\nthe type of value displayed by SHOW CREATE USER for password hashes containing unprintable\ncharacters when the print_identified_with_as_hex system variable is enabled.\nImportant\nAlthough we show 'auth_string' with quotation marks, a hexadecimal\nvalue used for this purpose must not be quoted.\n• If an authentication plugin performs no hashing of the authentication string, the BY\n'auth_string' and AS 'auth_string' clauses have the same effect: The authentication\nstring is stored as is in the mysql.user system table.\nCREATE USER permits these auth_option syntaxes:\n• IDENTIFIED BY 'auth_string'\nSets the account authentication plugin to the default plugin, passes the cleartext 'auth_string'\nvalue to the plugin for possible hashing, and stores the result in the account row in the mysql.user\nsystem table.\n• IDENTIFIED BY RANDOM PASSWORD\nSets the account authentication plugin to the default plugin, generates a random password, passes\nthe cleartext password value to the plugin for possible hashing, and stores the result in the account\nrow in the mysql.user system table. The statement also returns the cleartext password in a result\nset to make it available to the user or application executing the statement. For details about the result\nset and characteristics of randomly generated passwords, see Random Password Generation.\n• IDENTIFIED WITH auth_plugin\nSets the account authentication plugin to auth_plugin, clears the credentials to the empty string,\nand stores the result in the account row in the mysql.user system table.\n• IDENTIFIED WITH auth_plugin BY 'auth_string'\nSets the account authentication plugin to auth_plugin, passes the cleartext 'auth_string'\nvalue to the plugin for possible hashing, and stores the result in the account row in the mysql.user\nsystem table.\n• IDENTIFIED WITH auth_plugin BY RANDOM PASSWORD\nSets the account authentication plugin to auth_plugin, generates a random password, passes the\ncleartext password value to the plugin for possible hashing, and stores the result in the account row\nin the mysql.user system table. The statement also returns the cleartext password in a result set to\nmake it available to the user or application executing the statement. For details about the result set\nand characteristics of randomly generated passwords, see Random Password Generation.\n• IDENTIFIED WITH auth_plugin AS 'auth_string'\nSets the account authentication plugin to auth_plugin and stores the 'auth_string' value as is\nin the mysql.user account row. If the plugin requires a hashed string, the string is assumed to be\nalready hashed in the format the plugin requires.\nExample: Specify the password as cleartext; the default plugin is used:\nCREATE USER 'jeffrey'@'localhost'\n  IDENTIFIED BY 'password';\nExample: Specify the authentication plugin, along with a cleartext password value:\nCREATE USER 'jeffrey'@'localhost'\n  IDENTIFIED WITH caching_sha2_password BY 'password';\nIn each case, the password value stored in the account row is the cleartext value 'password' after it\nhas been hashed by the authentication plugin associated with the account.\nFor additional information about setting passwords and authentication plugins, see Section 8.2.14,\n“Assigning Account Passwords”, and Section 8.2.17, “Pluggable Authentication”.\nCREATE USER Multifactor Authentication Options\nThe auth_option part of CREATE USER defines an authentication method for one-factor/single-\nfactor authentication (1FA/SFA). CREATE USER also supports multifactor authentication (MFA), such\nthat accounts can have up to three authentication methods. That is, accounts can use two-factor\nauthentication (2FA) or three-factor authentication (3FA).\nThe authentication_policy system variable defines constraints for CREATE USER statements\nwith multifactor authentication (MFA) clauses. For example, the authentication_policy setting\ncontrols the number of authentication factors that accounts may have, and for each factor, which\nauthentication methods are permitted. See Configuring the Multifactor Authentication Policy.\nFor information about factor-specific rules that determine the default authentication plugin for\nauthentication clauses that name no plugin, see The Default Authentication Plugin.\nFollowing auth_option, there may appear different optional MFA clauses:\n• 2fa_auth_option: Specifies a factor 2 authentication method. The following example\ndefines caching_sha2_password as the factor 1 authentication method, and\nauthentication_ldap_sasl as the factor 2 authentication method.\nCREATE USER 'u1'@'localhost'\n  IDENTIFIED WITH caching_sha2_password\n    BY 'sha2_password'\n  AND IDENTIFIED WITH authentication_ldap_sasl\n    AS 'uid=u1_ldap,ou=People,dc=example,dc=com';\n• 3fa_auth_option: Following 2fa_auth_option, there may appear a 3fa_auth_option\nclause to specify a factor 3 authentication method. The following example defines\ncaching_sha2_password as the factor 1 authentication method, authentication_ldap_sasl\nas the factor 2 authentication method, and authentication_webauthn as the factor 3\nauthentication method\nCREATE USER 'u1'@'localhost'\n  IDENTIFIED WITH caching_sha2_password\n    BY 'sha2_password'\n  AND IDENTIFIED WITH authentication_ldap_sasl\n    AS 'uid=u1_ldap,ou=People,dc=example,dc=com'\n  AND IDENTIFIED WITH authentication_webauthn;\n• initial_auth_option: Specifies an initial authentication method for configuring FIDO/FIDO2\npasswordless authentication. As shown in the following, temporary authentication using either a\ngenerated random password or a user-specified auth-string is required to enable WebAuthn\npasswordless authentication.\nCREATE USER user\n  IDENTIFIED WITH authentication_webauthn\n  INITIAL AUTHENTICATION IDENTIFIED BY {RANDOM PASSWORD | 'auth_string'};\nFor information about configuring passwordless authentication using WebAuthn pluggable\nauthentication, See WebAuthn Passwordless Authentication.\nCREATE USER Role Options\nThe DEFAULT ROLE clause defines which roles become active when the user connects to the server\nand authenticates, or when the user executes the SET ROLE DEFAULT statement during a session.\nEach role name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nCREATE USER 'joe'@'10.0.0.1' DEFAULT ROLE administrator, developer;\nThe host name part of the role name, if omitted, defaults to '%'.\nThe DEFAULT ROLE clause permits a list of one or more comma-separated role names. These\nroles must exist at the time CREATE USER is executed; otherwise the statement raises an error\n(ER_USER_DOES_NOT_EXIST), and the user is not created.\nCREATE USER SSL/TLS Options\nMySQL can check X.509 certificate attributes in addition to the usual authentication that is based on\nthe user name and credentials. For background information on the use of SSL/TLS with MySQL, see\nSection 8.3, “Using Encrypted Connections”.\nTo specify SSL/TLS-related options for a MySQL account, use a REQUIRE clause that specifies one or\nmore tls_option values.\nOrder of REQUIRE options does not matter, but no option can be specified twice. The AND keyword is\noptional between REQUIRE options.\nCREATE USER permits these tls_option values:\n• NONE\nIndicates that all accounts named by the statement have no SSL or X.509 requirements.\nUnencrypted connections are permitted if the user name and password are valid. Encrypted\nconnections can be used, at the client's option, if the client has the proper certificate and key files.\nCREATE USER 'jeffrey'@'localhost' REQUIRE NONE;\nClients attempt to establish a secure connection by default. For clients that have REQUIRE NONE,\nthe connection attempt falls back to an unencrypted connection if a secure connection cannot\nbe established. To require an encrypted connection, a client need specify only the --ssl-\nmode=REQUIRED option; the connection attempt fails if a secure connection cannot be established.\nNONE is the default if no SSL-related REQUIRE options are specified.\n• SSL\nTells the server to permit only encrypted connections for all accounts named by the statement.\nCREATE USER 'jeffrey'@'localhost' REQUIRE SSL;\nClients attempt to establish a secure connection by default. For accounts that have REQUIRE SSL,\nthe connection attempt fails if a secure connection cannot be established.\n• X509\nFor all accounts named by the statement, requires that clients present a valid certificate, but the\nexact certificate, issuer, and subject do not matter. The only requirement is that it should be possible\nto verify its signature with one of the CA certificates. Use of X.509 certificates always implies\nencryption, so the SSL option is unnecessary in this case.\nCREATE USER 'jeffrey'@'localhost' REQUIRE X509;\nFor accounts with REQUIRE X509, clients must specify the --ssl-key and --ssl-cert options\nto connect. (It is recommended but not required that --ssl-ca also be specified so that the public\ncertificate provided by the server can be verified.) This is true for ISSUER and SUBJECT as well\nbecause those REQUIRE options imply the requirements of X509.\n• ISSUER 'issuer'\nFor all accounts named by the statement, requires that clients present a valid X.509 certificate issued\nby CA 'issuer'. If a client presents a certificate that is valid but has a different issuer, the server\nrejects the connection. Use of X.509 certificates always implies encryption, so the SSL option is\nunnecessary in this case.\nCREATE USER 'jeffrey'@'localhost'\n  REQUIRE ISSUER '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL/CN=CA/emailAddress=ca@example.com';\nBecause ISSUER implies the requirements of X509, clients must specify the --ssl-key and --\nssl-cert options to connect. (It is recommended but not required that --ssl-ca also be specified\nso that the public certificate provided by the server can be verified.)\n• SUBJECT 'subject'\nFor all accounts named by the statement, requires that clients present a valid X.509 certificate\ncontaining the subject subject. If a client presents a certificate that is valid but has a different\nsubject, the server rejects the connection. Use of X.509 certificates always implies encryption, so the\nSSL option is unnecessary in this case.\nCREATE USER 'jeffrey'@'localhost'\n  REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL demo client certificate/\n    CN=client/emailAddress=client@example.com';\nMySQL does a simple string comparison of the 'subject' value to the value in the certificate, so\nlettercase and component ordering must be given exactly as present in the certificate.\nBecause SUBJECT implies the requirements of X509, clients must specify the --ssl-key and --\nssl-cert options to connect. (It is recommended but not required that --ssl-ca also be specified\nso that the public certificate provided by the server can be verified.)\n• CIPHER 'cipher'\nFor all accounts named by the statement, requires a specific cipher method for encrypting\nconnections. This option is needed to ensure that ciphers and key lengths of sufficient strength are\nused. Encryption can be weak if old algorithms using short encryption keys are used.\nCREATE USER 'jeffrey'@'localhost'\n  REQUIRE CIPHER 'EDH-RSA-DES-CBC3-SHA';\nThe SUBJECT, ISSUER, and CIPHER options can be combined in the REQUIRE clause:\nCREATE USER 'jeffrey'@'localhost'\n  REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL demo client certificate/\n    CN=client/emailAddress=client@example.com'\n  AND ISSUER '/C=SE/ST=Stockholm/L=Stockholm/\n    O=MySQL/CN=CA/emailAddress=ca@example.com'\n  AND CIPHER 'EDH-RSA-DES-CBC3-SHA';\nCREATE USER Resource-Limit Options\nIt is possible to place limits on use of server resources by an account, as discussed in Section 8.2.21,\n“Setting Account Resource Limits”. To do so, use a WITH clause that specifies one or more\nresource_option values.\nOrder of WITH options does not matter, except that if a given resource limit is specified multiple times,\nthe last instance takes precedence.\nCREATE USER permits these resource_option values:\n• MAX_QUERIES_PER_HOUR count, MAX_UPDATES_PER_HOUR count,\nMAX_CONNECTIONS_PER_HOUR count\nFor all accounts named by the statement, these options restrict how many queries, updates, and\nconnections to the server are permitted to each account during any given one-hour period. If count\nis 0 (the default), this means that there is no limitation for the account.\n• MAX_USER_CONNECTIONS count\nFor all accounts named by the statement, restricts the maximum number of simultaneous\nconnections to the server by each account. A nonzero count specifies the limit for the account\nexplicitly. If count is 0 (the default), the server determines the number of simultaneous connections\nfor the account from the global value of the max_user_connections system variable. If\nmax_user_connections is also zero, there is no limit for the account.\nExample:\nCREATE USER 'jeffrey'@'localhost'\n  WITH MAX_QUERIES_PER_HOUR 500 MAX_UPDATES_PER_HOUR 100;\nCREATE USER Password-Management Options\nCREATE USER supports several password_option values for password management:\n• Password expiration options: You can expire an account password manually and establish its\npassword expiration policy. Policy options do not expire the password. Instead, they determine how\nthe server applies automatic expiration to the account based on password age, which is assessed\nfrom the date and time of the most recent account password change.\n• Password reuse options: You can restrict password reuse based on number of password changes,\ntime elapsed, or both.\n• Password verification-required options: You can indicate whether attempts to change an account\npassword must specify the current password, as verification that the user attempting to make the\nchange actually knows the current password.\n• Incorrect-password failed-login tracking options: You can cause the server to track failed login\nattempts and temporarily lock accounts for which too many consecutive incorrect passwords are\ngiven. The required number of failures and the lock time are configurable.\nThis section describes the syntax for password-management options. For information about\nestablishing policy for password management, see Section 8.2.15, “Password Management”.\nIf multiple password-management options of a given type are specified, the last one takes precedence.\nFor example, PASSWORD EXPIRE DEFAULT PASSWORD EXPIRE NEVER is the same as PASSWORD\nEXPIRE NEVER.\nNote\nExcept for the options that pertain to failed-login tracking, password-\nmanagement options apply only to accounts that use an authentication plugin\nthat stores credentials internally to MySQL. For accounts that use a plugin that\nperforms authentication against a credentials system that is external to MySQL,\npassword management must be handled externally against that system as well.\nFor more information about internal credentials storage, see Section 8.2.15,\n“Password Management”.\nA client has an expired password if the account password was expired manually or the password\nage is considered greater than its permitted lifetime per the automatic expiration policy. In this case,\nthe server either disconnects the client or restricts the operations permitted to it (see Section 8.2.16,\n“Server Handling of Expired Passwords”). Operations performed by a restricted client result in an error\nuntil the user establishes a new account password.\nCREATE USER permits these password_option values for controlling password expiration:\n• PASSWORD EXPIRE\nImmediately marks the password expired for all accounts named by the statement.\nCREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE;\n• PASSWORD EXPIRE DEFAULT\nSets all accounts named by the statement so that the global expiration policy applies, as specified by\nthe default_password_lifetime system variable.\nCREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;\n• PASSWORD EXPIRE NEVER\nThis expiration option overrides the global policy for all accounts named by the statement. For each,\nit disables password expiration so that the password never expires.\nCREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;\n• PASSWORD EXPIRE INTERVAL N DAY\nThis expiration option overrides the global policy for all accounts named by the statement. For each,\nit sets the password lifetime to N days. The following statement requires the password to be changed\nevery 180 days:\nCREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 180 DAY;\nCREATE USER permits these password_option values for controlling reuse of previous passwords\nbased on required minimum number of password changes:\n• PASSWORD HISTORY DEFAULT\nSets all accounts named by the statement so that the global policy about password history\nlength applies, to prohibit reuse of passwords before the number of changes specified by the\npassword_history system variable.\nCREATE USER 'jeffrey'@'localhost' PASSWORD HISTORY DEFAULT;\n• PASSWORD HISTORY N\nThis history-length option overrides the global policy for all accounts named by the statement. For\neach, it sets the password history length to N passwords, to prohibit reusing any of the N most\nrecently chosen passwords. The following statement prohibits reuse of any of the previous 6\npasswords:\nCREATE USER 'jeffrey'@'localhost' PASSWORD HISTORY 6;\nCREATE USER permits these password_option values for controlling reuse of previous passwords\nbased on time elapsed:\n• PASSWORD REUSE INTERVAL DEFAULT\nSets all statements named by the account so that the global policy about time elapsed\napplies, to prohibit reuse of passwords newer than the number of days specified by the\npassword_reuse_interval system variable.\nCREATE USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL DEFAULT;\n• PASSWORD REUSE INTERVAL N DAY\nThis time-elapsed option overrides the global policy for all accounts named by the statement. For\neach, it sets the password reuse interval to N days, to prohibit reuse of passwords newer than that\nmany days. The following statement prohibits password reuse for 360 days:\nCREATE USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL 360 DAY;\nCREATE USER permits these password_option values for controlling whether attempts to change an\naccount password must specify the current password, as verification that the user attempting to make\nthe change actually knows the current password:\n• PASSWORD REQUIRE CURRENT\nThis verification option overrides the global policy for all accounts named by the statement. For each,\nit requires that password changes specify the current password.\nCREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT;\n• PASSWORD REQUIRE CURRENT OPTIONAL\nThis verification option overrides the global policy for all accounts named by the statement. For each,\nit does not require that password changes specify the current password. (The current password may\nbut need not be given.)\nCREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT OPTIONAL;\n• PASSWORD REQUIRE CURRENT DEFAULT\nSets all statements named by the account so that the global policy about password verification\napplies, as specified by the password_require_current system variable.\nCREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT DEFAULT;\nCREATE USER permits these password_option values for controlling failed-login tracking:\n• FAILED_LOGIN_ATTEMPTS N\nWhether to track account login attempts that specify an incorrect password. N must be a number\nfrom 0 to 32767. A value of 0 disables failed-login tracking. Values greater than 0 indicate how many\nconsecutive password failures cause temporary account locking (if PASSWORD_LOCK_TIME is also\nnonzero).\n• PASSWORD_LOCK_TIME {N | UNBOUNDED}\nHow long to lock the account after too many consecutive login attempts provide an incorrect\npassword. N must be a number from 0 to 32767, or UNBOUNDED. A value of 0 disables temporary\naccount locking. Values greater than 0 indicate how long to lock the account in days. A value of\nUNBOUNDED causes the account locking duration to be unbounded; once locked, the account\nremains in a locked state until unlocked. For information about the conditions under which unlocking\noccurs, see Failed-Login Tracking and Temporary Account Locking.\nFor failed-login tracking and temporary locking to occur, an account's FAILED_LOGIN_ATTEMPTS and\nPASSWORD_LOCK_TIME options both must be nonzero. The following statement creates an account\nthat remains locked for two days after four consecutive password failures:\nCREATE USER 'jeffrey'@'localhost'\n  FAILED_LOGIN_ATTEMPTS 4 PASSWORD_LOCK_TIME 2;\nCREATE USER Comment and Attribute Options\nYou can also include an optional comment or attribute when creating a user, as described here:\n• User comment\nTo set a user comment, add COMMENT 'user_comment' to the CREATE USER statement, where\nuser_comment is the text of the user comment.\nExample (omitting any other options):\nCREATE USER 'jon'@'localhost' COMMENT 'Some information about Jon';\n• User attribute\nA user attribute is a JSON object made up of one or more key-value pairs, and is set by including\nATTRIBUTE 'json_object' as part of CREATE USER. json_object must be a valid JSON\nobject.\nExample (omitting any other options):\nCREATE USER 'jim'@'localhost'\n    ATTRIBUTE '{\"fname\": \"James\", \"lname\": \"Scott\", \"phone\": \"123-456-7890\"}';\nUser comments and user attributes are stored together in the ATTRIBUTE column of the Information\nSchema USER_ATTRIBUTES table. This query displays the row in this table inserted by the statement\njust shown for creating the user jim@localhost:\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->    WHERE USER = 'jim' AND HOST = 'localhost'\\G\n*************************** 1. row ***************************\n     USER: jim\n     HOST: localhost\nATTRIBUTE: {\"fname\": \"James\", \"lname\": \"Scott\", \"phone\": \"123-456-7890\"}\n1 row in set (0.00 sec)\nThe COMMENT option in actuality provides a shortcut for setting a user attribute whose only element\nhas comment as its key and whose value is the argument supplied for the option. You can see this by\nexecuting the statement CREATE USER 'jon'@'localhost' COMMENT 'Some information\nabout Jon', and observing the row which it inserts into the USER_ATTRIBUTES table:\nmysql> CREATE USER 'jon'@'localhost' COMMENT 'Some information about Jon';\nQuery OK, 0 rows affected (0.06 sec)\nmysql> SELECT * FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    ->    WHERE USER = 'jon' AND HOST = 'localhost';\n+------+-----------+-------------------------------------------+\n| USER | HOST      | ATTRIBUTE                                 |\n+------+-----------+-------------------------------------------+\n| jon  | localhost | {\"comment\": \"Some information about Jon\"} |\n+------+-----------+-------------------------------------------+\n1 row in set (0.00 sec)\nYou cannot use COMMENT and ATTRIBUTE together in the same CREATE USER statement; attempting\nto do so causes a syntax error. To set a user comment concurrently with setting a user attribute, use\nATTRIBUTE and include in its argument a value with a comment key, like this:\nmysql> CREATE USER 'bill'@'localhost'\n    ->        ATTRIBUTE '{\"fname\":\"William\", \"lname\":\"Schmidt\",\n    ->        \"comment\":\"Website developer\"}';\nQuery OK, 0 rows affected (0.16 sec)\nSince the content of the ATTRIBUTE row is a JSON object, you can employ any appropriate MySQL\nJSON functions or operators to manipulate it, as shown here:\nmysql> SELECT\n    ->   USER AS User,\n    ->   HOST AS Host,\n    ->   CONCAT(ATTRIBUTE->>\"$.fname\",\" \",ATTRIBUTE->>\"$.lname\") AS 'Full Name',\n    ->   ATTRIBUTE->>\"$.comment\" AS Comment\n    -> FROM INFORMATION_SCHEMA.USER_ATTRIBUTES\n    -> WHERE USER='bill' AND HOST='localhost';\n+------+-----------+-----------------+-------------------+\n| User | Host      | Full Name       | Comment           |\n+------+-----------+-----------------+-------------------+\n| bill | localhost | William Schmidt | Website developer |\n+------+-----------+-----------------+-------------------+\n1 row in set (0.00 sec)\nTo set or to make changes in the user comment or user attribute for an existing user, you can use a\nCOMMENT or ATTRIBUTE option with an ALTER USER statement.\nBecause the user comment and user attribute are stored together internally in a single JSON column,\nthis sets an upper limit on their maximum combined size; see JSON Storage Requirements, for more\ninformation.\nSee also the description of the Information Schema USER_ATTRIBUTES table for more information and\nexamples.\nCREATE USER Account-Locking Options\nMySQL supports account locking and unlocking using the ACCOUNT LOCK and ACCOUNT UNLOCK\noptions, which specify the locking state for an account. For additional discussion, see Section 8.2.20,\n“Account Locking”.\nIf multiple account-locking options are specified, the last one takes precedence.\nCREATE USER Binary Logging\nCREATE USER is written to the binary log if it succeeds, but not if it fails; in that case, rollback occurs\nand no changes are made. A statement written to the binary log includes all named users. If the IF\nNOT EXISTS clause is given, this includes even users that already exist and were not created.\nThe statement written to the binary log specifies an authentication plugin for each user, determined as\nfollows:\n• The plugin named in the original statement, if one was specified.\n• Otherwise, the default authentication plugin. In particular, if a user u1 already exists and uses a\nnondefault authentication plugin, the statement written to the binary log for CREATE USER IF NOT\nEXISTS u1 names the default authentication plugin. (If the statement written to the binary log must\nspecify a nondefault authentication plugin for a user, include it in the original statement.)\nIf the server adds the default authentication plugin for any nonexisting users in the statement written to\nthe binary log, it writes a warning to the error log naming those users.\nIf the original statement specifies the FAILED_LOGIN_ATTEMPTS or PASSWORD_LOCK_TIME option,\nthe statement written to the binary log includes the option.\nCREATE USER statements with clauses that support multifactor authentication (MFA) are written to the\nbinary log.\n• CREATE USER ... IDENTIFIED WITH .. INITIAL AUTHENTICATION IDENTIFIED\nWITH ... statements are written to the binary log as CREATE USER .. IDENTIFIED WITH ..\nINITIAL AUTHENTICATION IDENTIFIED WITH .. AS 'password-hash', where the\npassword-hash is the user-specified auth-string or the random password generated by server\nwhen the RANDOM PASSWORD clause is specified.\n15.7.1.4 DROP ROLE Statement\nDROP ROLE [IF EXISTS] role [, role ] ...\nDROP ROLE removes one or more roles (named collections of privileges). To use this statement, you\nmust have the global DROP ROLE or CREATE USER privilege. When the read_only system variable\nis enabled, DROP ROLE additionally requires the CONNECTION_ADMIN privilege (or the deprecated\nSUPER privilege).\nUsers who have the CREATE USER privilege can use this statement to drop accounts that are locked or\nunlocked. Users who have the DROP ROLE privilege can use this statement only to drop accounts that\nare locked (unlocked accounts are presumably user accounts used to log in to the server and not just\nas roles).\nRoles named in the mandatory_roles system variable value cannot be dropped.\nDROP ROLE either succeeds for all named roles or rolls back and has no effect if any error occurs. By\ndefault, an error occurs if you try to drop a role that does not exist. If the IF EXISTS clause is given,\nthe statement produces a warning for each named role that does not exist, rather than an error.\nThe statement is written to the binary log if it succeeds, but not if it fails; in that case, rollback occurs\nand no changes are made. A statement written to the binary log includes all named roles. If the IF\nEXISTS clause is given, this includes even roles that do not exist and were not dropped.\nEach role name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nDROP ROLE 'admin', 'developer';\nDROP ROLE 'webapp'@'localhost';\nThe host name part of the role name, if omitted, defaults to '%'.\nA dropped role is automatically revoked from any user account (or role) to which the role was granted.\nWithin any current session for such an account, its adjusted privileges apply beginning with the next\nstatement executed.\nFor role usage examples, see Section 8.2.10, “Using Roles”.\n15.7.1.5 DROP USER Statement\nDROP USER [IF EXISTS] user [, user] ...\nThe DROP USER statement removes one or more MySQL accounts and their privileges. It removes\nprivilege rows for the account from all grant tables.\nRoles named in the mandatory_roles system variable value cannot be dropped.\nTo use DROP USER, you must have the global CREATE USER privilege, or the DELETE privilege for the\nmysql system schema. When the read_only system variable is enabled, DROP USER additionally\nrequires the CONNECTION_ADMIN privilege (or the deprecated SUPER privilege).\nDROP USER fails with an error if any account to be dropped is named as the DEFINER attribute for\nany stored object. (That is, the statement fails if dropping an account would cause a stored object\nto become orphaned.) To perform the operation anyway, you must have the SET_ANY_DEFINER or\nALLOW_NONEXISTENT_DEFINER privilege; in this case, the statement succeeds with a warning rather\nthan failing with an error. For additional information, including how to identify which objects name a\ngiven account as the DEFINER attribute, see Orphan Stored Objects.\nDROP USER either succeeds for all named users or rolls back and has no effect if any error occurs. By\ndefault, an error occurs if you try to drop a user that does not exist. If the IF EXISTS clause is given,\nthe statement produces a warning for each named user that does not exist, rather than an error.\nThe statement is written to the binary log if it succeeds, but not if it fails; in that case, rollback occurs\nand no changes are made. A statement written to the binary log includes all named users. If the IF\nEXISTS clause is given, this includes even users that do not exist and were not dropped.\nEach account name uses the format described in Section 8.2.4, “Specifying Account Names”. For\nexample:\nDROP USER 'jeffrey'@'localhost';\nThe host name part of the account name, if omitted, defaults to '%'.\nImportant\nDROP USER does not automatically close any open user sessions. Rather, in\nthe event that a user with an open session is dropped, the statement does not\ntake effect until that user's session is closed. Once the session is closed, the\nuser is dropped, and that user's next attempt to log in fails. This is by design.\nDROP USER does not automatically drop or invalidate databases or objects within them that the old\nuser created. This includes stored programs or views for which the DEFINER attribute names the\ndropped user. Attempts to access such objects may produce an error if they execute in definer security\ncontext. (For information about security context, see Section 27.7, “Stored Object Access Control”.)\n15.7.1.6 GRANT Statement\nGRANT\n    priv_type [(column_list)]\n      [, priv_type [(column_list)]] ...\n    ON [object_type] priv_level\n    TO user_or_role [, user_or_role] ...\n    [WITH GRANT OPTION]\n    [AS user\n        [WITH ROLE\n            DEFAULT\n          | NONE\n          | ALL\n          | ALL EXCEPT role [, role ] ...\n          | role [, role ] ...\n        ]\n    ]\n}\nGRANT PROXY ON user_or_role\n    TO user_or_role [, user_or_role] ...\n    [WITH GRANT OPTION]\nGRANT role [, role] ...\n    TO user_or_role [, user_or_role] ...\n    [WITH ADMIN OPTION]\nobject_type: {\n    TABLE\n  | FUNCTION\n  | PROCEDURE\n}\npriv_level: {\n    *\n  | *.*\n  | db_name.*\n  | db_name.tbl_name\n  | tbl_name\n  | db_name.routine_name\n}\nuser_or_role: {\n    user (see Section 8.2.4, “Specifying Account Names”)\n  | role (see Section 8.2.5, “Specifying Role Names”)\n}\nThe GRANT statement assigns privileges and roles to MySQL user accounts and roles. There are\nseveral aspects to the GRANT statement, described under the following topics:\n• GRANT General Overview\n• Object Quoting Guidelines\n• Account Names\n• Privileges Supported by MySQL\n• Global Privileges\n• Database Privileges\n• Table Privileges\n• Column Privileges\n• Stored Routine Privileges\n• Proxy User Privileges\n• Granting Roles\n• The AS Clause and Privilege Restrictions\n• Other Account Characteristics\n• MySQL and Standard SQL Versions of GRANT\nGRANT General Overview\nThe GRANT statement enables system administrators to grant privileges and roles, which can be\ngranted to user accounts and roles. These syntax restrictions apply:\n• GRANT cannot mix granting both privileges and roles in the same statement. A given GRANT\nstatement must grant either privileges or roles.\n• The ON clause distinguishes whether the statement grants privileges or roles:\n• With ON, the statement grants privileges.\n• Without ON, the statement grants roles.\n• It is permitted to assign both privileges and roles to an account, but you must use separate GRANT\nstatements, each with syntax appropriate to what is to be granted.\nFor more information about roles, see Section 8.2.10, “Using Roles”.\nTo grant a privilege with GRANT, you must have the GRANT OPTION privilege, and you must have the\nprivileges that you are granting. (Alternatively, if you have the UPDATE privilege for the grant tables in\nthe mysql system schema, you can grant any account any privilege.) When the read_only system\nvariable is enabled, GRANT additionally requires the CONNECTION_ADMIN privilege (or the deprecated\nSUPER privilege).\nGRANT either succeeds for all named users and roles or rolls back and has no effect if any error occurs.\nThe statement is written to the binary log only if it succeeds for all named users and roles.\nThe REVOKE statement is related to GRANT and enables administrators to remove account privileges.\nSee Section 15.7.1.8, “REVOKE Statement”.\nEach account name uses the format described in Section 8.2.4, “Specifying Account Names”. Each\nrole name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nGRANT ALL ON db1.* TO 'jeffrey'@'localhost';\nGRANT 'role1', 'role2' TO 'user1'@'localhost', 'user2'@'localhost';\nGRANT SELECT ON world.* TO 'role3';\nThe host name part of the account or role name, if omitted, defaults to '%'.\nNormally, a database administrator first uses CREATE USER to create an account and define its\nnonprivilege characteristics such as its password, whether it uses secure connections, and limits on\naccess to server resources, then uses GRANT to define its privileges. ALTER USER may be used to\nchange the nonprivilege characteristics of existing accounts. For example:\nCREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';\nGRANT ALL ON db1.* TO 'jeffrey'@'localhost';\nGRANT SELECT ON db2.invoice TO 'jeffrey'@'localhost';\nALTER USER 'jeffrey'@'localhost' WITH MAX_QUERIES_PER_HOUR 90;\nFrom the mysql program, GRANT responds with Query OK, 0 rows affected when executed\nsuccessfully. To determine what privileges result from the operation, use SHOW GRANTS. See\nSection 15.7.7.22, “SHOW GRANTS Statement”.\nImportant\nUnder some circumstances, GRANT may be recorded in server logs or on\nthe client side in a history file such as ~/.mysql_history, which means\nthat cleartext passwords may be read by anyone having read access to that\ninformation. For information about the conditions under which this occurs for the\nserver logs and how to control it, see Section 8.1.2.3, “Passwords and Logging”.\nFor similar information about client-side logging, see Section 6.5.1.3, “mysql\nClient Logging”.\nGRANT supports host names up to 255 characters long. User names can be up to 32 characters.\nDatabase, table, column, and routine names can be up to 64 characters.\nWarning\nDo not attempt to change the permissible length for user names by altering the\nmysql.user system table. Doing so results in unpredictable behavior which\nmay even make it impossible for users to log in to the MySQL server. Never\nalter the structure of tables in the mysql system schema in any manner except\nby means of the procedure described in Chapter 3, Upgrading MySQL.\nObject Quoting Guidelines\nSeveral objects within GRANT statements are subject to quoting, although quoting is optional in many\ncases: Account, role, database, table, column, and routine names. For example, if a user_name\nor host_name value in an account name is legal as an unquoted identifier, you need not quote it.\nHowever, quotation marks are necessary to specify a user_name string containing special characters\n(such as -), or a host_name string containing special characters or wildcard characters such as % (for\nexample, 'test-user'@'%.com'). Quote the user name and host name separately.\nTo specify quoted values:\n• Quote database, table, column, and routine names as identifiers.\n• Quote user names and host names as identifiers or as strings.\n• Quote passwords as strings.\nFor string-quoting and identifier-quoting guidelines, see Section 11.1.1, “String Literals”, and\nSection 11.2, “Schema Object Names”.\nImportant\nThe use of the wildcard characters % and _ as described in the next few\nparagraphs is deprecated, and thus subject to removal in a future version of\nMySQL.\nThe _ and % wildcards are permitted when specifying database names in GRANT statements that grant\nprivileges at the database level (GRANT ... ON db_name.*). This means, for example, that to use\na _ character as part of a database name, specify it using the \\ escape character as \\_ in the GRANT\nstatement, to prevent the user from being able to access additional databases matching the wildcard\npattern (for example, GRANT ... ON `foo\\_bar`.* TO ...).\nIssuing multiple GRANT statements containing wildcards may not have the expected effect on DML\nstatements; when resolving grants involving wildcards, MySQL takes only the first matching grant into\nconsideration. In other words, if a user has two database-level grants using wildcards that match the\nsame database, the grant which was created first is applied. Consider the database db and table t\ncreated using the statements shown here:\nmysql> CREATE DATABASE db;\nQuery OK, 1 row affected (0.01 sec)\nmysql> CREATE TABLE db.t (c INT);\nQuery OK, 0 rows affected (0.01 sec)\nmysql> INSERT INTO db.t VALUES ROW(1);\nQuery OK, 1 row affected (0.00 sec)\nNext (assuming that the current account is the MySQL root account or another account having the\nnecessary privileges), we create a user u then issue two GRANT statements containing wildcards, like\nthis:\nmysql> CREATE USER u;\nQuery OK, 0 rows affected (0.01 sec)\nmysql> GRANT SELECT ON `d_`.* TO u;\nQuery OK, 0 rows affected (0.01 sec)\nmysql> GRANT INSERT ON `d%`.* TO u;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> EXIT\nBye\nIf we end the session and then log in again with the mysql client, this time as u, we see that this\naccount has only the privilege provided by the first matching grant, but not the second:\n$> mysql -uu -hlocalhost\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 10\nServer version: 9.1.0-tr Source distribution\nCopyright (c) 2000, 2023, Oracle and/or its affiliates.\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input\nstatement.\nmysql> TABLE db.t;\n+------+\n| c    |\n+------+\n|    1 |\n+------+\n1 row in set (0.00 sec)\nmysql> INSERT INTO db.t VALUES ROW(2);\nERROR 1142 (42000): INSERT command denied to user 'u'@'localhost' for table 't' \nIn privilege assignments, MySQL interprets occurrences of unescaped _ and % SQL wildcard\ncharacters in database names as literal characters under these circumstances:\n• When a database name is not used to grant privileges at the database level, but as a qualifier for\ngranting privileges to some other object such as a table or routine (for example, GRANT ... ON\ndb_name.tbl_name).\n• Enabling partial_revokes causes MySQL to interpret unescaped _ and % wildcard characters\nin database names as literal characters, just as if they had been escaped as \\_ and \\%. Because\nthis changes how MySQL interprets privileges, it may be advisable to avoid unescaped wildcard\ncharacters in privilege assignments for installations where partial_revokes may be enabled. For\nmore information, see Section 8.2.12, “Privilege Restriction Using Partial Revokes”.\nAccount Names\nA user value in a GRANT statement indicates a MySQL account to which the statement applies. To\naccommodate granting rights to users from arbitrary hosts, MySQL supports specifying the user value\nin the form 'user_name'@'host_name'.\nYou can specify wildcards in the host name. For example, 'user_name'@'%.example.com' applies\nto user_name for any host in the example.com domain, and 'user_name'@'198.51.100.%'\napplies to user_name for any host in the 198.51.100 class C subnet.\nThe simple form 'user_name' is a synonym for 'user_name'@'%'.\nNote\nMySQL automatically assigns all privileges granted to 'username'@'%' to the\n'username'@'localhost' account as well. This behavior is deprecated, and\nis subject to removal in a future version of MySQL.\nMySQL does not support wildcards in user names. To refer to an anonymous user, specify an account\nwith an empty user name with the GRANT statement:\nGRANT ALL ON test.* TO ''@'localhost' ...;\nIn this case, any user who connects from the local host with the correct password for the anonymous\nuser is permitted access, with the privileges associated with the anonymous-user account.\nFor additional information about user name and host name values in account names, see\nSection 8.2.4, “Specifying Account Names”.\nWarning\nIf you permit local anonymous users to connect to the MySQL server, you\nshould also grant privileges to all local users as 'user_name'@'localhost'.\nOtherwise, the anonymous user account for localhost in the mysql.user\nsystem table is used when named users try to log in to the MySQL server from\nthe local machine. For details, see Section 8.2.6, “Access Control, Stage 1:\nConnection Verification”.\nTo determine whether this issue applies to you, execute the following query,\nwhich lists any anonymous users:\nSELECT Host, User FROM mysql.user WHERE User='';\nTo avoid the problem just described, delete the local anonymous user account\nusing this statement:\nDROP USER ''@'localhost';\nPrivileges Supported by MySQL\nThe following tables summarize the permissible static and dynamic priv_type privilege types that\ncan be specified for the GRANT and REVOKE statements, and the levels at which each privilege can\nbe granted. For additional information about each privilege, see Section 8.2.2, “Privileges Provided\nby MySQL”. For information about the differences between static and dynamic privileges, see Static\nVersus Dynamic Privileges.\nTable 15.11 Permissible Static Privileges for GRANT and REVOKE\nPrivilege\nMeaning and Grantable Levels\nALL [PRIVILEGES]\nGrant all privileges at specified access level\nexcept GRANT OPTION and PROXY.\nALTER\nEnable use of ALTER TABLE. Levels: Global,\ndatabase, table.\nALTER ROUTINE\nEnable stored routines to be altered or dropped.\nLevels: Global, database, routine.\nCREATE\nEnable database and table creation. Levels:\nGlobal, database, table.\nCREATE ROLE\nEnable role creation. Level: Global.\nCREATE ROUTINE\nEnable stored routine creation. Levels: Global,\ndatabase.\nCREATE TABLESPACE\nEnable tablespaces and log file groups to be\ncreated, altered, or dropped. Level: Global.\nCREATE TEMPORARY TABLES\nEnable use of CREATE TEMPORARY TABLE.\nLevels: Global, database.\nCREATE USER\nEnable use of CREATE USER, DROP USER,\nRENAME USER, and REVOKE ALL PRIVILEGES.\nLevel: Global.\nCREATE VIEW\nEnable views to be created or altered. Levels:\nGlobal, database, table.\nDELETE\nEnable use of DELETE. Level: Global, database,\ntable.\nDROP\nEnable databases, tables, and views to be\ndropped. Levels: Global, database, table.\nDROP ROLE\nEnable roles to be dropped. Level: Global.\nEVENT\nEnable use of events for the Event Scheduler.\nLevels: Global, database.\nEXECUTE\nEnable the user to execute stored routines.\nLevels: Global, database, routine.\nFILE\nEnable the user to cause the server to read or\nwrite files. Level: Global.\nFLUSH_PRIVILEGES\nEnable the user to issue FLUSH PRIVILEGES\nstatements. Level: Global.\nGRANT OPTION\nEnable privileges to be granted to or removed\nfrom other accounts. Levels: Global, database,\ntable, routine, proxy.\nINDEX\nEnable indexes to be created or dropped. Levels:\nGlobal, database, table.\nINSERT\nEnable use of INSERT. Levels: Global, database,\ntable, column.\nPrivilege\nMeaning and Grantable Levels\nLOCK TABLES\nEnable use of LOCK TABLES on tables for which\nyou have the SELECT privilege. Levels: Global,\ndatabase.\nOPTIMIZE_LOCAL_TABLE\nEnable use of OPTIMIZE LOCAL TABLE or\nOPTIMIZE NO_WRITE_TO_BINLOG TABLE.\nLevels: Global, database, table.\nPROCESS\nEnable the user to see all processes with SHOW\nPROCESSLIST. Level: Global.\nPROXY\nEnable user proxying. Level: From user to user.\nREFERENCES\nEnable foreign key creation. Levels: Global,\ndatabase, table, column.\nRELOAD\nEnable use of FLUSH operations. Level: Global.\nREPLICATION CLIENT\nEnable the user to ask where source or replica\nservers are. Level: Global.\nREPLICATION SLAVE\nEnable replicas to read binary log events from the\nsource. Level: Global.\nSELECT\nEnable use of SELECT. Levels: Global, database,\ntable, column.\nSHOW DATABASES\nEnable SHOW DATABASES to show all databases.\nLevel: Global.\nSHOW VIEW\nEnable use of SHOW CREATE VIEW. Levels:\nGlobal, database, table.\nSHUTDOWN\nEnable use of mysqladmin shutdown. Level:\nGlobal.\nSUPER\nEnable use of other administrative operations\nsuch as CHANGE REPLICATION SOURCE TO,\nKILL, PURGE BINARY LOGS, SET GLOBAL, and\nmysqladmin debug command. Level: Global.\nTRIGGER\nEnable trigger operations. Levels: Global,\ndatabase, table.\nUPDATE\nEnable use of UPDATE. Levels: Global, database,\ntable, column.\nUSAGE\nSynonym for “no privileges”\nTable 15.12 Permissible Dynamic Privileges for GRANT and REVOKE\nPrivilege\nMeaning and Grantable Levels\nAPPLICATION_PASSWORD_ADMIN\nEnable dual password administration. Level:\nGlobal.\nAUDIT_ABORT_EXEMPT\nAllow queries blocked by audit log filter. Level:\nGlobal.\nAUDIT_ADMIN\nEnable audit log configuration. Level: Global.\nAUTHENTICATION_POLICY_ADMIN\nEnable authentication policy administration. Level:\nGlobal.\nBACKUP_ADMIN\nEnable backup administration. Level: Global.\nBINLOG_ADMIN\nEnable binary log control. Level: Global.\nBINLOG_ENCRYPTION_ADMIN\nEnable activation and deactivation of binary log\nencryption. Level: Global.\nPrivilege\nMeaning and Grantable Levels\nCLONE_ADMIN\nEnable clone administration. Level: Global.\nCONNECTION_ADMIN\nEnable connection limit/restriction control. Level:\nGlobal.\nENCRYPTION_KEY_ADMIN\nEnable InnoDB key rotation. Level: Global.\nFIREWALL_ADMIN\nEnable firewall rule administration, any user.\nLevel: Global.\nFIREWALL_EXEMPT\nExempt user from firewall restrictions. Level:\nGlobal.\nFIREWALL_USER\nEnable firewall rule administration, self. Level:\nGlobal.\nFLUSH_OPTIMIZER_COSTS\nEnable optimizer cost reloading. Level: Global.\nFLUSH_STATUS\nEnable status indicator flushing. Level: Global.\nFLUSH_TABLES\nEnable table flushing. Level: Global.\nFLUSH_USER_RESOURCES\nEnable user-resource flushing. Level: Global.\nGROUP_REPLICATION_ADMIN\nEnable Group Replication control. Level: Global.\nINNODB_REDO_LOG_ARCHIVE\nEnable redo log archiving administration. Level:\nGlobal.\nINNODB_REDO_LOG_ENABLE\nEnable or disable redo logging. Level: Global.\nNDB_STORED_USER\nEnable sharing of user or role between SQL\nnodes (NDB Cluster). Level: Global.\nPASSWORDLESS_USER_ADMIN\nEnable passwordless user account administration.\nLevel: Global.\nPERSIST_RO_VARIABLES_ADMIN\nEnable persisting read-only system variables.\nLevel: Global.\nREPLICATION_APPLIER\nAct as the PRIVILEGE_CHECKS_USER for a\nreplication channel. Level: Global.\nREPLICATION_SLAVE_ADMIN\nEnable regular replication control. Level: Global.\nRESOURCE_GROUP_ADMIN\nEnable resource group administration. Level:\nGlobal.\nRESOURCE_GROUP_USER\nEnable resource group administration. Level:\nGlobal.\nROLE_ADMIN\nEnable roles to be granted or revoked, use of\nWITH ADMIN OPTION. Level: Global.\nSESSION_VARIABLES_ADMIN\nEnable setting restricted session system variables.\nLevel: Global.\nSHOW_ROUTINE\nEnable access to stored routine definitions. Level:\nGlobal.\nSKIP_QUERY_REWRITE\nDo not rewrite queries executed by this user.\nLevel: Global.\nSYSTEM_USER\nDesignate account as system account. Level:\nGlobal.\nSYSTEM_VARIABLES_ADMIN\nEnable modifying or persisting global system\nvariables. Level: Global.\nTABLE_ENCRYPTION_ADMIN\nEnable overriding default encryption settings.\nLevel: Global.\nPrivilege\nMeaning and Grantable Levels\nTELEMETRY_LOG_ADMIN\nEnable telemetry log configuration for HeatWave\non AWS. Level: Global.\nTP_CONNECTION_ADMIN\nEnable thread pool connection administration.\nLevel: Global.\nVERSION_TOKEN_ADMIN\nEnable use of Version Tokens functions. Level:\nGlobal.\nXA_RECOVER_ADMIN\nEnable XA RECOVER execution. Level: Global.\nA trigger is associated with a table. To create or drop a trigger, you must have the TRIGGER privilege\nfor the table, not the trigger.\nIn GRANT statements, the ALL [PRIVILEGES] or PROXY privilege must be named by itself and cannot\nbe specified along with other privileges. ALL [PRIVILEGES] stands for all privileges available for the\nlevel at which privileges are to be granted except for the GRANT OPTION and PROXY privileges.\nMySQL account information is stored in the tables of the mysql system schema. For additional details,\nconsult Section 8.2, “Access Control and Account Management”, which discusses the mysql system\nschema and the access control system extensively.\nIf the grant tables hold privilege rows that contain mixed-case database or table names and the\nlower_case_table_names system variable is set to a nonzero value, REVOKE cannot be used to\nrevoke these privileges. It is necessary in such cases to manipulate the grant tables directly. (GRANT\ndoes not create such rows when lower_case_table_names is set, but such rows might have been\ncreated prior to setting that variable. The lower_case_table_names setting can only be configured\nat server startup.)\nPrivileges can be granted at several levels, depending on the syntax used for the ON clause. For\nREVOKE, the same ON syntax specifies which privileges to remove.\nFor the global, database, table, and routine levels, GRANT ALL assigns only the privileges that exist at\nthe level you are granting. For example, GRANT ALL ON db_name.* is a database-level statement,\nso it does not grant any global-only privileges such as FILE. Granting ALL does not assign the GRANT\nOPTION or PROXY privilege.\nThe object_type clause, if present, should be specified as TABLE, FUNCTION, or PROCEDURE when\nthe following object is a table, a stored function, or a stored procedure.\nThe privileges that a user holds for a database, table, column, or routine are formed additively as the\nlogical OR of the account privileges at each of the privilege levels, including the global level. It is not\npossible to deny a privilege granted at a higher level by absence of that privilege at a lower level. For\nexample, this statement grants the SELECT and INSERT privileges globally:\nGRANT SELECT, INSERT ON *.* TO u1;\nThe globally granted privileges apply to all databases, tables, and columns, even though not granted at\nany of those lower levels.\nIt is possible to deny explicitly a privilege granted at the global level by revoking it for particular\ndatabases, if the partial_revokes system variable is enabled:\nGRANT SELECT, INSERT, UPDATE ON *.* TO u1;\nREVOKE INSERT, UPDATE ON db1.* FROM u1;\nThe result of the preceding statements is that SELECT applies globally to all tables, whereas INSERT\nand UPDATE apply globally except to tables in db1. Account access to db1 is read only.\nDetails of the privilege-checking procedure are presented in Section 8.2.7, “Access Control, Stage 2:\nRequest Verification”.\nIf you are using table, column, or routine privileges for even one user, the server examines table,\ncolumn, and routine privileges for all users and this slows down MySQL a bit. Similarly, if you limit the\nnumber of queries, updates, or connections for any users, the server must monitor these values.\nMySQL enables you to grant privileges on databases or tables that do not exist. For tables, the\nprivileges to be granted must include the CREATE privilege. This behavior is by design, and is intended\nto enable the database administrator to prepare user accounts and privileges for databases or tables\nthat are to be created at a later time.\nImportant\nMySQL does not automatically revoke any privileges when you drop a database\nor table. However, if you drop a routine, any routine-level privileges granted for\nthat routine are revoked.\nGlobal Privileges\nGlobal privileges are administrative or apply to all databases on a given server. To assign global\nprivileges, use ON *.* syntax:\nGRANT ALL ON *.* TO 'someuser'@'somehost';\nGRANT SELECT, INSERT ON *.* TO 'someuser'@'somehost';\nThe CREATE TABLESPACE, CREATE USER, FILE, PROCESS, RELOAD, REPLICATION CLIENT,\nREPLICATION SLAVE, SHOW DATABASES, SHUTDOWN, and SUPER static privileges are administrative\nand can only be granted globally.\nDynamic privileges are all global and can only be granted globally.\nOther privileges can be granted globally or at more specific levels.\nThe effect of GRANT OPTION granted at the global level differs for static and dynamic privileges:\n• GRANT OPTION granted for any static global privilege applies to all static global privileges.\n• GRANT OPTION granted for any dynamic privilege applies only to that dynamic privilege.\nGRANT ALL at the global level grants all static global privileges and all currently registered dynamic\nprivileges. A dynamic privilege registered subsequent to execution of the GRANT statement is not\ngranted retroactively to any account.\nMySQL stores global privileges in the mysql.user system table.\nDatabase Privileges\nDatabase privileges apply to all objects in a given database. To assign database-level privileges, use\nON db_name.* syntax:\nGRANT ALL ON mydb.* TO 'someuser'@'somehost';\nGRANT SELECT, INSERT ON mydb.* TO 'someuser'@'somehost';\nIf you use ON * syntax (rather than ON *.*), privileges are assigned at the database level for the\ndefault database. An error occurs if there is no default database.\nThe CREATE, DROP, EVENT, GRANT OPTION, LOCK TABLES, and REFERENCES privileges can be\nspecified at the database level. Table or routine privileges also can be specified at the database level,\nin which case they apply to all tables or routines in the database.\nMySQL stores database privileges in the mysql.db system table.\nTable Privileges\nTable privileges apply to all columns in a given table. To assign table-level privileges, use ON\ndb_name.tbl_name syntax:\nGRANT ALL ON mydb.mytbl TO 'someuser'@'somehost';\nGRANT SELECT, INSERT ON mydb.mytbl TO 'someuser'@'somehost';\nIf you specify tbl_name rather than db_name.tbl_name, the statement applies to tbl_name in the\ndefault database. An error occurs if there is no default database.\nThe permissible priv_type values at the table level are ALTER, CREATE VIEW, CREATE, DELETE,\nDROP, GRANT OPTION, INDEX, INSERT, REFERENCES, SELECT, SHOW VIEW, TRIGGER, and UPDATE.\nTable-level privileges apply to base tables and views. They do not apply to tables created with\nCREATE TEMPORARY TABLE, even if the table names match. For information about TEMPORARY table\nprivileges, see Section 15.1.20.2, “CREATE TEMPORARY TABLE Statement”.\nMySQL stores table privileges in the mysql.tables_priv system table.\nColumn Privileges\nColumn privileges apply to single columns in a given table. Each privilege to be granted at the column\nlevel must be followed by the column or columns, enclosed within parentheses.\nGRANT SELECT (col1), INSERT (col1, col2) ON mydb.mytbl TO 'someuser'@'somehost';\nThe permissible priv_type values for a column (that is, when you use a column_list clause) are\nINSERT, REFERENCES, SELECT, and UPDATE.\nMySQL stores column privileges in the mysql.columns_priv system table.\nStored Routine Privileges\nThe ALTER ROUTINE, CREATE ROUTINE, EXECUTE, and GRANT OPTION privileges apply to stored\nroutines (procedures and functions). They can be granted at the global and database levels. Except for\nCREATE ROUTINE, these privileges can be granted at the routine level for individual routines.\nGRANT CREATE ROUTINE ON mydb.* TO 'someuser'@'somehost';\nGRANT EXECUTE ON PROCEDURE mydb.myproc TO 'someuser'@'somehost';\nThe permissible priv_type values at the routine level are ALTER ROUTINE, EXECUTE, and GRANT\nOPTION. CREATE ROUTINE is not a routine-level privilege because you must have the privilege at the\nglobal or database level to create a routine in the first place.\nMySQL stores routine-level privileges in the mysql.procs_priv system table.\nProxy User Privileges\nThe PROXY privilege enables one user to be a proxy for another. The proxy user impersonates or takes\nthe identity of the proxied user; that is, it assumes the privileges of the proxied user.\nGRANT PROXY ON 'localuser'@'localhost' TO 'externaluser'@'somehost';\nWhen PROXY is granted, it must be the only privilege named in the GRANT statement, and the only\npermitted WITH option is WITH GRANT OPTION.\nProxying requires that the proxy user authenticate through a plugin that returns the name of the proxied\nuser to the server when the proxy user connects, and that the proxy user have the PROXY privilege for\nthe proxied user. For details and examples, see Section 8.2.19, “Proxy Users”.\nMySQL stores proxy privileges in the mysql.proxies_priv system table.\nGranting Roles\nGRANT syntax without an ON clause grants roles rather than individual privileges. A role is a named\ncollection of privileges; see Section 8.2.10, “Using Roles”. For example:\nGRANT 'role1', 'role2' TO 'user1'@'localhost', 'user2'@'localhost';\nEach role to be granted must exist, as well as each user account or role to which it is to be granted.\nRoles cannot be granted to anonymous users.\nGranting a role does not automatically cause the role to be active. For information about role activation\nand inactivation, see Activating Roles.\nThese privileges are required to grant roles:\n• If you have the ROLE_ADMIN privilege (or the deprecated SUPER privilege), you can grant or revoke\nany role to users or roles.\n• If you were granted a role with a GRANT statement that includes the WITH ADMIN OPTION clause,\nyou become able to grant that role to other users or roles, or revoke it from other users or roles, as\nlong as the role is active at such time as you subsequently grant or revoke it. This includes the ability\nto use WITH ADMIN OPTION itself.\n• To grant a role that has the SYSTEM_USER privilege, you must have the SYSTEM_USER privilege.\nIt is possible to create circular references with GRANT. For example:\nCREATE USER 'u1', 'u2';\nCREATE ROLE 'r1', 'r2';\nGRANT 'u1' TO 'u1';   -- simple loop: u1 => u1\nGRANT 'r1' TO 'r1';   -- simple loop: r1 => r1\nGRANT 'r2' TO 'u2';\nGRANT 'u2' TO 'r2';   -- mixed user/role loop: u2 => r2 => u2\nCircular grant references are permitted but add no new privileges or roles to the grantee because a\nuser or role already has its privileges and roles.\nThe AS Clause and Privilege Restrictions\nGRANT can specify additional information about the privilege context to use for statement execution by\nusing an AS user [WITH ROLE] clause. This syntax is visible at the SQL level, although its primary\npurpose is to enable uniform replication across all nodes of grantor privilege restrictions imposed by\npartial revokes, by causing those restrictions to appear in the binary log. For information about partial\nrevokes, see Section 8.2.12, “Privilege Restriction Using Partial Revokes”.\nWhen the AS user clause is specified, statement execution takes into account any privilege\nrestrictions associated with the named user, including all roles specified by WITH ROLE, if present.\nThe result is that the privileges actually granted by the statement may be reduced relative to those\nspecified.\nThese conditions apply to the AS user clause:\n• AS has an effect only when the named user has privilege restrictions (which implies that the\npartial_revokes system variable is enabled).\n• If WITH ROLE is given, all roles named must be granted to the named user.\n• The named user should be a MySQL account specified as 'user_name'@'host_name',\nCURRENT_USER, or CURRENT_USER(). The current user may be named together with WITH ROLE\nfor the case that the executing user wants GRANT to execute with a set of roles applied that may\ndiffer from the roles active within the current session.\n• AS cannot be used to gain privileges not possessed by the user who executes the GRANT statement.\nThe executing user must have at least the privileges to be granted, but the AS clause can only\nrestrict the privileges granted, not escalate them.\n• With respect to the privileges to be granted, AS cannot specify a user/role combination that has more\nprivileges (fewer restrictions) than the user who executes the GRANT statement. The AS user/role\ncombination is permitted to have more privileges than the executing user, but only if the statement\ndoes not grant those additional privileges.\n• AS is supported only for granting global privileges (ON *.*).\n• AS is not supported for PROXY grants.\nThe following example illustrates the effect of the AS clause. Create a user u1 that has some global\nprivileges, as well as restrictions on those privileges:\nCREATE USER u1;\nGRANT SELECT, INSERT, UPDATE, DELETE ON *.* TO u1;\nREVOKE INSERT, UPDATE ON schema1.* FROM u1;\nREVOKE SELECT ON schema2.* FROM u1;\nAlso create a role r1 that lifts some of the privilege restrictions and grant the role to u1:\nCREATE ROLE r1;\nGRANT INSERT ON schema1.* TO r1;\nGRANT SELECT ON schema2.* TO r1;\nGRANT r1 TO u1;\nNow, using an account that has no privilege restrictions of its own, grant to multiple users the same\nset of global privileges, but each with different restrictions imposed by the AS clause, and check which\nprivileges are actually granted.\n• The GRANT statement here has no AS clause, so the privileges granted are exactly those specified:\nmysql> CREATE USER u2;\nmysql> GRANT SELECT, INSERT, UPDATE ON *.* TO u2;\nmysql> SHOW GRANTS FOR u2;\n+-------------------------------------------------+\n| Grants for u2@%                                 |\n+-------------------------------------------------+\n| GRANT SELECT, INSERT, UPDATE ON *.* TO `u2`@`%` |\n+-------------------------------------------------+\n• The GRANT statement here has an AS clause, so the privileges granted are those specified but with\nthe restrictions from u1 applied:\nmysql> CREATE USER u3;\nmysql> GRANT SELECT, INSERT, UPDATE ON *.* TO u3 AS u1;\nmysql> SHOW GRANTS FOR u3;\n+----------------------------------------------------+\n| Grants for u3@%                                    |\n+----------------------------------------------------+\n| GRANT SELECT, INSERT, UPDATE ON *.* TO `u3`@`%`    |\n| REVOKE INSERT, UPDATE ON `schema1`.* FROM `u3`@`%` |\n| REVOKE SELECT ON `schema2`.* FROM `u3`@`%`         |\n+----------------------------------------------------+\nAs mentioned previously, the AS clause can only add privilege restrictions; it cannot escalate\nprivileges. Thus, although u1 has the DELETE privilege, that is not included in the privileges granted\nbecause the statement does not specify granting DELETE.\n• The AS clause for the GRANT statement here makes the role r1 active for u1. That role lifts some of\nthe restrictions on u1. Consequently, the privileges granted have some restrictions, but not so many\nas for the previous GRANT statement:\nmysql> CREATE USER u4;\nmysql> GRANT SELECT, INSERT, UPDATE ON *.* TO u4 AS u1 WITH ROLE r1;\nmysql> SHOW GRANTS FOR u4;\n+-------------------------------------------------+\n| Grants for u4@%                                 |\n+-------------------------------------------------+\n| GRANT SELECT, INSERT, UPDATE ON *.* TO `u4`@`%` |\n| REVOKE UPDATE ON `schema1`.* FROM `u4`@`%`      |\n+-------------------------------------------------+\nIf a GRANT statement includes an AS user clause, privilege restrictions on the user who executes the\nstatement are ignored (rather than applied as they would be in the absence of an AS clause).\nOther Account Characteristics\nThe optional WITH clause is used to enable a user to grant privileges to other users. The WITH GRANT\nOPTION clause gives the user the ability to give to other users any privileges the user has at the\nspecified privilege level.\nTo grant the GRANT OPTION privilege to an account without otherwise changing its privileges, do this:\nGRANT USAGE ON *.* TO 'someuser'@'somehost' WITH GRANT OPTION;\nBe careful to whom you give the GRANT OPTION privilege because two users with different privileges\nmay be able to combine privileges!\nYou cannot grant another user a privilege which you yourself do not have; the GRANT OPTION\nprivilege enables you to assign only those privileges which you yourself possess.\nBe aware that when you grant a user the GRANT OPTION privilege at a particular privilege level, any\nprivileges the user possesses (or may be given in the future) at that level can also be granted by that\nuser to other users. Suppose that you grant a user the INSERT privilege on a database. If you then\ngrant the SELECT privilege on the database and specify WITH GRANT OPTION, that user can give to\nother users not only the SELECT privilege, but also INSERT. If you then grant the UPDATE privilege to\nthe user on the database, the user can grant INSERT, SELECT, and UPDATE.\nFor a nonadministrative user, you should not grant the ALTER privilege globally or for the mysql\nsystem schema. If you do that, the user can try to subvert the privilege system by renaming tables!\nFor additional information about security risks associated with particular privileges, see Section 8.2.2,\n“Privileges Provided by MySQL”.\nMySQL and Standard SQL Versions of GRANT\nThe biggest differences between the MySQL and standard SQL versions of GRANT are:\n• MySQL associates privileges with the combination of a host name and user name and not with only a\nuser name.\n• Standard SQL does not have global or database-level privileges, nor does it support all the privilege\ntypes that MySQL supports.\n• MySQL does not support the standard SQL UNDER privilege.\n• Standard SQL privileges are structured in a hierarchical manner. If you remove a user, all privileges\nthe user has been granted are revoked. This is also true in MySQL if you use DROP USER. See\nSection 15.7.1.5, “DROP USER Statement”.\n• In standard SQL, when you drop a table, all privileges for the table are revoked. In standard SQL,\nwhen you revoke a privilege, all privileges that were granted based on that privilege are also\nrevoked. In MySQL, privileges can be dropped with DROP USER or REVOKE statements.\n• In MySQL, it is possible to have the INSERT privilege for only some of the columns in a table. In this\ncase, you can still execute INSERT statements on the table, provided that you insert values only for\nthose columns for which you have the INSERT privilege. The omitted columns are set to their implicit\ndefault values if strict SQL mode is not enabled. In strict mode, the statement is rejected if any of the\nomitted columns have no default value. (Standard SQL requires you to have the INSERT privilege on\nall columns.) For information about strict SQL mode and implicit default values, see Section 7.1.11,\n“Server SQL Modes”, and Section 13.6, “Data Type Default Values”.\n15.7.1.7 RENAME USER Statement\nRENAME USER old_user TO new_user\n    [, old_user TO new_user] ...\nThe RENAME USER statement renames existing MySQL accounts. An error occurs for old accounts that\ndo not exist or new accounts that already exist.\nTo use RENAME USER, you must have the global CREATE USER privilege, or the UPDATE privilege\nfor the mysql system schema. When the read_only system variable is enabled, RENAME USER\nadditionally requires the CONNECTION_ADMIN privilege (or the deprecated SUPER privilege).\nRENAME USER fails with an error if any account to be renamed is named as the DEFINER attribute\nfor any stored object. (That is, the statement fails if renaming an account would cause a stored object\nto become orphaned.) To perform the operation anyway, you must have the SET_ANY_DEFINER or\nALLOW_NONEXISTENT_DEFINER privilege; in this case, the statement succeeds with a warning rather\nthan failing with an error. For additional information, including how to identify which objects name a\ngiven account as the DEFINER attribute, see Orphan Stored Objects.\nEach account name uses the format described in Section 8.2.4, “Specifying Account Names”. For\nexample:\nRENAME USER 'jeffrey'@'localhost' TO 'jeff'@'127.0.0.1';\nThe host name part of the account name, if omitted, defaults to '%'.\nRENAME USER causes the privileges held by the old user to be those held by the new user. However,\nRENAME USER does not automatically drop or invalidate databases or objects within them that the old\nuser created. This includes stored programs or views for which the DEFINER attribute names the old\nuser. Attempts to access such objects may produce an error if they execute in definer security context.\n(For information about security context, see Section 27.7, “Stored Object Access Control”.)\nThe privilege changes take effect as indicated in Section 8.2.13, “When Privilege Changes Take\nEffect”.\n15.7.1.8 REVOKE Statement\nREVOKE [IF EXISTS]\n    priv_type [(column_list)]\n      [, priv_type [(column_list)]] ...\n    ON [object_type] priv_level\n    FROM user_or_role [, user_or_role] ...\n    [IGNORE UNKNOWN USER]\nREVOKE [IF EXISTS] ALL [PRIVILEGES], GRANT OPTION\n    FROM user_or_role [, user_or_role] ...\n    [IGNORE UNKNOWN USER]\nREVOKE [IF EXISTS] PROXY ON user_or_role\n    FROM user_or_role [, user_or_role] ...\n    [IGNORE UNKNOWN USER]\nREVOKE [IF EXISTS] role [, role ] ...\n    FROM user_or_role [, user_or_role ] ...\n    [IGNORE UNKNOWN USER]\nuser_or_role: {\n    user (see Section 8.2.4, “Specifying Account Names”)\n  | role (see Section 8.2.5, “Specifying Role Names”\n}\nThe REVOKE statement enables system administrators to revoke privileges and roles, which can be\nrevoked from user accounts and roles.\nFor details on the levels at which privileges exist, the permissible priv_type, priv_level, and\nobject_type values, and the syntax for specifying users and passwords, see Section 15.7.1.6,\n“GRANT Statement”.\nFor information about roles, see Section 8.2.10, “Using Roles”.\nWhen the read_only system variable is enabled, REVOKE requires the CONNECTION_ADMIN or\nprivilege (or the deprecated SUPER privilege), in addition to any other required privileges described in\nthe following discussion.\nAll the forms shown for REVOKE support an IF EXISTS option as well as an IGNORE UNKNOWN USER\noption. With neither of these modifications, REVOKE either succeeds for all named users and roles,\nor rolls back and has no effect if any error occurs; the statement is written to the binary log only if it\nsucceeds for all named users and roles. The precise effects of IF EXISTS and IGNORE UNKNOWN\nUSER are discussed later in this section.\nEach account name uses the format described in Section 8.2.4, “Specifying Account Names”. Each\nrole name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nREVOKE INSERT ON *.* FROM 'jeffrey'@'localhost';\nREVOKE 'role1', 'role2' FROM 'user1'@'localhost', 'user2'@'localhost';\nREVOKE SELECT ON world.* FROM 'role3';\nThe host name part of the account or role name, if omitted, defaults to '%'.\nTo use the first REVOKE syntax, you must have the GRANT OPTION privilege, and you must have the\nprivileges that you are revoking.\nTo revoke all privileges from a user, use one of the following statements; either of these statements\ndrops all global, database, table, column, and routine privileges for the named users or roles:\nREVOKE ALL PRIVILEGES, GRANT OPTION\n  FROM user_or_role [, user_or_role] ...\nREVOKE ALL ON *.*\n  FROM user_or_role [, user_or_role] ...\nNeither of the two statements just shown revokes any roles.\nTo use these REVOKE statements, you must have the global CREATE USER privilege, or the UPDATE\nprivilege for the mysql system schema.\nThe syntax for which the REVOKE keyword is followed by one or more role names takes a FROM clause\nindicating one or more users or roles from which to revoke the roles.\nThe IF EXISTS and IGNORE UNKNOWN USER options have the effects listed here:\n• IF EXISTS means that, if the target user or role exists but no such privilege or role is found\nassigned to the target for any reason, a warning is raised, instead of an error; if no privilege or role\nnamed by the statement is assigned to the target, the statement has no (other) effect. Otherwise,\nREVOKE executes normally; if the user does not exist, the statement raises an error.\nExample: Given table t1 in database test, we execute the following statements, with the results\nshown.\nmysql> CREATE USER jerry@localhost;\nQuery OK, 0 rows affected (0.01 sec)\nmysql> REVOKE SELECT ON test.t1 FROM jerry@localhost;\nERROR 1147 (42000): There is no such grant defined for user 'jerry' on host\n'localhost' on table 't1' \nmysql> REVOKE IF EXISTS SELECT ON test.t1 FROM jerry@localhost;\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Warning\n   Code: 1147\nMessage: There is no such grant defined for user 'jerry' on host 'localhost' on\ntable 't1' \n1 row in set (0.00 sec)\nIF EXISTS causes an error to be demoted to a warning even if the privilege or role named does not\nexist, or the statement attempts to assign it at the wrong level.\n• If the REVOKE statement includes IGNORE UNKNOWN USER, the statement raises a warning for\nany target user or role named in the statement but not found; if no target named by the statement\nexists, REVOKE succeeds but has no actual effect. Otherwise, the statement executes as usual, and\nattempting to revoke a privilege not assigned to the target for whatever reason raises an error, as\nexpected.\nExample (continuing from the previous example):\nmysql> DROP USER IF EXISTS jerry@localhost;\nQuery OK, 0 rows affected (0.01 sec)\nmysql> REVOKE SELECT ON test.t1 FROM jerry@localhost;\nERROR 1147 (42000): There is no such grant defined for user 'jerry' on host\n'localhost' on table 't1' \nmysql> REVOKE SELECT ON test.t1 FROM jerry@localhost IGNORE UNKNOWN USER;\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Warning\n   Code: 3162\nMessage: Authorization ID jerry does not exist.\n1 row in set (0.00 sec)\n• The combination of IF EXISTS and IGNORE UNKNOWN USER means that REVOKE never raises\nan error for an unknown target user or role or for an unassigned or unavailable privilege, and the\nstatement as whole in such cases succeeds; roles or privileges are removed from existing target\nusers or roles whenever possible, and any revocation which is not possible raises a warning and\nexecutes as a NOOP.\nExample (again continuing from example in the previous item):\n# No such user, no such role\nmysql> DROP ROLE IF EXISTS Bogus;\nQuery OK, 0 rows affected, 1 warning (0.02 sec)\nmysql> SHOW WARNINGS;\n+-------+------+----------------------------------------------+\n| Level | Code | Message                                      |\n+-------+------+----------------------------------------------+\n| Note  | 3162 | Authorization ID 'Bogus'@'%' does not exist. |\n+-------+------+----------------------------------------------+\n1 row in set (0.00 sec)\n# This statement attempts to revoke a nonexistent role from a nonexistent user\nmysql> REVOKE Bogus ON test FROM jerry@localhost;\nERROR 3619 (HY000): Illegal privilege level specified for test\n# The same, with IF EXISTS\nmysql> REVOKE IF EXISTS Bogus ON test FROM jerry@localhost;\nERROR 1147 (42000): There is no such grant defined for user 'jerry' on host\n'localhost' on table 'test' \n# The same, with IGNORE UNKNOWN USER\nmysql> REVOKE Bogus ON test FROM jerry@localhost IGNORE UNKNOWN USER;\nERROR 3619 (HY000): Illegal privilege level specified for test\n# The same, with both options\nmysql> REVOKE IF EXISTS Bogus ON test FROM jerry@localhost IGNORE UNKNOWN USER;\nQuery OK, 0 rows affected, 2 warnings (0.01 sec)\nmysql> SHOW WARNINGS;\n+---------+------+--------------------------------------------+\n| Level   | Code | Message                                    |\n+---------+------+--------------------------------------------+\n| Warning | 3619 | Illegal privilege level specified for test |\n| Warning | 3162 | Authorization ID jerry does not exist.     |\n+---------+------+--------------------------------------------+\n2 rows in set (0.00 sec)\nRoles named in the mandatory_roles system variable value cannot be revoked. When IF EXISTS\nand IGNORE UNKNOWN USER are used together in a statement that tries to remove a mandatory\nprivilege, the error normally raised by attempting to do this is demoted to a warning; the statement\nexecutes successfully, but does not make any changes.\nA revoked role immediately affects any user account from which it was revoked, such that within any\ncurrent session for the account, its privileges are adjusted for the next statement executed.\nRevoking a role revokes the role itself, not the privileges that it represents. Suppose that an account\nis granted a role that includes a given privilege, and is also granted the privilege explicitly or another\nrole that includes the privilege. In this case, the account still possesses that privilege if the first role is\nrevoked. For example, if an account is granted two roles that each include SELECT, the account still\ncan select after either role is revoked.\nREVOKE ALL ON *.* (at the global level) revokes all granted static global privileges and all granted\ndynamic privileges.\nA revoked privilege that is granted but not known to the server is revoked with a warning. This\nsituation can occur for dynamic privileges. For example, a dynamic privilege can be granted while the\ncomponent that registers it is installed, but if that component is subsequently uninstalled, the privilege\nbecomes unregistered, although accounts that possess the privilege still possess it and it can be\nrevoked from them.\nREVOKE removes privileges, but does not remove rows from the mysql.user system table. To remove\na user account entirely, use DROP USER. See Section 15.7.1.5, “DROP USER Statement”.\nIf the grant tables hold privilege rows that contain mixed-case database or table names and the\nlower_case_table_names system variable is set to a nonzero value, REVOKE cannot be used to\nrevoke these privileges. It is necessary in such cases to manipulate the grant tables directly. (GRANT\ndoes not create such rows when lower_case_table_names is set, but such rows might have been\ncreated prior to setting the variable. The lower_case_table_names setting can only be configured\nwhen initializing the server.)\nWhen successfully executed from the mysql program, REVOKE responds with Query OK, 0\nrows affected. To determine what privileges remain after the operation, use SHOW GRANTS. See\nSection 15.7.7.22, “SHOW GRANTS Statement”.\n15.7.1.9 SET DEFAULT ROLE Statement\nSET DEFAULT ROLE\n    {NONE | ALL | role [, role ] ...}\n    TO user [, user ] ...\nFor each user named immediately after the TO keyword, this statement defines which roles become\nactive when the user connects to the server and authenticates, or when the user executes the SET\nROLE DEFAULT statement during a session.\nSET DEFAULT ROLE is alternative syntax for ALTER USER ... DEFAULT ROLE (see\nSection 15.7.1.1, “ALTER USER Statement”). However, ALTER USER can set the default for only a\nsingle user, whereas SET DEFAULT ROLE can set the default for multiple users. On the other hand,\nyou can specify CURRENT_USER as the user name for the ALTER USER statement, whereas you\ncannot for SET DEFAULT ROLE.\nSET DEFAULT ROLE requires these privileges:\n• Setting the default roles for another user requires the global CREATE USER privilege, or the UPDATE\nprivilege for the mysql.default_roles system table.\n• Setting the default roles for yourself requires no special privileges, as long as the roles you want as\nthe default have been granted to you.\nEach role name uses the format described in Section 8.2.5, “Specifying Role Names”. For example:\nSET DEFAULT ROLE 'admin', 'developer' TO 'joe'@'10.0.0.1';\nThe host name part of the role name, if omitted, defaults to '%'.\nThe clause following the DEFAULT ROLE keywords permits these values:\n• NONE: Set the default to NONE (no roles).\n• ALL: Set the default to all roles granted to the account.\n• role [, role ] ...: Set the default to the named roles, which must exist and be granted to the\naccount at the time SET DEFAULT ROLE is executed.\nNote\nSET DEFAULT ROLE and SET ROLE DEFAULT are different statements:\n• SET DEFAULT ROLE defines which account roles to activate by default within\naccount sessions.\n• SET ROLE DEFAULT sets the active roles within the current session to the\ncurrent account default roles.\nFor role usage examples, see Section 8.2.10, “Using Roles”.\n15.7.1.10 SET PASSWORD Statement\nSET PASSWORD [FOR user] auth_option\n    [REPLACE 'current_auth_string']\n    [RETAIN CURRENT PASSWORD]\nauth_option: {\n    = 'auth_string'\n  | TO RANDOM\n}\nThe SET PASSWORD statement assigns a password to a MySQL user account. The password may\nbe either explicitly specified in the statement or randomly generated by MySQL. The statement may\nalso include a password-verification clause that specifies the account current password to be replaced,\nand a clause that manages whether an account has a secondary password. 'auth_string' and\n'current_auth_string' each represent a cleartext (unencrypted) password.\nNote\nRather than using SET PASSWORD to assign passwords, ALTER USER is the\npreferred statement for account alterations, including assigning passwords. For\nexample:\nALTER USER user IDENTIFIED BY 'auth_string';\nNote\nClauses for random password generation, password verification, and secondary\npasswords apply only to accounts that use an authentication plugin that stores\ncredentials internally to MySQL. For accounts that use a plugin that performs\nauthentication against a credentials system that is external to MySQL, password\nmanagement must be handled externally against that system as well. For more\ninformation about internal credentials storage, see Section 8.2.15, “Password\nManagement”.\nThe REPLACE 'current_auth_string' clause performs password verification. If given:\n• REPLACE specifies the account current password to be replaced, as a cleartext (unencrypted) string.\n• The clause must be given if password changes for the account are required to specify the current\npassword, as verification that the user attempting to make the change actually knows the current\npassword.\n• The clause is optional if password changes for the account may but need not specify the current\npassword.\n• The statement fails if the clause is given but does not match the current password, even if the clause\nis optional.\n• REPLACE can be specified only when changing the account password for the current user.\nFor more information about password verification by specifying the current password, see\nSection 8.2.15, “Password Management”.\nThe RETAIN CURRENT PASSWORD clause implements dual-password capability. If given:\n• RETAIN CURRENT PASSWORD retains an account current password as its secondary password,\nreplacing any existing secondary password. The new password becomes the primary password, but\nclients can use the account to connect to the server using either the primary or secondary password.\n(Exception: If the new password specified by the SET PASSWORD statement is empty, the secondary\npassword becomes empty as well, even if RETAIN CURRENT PASSWORD is given.)\n• If you specify RETAIN CURRENT PASSWORD for an account that has an empty primary password,\nthe statement fails.\n• If an account has a secondary password and you change its primary password without specifying\nRETAIN CURRENT PASSWORD, the secondary password remains unchanged.\nFor more information about use of dual passwords, see Section 8.2.15, “Password Management”.\nSET PASSWORD permits these auth_option syntaxes:\n• = 'auth_string'\nAssigns the account the given literal password.\n• TO RANDOM\nAssigns the account a password randomly generated by MySQL. The statement also returns\nthe cleartext password in a result set to make it available to the user or application executing the\nstatement.\nFor details about the result set and characteristics of randomly generated passwords, see Random\nPassword Generation.\nImportant\nUnder some circumstances, SET PASSWORD may be recorded in server logs or\non the client side in a history file such as ~/.mysql_history, which means\nthat cleartext passwords may be read by anyone having read access to that\ninformation. For information about the conditions under which this occurs for the\nserver logs and how to control it, see Section 8.1.2.3, “Passwords and Logging”.\nFor similar information about client-side logging, see Section 6.5.1.3, “mysql\nClient Logging”.\nSET PASSWORD can be used with or without a FOR clause that explicitly names a user account:\n• With a FOR user clause, the statement sets the password for the named account, which must exist:\nSET PASSWORD FOR 'jeffrey'@'localhost' = 'auth_string';\n• With no FOR user clause, the statement sets the password for the current user:\nSET PASSWORD = 'auth_string';\nAny client who connects to the server using a nonanonymous account can change the password for\nthat account. (In particular, you can change your own password.) To see which account the server\nauthenticated you as, invoke the CURRENT_USER() function:\nSELECT CURRENT_USER();\nIf a FOR user clause is given, the account name uses the format described in Section 8.2.4,\n“Specifying Account Names”. For example:\nSET PASSWORD FOR 'bob'@'%.example.org' = 'auth_string';\nThe host name part of the account name, if omitted, defaults to '%'.\nSET PASSWORD interprets the string as a cleartext string, passes it to the authentication plugin\nassociated with the account, and stores the result returned by the plugin in the account row in the\nmysql.user system table. (The plugin is given the opportunity to hash the value into the encryption\nformat it expects. The plugin may use the value as specified, in which case no hashing occurs.)\nSetting the password for a named account (with a FOR clause) requires the UPDATE privilege for the\nmysql system schema. Setting the password for yourself (for a nonanonymous account with no FOR\nclause) requires no special privileges.\nStatements that modify secondary passwords require these privileges:\n• The APPLICATION_PASSWORD_ADMIN privilege is required to use the RETAIN CURRENT\nPASSWORD clause for SET PASSWORD statements that apply to your own account. The privilege\nis required to manipulate your own secondary password because most users require only one\npassword.\n• If an account is to be permitted to manipulate secondary passwords for all accounts, it should be\ngranted the CREATE USER privilege rather than APPLICATION_PASSWORD_ADMIN.\nWhen the read_only system variable is enabled, SET PASSWORD requires the CONNECTION_ADMIN\nprivilege (or the deprecated SUPER privilege), in addition to any other required privileges.\nFor additional information about setting passwords and authentication plugins, see Section 8.2.14,\n“Assigning Account Passwords”, and Section 8.2.17, “Pluggable Authentication”.\n15.7.1.11 SET ROLE Statement\nSET ROLE {\n    DEFAULT\n  | NONE\n  | ALL\n  | ALL EXCEPT role [, role ] ...\n  | role [, role ] ...\n}\nSET ROLE modifies the current user's effective privileges within the current session by specifying\nwhich of its granted roles are active. Granted roles include those granted explicitly to the user and\nthose named in the mandatory_roles system variable value.\nExamples:\nSET ROLE DEFAULT;\nSET ROLE 'role1', 'role2';\nSET ROLE ALL;\nSET ROLE ALL EXCEPT 'role1', 'role2';\nEach role name uses the format described in Section 8.2.5, “Specifying Role Names”. The host name\npart of the role name, if omitted, defaults to '%'.\nPrivileges that the user has been granted directly (rather than through roles) remain unaffected by\nchanges to the active roles.\nThe statement permits these role specifiers:\n• DEFAULT: Activate the account default roles. Default roles are those specified with SET DEFAULT\nROLE.\nWhen a user connects to the server and authenticates successfully, the server determines which\nroles to activate as the default roles. If the activate_all_roles_on_login system variable is\nenabled, the server activates all granted roles. Otherwise, the server executes SET ROLE DEFAULT\nimplicitly. The server activates only default roles that can be activated. The server writes warnings to\nits error log for default roles that cannot be activated, but the client receives no warnings.\nIf a user executes SET ROLE DEFAULT during a session, an error occurs if any default role cannot\nbe activated (for example, if it does not exist or is not granted to the user). In this case, the current\nactive roles are not changed.\n• NONE: Set the active roles to NONE (no active roles).\n• ALL: Activate all roles granted to the account.\n• ALL EXCEPT role [, role ] ...: Activate all roles granted to the account except those\nnamed. The named roles need not exist or be granted to the account.\n• role [, role ] ...: Activate the named roles, which must be granted to the account.\nNote\nSET DEFAULT ROLE and SET ROLE DEFAULT are different statements:\n• SET DEFAULT ROLE defines which account roles to activate by default within\naccount sessions.\n• SET ROLE DEFAULT sets the active roles within the current session to the\ncurrent account default roles.\nFor role usage examples, see Section 8.2.10, “Using Roles”.",
    "15.7.2 Resource Group Management Statements": "15.7.2 Resource Group Management Statements\nMySQL supports creation and management of resource groups, and permits assigning threads running\nwithin the server to particular groups so that threads execute according to the resources available to\nthe group. This section describes the SQL statements available for resource group management. For\ngeneral discussion of the resource group capability, see Section 7.1.16, “Resource Groups”.\n15.7.2.1 ALTER RESOURCE GROUP Statement\nALTER RESOURCE GROUP group_name\n    [VCPU [=] vcpu_spec [, vcpu_spec] ...]\n    [THREAD_PRIORITY [=] N]\n    [ENABLE|DISABLE [FORCE]]\nvcpu_spec: {N | M - N}\nALTER RESOURCE GROUP is used for resource group management (see Section 7.1.16, “Resource\nGroups”). This statement alters modifiable attributes of an existing resource group. It requires the\nRESOURCE_GROUP_ADMIN privilege.\ngroup_name identifies which resource group to alter. If the group does not exist, an error occurs.\nThe attributes for CPU affinity, priority, and whether the group is enabled can be modified with ALTER\nRESOURCE GROUP. These attributes are specified the same way as described for CREATE RESOURCE\nGROUP (see Section 15.7.2.2, “CREATE RESOURCE GROUP Statement”). Only the attributes\nspecified are altered. Unspecified attributes retain their current values.\nThe FORCE modifier is used with DISABLE. It determines statement behavior if the resource group has\nany threads assigned to it:\n• If FORCE is not given, existing threads in the group continue to run until they terminate, but new\nthreads cannot be assigned to the group.\n• If FORCE is given, existing threads in the group are moved to their respective default group (system\nthreads to SYS_default, user threads to USR_default).\nThe name and type attributes are set at group creation time and cannot be modified thereafter with\nALTER RESOURCE GROUP.\nExamples:\n• Alter a group CPU affinity:\nALTER RESOURCE GROUP rg1 VCPU = 0-63;\n• Alter a group thread priority:\nALTER RESOURCE GROUP rg2 THREAD_PRIORITY = 5;\n• Disable a group, moving any threads assigned to it to the default groups:\nALTER RESOURCE GROUP rg3 DISABLE FORCE;\nResource group management is local to the server on which it occurs. ALTER RESOURCE GROUP\nstatements are not written to the binary log and are not replicated.\n15.7.2.2 CREATE RESOURCE GROUP Statement\nCREATE RESOURCE GROUP group_name\n    TYPE = {SYSTEM|USER}\n    [VCPU [=] vcpu_spec [, vcpu_spec] ...]\n    [THREAD_PRIORITY [=] N]\n    [ENABLE|DISABLE]\nvcpu_spec: {N | M - N}\nCREATE RESOURCE GROUP is used for resource group management (see Section 7.1.16, “Resource\nGroups”). This statement creates a new resource group and assigns its initial attribute values. It\nrequires the RESOURCE_GROUP_ADMIN privilege.\ngroup_name identifies which resource group to create. If the group already exists, an error occurs.\nThe TYPE attribute is required. It should be SYSTEM for a system resource group, USER for a user\nresource group. The group type affects permitted THREAD_PRIORITY values, as described later.\nThe VCPU attribute indicates the CPU affinity; that is, the set of virtual CPUs the group can use:\n• If VCPU is not given, the resource group has no CPU affinity and can use all available CPUs.\n• If VCPU is given, the attribute value is a list of comma-separated CPU numbers or ranges:\n• Each number must be an integer in the range from 0 to the number of CPUs − 1. For example, on\na system with 64 CPUs, the number can range from 0 to 63.\n• A range is given in the form M − N, where M is less than or equal to N and both numbers are in the\nCPU range.\n• If a CPU number is an integer outside the permitted range or is not an integer, an error occurs.\nExample VCPU specifiers (these are all equivalent):\nVCPU = 0,1,2,3,9,10\nVCPU = 0-3,9-10\nVCPU = 9,10,0-3\nVCPU = 0,10,1,9,3,2\nThe THREAD_PRIORITY attribute indicates the priority for threads assigned to the group:\n• If THREAD_PRIORITY is not given, the default priority is 0.\n• If THREAD_PRIORITY is given, the attribute value must be in the range from -20 (highest priority)\nto 19 (lowest priority). The priority for system resource groups must be in the range from -20 to 0.\nThe priority for user resource groups must be in the range from 0 to 19. Use of different ranges for\nsystem and user groups ensures that user threads never have a higher priority than system threads.\nENABLE and DISABLE specify that the resource group is initially enabled or disabled. If neither is\nspecified, the group is enabled by default. A disabled group cannot have threads assigned to it.\nExamples:\n• Create an enabled user group that has a single CPU and the lowest priority:\nCREATE RESOURCE GROUP rg1\n  TYPE = USER\n  VCPU = 0\n  THREAD_PRIORITY = 19;\n• Create a disabled system group that has no CPU affinity (can use all CPUs) and the highest priority:\nCREATE RESOURCE GROUP rg2\n  TYPE = SYSTEM\n  THREAD_PRIORITY = -20\n  DISABLE;\nResource group management is local to the server on which it occurs. CREATE RESOURCE GROUP\nstatements are not written to the binary log and are not replicated.\n15.7.2.3 DROP RESOURCE GROUP Statement\nDROP RESOURCE GROUP group_name [FORCE]\nDROP RESOURCE GROUP is used for resource group management (see Section 7.1.16, “Resource\nGroups”). This statement drops a resource group. It requires the RESOURCE_GROUP_ADMIN privilege.\ngroup_name identifies which resource group to drop. If the group does not exist, an error occurs.\nThe FORCE modifier determines statement behavior if the resource group has any threads assigned to\nit:\n• If FORCE is not given and any threads are assigned to the group, an error occurs.\n• If FORCE is given, existing threads in the group are moved to their respective default group (system\nthreads to SYS_default, user threads to USR_default).\nExamples:\n• Drop a group, failing if the group contains any threads:\nDROP RESOURCE GROUP rg1;\n• Drop a group and move existing threads to the default groups:\nDROP RESOURCE GROUP rg2 FORCE;\nResource group management is local to the server on which it occurs. DROP RESOURCE GROUP\nstatements are not written to the binary log and are not replicated.\n15.7.2.4 SET RESOURCE GROUP Statement\nSET RESOURCE GROUP group_name\n    [FOR thread_id [, thread_id] ...]\nSET RESOURCE GROUP is used for resource group management (see Section 7.1.16,\n“Resource Groups”). This statement assigns threads to a resource group. It requires the\nRESOURCE_GROUP_ADMIN or RESOURCE_GROUP_USER privilege.\ngroup_name identifies which resource group to be assigned. Any thread_id values indicate threads\nto assign to the group. Thread IDs can be determined from the Performance Schema threads table. If\nthe resource group or any named thread ID does not exist, an error occurs.\nWith no FOR clause, the statement assigns the current thread for the session to the resource group.\nWith a FOR clause that names thread IDs, the statement assigns those threads to the resource group.\nFor attempts to assign a system thread to a user resource group or a user thread to a system resource\ngroup, a warning occurs.\nExamples:\n• Assign the current session thread to a group:\nSET RESOURCE GROUP rg1;\n• Assign the named threads to a group:\nSET RESOURCE GROUP rg2 FOR 14, 78, 4;\nResource group management is local to the server on which it occurs. SET RESOURCE GROUP\nstatements are not written to the binary log and are not replicated.\nAn alternative to SET RESOURCE GROUP is the RESOURCE_GROUP optimizer hint, which assigns\nindividual statements to a resource group. See Section 10.9.3, “Optimizer Hints”.",
    "15.7.3 Table Maintenance Statements": "15.7.3 Table Maintenance Statements\n15.7.3.1 ANALYZE TABLE Statement\nANALYZE [NO_WRITE_TO_BINLOG | LOCAL]\n    TABLE tbl_name [, tbl_name] ...\nANALYZE [NO_WRITE_TO_BINLOG | LOCAL]\n    TABLE tbl_name\n    UPDATE HISTOGRAM ON col_name [, col_name] ...\n        [WITH N BUCKETS]\n    [{MANUAL | AUTO} UPDATE]\nANALYZE [NO_WRITE_TO_BINLOG | LOCAL] \n    TABLE tbl_name\n    UPDATE HISTOGRAM ON col_name [USING DATA 'json_data']\nANALYZE [NO_WRITE_TO_BINLOG | LOCAL]\n    TABLE tbl_name\n    DROP HISTOGRAM ON col_name [, col_name] ...\nANALYZE TABLE generates table statistics:\n• ANALYZE TABLE without any HISTOGRAM clause performs a key distribution analysis and stores the\ndistribution for the named table or tables. For MyISAM tables, ANALYZE TABLE for key distribution\nanalysis is equivalent to using myisamchk --analyze.\n• ANALYZE TABLE with the UPDATE HISTOGRAM clause generates histogram statistics for the named\ntable columns and stores them in the data dictionary. Only one table name is permitted with this\nsyntax. MySQL also supports setting the histogram of a single column to a user-defined JSON value.\n• ANALYZE TABLE with the DROP HISTOGRAM clause removes histogram statistics for the named\ntable columns from the data dictionary. Only one table name is permitted for this syntax.\nThis statement requires SELECT and INSERT privileges for the table.\nANALYZE TABLE works with InnoDB, NDB, and MyISAM tables. It does not work with views.\nIf the innodb_read_only system variable is enabled, ANALYZE TABLE may fail because it\ncannot update statistics tables in the data dictionary, which use InnoDB. For ANALYZE TABLE\noperations that update the key distribution, failure may occur even if the operation updates the\ntable itself (for example, if it is a MyISAM table). To obtain the updated distribution statistics, set\ninformation_schema_stats_expiry=0.\nANALYZE TABLE is supported for partitioned tables, and you can use ALTER TABLE ... ANALYZE\nPARTITION to analyze one or more partitions; for more information, see Section 15.1.9, “ALTER\nTABLE Statement”, and Section 26.3.4, “Maintenance of Partitions”.\nDuring the analysis, the table is locked with a read lock for InnoDB and MyISAM.\nBy default, the server writes ANALYZE TABLE statements to the binary log so that they replicate to\nreplicas. To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias LOCAL.\n• ANALYZE TABLE Output\n• Key Distribution Analysis\n• Histogram Statistics Analysis\n• Other Considerations\nANALYZE TABLE Output\nANALYZE TABLE returns a result set with the columns shown in the following table.\nColumn\nValue\nTable\nThe table name\nOp\nanalyze or histogram\nMsg_type\nstatus, error, info, note, or warning\nMsg_text\nAn informational message\nKey Distribution Analysis\nANALYZE TABLE without either HISTOGRAM clause performs a key distribution analysis and stores the\ndistribution for the table or tables. Any existing histogram statistics remain unaffected.\nIf the table has not changed since the last key distribution analysis, the table is not analyzed again.\nMySQL uses the stored key distribution to decide the order in which tables should be joined for joins\non something other than a constant. In addition, key distributions can be used when deciding which\nindexes to use for a specific table within a query.\nTo check the stored key distribution cardinality, use the SHOW INDEX statement or the\nINFORMATION_SCHEMA STATISTICS table. See Section 15.7.7.23, “SHOW INDEX Statement”, and\nSection 28.3.34, “The INFORMATION_SCHEMA STATISTICS Table”.\nFor InnoDB tables, ANALYZE TABLE determines index cardinality by performing random dives on\neach of the index trees and updating index cardinality estimates accordingly. Because these are only\nestimates, repeated runs of ANALYZE TABLE could produce different numbers. This makes ANALYZE\nTABLE fast on InnoDB tables but not 100% accurate because it does not take all rows into account.\nYou can make the statistics collected by ANALYZE TABLE more precise and more stable by enabling\ninnodb_stats_persistent, as explained in Section 17.8.10.1, “Configuring Persistent Optimizer\nStatistics Parameters”. When innodb_stats_persistent is enabled, it is important to run ANALYZE\nTABLE after major changes to index column data, as statistics are not recalculated periodically (such\nas after a server restart).\nIf innodb_stats_persistent is enabled, you can change the number of random dives by modifying\nthe innodb_stats_persistent_sample_pages system variable. If innodb_stats_persistent\nis disabled, modify innodb_stats_transient_sample_pages instead.\nFor more information about key distribution analysis in InnoDB, see Section 17.8.10.1, “Configuring\nPersistent Optimizer Statistics Parameters”, and Section 17.8.10.3, “Estimating ANALYZE TABLE\nComplexity for InnoDB Tables”.\nMySQL uses index cardinality estimates in join optimization. If a join is not optimized in the right way,\ntry running ANALYZE TABLE. In the few cases that ANALYZE TABLE does not produce values good\nenough for your particular tables, you can use FORCE INDEX with your queries to force the use of a\nparticular index, or set the max_seeks_for_key system variable to ensure that MySQL prefers index\nlookups over table scans. See Section B.3.5, “Optimizer-Related Issues”.\nHistogram Statistics Analysis\nANALYZE TABLE with the HISTOGRAM clause enables management of histogram statistics for table\ncolumn values. For information about histogram statistics, see Section 10.9.6, “Optimizer Statistics”.\nThese histogram operations are available:\n• ANALYZE TABLE with an UPDATE HISTOGRAM clause generates histogram statistics for the named\ntable columns and stores them in the data dictionary. Only one table name is permitted for this\nsyntax.\nThe optional WITH N BUCKETS clause specifies the number of buckets for the histogram. The value\nof N must be an integer in the range from 1 to 1024. If this clause is omitted, the number of buckets is\n100.\nThe optional AUTO UPDATE clause enables automatic updates of histograms on the table. When\nenabled, an ANALYZE TABLE statement on this table automatically updates the histogram, using\nthe same number of buckets as last specified by WITH ... BUCKETS if this was previously set for\nthis table. In addition, when recalculating persistent statistics for the table (see Section 17.8.10.1,\n“Configuring Persistent Optimizer Statistics Parameters”), the InnoDB background statistics thread\nalso updates the histogram. MANUAL UPDATE disables automatic updates, and is the default setting\nif not specified.\n• ANALYZE TABLE with a DROP HISTOGRAM clause removes histogram statistics for the named table\ncolumns from the data dictionary. Only one table name is permitted for this syntax.\nStored histogram management statements affect only the named columns. Consider these statements:\nANALYZE TABLE t UPDATE HISTOGRAM ON c1, c2, c3 WITH 10 BUCKETS;\nANALYZE TABLE t UPDATE HISTOGRAM ON c1, c3 WITH 10 BUCKETS;\nANALYZE TABLE t DROP HISTOGRAM ON c2;\nThe first statement updates the histograms for columns c1, c2, and c3, replacing any existing\nhistograms for those columns. The second statement updates the histograms for c1 and c3, leaving\nthe c2 histogram unaffected. The third statement removes the histogram for c2, leaving those for c1\nand c3 unaffected.\nWhen sampling user data as part of building a histogram, not all values are read; this may lead to\nmissing some values considered important. In such cases, it might be useful to modify the histogram,\nor to set your own histogram explicitly based on your own criteria, such as the complete data set.\nANALYZE TABLE tbl_name UPDATE HISTOGRAM ON col_name USING DATA 'json_data'\nupdates a column of the histogram table with data supplied in the same JSON format used to display\nHISTOGRAM column values from the Information Schema COLUMN_STATISTICS table. Only one\ncolumn can be modified when updating the histogram with JSON data.\nWe can illustrate the use of USING DATA by first generating a histogram on column c1 of table t, like\nthis:\nmysql> ANALYZE TABLE t UPDATE HISTOGRAM ON c1;\n+-------+-----------+----------+-----------------------------------------------+\n| Table | Op        | Msg_type | Msg_text                                      |\n+-------+-----------+----------+-----------------------------------------------+\n| h.t   | histogram | status   | Histogram statistics created for column 'c1'. |\n+-------+-----------+----------+-----------------------------------------------+\n1 row in set (0.00 sec)\nWe can see the histogram generated in the COLUMN_STATISTICS table:\nmysql> TABLE information_schema.column_statistics\\G\n*************************** 1. row ***************************\nSCHEMA_NAME: h\n TABLE_NAME: t\nCOLUMN_NAME: c1\n  HISTOGRAM: {\"buckets\": [], \"data-type\": \"int\", \"auto-update\": false,\n\"null-values\": 0.0, \"collation-id\": 8, \"last-updated\": \"2024-03-26\n16:54:43.674995\", \"sampling-rate\": 1.0, \"histogram-type\": \"singleton\",\n\"number-of-buckets-specified\": 100}   \n1 row in set (0.00 sec)  \nNow we drop the histogram, and when we check COLUMN_STATISTICS, it is empty:\nmysql> ANALYZE TABLE t DROP HISTOGRAM ON c1;\n+-------+-----------+----------+-----------------------------------------------+\n| Table | Op        | Msg_type | Msg_text                                      |\n+-------+-----------+----------+-----------------------------------------------+\n| h.t   | histogram | status   | Histogram statistics removed for column 'c1'. |\n+-------+-----------+----------+-----------------------------------------------+\n1 row in set (0.01 sec)\nmysql> TABLE information_schema.column_statistics\\G\nEmpty set (0.00 sec)\nWe can restore the dropped histogram by inserting its JSON representation obtained previously from\nthe HISTOGRAM column of the COLUMN_STATISTICS table, and when we query that table again, we\ncan see that the histogram has been restored to its previous state:\nmysql> ANALYZE TABLE t UPDATE HISTOGRAM ON c1 \n    ->     USING DATA '{\"buckets\": [], \"data-type\": \"int\", \"auto-update\": false,\n    ->               \"null-values\": 0.0, \"collation-id\": 8, \"last-updated\": \"2024-03-26\n    ->               16:54:43.674995\", \"sampling-rate\": 1.0, \"histogram-type\": \"singleton\",\n    ->               \"number-of-buckets-specified\": 100}';   \n+-------+-----------+----------+-----------------------------------------------+\n| Table | Op        | Msg_type | Msg_text                                      |\n+-------+-----------+----------+-----------------------------------------------+\n| h.t   | histogram | status   | Histogram statistics created for column 'c1'. |\n+-------+-----------+----------+-----------------------------------------------+\nmysql> TABLE information_schema.column_statistics\\G\n*************************** 1. row ***************************\nSCHEMA_NAME: h\n TABLE_NAME: t\nCOLUMN_NAME: c1\n  HISTOGRAM: {\"buckets\": [], \"data-type\": \"int\", \"auto-update\": false,\n\"null-values\": 0.0, \"collation-id\": 8, \"last-updated\": \"2024-03-26\n16:54:43.674995\", \"sampling-rate\": 1.0, \"histogram-type\": \"singleton\",\n\"number-of-buckets-specified\": 100}      \nHistogram generation is not supported for encrypted tables (to avoid exposing data in the statistics) or\nTEMPORARY tables.\nHistogram generation applies to columns of all data types except geometry types (spatial data) and\nJSON.\nHistograms can be generated for stored and virtual generated columns.\nHistograms cannot be generated for columns that are covered by single-column unique indexes.\nHistogram management statements attempt to perform as much of the requested operation as\npossible, and report diagnostic messages for the remainder. For example, if an UPDATE HISTOGRAM\nstatement names multiple columns, but some of them do not exist or have an unsupported data type,\nhistograms are generated for the other columns, and messages are produced for the invalid columns.\nHistograms are affected by these DDL statements:\n• DROP TABLE removes histograms for columns in the dropped table.\n• DROP DATABASE removes histograms for any table in the dropped database because the statement\ndrops all tables in the database.\n• RENAME TABLE does not remove histograms. Instead, it renames histograms for the renamed table\nto be associated with the new table name.\n• ALTER TABLE statements that remove or modify a column remove histograms for that column.\n• ALTER TABLE ... CONVERT TO CHARACTER SET removes histograms for character columns\nbecause they are affected by the change of character set. Histograms for noncharacter columns\nremain unaffected.\nThe histogram_generation_max_mem_size system variable controls the maximum amount of\nmemory available for histogram generation. The global and session values may be set at runtime.\nChanging the global histogram_generation_max_mem_size value requires privileges sufficient to\nset global system variables. Changing the session histogram_generation_max_mem_size value\nrequires privileges sufficient to set restricted session system variables. See Section 7.1.9.1, “System\nVariable Privileges”.\nIf the estimated amount of data to be read into memory for histogram generation exceeds the limit\ndefined by histogram_generation_max_mem_size, MySQL samples the data rather than reading\nall of it into memory. Sampling is evenly distributed over the entire table. MySQL uses SYSTEM\nsampling, which is a page-level sampling method.\nThe sampling-rate value in the HISTOGRAM column of the Information Schema\nCOLUMN_STATISTICS table can be queried to determine the fraction of data that was sampled to\ncreate the histogram. The sampling-rate is a number between 0.0 and 1.0. A value of 1 means that\nall of the data was read (no sampling).\nThe following example demonstrates sampling. To ensure that the amount of data exceeds the\nhistogram_generation_max_mem_size limit for the purpose of the example, the limit is set to a\nlow value (2000000 bytes) prior to generating histogram statistics for the birth_date column of the\nemployees table.\nmysql> SET histogram_generation_max_mem_size = 2000000;\nmysql> USE employees;\nmysql> ANALYZE TABLE employees UPDATE HISTOGRAM ON birth_date WITH 16 BUCKETS\\G\n*************************** 1. row ***************************\n   Table: employees.employees\n      Op: histogram\nMsg_type: status\nMsg_text: Histogram statistics created for column 'birth_date'.\nmysql> SELECT HISTOGRAM->>'$.\"sampling-rate\"'\n       FROM INFORMATION_SCHEMA.COLUMN_STATISTICS\n       WHERE TABLE_NAME = \"employees\"\n       AND COLUMN_NAME = \"birth_date\";\n+---------------------------------+\n| HISTOGRAM->>'$.\"sampling-rate\"' |\n+---------------------------------+\n| 0.0491431208869665              |\n+---------------------------------+\nA sampling-rate value of 0.0491431208869665 means that approximately 4.9% of the data from\nthe birth_date column was read into memory for generating histogram statistics.\nThe InnoDB storage engine provides its own sampling implementation for data stored in InnoDB\ntables. The default sampling implementation used by MySQL when storage engines do not\nprovide their own requires a full table scan, which is costly for large tables. The InnoDB sampling\nimplementation improves sampling performance by avoiding full table scans.\nThe sampled_pages_read and sampled_pages_skipped INNODB_METRICS counters can be\nused to monitor sampling of InnoDB data pages. (For general INNODB_METRICS counter usage\ninformation, see Section 28.4.21, “The INFORMATION_SCHEMA INNODB_METRICS Table”.)\nThe following example demonstrates sampling counter usage, which requires enabling the counters\nprior to generating histogram statistics.\nmysql> SET GLOBAL innodb_monitor_enable = 'sampled%';\nmysql> USE employees;\nmysql> ANALYZE TABLE employees UPDATE HISTOGRAM ON birth_date WITH 16 BUCKETS\\G\n*************************** 1. row ***************************\n   Table: employees.employees\n      Op: histogram\nMsg_type: status\nMsg_text: Histogram statistics created for column 'birth_date'.\nmysql> USE INFORMATION_SCHEMA;\nmysql> SELECT NAME, COUNT FROM INNODB_METRICS WHERE NAME LIKE 'sampled%'\\G\n*************************** 1. row ***************************\n NAME: sampled_pages_read\nCOUNT: 43\n*************************** 2. row ***************************\n NAME: sampled_pages_skipped\nCOUNT: 843\nThis formula approximates a sampling rate based on the sampling counter data:\nsampling rate = sampled_page_read/(sampled_pages_read + sampled_pages_skipped)\nA sampling rate based on sampling counter data is roughly the same as the sampling-rate value in\nthe HISTOGRAM column of the Information Schema COLUMN_STATISTICS table.\nFor information about memory allocations performed for histogram generation, monitor the\nPerformance Schema memory/sql/histograms instrument. See Section 29.12.20.10, “Memory\nSummary Tables”.\nOther Considerations\nANALYZE TABLE clears table statistics from the Information Schema INNODB_TABLESTATS table and\nsets the STATS_INITIALIZED column to Uninitialized. Statistics are collected again the next\ntime the table is accessed.\n15.7.3.2 CHECK TABLE Statement\nCHECK TABLE tbl_name [, tbl_name] ... [option] ...\noption: {\n    FOR UPGRADE\n  | QUICK\n  | FAST\n  | MEDIUM\n  | EXTENDED\n  | CHANGED\n}\nCHECK TABLE checks a table or tables for errors. CHECK TABLE can also check views for problems,\nsuch as tables that are referenced in the view definition that no longer exist.\nTo check a table, you must have some privilege for it.\nCHECK TABLE works for InnoDB, MyISAM, ARCHIVE, and CSV tables.\nBefore running CHECK TABLE on InnoDB tables, see CHECK TABLE Usage Notes for InnoDB Tables.\nCHECK TABLE is supported for partitioned tables, and you can use ALTER TABLE ... CHECK\nPARTITION to check one or more partitions; for more information, see Section 15.1.9, “ALTER TABLE\nStatement”, and Section 26.3.4, “Maintenance of Partitions”.\nCHECK TABLE ignores virtual generated columns that are not indexed.\n• CHECK TABLE Output\n• Checking Version Compatibility\n• Checking Data Consistency\n• CHECK TABLE Usage Notes for InnoDB Tables\n• CHECK TABLE Usage Notes for MyISAM Tables\nCHECK TABLE Output\nCHECK TABLE returns a result set with the columns shown in the following table.\nColumn\nValue\nTable\nThe table name\nOp\nAlways check\nMsg_type\nstatus, error, info, note, or warning\nMsg_text\nAn informational message\nThe statement might produce many rows of information for each checked table. The last row has a\nMsg_type value of status and the Msg_text normally should be OK. Table is already up to\ndate means that the storage engine for the table indicated that there was no need to check the table.\nChecking Version Compatibility\nThe FOR UPGRADE option checks whether the named tables are compatible with the current version\nof MySQL. With FOR UPGRADE, the server checks each table to determine whether there have been\nany incompatible changes in any of the table's data types or indexes since the table was created. If not,\nthe check succeeds. Otherwise, if there is a possible incompatibility, the server runs a full check on the\ntable (which might take some time).\nIncompatibilities might occur because the storage format for a data type has changed or because its\nsort order has changed. Our aim is to avoid these changes, but occasionally they are necessary to\ncorrect problems that would be worse than an incompatibility between releases.\nFOR UPGRADE discovers these incompatibilities:\n• The indexing order for end-space in TEXT columns for InnoDB and MyISAM tables changed\nbetween MySQL 4.1 and 5.0.\n• The storage method of the new DECIMAL data type changed between MySQL 5.0.3 and 5.0.5.\n• Changes are sometimes made to character sets or collations that require table indexes to be rebuilt.\nFor details about such changes, see Section 3.5, “Changes in MySQL 9.1”. For information about\nrebuilding tables, see Section 3.14, “Rebuilding or Repairing Tables or Indexes”.\n• MySQL 9.1 does not support the 2-digit YEAR(2) data type permitted in older versions of MySQL.\nFor tables containing YEAR(2) columns, CHECK TABLE recommends REPAIR TABLE, which\nconverts 2-digit YEAR(2) columns to 4-digit YEAR columns.\n• Trigger creation time is maintained.\n• A table is reported as needing a rebuild if it contains old temporal columns in pre-5.6.4 format (TIME,\nDATETIME, and TIMESTAMP columns without support for fractional seconds precision). This helps\nthe MySQL upgrade procedure detect and upgrade tables containing old temporal columns.\n• Warnings are issued for tables that use nonnative partitioning because nonnative partitioning is\nremoved in MySQL 9.1. See Chapter 26, Partitioning.\nChecking Data Consistency\nThe following table shows the other check options that can be given. These options are passed to the\nstorage engine, which may use or ignore them.\nType\nMeaning\nQUICK\nDo not scan the rows to check for incorrect links.\nApplies to InnoDB and MyISAM tables and views.\nFAST\nCheck only tables that have not been closed\nproperly. Ignored for InnoDB; applies only to\nMyISAM tables and views.\nCHANGED\nCheck only tables that have been changed since\nthe last check or that have not been closed\nproperly. Ignored for InnoDB; applies only to\nMyISAM tables and views.\nMEDIUM\nScan rows to verify that deleted links are valid.\nThis also calculates a key checksum for the rows\nand verifies this with a calculated checksum for\nType\nMeaning\nthe keys. Ignored for InnoDB; applies only to\nMyISAM tables and views.\nEXTENDED\nDo a full key lookup for all keys for each row. This\nensures that the table is 100% consistent, but\ntakes a long time. Ignored for InnoDB; applies\nonly to MyISAM tables and views.\nYou can combine check options, as in the following example that does a quick check on the table to\ndetermine whether it was closed properly:\nCHECK TABLE test_table FAST QUICK;\nNote\nIf CHECK TABLE finds no problems with a table that is marked as “corrupted” or\n“not closed properly”, CHECK TABLE may remove the mark.\nIf a table is corrupted, the problem is most likely in the indexes and not in the data part. All of the\npreceding check types check the indexes thoroughly and should thus find most errors.\nTo check a table that you assume is okay, use no check options or the QUICK option. The latter should\nbe used when you are in a hurry and can take the very small risk that QUICK does not find an error in\nthe data file. (In most cases, under normal usage, MySQL should find any error in the data file. If this\nhappens, the table is marked as “corrupted” and cannot be used until it is repaired.)\nFAST and CHANGED are mostly intended to be used from a script (for example, to be executed from\ncron) to check tables periodically. In most cases, FAST is to be preferred over CHANGED. (The only\ncase when it is not preferred is when you suspect that you have found a bug in the MyISAM code.)\nEXTENDED is to be used only after you have run a normal check but still get errors from a table\nwhen MySQL tries to update a row or find a row by key. This is very unlikely if a normal check has\nsucceeded.\nUse of CHECK TABLE ... EXTENDED might influence execution plans generated by the query\noptimizer.\nSome problems reported by CHECK TABLE cannot be corrected automatically:\n• Found row where the auto_increment column has the value 0.\nThis means that you have a row in the table where the AUTO_INCREMENT index column contains the\nvalue 0. (It is possible to create a row where the AUTO_INCREMENT column is 0 by explicitly setting\nthe column to 0 with an UPDATE statement.)\nThis is not an error in itself, but could cause trouble if you decide to dump the table and restore it\nor do an ALTER TABLE on the table. In this case, the AUTO_INCREMENT column changes value\naccording to the rules of AUTO_INCREMENT columns, which could cause problems such as a\nduplicate-key error.\nTo get rid of the warning, execute an UPDATE statement to set the column to some value other than\n0.\nCHECK TABLE Usage Notes for InnoDB Tables\nThe following notes apply to InnoDB tables:\n• If CHECK TABLE encounters a corrupt page, the server exits to prevent error propagation (Bug\n#10132). If the corruption occurs in a secondary index but table data is readable, running CHECK\nTABLE can still cause a server exit.\n• If CHECK TABLE encounters a corrupted DB_TRX_ID or DB_ROLL_PTR field in a clustered index,\nCHECK TABLE can cause InnoDB to access an invalid undo log record, resulting in an MVCC-\nrelated server exit.\n• If CHECK TABLE encounters errors in InnoDB tables or indexes, it reports an error, and usually\nmarks the index and sometimes marks the table as corrupted, preventing further use of the index or\ntable. Such errors include an incorrect number of entries in a secondary index or incorrect links.\n• If CHECK TABLE finds an incorrect number of entries in a secondary index, it reports an error but\ndoes not cause a server exit or prevent access to the file.\n• CHECK TABLE surveys the index page structure, then surveys each key entry. It does not validate\nthe key pointer to a clustered record or follow the path for BLOB pointers.\n• When an InnoDB table is stored in its own .ibd file, the first 3 pages of the .ibd file contain\nheader information rather than table or index data. The CHECK TABLE statement does not detect\ninconsistencies that affect only the header data. To verify the entire contents of an InnoDB .ibd file,\nuse the innochecksum command.\n• When running CHECK TABLE on large InnoDB tables, other threads may be blocked during CHECK\nTABLE execution. To avoid timeouts, the semaphore wait threshold (600 seconds) is extended by\n2 hours (7200 seconds) for CHECK TABLE operations. If InnoDB detects semaphore waits of 240\nseconds or more, it starts printing InnoDB monitor output to the error log. If a lock request extends\nbeyond the semaphore wait threshold, InnoDB aborts the process. To avoid the possibility of a\nsemaphore wait timeout entirely, run CHECK TABLE QUICK instead of CHECK TABLE.\n• CHECK TABLE functionality for InnoDB SPATIAL indexes includes an R-tree validity check and a\ncheck to ensure that the R-tree row count matches the clustered index.\n• CHECK TABLE supports secondary indexes on virtual generated columns, which are supported by\nInnoDB.\n• InnoDB supports parallel clustered index reads, which can improve CHECK TABLE performance.\nInnoDB reads the clustered index twice during a CHECK TABLE operation. The second read can be\nperformed in parallel. The innodb_parallel_read_threads session variable must be set to a\nvalue greater than 1 for parallel clustered index reads to occur. The actual number of threads used\nto perform a parallel clustered index read is determined by the innodb_parallel_read_threads\nsetting or the number of index subtrees to scan, whichever is smaller.\nCHECK TABLE Usage Notes for MyISAM Tables\nThe following notes apply to MyISAM tables:\n• CHECK TABLE updates key statistics for MyISAM tables.\n• If CHECK TABLE output does not return OK or Table is already up to date, you should\nnormally run a repair of the table. See Section 9.6, “MyISAM Table Maintenance and Crash\nRecovery”.\n• If none of the CHECK TABLE options QUICK, MEDIUM, or EXTENDED are specified, the default check\ntype for dynamic-format MyISAM tables is MEDIUM. This has the same result as running myisamchk\n--medium-check tbl_name on the table. The default check type also is MEDIUM for static-format\nMyISAM tables, unless CHANGED or FAST is specified. In that case, the default is QUICK. The row\nscan is skipped for CHANGED and FAST because the rows are very seldom corrupted.\n15.7.3.3 CHECKSUM TABLE Statement\nCHECKSUM TABLE tbl_name [, tbl_name] ... [QUICK | EXTENDED]\nCHECKSUM TABLE reports a checksum for the contents of a table. You can use this statement to verify\nthat the contents are the same before and after a backup, rollback, or other operation that is intended\nto put the data back to a known state.\nThis statement requires the SELECT privilege for the table.\nThis statement is not supported for views. If you run CHECKSUM TABLE against a view, the Checksum\nvalue is always NULL, and a warning is returned.\nFor a nonexistent table, CHECKSUM TABLE returns NULL and generates a warning.\nDuring the checksum operation, the table is locked with a read lock for InnoDB and MyISAM.\nPerformance Considerations\nBy default, the entire table is read row by row and the checksum is calculated. For large tables, this\ncould take a long time, thus you would only perform this operation occasionally. This row-by-row\ncalculation is what you get with the EXTENDED clause, with InnoDB and all other storage engines other\nthan MyISAM, and with MyISAM tables not created with the CHECKSUM=1 clause.\nFor MyISAM tables created with the CHECKSUM=1 clause, CHECKSUM TABLE or CHECKSUM\nTABLE ... QUICK returns the “live” table checksum that can be returned very fast. If the table\ndoes not meet all these conditions, the QUICK method returns NULL. The QUICK method is not\nsupported with InnoDB tables. See Section 15.1.20, “CREATE TABLE Statement” for the syntax of the\nCHECKSUM clause.\nThe checksum value depends on the table row format. If the row format changes, the checksum\nalso changes. For example, the storage format for temporal types such as TIME, DATETIME, and\nTIMESTAMP changed in MySQL 5.6 prior to MySQL 5.6.5, so if a 5.5 table is upgraded to MySQL 5.6,\nthe checksum value may change.\nImportant\nIf the checksums for two tables are different, then it is almost certain that the\ntables are different in some way. However, because the hashing function used\nby CHECKSUM TABLE is not guaranteed to be collision-free, there is a slight\nchance that two tables which are not identical can produce the same checksum.\n15.7.3.4 OPTIMIZE TABLE Statement\nOPTIMIZE [NO_WRITE_TO_BINLOG | LOCAL]\n    TABLE tbl_name [, tbl_name] ...\nOPTIMIZE TABLE reorganizes the physical storage of table data and associated index data, to reduce\nstorage space and improve I/O efficiency when accessing the table. The exact changes made to each\ntable depend on the storage engine used by that table.\nUse OPTIMIZE TABLE in these cases, depending on the type of table:\n• After doing substantial insert, update, or delete operations on an InnoDB table that has its own\n.ibd file because it was created with the innodb_file_per_table option enabled. The table and\nindexes are reorganized, and disk space can be reclaimed for use by the operating system.\n• After doing substantial insert, update, or delete operations on columns that\nare part of a FULLTEXT index in an InnoDB table. Set the configuration option\ninnodb_optimize_fulltext_only=1 first. To keep the index maintenance period to a\nreasonable time, set the innodb_ft_num_word_optimize option to specify how many words to\nupdate in the search index, and run a sequence of OPTIMIZE TABLE statements until the search\nindex is fully updated.\n• After deleting a large part of a MyISAM or ARCHIVE table, or making many changes to a MyISAM or\nARCHIVE table with variable-length rows (tables that have VARCHAR, VARBINARY, BLOB, or TEXT\ncolumns). Deleted rows are maintained in a linked list and subsequent INSERT operations reuse\nold row positions. You can use OPTIMIZE TABLE to reclaim the unused space and to defragment\nthe data file. After extensive changes to a table, this statement may also improve performance of\nstatements that use the table, sometimes significantly.\nThis statement requires SELECT and INSERT privileges for the table.\nOPTIMIZE TABLE works for InnoDB, MyISAM, and ARCHIVE tables. OPTIMIZE TABLE is also\nsupported for dynamic columns of in-memory NDB tables. It does not work for fixed-width columns\nof in-memory tables, nor does it work for Disk Data tables. The performance of OPTIMIZE on NDB\nCluster tables can be tuned using --ndb-optimization-delay, which controls the length of\ntime to wait between processing batches of rows by OPTIMIZE TABLE. For more information, see\nSection 25.2.7.11, “Previous NDB Cluster Issues Resolved in NDB Cluster 9.1”.\nFor NDB Cluster tables, OPTIMIZE TABLE can be interrupted by (for example) killing the SQL thread\nperforming the OPTIMIZE operation.\nBy default, OPTIMIZE TABLE does not work for tables created using any other storage engine and\nreturns a result indicating this lack of support. You can make OPTIMIZE TABLE work for other storage\nengines by starting mysqld with the --skip-new option. In this case, OPTIMIZE TABLE is just\nmapped to ALTER TABLE.\nThis statement does not work with views.\nOPTIMIZE TABLE is supported for partitioned tables. For information about using this statement with\npartitioned tables and table partitions, see Section 26.3.4, “Maintenance of Partitions”.\nBy default, the server writes OPTIMIZE TABLE statements to the binary log so that they replicate to\nreplicas. To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias LOCAL.\nYou must have the OPTIMIZE_LOCAL_TABLE privilege to use this option.\n• OPTIMIZE TABLE Output\n• InnoDB Details\n• MyISAM Details\n• Other Considerations\nOPTIMIZE TABLE Output\nOPTIMIZE TABLE returns a result set with the columns shown in the following table.\nColumn\nValue\nTable\nThe table name\nOp\nAlways optimize\nMsg_type\nstatus, error, info, note, or warning\nMsg_text\nAn informational message\nOPTIMIZE TABLE table catches and throws any errors that occur while copying table statistics from\nthe old file to the newly created file. For example. if the user ID of the owner of the .MYD or .MYI file\nis different from the user ID of the mysqld process, OPTIMIZE TABLE generates a \"cannot change\nownership of the file\" error unless mysqld is started by the root user.\nInnoDB Details\nFor InnoDB tables, OPTIMIZE TABLE is mapped to ALTER TABLE ... FORCE, which rebuilds the\ntable to update index statistics and free unused space in the clustered index. This is displayed in the\noutput of OPTIMIZE TABLE when you run it on an InnoDB table, as shown here:\nmysql> OPTIMIZE TABLE foo;\n+----------+----------+----------+-------------------------------------------------------------------+\n| Table    | Op       | Msg_type | Msg_text                                                          |\n+----------+----------+----------+-------------------------------------------------------------------+\n| test.foo | optimize | note     | Table does not support optimize, doing recreate + analyze instead |\n| test.foo | optimize | status   | OK                                                                |\n+----------+----------+----------+-------------------------------------------------------------------+\nOPTIMIZE TABLE uses online DDL for regular and partitioned InnoDB tables, which reduces\ndowntime for concurrent DML operations. The table rebuild triggered by OPTIMIZE TABLE is\ncompleted in place. An exclusive table lock is only taken briefly during the prepare phase and the\ncommit phase of the operation. During the prepare phase, metadata is updated and an intermediate\ntable is created. During the commit phase, table metadata changes are committed.\nOPTIMIZE TABLE rebuilds the table using the table copy method under the following conditions:\n• When the old_alter_table system variable is enabled.\n• When the server is started with the --skip-new option.\nOPTIMIZE TABLE using online DDL is not supported for InnoDB tables that contain FULLTEXT\nindexes. The table copy method is used instead.\nInnoDB stores data using a page-allocation method and does not suffer from fragmentation in the\nsame way that legacy storage engines (such as MyISAM) do. When considering whether or not to run\noptimize, consider the workload of transactions that your server is expected to process:\n• Some level of fragmentation is expected. InnoDB only fills pages 93% full, to leave room for updates\nwithout having to split pages.\n• Delete operations might leave gaps that leave pages less filled than desired, which could make it\nworthwhile to optimize the table.\n• Updates to rows usually rewrite the data within the same page, depending on the data type and\nrow format, when sufficient space is available. See Section 17.9.1.5, “How Compression Works for\nInnoDB Tables” and Section 17.10, “InnoDB Row Formats”.\n• High-concurrency workloads might leave gaps in indexes over time, as InnoDB retains multiple\nversions of the same data due through its MVCC mechanism. See Section 17.3, “InnoDB Multi-\nVersioning”.\nMyISAM Details\nFor MyISAM tables, OPTIMIZE TABLE works as follows:\n1. If the table has deleted or split rows, repair the table.\n2. If the index pages are not sorted, sort them.\n3. If the table's statistics are not up to date (and the repair could not be accomplished by sorting the\nindex), update them.\nOther Considerations\nOPTIMIZE TABLE is performed online for regular and partitioned InnoDB tables. Otherwise, MySQL\nlocks the table during the time OPTIMIZE TABLE is running.\nOPTIMIZE TABLE does not sort R-tree indexes, such as spatial indexes on POINT columns. (Bug\n#23578)\n15.7.3.5 REPAIR TABLE Statement\nREPAIR [NO_WRITE_TO_BINLOG | LOCAL]\n    TABLE tbl_name [, tbl_name] ...\n    [QUICK] [EXTENDED] [USE_FRM]\nREPAIR TABLE repairs a possibly corrupted table, for certain storage engines only.\nThis statement requires SELECT and INSERT privileges for the table.\nAlthough normally you should never have to run REPAIR TABLE, if disaster strikes, this statement is\nvery likely to get back all your data from a MyISAM table. If your tables become corrupted often, try to\nfind the reason for it, to eliminate the need to use REPAIR TABLE. See Section B.3.3.3, “What to Do If\nMySQL Keeps Crashing”, and Section 18.2.4, “MyISAM Table Problems”.\nREPAIR TABLE checks the table to see whether an upgrade is required. If so, it performs the upgrade,\nfollowing the same rules as CHECK TABLE ... FOR UPGRADE. See Section 15.7.3.2, “CHECK\nTABLE Statement”, for more information.\nImportant\n• Make a backup of a table before performing a table repair operation; under\nsome circumstances the operation might cause data loss. Possible causes\ninclude but are not limited to file system errors. See Chapter 9, Backup and\nRecovery.\n• If the server exits during a REPAIR TABLE operation, it is essential after\nrestarting it that you immediately execute another REPAIR TABLE statement\nfor the table before performing any other operations on it. In the worst case,\nyou might have a new clean index file without information about the data file,\nand then the next operation you perform could overwrite the data file. This\nis an unlikely but possible scenario that underscores the value of making a\nbackup first.\n• In the event that a table on the source becomes corrupted and you run\nREPAIR TABLE on it, any resulting changes to the original table are not\npropagated to replicas.\n• REPAIR TABLE Storage Engine and Partitioning Support\n• REPAIR TABLE Options\n• REPAIR TABLE Output\n• Table Repair Considerations\nREPAIR TABLE Storage Engine and Partitioning Support\nREPAIR TABLE works for MyISAM, ARCHIVE, and CSV tables. For MyISAM tables, it has the same\neffect as myisamchk --recover tbl_name by default. This statement does not work with views.\nREPAIR TABLE is supported for partitioned tables. However, the USE_FRM option cannot be used with\nthis statement on a partitioned table.\nYou can use ALTER TABLE ... REPAIR PARTITION to repair one or more partitions; for more\ninformation, see Section 15.1.9, “ALTER TABLE Statement”, and Section 26.3.4, “Maintenance of\nPartitions”.\nREPAIR TABLE Options\n• NO_WRITE_TO_BINLOG or LOCAL\nBy default, the server writes REPAIR TABLE statements to the binary log so that they replicate to\nreplicas. To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias\nLOCAL.\n• QUICK\nIf you use the QUICK option, REPAIR TABLE tries to repair only the index file, and not the data file.\nThis type of repair is like that done by myisamchk --recover --quick.\n• EXTENDED\nIf you use the EXTENDED option, MySQL creates the index row by row instead of creating one index\nat a time with sorting. This type of repair is like that done by myisamchk --safe-recover.\n• USE_FRM\nThe USE_FRM option is available for use if the .MYI index file is missing or if its header is corrupted.\nThis option tells MySQL not to trust the information in the .MYI file header and to re-create it using\ninformation from the data dictionary. This kind of repair cannot be done with myisamchk.\nCaution\nUse the USE_FRM option only if you cannot use regular REPAIR modes.\nTelling the server to ignore the .MYI file makes important table metadata\nstored in the .MYI unavailable to the repair process, which can have\ndeleterious consequences:\n• The current AUTO_INCREMENT value is lost.\n• The link to deleted records in the table is lost, which means that free space\nfor deleted records remains unoccupied thereafter.\n• The .MYI header indicates whether the table is compressed. If the server\nignores this information, it cannot tell that a table is compressed and repair\ncan cause change or loss of table contents. This means that USE_FRM\nshould not be used with compressed tables. That should not be necessary,\nanyway: Compressed tables are read only, so they should not become\ncorrupt.\nIf you use USE_FRM for a table that was created by a different version of the\nMySQL server than the one you are currently running, REPAIR TABLE does\nnot attempt to repair the table. In this case, the result set returned by REPAIR\nTABLE contains a line with a Msg_type value of error and a Msg_text\nvalue of Failed repairing incompatible .FRM file.\nIf USE_FRM is used, REPAIR TABLE does not check the table to see whether\nan upgrade is required.\nREPAIR TABLE Output\nREPAIR TABLE returns a result set with the columns shown in the following table.\nColumn\nValue\nTable\nThe table name\nOp\nAlways repair\nMsg_type\nstatus, error, info, note, or warning\nMsg_text\nAn informational message\nThe REPAIR TABLE statement might produce many rows of information for each repaired table. The\nlast row has a Msg_type value of status and Msg_test normally should be OK. For a MyISAM table,\nif you do not get OK, you should try repairing it with myisamchk --safe-recover. (REPAIR TABLE\ndoes not implement all the options of myisamchk. With myisamchk --safe-recover, you can also\nuse options that REPAIR TABLE does not support, such as --max-record-length.)\nREPAIR TABLE table catches and throws any errors that occur while copying table statistics from the\nold corrupted file to the newly created file. For example. if the user ID of the owner of the .MYD or .MYI\nfile is different from the user ID of the mysqld process, REPAIR TABLE generates a \"cannot change\nownership of the file\" error unless mysqld is started by the root user.\nTable Repair Considerations\nYou may be able to increase REPAIR TABLE performance by setting certain system variables. See\nSection 10.6.3, “Optimizing REPAIR TABLE Statements”.\nREPAIR TABLE upgrades a table if it contains old temporal columns in pre-5.6.4 format; namely, the\nTIME, DATETIME, and TIMESTAMP columns that lacked support for fractional seconds precision.",
    "15.7.4 Component, Plugin, and Loadable Function Statements": "15.7.4 Component, Plugin, and Loadable Function Statements\n15.7.4.1 CREATE FUNCTION Statement for Loadable Functions\nCREATE [AGGREGATE] FUNCTION [IF NOT EXISTS] function_name\n    RETURNS {STRING|INTEGER|REAL|DECIMAL}\n    SONAME shared_library_name\nThis statement loads the loadable function named function_name. (CREATE FUNCTION is also used\nto created stored functions; see Section 15.1.17, “CREATE PROCEDURE and CREATE FUNCTION\nStatements”.)\nA loadable function is a way to extend MySQL with a new function that works like a native (built-in)\nMySQL function such as ABS() or CONCAT(). See Adding a Loadable Function.\nfunction_name is the name that should be used in SQL statements to invoke the function. The\nRETURNS clause indicates the type of the function's return value. DECIMAL is a legal value after\nRETURNS, but currently DECIMAL functions return string values and should be written like STRING\nfunctions.\nIF NOT EXISTS prevents an error from occurring if there already exists a loadable function with the\nsame name. It does not prevent an error from occurring if there already exists a built-in function having\nthe same name. IF NOT EXISTS is also supported for CREATE FUNCTION statements. See Function\nName Resolution.\nThe AGGREGATE keyword, if given, signifies that the function is an aggregate (group) function. An\naggregate function works exactly like a native MySQL aggregate function such as SUM() or COUNT().\nshared_library_name is the base name of the shared library file containing the code that\nimplements the function. The file must be located in the plugin directory. This directory is given by the\nvalue of the plugin_dir system variable. For more information, see Section 7.7.1, “Installing and\nUninstalling Loadable Functions”.\nCREATE FUNCTION requires the INSERT privilege for the mysql system schema because it adds a\nrow to the mysql.func system table to register the function.\nCREATE FUNCTION also adds the function to the Performance Schema user_defined_functions\ntable that provides runtime information about installed loadable functions. See Section 29.12.22.11,\n“The user_defined_functions Table”.\nNote\nLike the mysql.func system table, the Performance Schema\nuser_defined_functions table lists loadable functions installed\nusing CREATE FUNCTION. Unlike the mysql.func table, the\nuser_defined_functions table also lists loadable functions installed\nautomatically by server components or plugins. This difference makes\nuser_defined_functions preferable to mysql.func for checking which\nloadable functions are installed.\nDuring the normal startup sequence, the server loads functions registered in the mysql.func table. If\nthe server is started with the --skip-grant-tables option, functions registered in the table are not\nloaded and are unavailable.\nNote\nTo upgrade the shared library associated with a loadable function, issue a DROP\nFUNCTION statement, upgrade the shared library, and then issue a CREATE\nFUNCTION statement. If you upgrade the shared library first and then use DROP\nFUNCTION, the server may unexpectedly shut down.\n15.7.4.2 DROP FUNCTION Statement for Loadable Functions\nDROP FUNCTION [IF EXISTS] function_name\nThis statement drops the loadable function named function_name. (DROP FUNCTION is also\nused to drop stored functions; see Section 15.1.29, “DROP PROCEDURE and DROP FUNCTION\nStatements”.)\nDROP FUNCTION is the complement of CREATE FUNCTION. It requires the DELETE privilege for the\nmysql system schema because it removes the row from the mysql.func system table that registers\nthe function.\nDROP FUNCTION also removes the function from the Performance Schema\nuser_defined_functions table that provides runtime information about installed loadable\nfunctions. See Section 29.12.22.11, “The user_defined_functions Table”.\nDuring the normal startup sequence, the server loads functions registered in the mysql.func table.\nBecause DROP FUNCTION removes the mysql.func row for the dropped function, the server does\nnot load the function during subsequent restarts.\nDROP FUNCTION cannot be used to drop a loadable function that is installed automatically by\ncomponents or plugins rather than by using CREATE FUNCTION. Such a function is also dropped\nautomatically, when the component or plugin that installed it is uninstalled.\nNote\nTo upgrade the shared library associated with a loadable function, issue a DROP\nFUNCTION statement, upgrade the shared library, and then issue a CREATE\nFUNCTION statement. If you upgrade the shared library first and then use DROP\nFUNCTION, the server may unexpectedly shut down.\n15.7.4.3 INSTALL COMPONENT Statement\nINSTALL COMPONENT component_name  [, component_name ...\n     [SET variable = expr [, variable = expr] ...] \n  \n  variable: {\n    {GLOBAL | @@GLOBAL.} [component_prefix.]system_var_name\n  | {PERSIST | @@PERSIST.} [component_prefix.]system_var_name\n}\nThis statement installs one or more components, which become active immediately. A component\nprovides services that are available to the server and other components; see Section 7.5, “MySQL\nComponents”. INSTALL COMPONENT requires the INSERT privilege for the mysql.component\nsystem table because it adds a row to that table to register the component.\nExample:\nINSTALL COMPONENT 'file://component1', 'file://component2';\nA component is named using a URN that begins with file:// and indicates the base name of the\nlibrary file that implements the component, located in the directory named by the plugin_dir system\nvariable. Component names do not include any platform-dependent file name suffix such as .so or\n.dll. (These naming details are subject to change because component name interpretation is itself\nperformed by a service and the component infrastructure makes it possible to replace the default\nservice implementation with alternative implementations.)\nINSTALL COMPONENT permits setting the values of component system variables when you install\none or more components. The SET clause enables you to specify variable values precisely when\nthey are needed, without the inconvenience or limitations associated with other forms of assignment.\nSpecifically, you can also set component variables with these alternatives:\n• At server startup using options on the command line or in an option file, but doing so involves a\nserver restart. The values do not take effect until you install the component. You can specify an\ninvalid variable name for a component on the command line without triggering an error.\n• Dynamically while the server is running by means of the SET statement, which enables you to\nmodify operation of the server without having to stop and restart it. Setting a read-only variable is not\npermitted.\nThe optional SET clause applies a value, or values, only to the component specified in the INSTALL\nCOMPONENT statement, rather than to all subsequent installations of that component. SET GLOBAL|\nPERSIST works for all types of variables, including read-only variables, without having to restart the\nserver. A component system variable that you set using INSTALL COMPONENT takes precedence over\nany conflicting value coming from the command line or an option file.\nExample:\nINSTALL COMPONENT 'file://component1', 'file://component2' \n    SET GLOBAL component1.var1 = 12 + 3, PERSIST component2.var2 = 'strings';\nOmitting PERSIST or GLOBAL is equivalent to specifying GLOBAL.\nSpecifying PERSIST for any variable in SET silently executes SET PERSIST_ONLY immediately after\nINSTALL COMPONENT loads the components, but before updating the mysql.component table.\nIf SET PERSIST_ONLY fails, then the server unloads all of the previously loaded new components\nwithout persisting anything to mysql.component.\nThe SET clause accepts only valid variable names of the component being installed and emits an\nerror message for all invalid names. Subqueries, stored functions, and aggregate functions are not\npermitted as part of the value expression. If you install a single component, it is not necessary to prefix\nthe variable name with the component name.\nNote\nWhile specifying a variable value using the SET clause is similar to that of\nthe command line—it is available immediately at variable registration—\nthere is a distinct difference in how the SET clause handles invalid numerical\nvalues for boolean variables. For example, if you set a boolean variable to 11\n(component1.boolvar = 11), you see the following behavior:\n• SET clause yields true\n• Command line yields false (11 is neither ON nor 1)\nIf any error occurs, the statement fails and has no effect. For example, this happens if a component\nname is erroneous, a named component does not exist or is already installed, or component\ninitialization fails.\nA loader service handles component loading, which includes adding installed components to the\nmysql.component system table that serves as a registry. For subsequent server restarts, any\ncomponents listed in mysql.component are loaded by the loader service during the startup\nsequence. This occurs even if the server is started with the --skip-grant-tables option.\nIf a component depends on services not present in the registry and you attempt to install the\ncomponent without also installing the component or components that provide the services on which it\ndepends, an error occurs:\nERROR 3527 (HY000): Cannot satisfy dependency for service 'component_a'\nrequired by component 'component_b'.\nTo avoid this problem, either install all components in the same statement, or install the dependent\ncomponent after installing any components on which it depends.\nNote\nFor keyring components, do not use INSTALL COMPONENT. Instead, configure\nkeyring component loading using a manifest file. See Section 8.4.4.2, “Keyring\nComponent Installation”.\n15.7.4.4 INSTALL PLUGIN Statement\nINSTALL PLUGIN plugin_name SONAME 'shared_library_name'\nThis statement installs a server plugin. It requires the INSERT privilege for the mysql.plugin system\ntable because it adds a row to that table to register the plugin.\nplugin_name is the name of the plugin as defined in the plugin descriptor structure contained\nin the library file (see Plugin Data Structures). Plugin names are not case-sensitive. For maximal\ncompatibility, plugin names should be limited to ASCII letters, digits, and underscore because they are\nused in C source files, shell command lines, M4 and Bourne shell scripts, and SQL environments.\nshared_library_name is the name of the shared library that contains the plugin code. The\nname includes the file name extension (for example, libmyplugin.so, libmyplugin.dll, or\nlibmyplugin.dylib).\nThe shared library must be located in the plugin directory (the directory named by the plugin_dir\nsystem variable). The library must be in the plugin directory itself, not in a subdirectory. By default,\nplugin_dir is the plugin directory under the directory named by the pkglibdir configuration\nvariable, but it can be changed by setting the value of plugin_dir at server startup. For example, set\nits value in a my.cnf file:\n[mysqld]\nplugin_dir=/path/to/plugin/directory\nIf the value of plugin_dir is a relative path name, it is taken to be relative to the MySQL base\ndirectory (the value of the basedir system variable).\nINSTALL PLUGIN loads and initializes the plugin code to make the plugin available for use. A plugin is\ninitialized by executing its initialization function, which handles any setup that the plugin must perform\nbefore it can be used. When the server shuts down, it executes the deinitialization function for each\nplugin that is loaded so that the plugin has a chance to perform any final cleanup.\nINSTALL PLUGIN also registers the plugin by adding a line that indicates the plugin name and library\nfile name to the mysql.plugin system table. During the normal startup sequence, the server loads\nand initializes plugins registered in mysql.plugin. This means that a plugin is installed with INSTALL\nPLUGIN only once, not every time the server starts. If the server is started with the --skip-grant-\ntables option, plugins registered in the mysql.plugin table are not loaded and are unavailable.\nA plugin library can contain multiple plugins. For each of them to be installed, use a separate INSTALL\nPLUGIN statement. Each statement names a different plugin, but all of them specify the same library\nname.\nINSTALL PLUGIN causes the server to read option (my.cnf) files just as during server startup. This\nenables the plugin to pick up any relevant options from those files. It is possible to add plugin options\nto an option file even before loading a plugin (if the loose prefix is used). It is also possible to uninstall\na plugin, edit my.cnf, and install the plugin again. Restarting the plugin this way enables it to the new\noption values without a server restart.\nFor options that control individual plugin loading at server startup, see Section 7.6.1, “Installing and\nUninstalling Plugins”. If you need to load plugins for a single server startup when the --skip-grant-\ntables option is given (which tells the server not to read system tables), use the --plugin-load\noption. See Section 7.1.7, “Server Command Options”.\nTo remove a plugin, use the UNINSTALL PLUGIN statement.\nFor additional information about plugin loading, see Section 7.6.1, “Installing and Uninstalling Plugins”.\nTo see what plugins are installed, use the SHOW PLUGINS statement or query the\nINFORMATION_SCHEMA the PLUGINS table.\nIf you recompile a plugin library and need to reinstall it, you can use either of the following methods:\n• Use UNINSTALL PLUGIN to uninstall all plugins in the library, install the new plugin library file\nin the plugin directory, and then use INSTALL PLUGIN to install all plugins in the library. This\nprocedure has the advantage that it can be used without stopping the server. However, if the plugin\nlibrary contains many plugins, you must issue many INSTALL PLUGIN and UNINSTALL PLUGIN\nstatements.\n• Stop the server, install the new plugin library file in the plugin directory, and restart the server.\n15.7.4.5 UNINSTALL COMPONENT Statement\nUNINSTALL COMPONENT component_name [, component_name ] ...\nThis statement deactivates and uninstalls one or more components. A component provides services\nthat are available to the server and other components; see Section 7.5, “MySQL Components”.\nUNINSTALL COMPONENT is the complement of INSTALL COMPONENT. It requires the DELETE\nprivilege for the mysql.component system table because it removes the row from that table that\nregisters the component. UNINSTALL COMPONENT does not undo persisted variables, including the\nvariables persisted using INSTALL COMPONENT ... SET PERSIST.\nExample:\nUNINSTALL COMPONENT 'file://component1', 'file://component2';\nFor information about component naming, see Section 15.7.4.3, “INSTALL COMPONENT Statement”.\nIf any error occurs, the statement fails and has no effect. For example, this happens if a component\nname is erroneous, a named component is not installed, or cannot be uninstalled because other\ninstalled components depend on it.\nA loader service handles component unloading, which includes removing uninstalled components from\nthe mysql.component system table that serves as a registry. As a result, unloaded components are\nnot loaded during the startup sequence for subsequent server restarts.\nNote\nThis statement has no effect for keyring components, which are loaded using\na manifest file and cannot be uninstalled. See Section 8.4.4.2, “Keyring\nComponent Installation”.\n15.7.4.6 UNINSTALL PLUGIN Statement\nUNINSTALL PLUGIN plugin_name\nThis statement removes an installed server plugin. UNINSTALL PLUGIN is the complement of\nINSTALL PLUGIN. It requires the DELETE privilege for the mysql.plugin system table because it\nremoves the row from that table that registers the plugin.\nplugin_name must be the name of some plugin that is listed in the mysql.plugin table. The\nserver executes the plugin's deinitialization function and removes the row for the plugin from the\nmysql.plugin system table, so that subsequent server restarts do not load and initialize the plugin.\nUNINSTALL PLUGIN does not remove the plugin's shared library file.\nYou cannot uninstall a plugin if any table that uses it is open.\nPlugin removal has implications for the use of associated tables. For example, if a full-text parser plugin\nis associated with a FULLTEXT index on the table, uninstalling the plugin makes the table unusable.\nAny attempt to access the table results in an error. The table cannot even be opened, so you cannot\ndrop an index for which the plugin is used. This means that uninstalling a plugin is something to do with\ncare unless you do not care about the table contents. If you are uninstalling a plugin with no intention of\nreinstalling it later and you care about the table contents, you should dump the table with mysqldump\nand remove the WITH PARSER clause from the dumped CREATE TABLE statement so that you can\nreload the table later. If you do not care about the table, DROP TABLE can be used even if any plugins\nassociated with the table are missing.\nFor additional information about plugin loading, see Section 7.6.1, “Installing and Uninstalling Plugins”.",
    "15.7.5 CLONE Statement": "15.7.5 CLONE Statement\nCLONE clone_action\nclone_action: {\n    LOCAL DATA DIRECTORY [=] 'clone_dir';\n  | INSTANCE FROM 'user'@'host':port\n    IDENTIFIED BY 'password'\n    [DATA DIRECTORY [=] 'clone_dir']\n    [REQUIRE [NO] SSL]\n}\nThe CLONE statement is used to clone data locally or from a remote MySQL server instance. To use\nCLONE syntax, the clone plugin must be installed. See Section 7.6.7, “The Clone Plugin”.\nCLONE LOCAL DATA DIRECTORY syntax clones data from the local MySQL data directory to a\ndirectory on the same server or node where the MySQL server instance runs. The 'clone_dir'\ndirectory is the full path of the local directory that data is cloned to. An absolute path is required.\nThe specified directory must not exist, but the specified path must be an existent path. The MySQL\nserver requires the necessary write access to create the specified directory. For more information, see\nSection 7.6.7.2, “Cloning Data Locally”.\nCLONE INSTANCE syntax clones data from a remote MySQL server instance (the donor) and transfers\nit to the MySQL instance where the cloning operation was initiated (the recipient).\n• user is the clone user on the donor MySQL server instance.\n• host is the hostname address of the donor MySQL server instance. Internet Protocol version 6\n(IPv6) address format is not supported. An alias to the IPv6 address can be used instead. An IPv4\naddress can be used as is.\n• port is the port number of the donor MySQL server instance. (The X Protocol port specified by\nmysqlx_port is not supported. Connecting to the donor MySQL server instance through MySQL\nRouter is also not supported.)\n• IDENTIFIED BY 'password' specifies the password of the clone user on the donor MySQL\nserver instance.\n• DATA DIRECTORY [=] 'clone_dir' is an optional clause used to specify a directory on the\nrecipient for the data you are cloning. Use this option if you do not want to remove existing data\nin the recipient data directory. An absolute path is required, and the directory must not exist. The\nMySQL server must have the necessary write access to create the directory.\nWhen the optional DATA DIRECTORY [=] 'clone_dir' clause is not used, a cloning operation\nremoves existing data in the recipient data directory, replaces it with the cloned data, and\nautomatically restarts the server afterward.\n• [REQUIRE [NO] SSL] explicitly specifies whether an encrypted connection is to be used or not\nwhen transferring cloned data over the network. An error is returned if the explicit specification\ncannot be satisfied. If an SSL clause is not specified, clone attempts to establish an encrypted\nconnection by default, falling back to an insecure connection if the secure connection attempt fails.\nA secure connection is required when cloning encrypted data regardless of whether this clause is\nspecified. For more information, see Configuring an Encrypted Connection for Cloning.\nFor additional information about cloning data from a remote MySQL server instance, see\nSection 7.6.7.3, “Cloning Remote Data”.",
    "15.7.6 SET Statements": "15.7.6 SET Statements\nThe SET statement has several forms. Descriptions for those forms that are not associated with a\nspecific server capability appear in subsections of this section:\n• SET var_name = value enables you to assign values to variables that affect the operation of the\nserver or clients. See Section 15.7.6.1, “SET Syntax for Variable Assignment”.\n• SET CHARACTER SET and SET NAMES assign values to character set and collation variables\nassociated with the current connection to the server. See Section 15.7.6.2, “SET CHARACTER SET\nStatement”, and Section 15.7.6.3, “SET NAMES Statement”.\nDescriptions for the other forms appear elsewhere, grouped with other statements related to the\ncapability they help implement:\n• SET DEFAULT ROLE and SET ROLE set the default role and current role for user accounts. See\nSection 15.7.1.9, “SET DEFAULT ROLE Statement”, and Section 15.7.1.11, “SET ROLE Statement”.\n• SET PASSWORD assigns account passwords. See Section 15.7.1.10, “SET PASSWORD Statement”.\n• SET RESOURCE GROUP assigns threads to a resource group. See Section 15.7.2.4, “SET\nRESOURCE GROUP Statement”.\n• SET TRANSACTION ISOLATION LEVEL sets the isolation level for transaction processing. See\nSection 15.3.7, “SET TRANSACTION Statement”.\n15.7.6.1 SET Syntax for Variable Assignment\nSET variable = expr [, variable = expr] ...\nvariable: {\n    user_var_name\n  | param_name\n  | local_var_name\n  | {GLOBAL | @@GLOBAL.} system_var_name\n  | {PERSIST | @@PERSIST.} system_var_name\n  | {PERSIST_ONLY | @@PERSIST_ONLY.} system_var_name\n  | [SESSION | @@SESSION. | @@] system_var_name\n}\nSET syntax for variable assignment enables you to assign values to different types of variables that\naffect the operation of the server or clients:\n• User-defined variables. See Section 11.4, “User-Defined Variables”.\n• Stored procedure and function parameters, and stored program local variables. See Section 15.6.4,\n“Variables in Stored Programs”.\n• System variables. See Section 7.1.8, “Server System Variables”. System variables also can be set at\nserver startup, as described in Section 7.1.9, “Using System Variables”.\nA SET statement that assigns variable values is not written to the binary log, so in replication scenarios\nit affects only the host on which you execute it. To affect all replication hosts, execute the statement on\neach host.\nThe following sections describe SET syntax for setting variables. They use the = assignment operator,\nbut the := assignment operator is also permitted for this purpose.\n• User-Defined Variable Assignment\n• Parameter and Local Variable Assignment\n• System Variable Assignment\n• SET Error Handling\n• Multiple Variable Assignment\n• System Variable References in Expressions\nUser-Defined Variable Assignment\nUser-defined variables are created locally within a session and exist only within the context of that\nsession; see Section 11.4, “User-Defined Variables”.\nA user-defined variable is written as @var_name and is assigned an expression value as follows:\nSET @var_name = expr;\nExamples:\nSET @name = 43;\nSET @total_tax = (SELECT SUM(tax) FROM taxable_transactions);\nAs demonstrated by those statements, expr can range from simple (a literal value) to more complex\n(the value returned by a scalar subquery).\nThe Performance Schema user_variables_by_thread table contains information about user-\ndefined variables. See Section 29.12.10, “Performance Schema User-Defined Variable Tables”.\nParameter and Local Variable Assignment\nSET applies to parameters and local variables in the context of the stored object within which they\nare defined. The following procedure uses the increment procedure parameter and counter local\nvariable:\nCREATE PROCEDURE p(increment INT)\nBEGIN\n  DECLARE counter INT DEFAULT 0;\n  WHILE counter < 10 DO\n    -- ... do work ...\n    SET counter = counter + increment;\n  END WHILE;\nEND;\nSystem Variable Assignment\nThe MySQL server maintains system variables that configure its operation. A system variable can\nhave a global value that affects server operation as a whole, a session value that affects the current\nsession, or both. Many system variables are dynamic and can be changed at runtime using the SET\nstatement to affect operation of the current server instance. SET can also be used to persist certain\nsystem variables to the mysqld-auto.cnf file in the data directory, to affect server operation for\nsubsequent startups.\nIf a SET statement is issued for a sensitive system variable, the query is rewritten to replace the value\nwith “<redacted>” before it is logged to the general log and audit log. This takes place even if secure\nstorage through a keyring component is not available on the server instance.\nIf you change a session system variable, the value remains in effect within your session until you\nchange the variable to a different value or the session ends. The change has no effect on other\nsessions.\nIf you change a global system variable, the value is remembered and used to initialize the session\nvalue for new sessions until you change the variable to a different value or the server exits. The change\nis visible to any client that accesses the global value. However, the change affects the corresponding\nsession value only for clients that connect after the change. The global variable change does not affect\nthe session value for any current client sessions (not even the session within which the global value\nchange occurs).\nTo make a global system variable setting permanent so that it applies across server restarts, you can\npersist it to the mysqld-auto.cnf file in the data directory. It is also possible to make persistent\nconfiguration changes by manually modifying a my.cnf option file, but that is more cumbersome,\nand an error in a manually entered setting might not be discovered until much later. SET statements\nthat persist system variables are more convenient and avoid the possibility of malformed settings\nbecause settings with syntax errors do not succeed and do not change server configuration. For more\ninformation about persisting system variables and the mysqld-auto.cnf file, see Section 7.1.9.3,\n“Persisted System Variables”.\nNote\nSetting or persisting a global system variable value always requires special\nprivileges. Setting a session system variable value normally requires no special\nprivileges and can be done by any user, although there are exceptions. For\nmore information, see Section 7.1.9.1, “System Variable Privileges”.\nThe following discussion describes the syntax options for setting and persisting system variables:\n• To assign a value to a global system variable, precede the variable name by the GLOBAL keyword or\nthe @@GLOBAL. qualifier:\nSET GLOBAL max_connections = 1000;\nSET @@GLOBAL.max_connections = 1000;\n• To assign a value to a session system variable, precede the variable name by the SESSION or\nLOCAL keyword, by the @@SESSION., @@LOCAL., or @@ qualifier, or by no keyword or no modifier at\nall:\nSET SESSION sql_mode = 'TRADITIONAL';\nSET LOCAL sql_mode = 'TRADITIONAL';\nSET @@SESSION.sql_mode = 'TRADITIONAL';\nSET @@LOCAL.sql_mode = 'TRADITIONAL';\nSET @@sql_mode = 'TRADITIONAL';\nSET sql_mode = 'TRADITIONAL';\nA client can change its own session variables, but not those of any other client.\n• To persist a global system variable to the mysqld-auto.cnf option file in the data directory,\nprecede the variable name by the PERSIST keyword or the @@PERSIST. qualifier:\nSET PERSIST max_connections = 1000;\nSET @@PERSIST.max_connections = 1000;\nThis SET syntax enables you to make configuration changes at runtime that also persist across\nserver restarts. Like SET GLOBAL, SET PERSIST sets the global variable runtime value, but also\nwrites the variable setting to the mysqld-auto.cnf file (replacing any existing variable setting if\nthere is one).\n• To persist a global system variable to the mysqld-auto.cnf file without setting the global\nvariable runtime value, precede the variable name by the PERSIST_ONLY keyword or the\n@@PERSIST_ONLY. qualifier:\nSET PERSIST_ONLY back_log = 100;\nSET @@PERSIST_ONLY.back_log = 100;\nLike PERSIST, PERSIST_ONLY writes the variable setting to mysqld-auto.cnf. However,\nunlike PERSIST, PERSIST_ONLY does not modify the global variable runtime value. This makes\nPERSIST_ONLY suitable for configuring read-only system variables that can be set only at server\nstartup.\nTo set a global system variable value to the compiled-in MySQL default value or a session system\nvariable to the current corresponding global value, set the variable to the value DEFAULT. For example,\nthe following two statements are identical in setting the session value of max_join_size to the\ncurrent global value:\nSET @@SESSION.max_join_size = DEFAULT;\nSET @@SESSION.max_join_size = @@GLOBAL.max_join_size;\nUsing SET to persist a global system variable to a value of DEFAULT or to its literal default value\nassigns the variable its default value and adds a setting for the variable to mysqld-auto.cnf. To\nremove the variable from the file, use RESET PERSIST.\nSome system variables cannot be persisted or are persist-restricted. See Section 7.1.9.4,\n“Nonpersistible and Persist-Restricted System Variables”.\nA system variable implemented by a plugin can be persisted if the plugin is installed when the SET\nstatement is executed. Assignment of the persisted plugin variable takes effect for subsequent server\nrestarts if the plugin is still installed. If the plugin is no longer installed, the plugin variable no longer\nexists when the server reads the mysqld-auto.cnf file. In this case, the server writes a warning to\nthe error log and continues:\ncurrently unknown variable 'var_name'\nwas read from the persisted config file\nTo display system variable names and values:\n• Use the SHOW VARIABLES statement; see Section 15.7.7.40, “SHOW VARIABLES Statement”.\n• Several Performance Schema tables provide system variable information. See Section 29.12.14,\n“Performance Schema System Variable Tables”.\n• The Performance Schema variables_info table contains information showing when and by\nwhich user each system variable was most recently set. See Section 29.12.14.3, “Performance\nSchema variables_info Table”.\n• The Performance Schema persisted_variables table provides an SQL interface to the\nmysqld-auto.cnf file, enabling its contents to be inspected at runtime using SELECT statements.\nSee Section 29.12.14.2, “Performance Schema persisted_variables Table”.\nSET Error Handling\nIf any variable assignment in a SET statement fails, the entire statement fails and no variables are\nchanged, nor is the mysqld-auto.cnf file changed.\nSET produces an error under the circumstances described here. Most of the examples show SET\nstatements that use keyword syntax (for example, GLOBAL or SESSION), but the principles are also\ntrue for statements that use the corresponding modifiers (for example, @@GLOBAL. or @@SESSION.).\n• Use of SET (any variant) to set a read-only variable:\nmysql> SET GLOBAL version = 'abc';\nERROR 1238 (HY000): Variable 'version' is a read only variable\n• Use of GLOBAL, PERSIST, or PERSIST_ONLY to set a variable that has only a session value:\nmysql> SET GLOBAL sql_log_bin = ON;\nERROR 1228 (HY000): Variable 'sql_log_bin' is a SESSION\nvariable and can't be used with SET GLOBAL\n• Use of SESSION to set a variable that has only a global value:\nmysql> SET SESSION max_connections = 1000;\nERROR 1229 (HY000): Variable 'max_connections' is a\nGLOBAL variable and should be set with SET GLOBAL\n• Omission of GLOBAL, PERSIST, or PERSIST_ONLY to set a variable that has only a global value:\nmysql> SET max_connections = 1000;\nERROR 1229 (HY000): Variable 'max_connections' is a\nGLOBAL variable and should be set with SET GLOBAL\n• Use of PERSIST or PERSIST_ONLY to set a variable that cannot be persisted:\nmysql> SET PERSIST port = 3307;\nERROR 1238 (HY000): Variable 'port' is a read only variable\nmysql> SET PERSIST_ONLY port = 3307;\nERROR 1238 (HY000): Variable 'port' is a non persistent read only variable\n• The @@GLOBAL., @@PERSIST., @@PERSIST_ONLY., @@SESSION., and @@ modifiers apply only\nto system variables. An error occurs for attempts to apply them to user-defined variables, stored\nprocedure or function parameters, or stored program local variables.\n• Not all system variables can be set to DEFAULT. In such cases, assigning DEFAULT results in an\nerror.\n• An error occurs for attempts to assign DEFAULT to user-defined variables, stored procedure or\nfunction parameters, or stored program local variables.\nMultiple Variable Assignment\nA SET statement can contain multiple variable assignments, separated by commas. This statement\nassigns values to a user-defined variable and a system variable:\nSET @x = 1, SESSION sql_mode = '';\nIf you set multiple system variables in a single statement, the most recent GLOBAL, PERSIST,\nPERSIST_ONLY, or SESSION keyword in the statement is used for following assignments that have no\nkeyword specified.\nExamples of multiple-variable assignment:\nSET GLOBAL sort_buffer_size = 1000000, SESSION sort_buffer_size = 1000000;\nSET @@GLOBAL.sort_buffer_size = 1000000, @@LOCAL.sort_buffer_size = 1000000;\nSET GLOBAL max_connections = 1000, sort_buffer_size = 1000000;\nThe @@GLOBAL., @@PERSIST., @@PERSIST_ONLY., @@SESSION., and @@ modifiers apply only to\nthe immediately following system variable, not any remaining system variables. This statement sets the\nsort_buffer_size global value to 50000 and the session value to 1000000:\nSET @@GLOBAL.sort_buffer_size = 50000, sort_buffer_size = 1000000;\nSystem Variable References in Expressions\nTo refer to the value of a system variable in expressions, use one of the @@-modifiers (except\n@@PERSIST. and @@PERSIST_ONLY., which are not permitted in expressions). For example, you can\nretrieve system variable values in a SELECT statement like this:\nSELECT @@GLOBAL.sql_mode, @@SESSION.sql_mode, @@sql_mode;\nNote\nA reference to a system variable in an expression as @@var_name (with @@\nrather than @@GLOBAL. or @@SESSION.) returns the session value if it exists\nand the global value otherwise. This differs from SET @@var_name = expr,\nwhich always refers to the session value.\n15.7.6.2 SET CHARACTER SET Statement\nSET {CHARACTER SET | CHARSET}\n    {'charset_name' | DEFAULT}\nThis statement maps all strings sent between the server and the current client with the given mapping.\nSET CHARACTER SET sets three session system variables: character_set_client and\ncharacter_set_results are set to the given character set, and character_set_connection\nto the value of character_set_database. See Section 12.4, “Connection Character Sets and\nCollations”.\ncharset_name may be quoted or unquoted.\nThe default character set mapping can be restored by using the value DEFAULT. The default depends\non the server configuration.\nSome character sets cannot be used as the client character set. Attempting to use them with SET\nCHARACTER SET produces an error. See Impermissible Client Character Sets.\n15.7.6.3 SET NAMES Statement\nSET NAMES {'charset_name'\n    [COLLATE 'collation_name'] | DEFAULT}\nThis statement sets the three session system variables character_set_client,\ncharacter_set_connection, and character_set_results to the given character set. Setting\ncharacter_set_connection to charset_name also sets collation_connection to the default\ncollation for charset_name. See Section 12.4, “Connection Character Sets and Collations”.\nThe optional COLLATE clause may be used to specify a collation explicitly. If given, the collation must\none of the permitted collations for charset_name.\ncharset_name and collation_name may be quoted or unquoted.\nThe default mapping can be restored by using a value of DEFAULT. The default depends on the server\nconfiguration.\nSome character sets cannot be used as the client character set. Attempting to use them with SET\nNAMES produces an error. See Impermissible Client Character Sets.",
    "15.7.7 SHOW Statements": "15.7.7 SHOW Statements\nSHOW has many forms that provide information about databases, tables, columns, or status information\nabout the server. This section describes those following:\nSHOW BINARY LOG STATUS\nSHOW BINARY LOGS\nSHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]\nSHOW {CHARACTER SET | CHARSET} [like_or_where]\nSHOW COLLATION [like_or_where]\nSHOW [FULL] COLUMNS FROM tbl_name [FROM db_name] [like_or_where]\nSHOW CREATE DATABASE db_name\nSHOW CREATE EVENT event_name\nSHOW CREATE FUNCTION func_name\nSHOW CREATE PROCEDURE proc_name\nSHOW CREATE TABLE tbl_name\nSHOW CREATE TRIGGER trigger_name\nSHOW CREATE VIEW view_name\nSHOW DATABASES [like_or_where]\nSHOW ENGINE engine_name {STATUS | MUTEX}\nSHOW [STORAGE] ENGINES\nSHOW ERRORS [LIMIT [offset,] row_count]\nSHOW EVENTS\nSHOW FUNCTION CODE func_name\nSHOW FUNCTION STATUS [like_or_where]\nSHOW GRANTS FOR user\nSHOW INDEX FROM tbl_name [FROM db_name]\nSHOW OPEN TABLES [FROM db_name] [like_or_where]\nSHOW PLUGINS\nSHOW PROCEDURE CODE proc_name\nSHOW PROCEDURE STATUS [like_or_where]\nSHOW PRIVILEGES\nSHOW [FULL] PROCESSLIST\nSHOW PROFILE [types] [FOR QUERY n] [OFFSET n] [LIMIT n]\nSHOW PROFILES\nSHOW RELAYLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]\nSHOW REPLICA STATUS [FOR CHANNEL channel]\nSHOW REPLICAS\nSHOW [GLOBAL | SESSION] STATUS [like_or_where]\nSHOW TABLE STATUS [FROM db_name] [like_or_where]\nSHOW [FULL] TABLES [FROM db_name] [like_or_where]\nSHOW TRIGGERS [FROM db_name] [like_or_where]\nSHOW [GLOBAL | SESSION] VARIABLES [like_or_where]\nSHOW WARNINGS [LIMIT [offset,] row_count]\nlike_or_where: {\n    LIKE 'pattern'\n  | WHERE expr\n}\nIf the syntax for a given SHOW statement includes a LIKE 'pattern' part, 'pattern' is a string that\ncan contain the SQL % and _ wildcard characters. The pattern is useful for restricting statement output\nto matching values.\nSeveral SHOW statements also accept a WHERE clause that provides more flexibility in specifying which\nrows to display. See Section 28.8, “Extensions to SHOW Statements”.\nIn SHOW statement results, user names and host names are quoted using backticks (`).\nMany MySQL APIs (such as PHP) enable you to treat the result returned from a SHOW statement\nas you would a result set from a SELECT; see Chapter 31, Connectors and APIs, or your API\ndocumentation for more information. In addition, you can work in SQL with results from queries on\ntables in the INFORMATION_SCHEMA database, which you cannot easily do with results from SHOW\nstatements. See Chapter 28, INFORMATION_SCHEMA Tables.\n15.7.7.1 SHOW BINARY LOG STATUS Statement\nSHOW BINARY LOG STATUS\nThis statement provides status information about binary log files on the source server, and requires the\nREPLICATION CLIENT privilege (or the deprecated SUPER privilege).\nExample:\nmysql> SHOW BINARY LOG STATUS\\G\n*************************** 1. row ***************************\n             File: source-bin.000002\n         Position: 1307\n     Binlog_Do_DB: test\n Binlog_Ignore_DB: manual, mysql\nExecuted_Gtid_Set: 3E11FA47-71CA-11E1-9E33-C80AA9429562:1-5\n1 row in set (0.00 sec)\nWhen global transaction IDs are in use, Executed_Gtid_Set shows the set of GTIDs for transactions\nthat have been executed on the source. This is the same as the value for the gtid_executed system\nvariable on this server, as well as the value for Executed_Gtid_Set in the output of SHOW REPLICA\nSTATUS on this server.\n15.7.7.2 SHOW BINARY LOGS Statement\nSHOW BINARY LOGS\nLists the binary log files on the server. This statement is used as part of the procedure described in\nSection 15.4.1.1, “PURGE BINARY LOGS Statement”, that shows how to determine which logs can be\npurged. SHOW BINARY LOGS requires the REPLICATION CLIENT privilege (or the deprecated SUPER\nprivilege).\nEncrypted binary log files have a 512-byte file header that stores information required for encryption\nand decryption of the file. This is included in the file size displayed by SHOW BINARY LOGS. The\nEncrypted column shows whether or not the binary log file is encrypted. Binary log encryption is\nactive if binlog_encryption=ON is set for the server. Existing binary log files are not encrypted or\ndecrypted if binary log encryption is activated or deactivated while the server is running.\nmysql> SHOW BINARY LOGS;\n+---------------+-----------+-----------+\n| Log_name      | File_size | Encrypted |\n+---------------+-----------+-----------+\n| binlog.000015 |    724935 |       Yes |\n| binlog.000016 |    733481 |       Yes |\n+---------------+-----------+-----------+\n15.7.7.3 SHOW BINLOG EVENTS Statement\nSHOW BINLOG EVENTS\n   [IN 'log_name']\n   [FROM pos]\n   [LIMIT [offset,] row_count]\nShows the events in the binary log. If you do not specify 'log_name', the first binary log is displayed.\nSHOW BINLOG EVENTS requires the REPLICATION SLAVE privilege.\nThe LIMIT clause has the same syntax as for the SELECT statement. See Section 15.2.13, “SELECT\nStatement”.\nNote\nIssuing a SHOW BINLOG EVENTS with no LIMIT clause could start a very time-\nand resource-consuming process because the server returns to the client the\ncomplete contents of the binary log (which includes all statements executed by\nthe server that modify data). As an alternative to SHOW BINLOG EVENTS, use\nthe mysqlbinlog utility to save the binary log to a text file for later examination\nand analysis. See Section 6.6.9, “mysqlbinlog — Utility for Processing Binary\nLog Files”.\nSHOW BINLOG EVENTS displays the following fields for each event in the binary log:\n• Log_name\nThe name of the file that is being listed.\n• Pos\nThe position at which the event occurs.\n• Event_type\nAn identifier that describes the event type.\n• Server_id\nThe server ID of the server on which the event originated.\n• End_log_pos\nThe position at which the next event begins, which is equal to Pos plus the size of the event.\n• Info\nMore detailed information about the event type. The format of this information depends on the event\ntype.\nFor compressed transaction payloads, the Transaction_payload_event is first printed as a single\nunit, then it is unpacked and each event inside it is printed.\nSome events relating to the setting of user and system variables are not included in the output from\nSHOW BINLOG EVENTS. To get complete coverage of events within a binary log, use mysqlbinlog.\nSHOW BINLOG EVENTS does not work with relay log files. You can use SHOW RELAYLOG EVENTS for\nthis purpose.\n15.7.7.4 SHOW CHARACTER SET Statement\nSHOW {CHARACTER SET | CHARSET}\n    [LIKE 'pattern' | WHERE expr]\nThe SHOW CHARACTER SET statement shows all available character sets. The LIKE clause, if present,\nindicates which character set names to match. The WHERE clause can be given to select rows using\nmore general conditions, as discussed in Section 28.8, “Extensions to SHOW Statements”. For\nexample:\nmysql> SHOW CHARACTER SET LIKE 'latin%';\n+---------+-----------------------------+-------------------+--------+\n| Charset | Description                 | Default collation | Maxlen |\n+---------+-----------------------------+-------------------+--------+\n| latin1  | cp1252 West European        | latin1_swedish_ci |      1 |\n| latin2  | ISO 8859-2 Central European | latin2_general_ci |      1 |\n| latin5  | ISO 8859-9 Turkish          | latin5_turkish_ci |      1 |\n| latin7  | ISO 8859-13 Baltic          | latin7_general_ci |      1 |\n+---------+-----------------------------+-------------------+--------+\nSHOW CHARACTER SET output has these columns:\n• Charset\nThe character set name.\n• Description\nA description of the character set.\n• Default collation\nThe default collation for the character set.\n• Maxlen\nThe maximum number of bytes required to store one character.\nThe filename character set is for internal use only; consequently, SHOW CHARACTER SET does not\ndisplay it.\nCharacter set information is also available from the INFORMATION_SCHEMA CHARACTER_SETS table.\n15.7.7.5 SHOW COLLATION Statement\nSHOW COLLATION\n    [LIKE 'pattern' | WHERE expr]\nThis statement lists collations supported by the server. By default, the output from SHOW COLLATION\nincludes all available collations. The LIKE clause, if present, indicates which collation names to\nmatch. The WHERE clause can be given to select rows using more general conditions, as discussed in\nSection 28.8, “Extensions to SHOW Statements”. For example:\nmysql> SHOW COLLATION WHERE Charset = 'latin1';\n+-------------------+---------+----+---------+----------+---------+\n| Collation         | Charset | Id | Default | Compiled | Sortlen |\n+-------------------+---------+----+---------+----------+---------+\n| latin1_german1_ci | latin1  |  5 |         | Yes      |       1 |\n| latin1_swedish_ci | latin1  |  8 | Yes     | Yes      |       1 |\n| latin1_danish_ci  | latin1  | 15 |         | Yes      |       1 |\n| latin1_german2_ci | latin1  | 31 |         | Yes      |       2 |\n| latin1_bin        | latin1  | 47 |         | Yes      |       1 |\n| latin1_general_ci | latin1  | 48 |         | Yes      |       1 |\n| latin1_general_cs | latin1  | 49 |         | Yes      |       1 |\n| latin1_spanish_ci | latin1  | 94 |         | Yes      |       1 |\n+-------------------+---------+----+---------+----------+---------+\nSHOW COLLATION output has these columns:\n• Collation\nThe collation name.\n• Charset\nThe name of the character set with which the collation is associated.\n• Id\nThe collation ID.\n• Default\nWhether the collation is the default for its character set.\n• Compiled\nWhether the character set is compiled into the server.\n• Sortlen\nThis is related to the amount of memory required to sort strings expressed in the character set.\n• Pad_attribute\nThe collation pad attribute, one of NO PAD or PAD SPACE. This attribute affects whether trailing\nspaces are significant in string comparisons; for more information, see Trailing Space Handling in\nComparisons.\nTo see the default collation for each character set, use the following statement. Default is a reserved\nword, so to use it as an identifier, it must be quoted as such:\nmysql> SHOW COLLATION WHERE `Default` = 'Yes';\n+---------------------+----------+----+---------+----------+---------+\n| Collation           | Charset  | Id | Default | Compiled | Sortlen |\n+---------------------+----------+----+---------+----------+---------+\n| big5_chinese_ci     | big5     |  1 | Yes     | Yes      |       1 |\n| dec8_swedish_ci     | dec8     |  3 | Yes     | Yes      |       1 |\n| cp850_general_ci    | cp850    |  4 | Yes     | Yes      |       1 |\n| hp8_english_ci      | hp8      |  6 | Yes     | Yes      |       1 |\n| koi8r_general_ci    | koi8r    |  7 | Yes     | Yes      |       1 |\n| latin1_swedish_ci   | latin1   |  8 | Yes     | Yes      |       1 |\n...\nCollation information is also available from the INFORMATION_SCHEMA COLLATIONS table. See\nSection 28.3.6, “The INFORMATION_SCHEMA COLLATIONS Table”.\n15.7.7.6 SHOW COLUMNS Statement\nSHOW [EXTENDED] [FULL] {COLUMNS | FIELDS}\n    {FROM | IN} tbl_name\n    [{FROM | IN} db_name]\n    [LIKE 'pattern' | WHERE expr]\nSHOW COLUMNS displays information about the columns in a given table. It also works for views. SHOW\nCOLUMNS displays information only for those columns for which you have some privilege.\nmysql> SHOW COLUMNS FROM City;\n+-------------+----------+------+-----+---------+----------------+\n| Field       | Type     | Null | Key | Default | Extra          |\n+-------------+----------+------+-----+---------+----------------+\n| ID          | int(11)  | NO   | PRI | NULL    | auto_increment |\n| Name        | char(35) | NO   |     |         |                |\n| CountryCode | char(3)  | NO   | MUL |         |                |\n| District    | char(20) | NO   |     |         |                |\n| Population  | int(11)  | NO   |     | 0       |                |\n+-------------+----------+------+-----+---------+----------------+\nAn alternative to tbl_name FROM db_name syntax is db_name.tbl_name. These two statements\nare equivalent:\nSHOW COLUMNS FROM mytable FROM mydb;\nSHOW COLUMNS FROM mydb.mytable;\nThe optional EXTENDED keyword causes the output to include information about hidden columns that\nMySQL uses internally and are not accessible by users.\nThe optional FULL keyword causes the output to include the column collation and comments, as well\nas the privileges you have for each column.\nThe LIKE clause, if present, indicates which column names to match. The WHERE clause can be given\nto select rows using more general conditions, as discussed in Section 28.8, “Extensions to SHOW\nStatements”.\nThe data types may differ from what you expect them to be based on a CREATE TABLE statement\nbecause MySQL sometimes changes data types when you create or alter a table. The conditions under\nwhich this occurs are described in Section 15.1.20.7, “Silent Column Specification Changes”.\nSHOW COLUMNS displays the following values for each table column:\n• Field\nThe name of the column.\n• Type\nThe column data type.\n• Collation\nThe collation for nonbinary string columns, or NULL for other columns. This value is displayed only if\nyou use the FULL keyword.\n• Null\nThe column nullability. The value is YES if NULL values can be stored in the column, NO if not.\n• Key\nWhether the column is indexed:\n• If Key is empty, the column either is not indexed or is indexed only as a secondary column in a\nmultiple-column, nonunique index.\n• If Key is PRI, the column is a PRIMARY KEY or is one of the columns in a multiple-column\nPRIMARY KEY.\n• If Key is UNI, the column is the first column of a UNIQUE index. (A UNIQUE index permits multiple\nNULL values, but you can tell whether the column permits NULL by checking the Null field.)\n• If Key is MUL, the column is the first column of a nonunique index in which multiple occurrences of\na given value are permitted within the column.\nIf more than one of the Key values applies to a given column of a table, Key displays the one with\nthe highest priority, in the order PRI, UNI, MUL.\nA UNIQUE index may be displayed as PRI if it cannot contain NULL values and there is no PRIMARY\nKEY in the table. A UNIQUE index may display as MUL if several columns form a composite UNIQUE\nindex; although the combination of the columns is unique, each column can still hold multiple\noccurrences of a given value.\n• Default\nThe default value for the column. This is NULL if the column has an explicit default of NULL, or if the\ncolumn definition includes no DEFAULT clause.\n• Extra\nAny additional information that is available about a given column. The value is nonempty in these\ncases:\n• auto_increment for columns that have the AUTO_INCREMENT attribute.\n• on update CURRENT_TIMESTAMP for TIMESTAMP or DATETIME columns that have the ON\nUPDATE CURRENT_TIMESTAMP attribute.\n• VIRTUAL GENERATED or STORED GENERATED for generated columns.\n• DEFAULT_GENERATED for columns that have an expression default value.\n• Privileges\nThe privileges you have for the column. This value is displayed only if you use the FULL keyword.\n• Comment\nAny comment included in the column definition. This value is displayed only if you use the FULL\nkeyword.\nTable column information is also available from the INFORMATION_SCHEMA COLUMNS table. See\nSection 28.3.8, “The INFORMATION_SCHEMA COLUMNS Table”. The extended information about\nhidden columns is available only using SHOW EXTENDED COLUMNS; it cannot be obtained from the\nCOLUMNS table.\nYou can list a table's columns with the mysqlshow db_name tbl_name command.\nThe DESCRIBE statement provides information similar to SHOW COLUMNS. See Section 15.8.1,\n“DESCRIBE Statement”.\nThe SHOW CREATE TABLE, SHOW TABLE STATUS, and SHOW INDEX statements also provide\ninformation about tables. See Section 15.7.7, “SHOW Statements”.\nSHOW COLUMNS includes the table's generated invisible primary key, if it has one, by default.\nYou can cause this information to be suppressed in the statement's output by setting\nshow_gipk_in_create_table_and_information_schema = OFF. For more information, see\nSection 15.1.20.11, “Generated Invisible Primary Keys”.\n15.7.7.7 SHOW CREATE DATABASE Statement\nSHOW CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name\nShows the CREATE DATABASE statement that creates the named database. If the SHOW statement\nincludes an IF NOT EXISTS clause, the output too includes such a clause. SHOW CREATE SCHEMA is\na synonym for SHOW CREATE DATABASE.\nmysql> SHOW CREATE DATABASE test\\G\n*************************** 1. row ***************************\n       Database: test\nCreate Database: CREATE DATABASE `test` /*!40100 DEFAULT CHARACTER SET utf8mb4\n                 COLLATE utf8mb4_0900_ai_ci */ /*!80014 DEFAULT ENCRYPTION='N' */\nmysql> SHOW CREATE SCHEMA test\\G\n*************************** 1. row ***************************\n       Database: test\nCreate Database: CREATE DATABASE `test` /*!40100 DEFAULT CHARACTER SET utf8mb4\n                 COLLATE utf8mb4_0900_ai_ci */ /*!80014 DEFAULT ENCRYPTION='N' */\nSHOW CREATE DATABASE quotes table and column names according to the value of the\nsql_quote_show_create option. See Section 7.1.8, “Server System Variables”.\n15.7.7.8 SHOW CREATE EVENT Statement\nSHOW CREATE EVENT event_name\nThis statement displays the CREATE EVENT statement needed to re-create a given event. It requires\nthe EVENT privilege for the database from which the event is to be shown. For example (using the\nsame event e_daily defined and then altered in Section 15.7.7.19, “SHOW EVENTS Statement”):\nmysql> SHOW CREATE EVENT myschema.e_daily\\G\n*************************** 1. row ***************************\n               Event: e_daily\n            sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,\n                      NO_ZERO_IN_DATE,NO_ZERO_DATE,\n                      ERROR_FOR_DIVISION_BY_ZERO,\n                      NO_ENGINE_SUBSTITUTION\n           time_zone: SYSTEM\n        Create Event: CREATE DEFINER=`jon`@`ghidora` EVENT `e_daily`\n                        ON SCHEDULE EVERY 1 DAY\n                        STARTS CURRENT_TIMESTAMP + INTERVAL 6 HOUR\n                        ON COMPLETION NOT PRESERVE\n                        ENABLE\n                        COMMENT 'Saves total number of sessions then\n                                clears the table each day'\n                        DO BEGIN\n                          INSERT INTO site_activity.totals (time, total)\n                            SELECT CURRENT_TIMESTAMP, COUNT(*)\n                              FROM site_activity.sessions;\n                          DELETE FROM site_activity.sessions;\n                        END\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\ncharacter_set_client is the session value of the character_set_client system\nvariable when the event was created. collation_connection is the session value of the\ncollation_connection system variable when the event was created. Database Collation is\nthe collation of the database with which the event is associated.\nThe output reflects the current status of the event (ENABLE) rather than the status with which it was\ncreated.\n15.7.7.9 SHOW CREATE FUNCTION Statement\nSHOW CREATE FUNCTION func_name\nThis statement is similar to SHOW CREATE PROCEDURE but for stored functions. See\nSection 15.7.7.10, “SHOW CREATE PROCEDURE Statement”.\n15.7.7.10 SHOW CREATE PROCEDURE Statement\nSHOW CREATE PROCEDURE proc_name\nThis statement is a MySQL extension. It returns the exact string that can be used to re-create the\nnamed stored procedure. A similar statement, SHOW CREATE FUNCTION, displays information about\nstored functions (see Section 15.7.7.9, “SHOW CREATE FUNCTION Statement”).\nTo use either statement, you must be the user named as the routine DEFINER, have the\nSHOW_ROUTINE privilege, have the SELECT privilege at the global level, or have the CREATE\nROUTINE, ALTER ROUTINE, or EXECUTE privilege granted at a scope that includes the routine. The\nvalue displayed for the Create Procedure or Create Function field is NULL if you have only\nCREATE ROUTINE, ALTER ROUTINE, or EXECUTE.\nmysql> SHOW CREATE PROCEDURE test.citycount\\G\n*************************** 1. row ***************************\n           Procedure: citycount\n            sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,\n                      NO_ZERO_IN_DATE,NO_ZERO_DATE,\n                      ERROR_FOR_DIVISION_BY_ZERO,\n                      NO_ENGINE_SUBSTITUTION\n    Create Procedure: CREATE DEFINER=`me`@`localhost`\n                      PROCEDURE `citycount`(IN country CHAR(3), OUT cities INT)\n                      BEGIN\n                        SELECT COUNT(*) INTO cities FROM world.city\n                        WHERE CountryCode = country;\n                      END\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\nmysql> SHOW CREATE FUNCTION test.hello\\G\n*************************** 1. row ***************************\n            Function: hello\n            sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,\n                      NO_ZERO_IN_DATE,NO_ZERO_DATE,\n                      ERROR_FOR_DIVISION_BY_ZERO,\n                      NO_ENGINE_SUBSTITUTION\n     Create Function: CREATE DEFINER=`me`@`localhost`\n                      FUNCTION `hello`(s CHAR(20))\n                      RETURNS char(50) CHARSET utf8mb4\n                      DETERMINISTIC\n                      RETURN CONCAT('Hello, ',s,'!')\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\ncharacter_set_client is the session value of the character_set_client system\nvariable when the routine was created. collation_connection is the session value of the\ncollation_connection system variable when the routine was created. Database Collation is\nthe collation of the database with which the routine is associated.\n15.7.7.11 SHOW CREATE TABLE Statement\nSHOW CREATE TABLE tbl_name\nShows the CREATE TABLE statement that creates the named table. To use this statement, you must\nhave some privilege for the table. This statement also works with views.\nmysql> SHOW CREATE TABLE t\\G\n*************************** 1. row ***************************\n       Table: t\nCreate Table: CREATE TABLE `t` (\n  `id` int NOT NULL AUTO_INCREMENT,\n  `s` char(60) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nSHOW CREATE TABLE displays all CHECK constraints as table constraints. That is, a CHECK constraint\noriginally specified as part of a column definition displays as a separate clause not part of the column\ndefinition. Example:\nmysql> CREATE TABLE t1 (\n         i1 INT CHECK (i1 <> 0),      -- column constraint\n         i2 INT,\n         CHECK (i2 > i1),             -- table constraint\n         CHECK (i2 <> 0) NOT ENFORCED -- table constraint, not enforced\n       );\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `i1` int DEFAULT NULL,\n  `i2` int DEFAULT NULL,\n  CONSTRAINT `t1_chk_1` CHECK ((`i1` <> 0)),\n  CONSTRAINT `t1_chk_2` CHECK ((`i2` > `i1`)),\n  CONSTRAINT `t1_chk_3` CHECK ((`i2` <> 0)) /*!80016 NOT ENFORCED */\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\nSHOW CREATE TABLE quotes table and column names according to the value of the\nsql_quote_show_create option. See Section 7.1.8, “Server System Variables”.\nWhen altering the storage engine of a table, table options that are not applicable to the new storage\nengine are retained in the table definition to enable reverting the table with its previously defined\noptions to the original storage engine, if necessary. For example, when changing the storage engine\nfrom InnoDB to MyISAM, options specific to InnoDB, such as ROW_FORMAT=COMPACT, are retained,\nas shown here:\nmysql> CREATE TABLE t1 (c1 INT PRIMARY KEY) ROW_FORMAT=COMPACT ENGINE=InnoDB;\nmysql> ALTER TABLE t1 ENGINE=MyISAM;\nmysql> SHOW CREATE TABLE t1\\G\n*************************** 1. row ***************************\n       Table: t1\nCreate Table: CREATE TABLE `t1` (\n  `c1` int NOT NULL,\n  PRIMARY KEY (`c1`)\n) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=COMPACT\nWhen creating a table with strict mode disabled, the storage engine's default row format is used\nif the specified row format is not supported. The actual row format of the table is reported in the\nRow_format column in response to SHOW TABLE STATUS. SHOW CREATE TABLE shows the row\nformat that was specified in the CREATE TABLE statement.\nSHOW CREATE TABLE also includes the definition of the table's generated invisible primary key, if\nit has such a key, by default. You can cause this information to be suppressed in the statement's\noutput by setting show_gipk_in_create_table_and_information_schema = OFF. For more\ninformation, see Section 15.1.20.11, “Generated Invisible Primary Keys”.\n15.7.7.12 SHOW CREATE TRIGGER Statement\nSHOW CREATE TRIGGER trigger_name\nThis statement shows the CREATE TRIGGER statement that creates the named trigger. This statement\nrequires the TRIGGER privilege for the table associated with the trigger.\nmysql> SHOW CREATE TRIGGER ins_sum\\G\n*************************** 1. row ***************************\n               Trigger: ins_sum\n              sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,\n                        NO_ZERO_IN_DATE,NO_ZERO_DATE,\n                        ERROR_FOR_DIVISION_BY_ZERO,\n                        NO_ENGINE_SUBSTITUTION\nSQL Original Statement: CREATE DEFINER=`me`@`localhost` TRIGGER `ins_sum`\n                        BEFORE INSERT ON `account`\n                        FOR EACH ROW SET @sum = @sum + NEW.amount\n  character_set_client: utf8mb4\n  collation_connection: utf8mb4_0900_ai_ci\n    Database Collation: utf8mb4_0900_ai_ci\n               Created: 2018-08-08 10:10:12.61\nSHOW CREATE TRIGGER output has these columns:\n• Trigger: The trigger name.\n• sql_mode: The SQL mode in effect when the trigger executes.\n• SQL Original Statement: The CREATE TRIGGER statement that defines the trigger.\n• character_set_client: The session value of the character_set_client system variable\nwhen the trigger was created.\n• collation_connection: The session value of the collation_connection system variable\nwhen the trigger was created.\n• Database Collation: The collation of the database with which the trigger is associated.\n• Created: The date and time when the trigger was created. This is a TIMESTAMP(2) value (with a\nfractional part in hundredths of seconds) for triggers.\nTrigger information is also available from the INFORMATION_SCHEMA TRIGGERS table. See\nSection 28.3.44, “The INFORMATION_SCHEMA TRIGGERS Table”.\n15.7.7.13 SHOW CREATE USER Statement\nSHOW CREATE USER user\nThis statement shows the CREATE USER statement that creates the named user. An error occurs if\nthe user does not exist. The statement requires the SELECT privilege for the mysql system schema,\nexcept to see information for the current user. For the current user, the SELECT privilege for the\nmysql.user system table is required for display of the password hash in the IDENTIFIED AS clause;\notherwise, the hash displays as <secret>.\nTo name the account, use the format described in Section 8.2.4, “Specifying Account Names”.\nThe host name part of the account name, if omitted, defaults to '%'. It is also possible to specify\nCURRENT_USER or CURRENT_USER() to refer to the account associated with the current session.\nPassword hash values displayed in the IDENTIFIED WITH clause of output from SHOW CREATE\nUSER may contain unprintable characters that have adverse effects on terminal displays and in other\nenvironments. Enabling the print_identified_with_as_hex system variable causes SHOW\nCREATE USER to display such hash values as hexadecimal strings rather than as regular string literals.\nHash values that do not contain unprintable characters still display as regular string literals, even with\nthis variable enabled.\nmysql> CREATE USER 'u1'@'localhost' IDENTIFIED BY 'secret';\nmysql> SET print_identified_with_as_hex = ON;\nmysql> SHOW CREATE USER 'u1'@'localhost'\\G\n*************************** 1. row ***************************\nCREATE USER for u1@localhost: CREATE USER `u1`@`localhost`\nIDENTIFIED WITH 'caching_sha2_password'\nAS 0x244124303035240C7745603626313D613C4C10633E0A104B1E14135A544A7871567245614F4872344643546336546F624F6C78\nREQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK\nPASSWORD HISTORY DEFAULT PASSWORD REUSE INTERVAL DEFAULT\nPASSWORD REQUIRE CURRENT DEFAULT\nTo display the privileges granted to an account, use the SHOW GRANTS statement. See\nSection 15.7.7.22, “SHOW GRANTS Statement”.\n15.7.7.14 SHOW CREATE VIEW Statement\nSHOW CREATE VIEW view_name\nThis statement shows the CREATE VIEW statement that creates the named view.\nmysql> SHOW CREATE VIEW v\\G\n*************************** 1. row ***************************\n                View: v\n         Create View: CREATE ALGORITHM=UNDEFINED\n                      DEFINER=`bob`@`localhost`\n                      SQL SECURITY DEFINER VIEW\n                      `v` AS select 1 AS `a`,2 AS `b`\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\ncharacter_set_client is the session value of the character_set_client system\nvariable when the view was created. collation_connection is the session value of the\ncollation_connection system variable when the view was created.\nUse of SHOW CREATE VIEW requires the SHOW VIEW privilege, and the SELECT privilege for the view\nin question.\nView information is also available from the INFORMATION_SCHEMA VIEWS table. See Section 28.3.47,\n“The INFORMATION_SCHEMA VIEWS Table”.\nMySQL lets you use different sql_mode settings to tell the server the type of SQL syntax to support.\nFor example, you might use the ANSI SQL mode to ensure MySQL correctly interprets the standard\nSQL concatenation operator, the double bar (||), in your queries. If you then create a view that\nconcatenates items, you might worry that changing the sql_mode setting to a value different from\nANSI could cause the view to become invalid. But this is not the case. No matter how you write out a\nview definition, MySQL always stores it the same way, in a canonical form. Here is an example that\nshows how the server changes a double bar concatenation operator to a CONCAT() function:\nmysql> SET sql_mode = 'ANSI';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> CREATE VIEW test.v AS SELECT 'a' || 'b' as col1;\nQuery OK, 0 rows affected (0.01 sec)\nmysql> SHOW CREATE VIEW test.v\\G\n*************************** 1. row ***************************\n                View: v\n         Create View: CREATE VIEW \"v\" AS select concat('a','b') AS \"col1\"\n...\n1 row in set (0.00 sec)\nThe advantage of storing a view definition in canonical form is that changes made later to the value\nof sql_mode do not affect the results from the view. However an additional consequence is that\ncomments prior to SELECT are stripped from the definition by the server.\n15.7.7.15 SHOW DATABASES Statement\nSHOW {DATABASES | SCHEMAS}\n    [LIKE 'pattern' | WHERE expr]\nSHOW DATABASES lists the databases on the MySQL server host. SHOW SCHEMAS is a synonym\nfor SHOW DATABASES. The LIKE clause, if present, indicates which database names to match. The\nWHERE clause can be given to select rows using more general conditions, as discussed in Section 28.8,\n“Extensions to SHOW Statements”.\nYou see only those databases for which you have some kind of privilege, unless you have the global\nSHOW DATABASES privilege. You can also get this list using the mysqlshow command.\nIf the server was started with the --skip-show-database option, you cannot use this statement at\nall unless you have the SHOW DATABASES privilege.\nMySQL implements databases as directories in the data directory, so this statement simply lists\ndirectories in that location. However, the output may include names of directories that do not\ncorrespond to actual databases.\nDatabase information is also available from the INFORMATION_SCHEMA SCHEMATA table. See\nSection 28.3.31, “The INFORMATION_SCHEMA SCHEMATA Table”.\nCaution\nBecause any static global privilege is considered a privilege for all databases,\nany static global privilege enables a user to see all database names with SHOW\nDATABASES or by examining the SCHEMATA table of INFORMATION_SCHEMA,\nexcept databases that have been restricted at the database level by partial\nrevokes.\n15.7.7.16 SHOW ENGINE Statement\nSHOW ENGINE engine_name {STATUS | MUTEX}\nSHOW ENGINE displays operational information about a storage engine. It requires the PROCESS\nprivilege. The statement has these variants:\nSHOW ENGINE INNODB STATUS\nSHOW ENGINE INNODB MUTEX\nSHOW ENGINE PERFORMANCE_SCHEMA STATUS\nSHOW ENGINE INNODB STATUS displays extensive information from the standard InnoDB Monitor\nabout the state of the InnoDB storage engine. For information about the standard monitor and other\nInnoDB Monitors that provide information about InnoDB processing, see Section 17.17, “InnoDB\nMonitors”.\nSHOW ENGINE INNODB MUTEX displays InnoDB mutex and rw-lock statistics.\nNote\nInnoDB mutexes and rwlocks can also be monitored using Performance\nSchema tables. See Section 17.16.2, “Monitoring InnoDB Mutex Waits Using\nPerformance Schema”.\nMutex statistics collection is configured dynamically using the following options:\n• To enable the collection of mutex statistics, run:\nSET GLOBAL innodb_monitor_enable='latch';\n• To reset mutex statistics, run:\nSET GLOBAL innodb_monitor_reset='latch';\n• To disable the collection of mutex statistics, run:\nSET GLOBAL innodb_monitor_disable='latch';\nCollection of mutex statistics for SHOW ENGINE INNODB MUTEX can also be enabled by setting\ninnodb_monitor_enable='all', or disabled by setting innodb_monitor_disable='all'.\nSHOW ENGINE INNODB MUTEX output has these columns:\n• Type\nAlways InnoDB.\n• Name\nFor mutexes, the Name field reports only the mutex name. For rwlocks, the Name field reports the\nsource file where the rwlock is implemented, and the line number in the file where the rwlock is\ncreated. The line number is specific to your version of MySQL.\n• Status\nThe mutex status. This field reports the number of spins, waits, and calls. Statistics for low-level\noperating system mutexes, which are implemented outside of InnoDB, are not reported.\n• spins indicates the number of spins.\n• waits indicates the number of mutex waits.\n• calls indicates how many times the mutex was requested.\nSHOW ENGINE INNODB MUTEX does not list mutexes and rw-locks for each buffer pool block, as the\namount of output would be overwhelming on systems with a large buffer pool. SHOW ENGINE INNODB\nMUTEX does, however, print aggregate BUF_BLOCK_MUTEX spin, wait, and call values for buffer pool\nblock mutexes and rw-locks. SHOW ENGINE INNODB MUTEX also does not list any mutexes or rw-\nlocks that have never been waited on (os_waits=0). Thus, SHOW ENGINE INNODB MUTEX only\ndisplays information about mutexes and rw-locks outside of the buffer pool that have caused at least\none OS-level wait.\nUse SHOW ENGINE PERFORMANCE_SCHEMA STATUS to inspect the internal operation of the\nPerformance Schema code:\nmysql> SHOW ENGINE PERFORMANCE_SCHEMA STATUS\\G\n...\n*************************** 3. row ***************************\n  Type: performance_schema\n  Name: events_waits_history.size\nStatus: 76\n*************************** 4. row ***************************\n  Type: performance_schema\n  Name: events_waits_history.count\nStatus: 10000\n*************************** 5. row ***************************\n  Type: performance_schema\n  Name: events_waits_history.memory\nStatus: 760000\n...\n*************************** 57. row ***************************\n  Type: performance_schema\n  Name: performance_schema.memory\nStatus: 26459600\n...\nThis statement is intended to help the DBA understand the effects that different Performance Schema\noptions have on memory requirements.\nName values consist of two parts, which name an internal buffer and a buffer attribute, respectively.\nInterpret buffer names as follows:\n• An internal buffer that is not exposed as a table is named within parentheses. Examples:\n(pfs_cond_class).size, (pfs_mutex_class).memory.\n• An internal buffer that is exposed as a table in the performance_schema database is\nnamed after the table, without parentheses. Examples: events_waits_history.size,\nmutex_instances.count.\n• A value that applies to the Performance Schema as a whole begins with performance_schema.\nExample: performance_schema.memory.\nBuffer attributes have these meanings:\n• size is the size of the internal record used by the implementation, such as the size of a row in a\ntable. size values cannot be changed.\n• count is the number of internal records, such as the number of rows in a table. count values can\nbe changed using Performance Schema configuration options.\n• For a table, tbl_name.memory is the product of size and count. For the Performance Schema as\na whole, performance_schema.memory is the sum of all the memory used (the sum of all other\nmemory values).\nIn some cases, there is a direct relationship between a Performance Schema configuration\nparameter and a SHOW ENGINE value. For example, events_waits_history_long.count\ncorresponds to performance_schema_events_waits_history_long_size. In other cases,\nthe relationship is more complex. For example, events_waits_history.count corresponds to\nperformance_schema_events_waits_history_size (the number of rows per thread) multiplied\nby performance_schema_max_thread_instances (the number of threads).\nSHOW ENGINE NDB STATUS. \n If the server has the NDB storage engine enabled, SHOW ENGINE\nNDB STATUS displays cluster status information such as the number of connected data nodes, the\ncluster connectstring, and cluster binary log epochs, as well as counts of various Cluster API objects\ncreated by the MySQL Server when connected to the cluster. Sample output from this statement is\nshown here:\nmysql> SHOW ENGINE NDB STATUS;\n+------------+-----------------------+--------------------------------------------------+\n| Type       | Name                  | Status                                           |\n+------------+-----------------------+--------------------------------------------------+\n| ndbcluster | connection            | cluster_node_id=7,\n  connected_host=198.51.100.103, connected_port=1186, number_of_data_nodes=4,\n  number_of_ready_data_nodes=3, connect_count=0                                         |\n| ndbcluster | NdbTransaction        | created=6, free=0, sizeof=212                    |\n| ndbcluster | NdbOperation          | created=8, free=8, sizeof=660                    |\n| ndbcluster | NdbIndexScanOperation | created=1, free=1, sizeof=744                    |\n| ndbcluster | NdbIndexOperation     | created=0, free=0, sizeof=664                    |\n| ndbcluster | NdbRecAttr            | created=1285, free=1285, sizeof=60               |\n| ndbcluster | NdbApiSignal          | created=16, free=16, sizeof=136                  |\n| ndbcluster | NdbLabel              | created=0, free=0, sizeof=196                    |\n| ndbcluster | NdbBranch             | created=0, free=0, sizeof=24                     |\n| ndbcluster | NdbSubroutine         | created=0, free=0, sizeof=68                     |\n| ndbcluster | NdbCall               | created=0, free=0, sizeof=16                     |\n| ndbcluster | NdbBlob               | created=1, free=1, sizeof=264                    |\n| ndbcluster | NdbReceiver           | created=4, free=0, sizeof=68                     |\n| ndbcluster | binlog                | latest_epoch=155467, latest_trans_epoch=148126,\n  latest_received_binlog_epoch=0, latest_handled_binlog_epoch=0,\n  latest_applied_binlog_epoch=0                                                         |\n+------------+-----------------------+--------------------------------------------------+\nThe Status column in each of these rows provides information about the MySQL server's connection\nto the cluster and about the cluster binary log's status, respectively. The Status information is in the\nform of comma-delimited set of name-value pairs.\nThe connection row's Status column contains the name-value pairs described in the following\ntable.\nName\nValue\ncluster_node_id\nThe node ID of the MySQL server in the cluster\nconnected_host\nThe host name or IP address of the cluster\nmanagement server to which the MySQL server is\nconnected\nconnected_port\nThe port used by the MySQL server to connect to\nthe management server (connected_host)\nnumber_of_data_nodes\nThe number of data nodes configured for the\ncluster (that is, the number of [ndbd] sections in\nthe cluster config.ini file)\nnumber_of_ready_data_nodes\nThe number of data nodes in the cluster that are\nactually running\nconnect_count\nThe number of times this mysqld has connected\nor reconnected to cluster data nodes\nThe binlog row's Status column contains information relating to NDB Cluster Replication. The\nname-value pairs it contains are described in the following table.\nName\nValue\nlatest_epoch\nThe most recent epoch most recently run on this\nMySQL server (that is, the sequence number of\nthe most recent transaction run on the server)\nlatest_trans_epoch\nThe most recent epoch processed by the cluster's\ndata nodes\nlatest_received_binlog_epoch\nThe most recent epoch received by the binary log\nthread\nlatest_handled_binlog_epoch\nThe most recent epoch processed by the binary\nlog thread (for writing to the binary log)\nlatest_applied_binlog_epoch\nThe most recent epoch actually written to the\nbinary log\nSee Section 25.7, “NDB Cluster Replication”, for more information.\nThe remaining rows from the output of SHOW ENGINE NDB STATUS which are most likely to prove\nuseful in monitoring the cluster are listed here by Name:\n• NdbTransaction: The number and size of NdbTransaction objects that have been created.\nAn NdbTransaction is created each time a table schema operation (such as CREATE TABLE or\nALTER TABLE) is performed on an NDB table.\n• NdbOperation: The number and size of NdbOperation objects that have been created.\n• NdbIndexScanOperation: The number and size of NdbIndexScanOperation objects that have\nbeen created.\n• NdbIndexOperation: The number and size of NdbIndexOperation objects that have been\ncreated.\n• NdbRecAttr: The number and size of NdbRecAttr objects that have been created. In general, one\nof these is created each time a data manipulation statement is performed by an SQL node.\n• NdbBlob: The number and size of NdbBlob objects that have been created. An NdbBlob is created\nfor each new operation involving a BLOB column in an NDB table.\n• NdbReceiver: The number and size of any NdbReceiver object that have been created. The\nnumber in the created column is the same as the number of data nodes in the cluster to which the\nMySQL server has connected.\nNote\nSHOW ENGINE NDB STATUS returns an empty result if no operations involving\nNDB tables have been performed during the current session by the MySQL\nclient accessing the SQL node on which this statement is run.\n15.7.7.17 SHOW ENGINES Statement\nSHOW [STORAGE] ENGINES\nSHOW ENGINES displays status information about the server's storage engines. This is particularly\nuseful for checking whether a storage engine is supported, or to see what the default engine is.\nFor information about MySQL storage engines, see Chapter 17, The InnoDB Storage Engine, and\nChapter 18, Alternative Storage Engines.\nmysql> SHOW ENGINES\\G\n*************************** 1. row ***************************\n      Engine: MEMORY\n     Support: YES\n     Comment: Hash based, stored in memory, useful for temporary tables\nTransactions: NO\n          XA: NO\n  Savepoints: NO\n*************************** 2. row ***************************\n      Engine: InnoDB\n     Support: DEFAULT\n     Comment: Supports transactions, row-level locking, and foreign keys\nTransactions: YES\n          XA: YES\n  Savepoints: YES\n*************************** 3. row ***************************\n      Engine: PERFORMANCE_SCHEMA\n     Support: YES\n     Comment: Performance Schema\nTransactions: NO\n          XA: NO\n  Savepoints: NO\n*************************** 4. row ***************************\n      Engine: MyISAM\n     Support: YES\n     Comment: MyISAM storage engine\nTransactions: NO\n          XA: NO\n  Savepoints: NO\n*************************** 5. row ***************************\n      Engine: MRG_MYISAM\n     Support: YES\n     Comment: Collection of identical MyISAM tables\nTransactions: NO\n          XA: NO\n  Savepoints: NO\n*************************** 6. row ***************************\n      Engine: BLACKHOLE\n     Support: YES\n     Comment: /dev/null storage engine (anything you write to it disappears)\nTransactions: NO\n          XA: NO\n  Savepoints: NO\n*************************** 7. row ***************************\n      Engine: CSV\n     Support: YES\n     Comment: CSV storage engine\nTransactions: NO\n          XA: NO\n  Savepoints: NO\n*************************** 8. row ***************************\n      Engine: ARCHIVE\n     Support: YES\n     Comment: Archive storage engine\nTransactions: NO\n          XA: NO\n  Savepoints: NO\nThe output from SHOW ENGINES may vary according to the MySQL version used and other factors.\nSHOW ENGINES output has these columns:\n• Engine\nThe name of the storage engine.\n• Support\nThe server's level of support for the storage engine, as shown in the following table.\nValue\nMeaning\nYES\nThe engine is supported and is active\nDEFAULT\nLike YES, plus this is the default engine\nNO\nThe engine is not supported\nDISABLED\nThe engine is supported but has been disabled\nA value of NO means that the server was compiled without support for the engine, so it cannot be\nenabled at runtime.\nA value of DISABLED occurs either because the server was started with an option that disables the\nengine, or because not all options required to enable it were given. In the latter case, the error log\nshould contain a reason indicating why the option is disabled. See Section 7.4.2, “The Error Log”.\nYou might also see DISABLED for a storage engine if the server was compiled to support it, but was\nstarted with a --skip-engine_name option. For the NDB storage engine, DISABLED means the\nserver was compiled with support for NDB Cluster, but was not started with the --ndbcluster\noption.\nAll MySQL servers support MyISAM tables. It is not possible to disable MyISAM.\n• Comment\nA brief description of the storage engine.\n• Transactions\nWhether the storage engine supports transactions.\n• XA\nWhether the storage engine supports XA transactions.\n• Savepoints\nWhether the storage engine supports savepoints.\nStorage engine information is also available from the INFORMATION_SCHEMA ENGINES table. See\nSection 28.3.13, “The INFORMATION_SCHEMA ENGINES Table”.\n15.7.7.18 SHOW ERRORS Statement\nSHOW ERRORS [LIMIT [offset,] row_count]\nSHOW COUNT(*) ERRORS\nSHOW ERRORS is a diagnostic statement that is similar to SHOW WARNINGS, except that it displays\ninformation only for errors, rather than for errors, warnings, and notes.\nThe LIMIT clause has the same syntax as for the SELECT statement. See Section 15.2.13, “SELECT\nStatement”.\nThe SHOW COUNT(*) ERRORS statement displays the number of errors. You can also retrieve this\nnumber from the error_count variable:\nSHOW COUNT(*) ERRORS;\nSELECT @@error_count;\nSHOW ERRORS and error_count apply only to errors, not warnings or notes. In other respects, they\nare similar to SHOW WARNINGS and warning_count. In particular, SHOW ERRORS cannot display\ninformation for more than max_error_count messages, and error_count can exceed the value of\nmax_error_count if the number of errors exceeds max_error_count.\nFor more information, see Section 15.7.7.41, “SHOW WARNINGS Statement”.\n15.7.7.19 SHOW EVENTS Statement\nSHOW EVENTS\n    [{FROM | IN} schema_name]\n    [LIKE 'pattern' | WHERE expr]\nThis statement displays information about Event Manager events, which are discussed in Section 27.5,\n“Using the Event Scheduler”. It requires the EVENT privilege for the database from which the events are\nto be shown.\nIn its simplest form, SHOW EVENTS lists all of the events in the current schema:\nmysql> SELECT CURRENT_USER(), SCHEMA();\n+----------------+----------+\n| CURRENT_USER() | SCHEMA() |\n+----------------+----------+\n| jon@ghidora    | myschema |\n+----------------+----------+\n1 row in set (0.00 sec)\nmysql> SHOW EVENTS\\G\n*************************** 1. row ***************************\n                  Db: myschema\n                Name: e_daily\n             Definer: jon@ghidora\n           Time zone: SYSTEM\n                Type: RECURRING\n          Execute at: NULL\n      Interval value: 1\n      Interval field: DAY\n              Starts: 2018-08-08 11:06:34\n                Ends: NULL\n              Status: ENABLED\n          Originator: 1\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\nTo see events for a specific schema, use the FROM clause. For example, to see events for the test\nschema, use the following statement:\nSHOW EVENTS FROM test;\nThe LIKE clause, if present, indicates which event names to match. The WHERE clause can be given\nto select rows using more general conditions, as discussed in Section 28.8, “Extensions to SHOW\nStatements”.\nSHOW EVENTS output has these columns:\n• Db\nThe name of the schema (database) to which the event belongs.\n• Name\nThe name of the event.\n• Definer\nThe account of the user who created the event, in 'user_name'@'host_name' format.\n• Time zone\nThe event time zone, which is the time zone used for scheduling the event and that is in effect within\nthe event as it executes. The default value is SYSTEM.\n• Type\nThe event repetition type, either ONE TIME (transient) or RECURRING (repeating).\n• Execute At\nFor a one-time event, this is the DATETIME value specified in the AT clause of the CREATE EVENT\nstatement used to create the event, or of the last ALTER EVENT statement that modified the\nevent. The value shown in this column reflects the addition or subtraction of any INTERVAL value\nincluded in the event's AT clause. For example, if an event is created using ON SCHEDULE AT\nCURRENT_TIMESTAMP + '1:6' DAY_HOUR, and the event was created at 2018-02-09 14:05:30,\nthe value shown in this column would be '2018-02-10 20:05:30'. If the event's timing is\ndetermined by an EVERY clause instead of an AT clause (that is, if the event is recurring), the value\nof this column is NULL.\n• Interval Value\nFor a recurring event, the number of intervals to wait between event executions. For a transient\nevent, the value of this column is always NULL.\n• Interval Field\nThe time units used for the interval which a recurring event waits before repeating. For a transient\nevent, the value of this column is always NULL.\n• Starts\nThe start date and time for a recurring event. This is displayed as a DATETIME value, and is NULL\nif no start date and time are defined for the event. For a transient event, this column is always\nNULL. For a recurring event whose definition includes a STARTS clause, this column contains\nthe corresponding DATETIME value. As with the Execute At column, this value resolves any\nexpressions used. If there is no STARTS clause affecting the timing of the event, this column is NULL\n• Ends\nFor a recurring event whose definition includes a ENDS clause, this column contains the\ncorresponding DATETIME value. As with the Execute At column, this value resolves any\nexpressions used. If there is no ENDS clause affecting the timing of the event, this column is NULL.\n• Status\nThe event status. One of ENABLED, DISABLED, or REPLICA_SIDE_DISABLED.\nREPLICA_SIDE_DISABLED indicates that the creation of the event occurred on another MySQL\nserver acting as a replication source and replicated to the current MySQL server which is acting as\na replica, but the event is not presently being executed on the replica. For more information, see\nSection 19.5.1.16, “Replication of Invoked Features”. information.\nREPLICA_SIDE_DISABLED replaces SLAVESIDE_DISABLED, which is now deprecated and subject\nto removal in a future version of MySQL.\n• Originator\nThe server ID of the MySQL server on which the event was created; used in replication. This value\nmay be updated by ALTER EVENT to the server ID of the server on which that statement occurs, if\nexecuted on a source server. The default value is 0.\n• character_set_client\nThe session value of the character_set_client system variable when the event was created.\n• collation_connection\nThe session value of the collation_connection system variable when the event was created.\n• Database Collation\nThe collation of the database with which the event is associated.\nFor more information about REPLICA_SIDE_DISABLED and the Originator column, see\nSection 19.5.1.16, “Replication of Invoked Features”.\nTimes displayed by SHOW EVENTS are given in the event time zone, as discussed in Section 27.5.4,\n“Event Metadata”.\nEvent information is also available from the INFORMATION_SCHEMA EVENTS table. See\nSection 28.3.14, “The INFORMATION_SCHEMA EVENTS Table”.\nThe event action statement is not shown in the output of SHOW EVENTS. Use SHOW CREATE EVENT or\nthe INFORMATION_SCHEMA EVENTS table.\n15.7.7.20 SHOW FUNCTION CODE Statement\nSHOW FUNCTION CODE func_name\nThis statement is similar to SHOW PROCEDURE CODE but for stored functions. See Section 15.7.7.28,\n“SHOW PROCEDURE CODE Statement”.\n15.7.7.21 SHOW FUNCTION STATUS Statement\nSHOW FUNCTION STATUS\n    [LIKE 'pattern' | WHERE expr]\nThis statement is similar to SHOW PROCEDURE STATUS but for stored functions. See\nSection 15.7.7.29, “SHOW PROCEDURE STATUS Statement”.\n15.7.7.22 SHOW GRANTS Statement\nSHOW GRANTS\n    [FOR user_or_role\n        [USING role [, role] ...]]\nuser_or_role: {\n    user (see Section 8.2.4, “Specifying Account Names”)\n  | role (see Section 8.2.5, “Specifying Role Names”.\n}\nThis statement displays the privileges and roles that are assigned to a MySQL user account or role, in\nthe form of GRANT statements that must be executed to duplicate the privilege and role assignments.\nNote\nTo display nonprivilege information for MySQL accounts, use the SHOW CREATE\nUSER statement. See Section 15.7.7.13, “SHOW CREATE USER Statement”.\nSHOW GRANTS requires the SELECT privilege for the mysql system schema, except to display\nprivileges and roles for the current user.\nTo name the account or role for SHOW GRANTS, use the same format as for the GRANT statement (for\nexample, 'jeffrey'@'localhost'):\nmysql> SHOW GRANTS FOR 'jeffrey'@'localhost';\n+------------------------------------------------------------------+\n| Grants for jeffrey@localhost                                     |\n+------------------------------------------------------------------+\n| GRANT USAGE ON *.* TO `jeffrey`@`localhost`                      |\n| GRANT SELECT, INSERT, UPDATE ON `db1`.* TO `jeffrey`@`localhost` |\n+------------------------------------------------------------------+\nThe host part, if omitted, defaults to '%'. For additional information about specifying account and role\nnames, see Section 8.2.4, “Specifying Account Names”, and Section 8.2.5, “Specifying Role Names”.\nTo display the privileges granted to the current user (the account you are using to connect to the\nserver), you can use any of the following statements:\nSHOW GRANTS;\nSHOW GRANTS FOR CURRENT_USER;\nSHOW GRANTS FOR CURRENT_USER();\nIf SHOW GRANTS FOR CURRENT_USER (or any equivalent syntax) is used in definer context, such as\nwithin a stored procedure that executes with definer rather than invoker privileges, the grants displayed\nare those of the definer and not the invoker.\nIn MySQL 9.1 compared to previous series, SHOW GRANTS no longer displays ALL PRIVILEGES\nin its global-privileges output because the meaning of ALL PRIVILEGES at the global level varies\ndepending on which dynamic privileges are defined. Instead, SHOW GRANTS explicitly lists each\ngranted global privilege:\nmysql> SHOW GRANTS FOR 'root'@'localhost';\n+---------------------------------------------------------------------+\n| Grants for root@localhost                                           |\n+---------------------------------------------------------------------+\n| GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD,         |\n| SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES,  |\n| SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION   |\n| SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE,  |\n| ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE,      |\n| CREATE ROLE, DROP ROLE ON *.* TO `root`@`localhost` WITH GRANT      |\n| OPTION                                                              |\n| GRANT PROXY ON ''@'' TO `root`@`localhost` WITH GRANT OPTION        |\n+---------------------------------------------------------------------+\nApplications that process SHOW GRANTS output should be adjusted accordingly.\nAt the global level, GRANT OPTION applies to all granted static global privileges if granted for any of\nthem, but applies individually to granted dynamic privileges. SHOW GRANTS displays global privileges\nthis way:\n• One line listing all granted static privileges, if there are any, including WITH GRANT OPTION if\nappropriate.\n• One line listing all granted dynamic privileges for which GRANT OPTION is granted, if there are any,\nincluding WITH GRANT OPTION.\n• One line listing all granted dynamic privileges for which GRANT OPTION is not granted, if there are\nany, without WITH GRANT OPTION.\nWith the optional USING clause, SHOW GRANTS enables you to examine the privileges associated with\nroles for the user. Each role named in the USING clause must be granted to the user.\nSuppose that user u1 is assigned roles r1 and r2, as follows:\nCREATE ROLE 'r1', 'r2';\nGRANT SELECT ON db1.* TO 'r1';\nGRANT INSERT, UPDATE, DELETE ON db1.* TO 'r2';\nCREATE USER 'u1'@'localhost' IDENTIFIED BY 'u1pass';\nGRANT 'r1', 'r2' TO 'u1'@'localhost';\nSHOW GRANTS without USING shows the granted roles:\nmysql> SHOW GRANTS FOR 'u1'@'localhost';\n+---------------------------------------------+\n| Grants for u1@localhost                     |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO `u1`@`localhost`      |\n| GRANT `r1`@`%`,`r2`@`%` TO `u1`@`localhost` |\n+---------------------------------------------+\nAdding a USING clause causes the statement to also display the privileges associated with each role\nnamed in the clause:\nmysql> SHOW GRANTS FOR 'u1'@'localhost' USING 'r1';\n+---------------------------------------------+\n| Grants for u1@localhost                     |\n+---------------------------------------------+\n| GRANT USAGE ON *.* TO `u1`@`localhost`      |\n| GRANT SELECT ON `db1`.* TO `u1`@`localhost` |\n| GRANT `r1`@`%`,`r2`@`%` TO `u1`@`localhost` |\n+---------------------------------------------+\nmysql> SHOW GRANTS FOR 'u1'@'localhost' USING 'r2';\n+-------------------------------------------------------------+\n| Grants for u1@localhost                                     |\n+-------------------------------------------------------------+\n| GRANT USAGE ON *.* TO `u1`@`localhost`                      |\n| GRANT INSERT, UPDATE, DELETE ON `db1`.* TO `u1`@`localhost` |\n| GRANT `r1`@`%`,`r2`@`%` TO `u1`@`localhost`                 |\n+-------------------------------------------------------------+\nmysql> SHOW GRANTS FOR 'u1'@'localhost' USING 'r1', 'r2';\n+---------------------------------------------------------------------+\n| Grants for u1@localhost                                             |\n+---------------------------------------------------------------------+\n| GRANT USAGE ON *.* TO `u1`@`localhost`                              |\n| GRANT SELECT, INSERT, UPDATE, DELETE ON `db1`.* TO `u1`@`localhost` |\n| GRANT `r1`@`%`,`r2`@`%` TO `u1`@`localhost`                         |\n+---------------------------------------------------------------------+\nNote\nA privilege granted to an account is always in effect, but a role is not. The active\nroles for an account can differ across and within sessions, depending on the\nvalue of the activate_all_roles_on_login system variable, the account\ndefault roles, and whether SET ROLE has been executed within a session.\nMySQL supports partial revocation of global privileges, such that a global privilege can be restricted\nfrom applying to particular schemas (see Section 8.2.12, “Privilege Restriction Using Partial Revokes”).\nTo indicate which global schema privileges have been revoked for particular schemas, SHOW GRANTS\noutput includes REVOKE statements:\nmysql> SET PERSIST partial_revokes = ON;\nmysql> CREATE USER u1;\nmysql> GRANT SELECT, INSERT, DELETE ON *.* TO u1;\nmysql> REVOKE SELECT, INSERT ON mysql.* FROM u1;\nmysql> REVOKE DELETE ON world.* FROM u1;\nmysql> SHOW GRANTS FOR u1;\n+--------------------------------------------------+\n| Grants for u1@%                                  |\n+--------------------------------------------------+\n| GRANT SELECT, INSERT, DELETE ON *.* TO `u1`@`%`  |\n| REVOKE SELECT, INSERT ON `mysql`.* FROM `u1`@`%` |\n| REVOKE DELETE ON `world`.* FROM `u1`@`%`         |\n+--------------------------------------------------+\nSHOW GRANTS does not display privileges that are available to the named account but are granted to\na different account. For example, if an anonymous account exists, the named account might be able to\nuse its privileges, but SHOW GRANTS does not display them.\nSHOW GRANTS displays mandatory roles named in the mandatory_roles system variable value as\nfollows:\n• SHOW GRANTS without a FOR clause displays privileges for the current user, and includes mandatory\nroles.\n• SHOW GRANTS FOR user displays privileges for the named user, and does not include mandatory\nroles.\nThis behavior is for the benefit of applications that use the output of SHOW GRANTS FOR user to\ndetermine which privileges are granted explicitly to the named user. Were that output to include\nmandatory roles, it would be difficult to distinguish roles granted explicitly to the user from mandatory\nroles.\nFor the current user, applications can determine privileges with or without mandatory roles by using\nSHOW GRANTS or SHOW GRANTS FOR CURRENT_USER, respectively.\n15.7.7.23 SHOW INDEX Statement\nSHOW [EXTENDED] {INDEX | INDEXES | KEYS}\n    {FROM | IN} tbl_name\n    [{FROM | IN} db_name]\n    [WHERE expr]\nSHOW INDEX returns table index information. The format resembles that of the SQLStatistics call in\nODBC. This statement requires some privilege for any column in the table.\nmysql> SHOW INDEX FROM City\\G\n*************************** 1. row ***************************\n        Table: city\n   Non_unique: 0\n     Key_name: PRIMARY\n Seq_in_index: 1\n  Column_name: ID\n    Collation: A\n  Cardinality: 4188\n     Sub_part: NULL\n       Packed: NULL\n         Null:\n   Index_type: BTREE\n      Comment:\nIndex_comment:\n      Visible: YES\n   Expression: NULL\n*************************** 2. row ***************************\n        Table: city\n   Non_unique: 1\n     Key_name: CountryCode\n Seq_in_index: 1\n  Column_name: CountryCode\n    Collation: A\n  Cardinality: 232\n     Sub_part: NULL\n       Packed: NULL\n         Null:\n   Index_type: BTREE\n      Comment:\nIndex_comment:\n      Visible: YES\n   Expression: NULL\nAn alternative to tbl_name FROM db_name syntax is db_name.tbl_name. These two statements\nare equivalent:\nSHOW INDEX FROM mytable FROM mydb;\nSHOW INDEX FROM mydb.mytable;\nThe optional EXTENDED keyword causes the output to include information about hidden indexes that\nMySQL uses internally and are not accessible by users.\nThe WHERE clause can be given to select rows using more general conditions, as discussed in\nSection 28.8, “Extensions to SHOW Statements”.\nSHOW INDEX returns the following fields:\n• Table\nThe name of the table.\n• Non_unique\n0 if the index cannot contain duplicates, 1 if it can.\n• Key_name\nThe name of the index. If the index is the primary key, the name is always PRIMARY.\n• Seq_in_index\nThe column sequence number in the index, starting with 1.\n• Column_name\nThe column name. See also the description for the Expression column.\n• Collation\nHow the column is sorted in the index. This can have values A (ascending), D (descending), or NULL\n(not sorted).\n• Cardinality\nAn estimate of the number of unique values in the index. To update this number, run ANALYZE\nTABLE or (for MyISAM tables) myisamchk -a.\nCardinality is counted based on statistics stored as integers, so the value is not necessarily\nexact even for small tables. The higher the cardinality, the greater the chance that MySQL uses the\nindex when doing joins.\n• Sub_part\nThe index prefix. That is, the number of indexed characters if the column is only partly indexed, NULL\nif the entire column is indexed.\nNote\nPrefix limits are measured in bytes. However, prefix lengths for index\nspecifications in CREATE TABLE, ALTER TABLE, and CREATE INDEX\nstatements are interpreted as number of characters for nonbinary string types\n(CHAR, VARCHAR, TEXT) and number of bytes for binary string types (BINARY,\nVARBINARY, BLOB). Take this into account when specifying a prefix length for\na nonbinary string column that uses a multibyte character set.\nFor additional information about index prefixes, see Section 10.3.5, “Column Indexes”, and\nSection 15.1.15, “CREATE INDEX Statement”.\n• Packed\nIndicates how the key is packed. NULL if it is not.\n• Null\nContains YES if the column may contain NULL values and '' if not.\n• Index_type\nThe index method used (BTREE, FULLTEXT, HASH, RTREE).\n• Comment\nInformation about the index not described in its own column, such as disabled if the index is\ndisabled.\n• Index_comment\nAny comment provided for the index with a COMMENT attribute when the index was created.\n• Visible\nWhether the index is visible to the optimizer. See Section 10.3.12, “Invisible Indexes”.\n• Expression\nMySQL supports functional key parts (see Functional Key Parts); this affects both the Column_name\nand Expression columns:\n• For a nonfunctional key part, Column_name indicates the column indexed by the key part and\nExpression is NULL.\n• For a functional key part, Column_name column is NULL and Expression indicates the\nexpression for the key part.\nInformation about table indexes is also available from the INFORMATION_SCHEMA STATISTICS table.\nSee Section 28.3.34, “The INFORMATION_SCHEMA STATISTICS Table”. The extended information\nabout hidden indexes is available only using SHOW EXTENDED INDEX; it cannot be obtained from the\nSTATISTICS table.\nYou can list a table's indexes with the mysqlshow -k db_name tbl_name command.\nSHOW INDEX includes the table's generated invisible key, if it has one, by default.\nYou can cause this information to be suppressed in the statement's output by setting\nshow_gipk_in_create_table_and_information_schema = OFF. For more information, see\nSection 15.1.20.11, “Generated Invisible Primary Keys”.\n15.7.7.24 SHOW OPEN TABLES Statement\nSHOW OPEN TABLES\n    [{FROM | IN} db_name]\n    [LIKE 'pattern' | WHERE expr]\nSHOW OPEN TABLES lists the non-TEMPORARY tables that are currently open in the table cache. See\nSection 10.4.3.1, “How MySQL Opens and Closes Tables”. The FROM clause, if present, restricts the\ntables shown to those present in the db_name database. The LIKE clause, if present, indicates which\ntable names to match. The WHERE clause can be given to select rows using more general conditions,\nas discussed in Section 28.8, “Extensions to SHOW Statements”.\nSHOW OPEN TABLES output has these columns:\n• Database\nThe database containing the table.\n• Table\nThe table name.\n• In_use\nThe number of table locks or lock requests there are for the table. For example, if one client acquires\na lock for a table using LOCK TABLE t1 WRITE, In_use is 1. If another client issues LOCK TABLE\nt1 WRITE while the table remains locked, the client blocks, waiting for the lock, but the lock request\ncauses In_use to be 2. If the count is zero, the table is open but not currently being used. In_use\nis also increased by the HANDLER ... OPEN statement and decreased by HANDLER ... CLOSE.\n• Name_locked\nWhether the table name is locked. Name locking is used for operations such as dropping or\nrenaming tables.\nIf you have no privileges for a table, it does not show up in the output from SHOW OPEN TABLES.\n15.7.7.25 SHOW PARSE_TREE Statement\nSHOW PARSE_TREE select_statement\nSHOW PARSE_TREE displays a representation of the parse tree for the input SELECT statement, in\nJSON format.\nNote\nThis statement is available only in debug builds, or if the MySQL server was\nbuilt using -DWITH_SHOW_PARSE_TREE. It is intended for use in testing and\ndevelopment only, and not in production.\nExample:\nmysql> SHOW PARSE_TREE SELECT * FROM t3 WHERE o_id > 2\\G\n*************************** 1. row ***************************\nShow_parse_tree: {\n  \"text\": \"SELECT * FROM t3 WHERE o_id > 2\",\n  \"type\": \"PT_select_stmt\",\n  \"components\": [\n    {\n      \"text\": \"SELECT * FROM t3 WHERE o_id > 2\",\n      \"type\": \"PT_query_expression\",\n      \"components\": [\n        {\n          \"text\": \"SELECT * FROM t3 WHERE o_id > 2\",\n          \"type\": \"PT_query_specification\",\n          \"components\": [\n            {\n              \"text\": \"*\",\n              \"type\": \"PT_select_item_list\",\n              \"components\": [\n                {\n                  \"text\": \"*\",\n                  \"type\": \"Item_asterisk\"\n                }\n              ]\n            },\n            {\n              \"text\": \"t3\",\n              \"type\": \"PT_table_factor_table_ident\",\n              \"table_ident\": \"`t3`\"\n            },\n            {\n              \"text\": \"o_id > 2\",\n              \"type\": \"PTI_where\",\n              \"components\": [\n                {\n                  \"text\": \"o_id > 2\",\n                  \"type\": \"PTI_comp_op\",\n                  \"operator\": \">\",\n                  \"components\": [\n                    {\n                      \"text\": \"o_id\",\n                      \"type\": \"PTI_simple_ident_ident\"\n                    },\n                    {\n                      \"text\": \"2\",\n                      \"type\": \"Item_int\"\n                    }\n                  ]\n                }\n              ]\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n1 row in set (0.01 sec)\n15.7.7.26 SHOW PLUGINS Statement\nSHOW PLUGINS\nSHOW PLUGINS displays information about server plugins.\nExample of SHOW PLUGINS output:\nmysql> SHOW PLUGINS\\G\n*************************** 1. row ***************************\n   Name: binlog\n Status: ACTIVE\n   Type: STORAGE ENGINE\nLibrary: NULL\nLicense: GPL\n*************************** 2. row ***************************\n   Name: CSV\n Status: ACTIVE\n   Type: STORAGE ENGINE\nLibrary: NULL\nLicense: GPL\n*************************** 3. row ***************************\n   Name: MEMORY\n Status: ACTIVE\n   Type: STORAGE ENGINE\nLibrary: NULL\nLicense: GPL\n*************************** 4. row ***************************\n   Name: MyISAM\n Status: ACTIVE\n   Type: STORAGE ENGINE\nLibrary: NULL\nLicense: GPL\n...\nSHOW PLUGINS output has these columns:\n• Name\nThe name used to refer to the plugin in statements such as INSTALL PLUGIN and UNINSTALL\nPLUGIN.\n• Status\nThe plugin status, one of ACTIVE, INACTIVE, DISABLED, DELETING, or DELETED.\n• Type\nThe type of plugin, such as STORAGE ENGINE, INFORMATION_SCHEMA, or AUTHENTICATION.\n• Library\nThe name of the plugin shared library file. This is the name used to refer to the plugin file in\nstatements such as INSTALL PLUGIN and UNINSTALL PLUGIN. This file is located in the directory\nnamed by the plugin_dir system variable. If the library name is NULL, the plugin is compiled in\nand cannot be uninstalled with UNINSTALL PLUGIN.\n• License\nHow the plugin is licensed (for example, GPL).\nFor plugins installed with INSTALL PLUGIN, the Name and Library values are also registered in the\nmysql.plugin system table.\nFor information about plugin data structures that form the basis of the information displayed by SHOW\nPLUGINS, see The MySQL Plugin API.\nPlugin information is also available from the INFORMATION_SCHEMA .PLUGINS table. See\nSection 28.3.22, “The INFORMATION_SCHEMA PLUGINS Table”.\n15.7.7.27 SHOW PRIVILEGES Statement\nSHOW PRIVILEGES\nSHOW PRIVILEGES shows the list of system privileges that the MySQL server supports. The privileges\ndisplayed include all static privileges, and all currently registered dynamic privileges.\nmysql> SHOW PRIVILEGES\\G\n*************************** 1. row ***************************\nPrivilege: Alter\n  Context: Tables\n  Comment: To alter the table\n*************************** 2. row ***************************\nPrivilege: Alter routine\n  Context: Functions,Procedures\n  Comment: To alter or drop stored functions/procedures\n*************************** 3. row ***************************\nPrivilege: Create\n  Context: Databases,Tables,Indexes\n  Comment: To create new databases and tables\n*************************** 4. row ***************************\nPrivilege: Create routine\n  Context: Databases\n  Comment: To use CREATE FUNCTION/PROCEDURE\n*************************** 5. row ***************************\nPrivilege: Create role\n  Context: Server Admin\n  Comment: To create new roles\n...\nPrivileges belonging to a specific user are displayed by the SHOW GRANTS statement. See\nSection 15.7.7.22, “SHOW GRANTS Statement”, for more information.\n15.7.7.28 SHOW PROCEDURE CODE Statement\nSHOW PROCEDURE CODE proc_name\nThis statement is a MySQL extension that is available only for servers that have been built with\ndebugging support. It displays a representation of the internal implementation of the named stored\nprocedure. A similar statement, SHOW FUNCTION CODE, displays information about stored functions\n(see Section 15.7.7.20, “SHOW FUNCTION CODE Statement”).\nTo use either statement, you must be the user named as the routine DEFINER, have the\nSHOW_ROUTINE privilege, or have the SELECT privilege at the global level.\nIf the named routine is available, each statement produces a result set. Each row in the result set\ncorresponds to one “instruction” in the routine. The first column is Pos, which is an ordinal number\nbeginning with 0. The second column is Instruction, which contains an SQL statement (usually\nchanged from the original source), or a directive which has meaning only to the stored-routine handler.\nmysql> DELIMITER //\nmysql> CREATE PROCEDURE p1 ()\n       BEGIN\n         DECLARE fanta INT DEFAULT 55;\n         DROP TABLE t2;\n         LOOP\n           INSERT INTO t3 VALUES (fanta);\n           END LOOP;\n         END//\nQuery OK, 0 rows affected (0.01 sec)\nmysql> SHOW PROCEDURE CODE p1//\n+-----+----------------------------------------+\n| Pos | Instruction                            |\n+-----+----------------------------------------+\n|   0 | set fanta@0 55                         |\n|   1 | stmt 9 \"DROP TABLE t2\"                 |\n|   2 | stmt 5 \"INSERT INTO t3 VALUES (fanta)\" |\n|   3 | jump 2                                 |\n+-----+----------------------------------------+\n4 rows in set (0.00 sec)\nmysql> CREATE FUNCTION test.hello (s CHAR(20))\n       RETURNS CHAR(50) DETERMINISTIC\n       RETURN CONCAT('Hello, ',s,'!');\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SHOW FUNCTION CODE test.hello;\n+-----+---------------------------------------+\n| Pos | Instruction                           |\n+-----+---------------------------------------+\n|   0 | freturn 254 concat('Hello, ',s@0,'!') |\n+-----+---------------------------------------+\n1 row in set (0.00 sec)\nIn this example, the nonexecutable BEGIN and END statements have disappeared, and for the\nDECLARE variable_name statement, only the executable part appears (the part where the default is\nassigned). For each statement that is taken from source, there is a code word stmt followed by a type\n(9 means DROP, 5 means INSERT, and so on). The final row contains an instruction jump 2, meaning\nGOTO instruction #2.\n15.7.7.29 SHOW PROCEDURE STATUS Statement\nSHOW PROCEDURE STATUS\n    [LIKE 'pattern' | WHERE expr]\nThis statement is a MySQL extension. It returns characteristics of a stored procedure, such as the\ndatabase, name, type, creator, creation and modification dates, and character set information. A\nsimilar statement, SHOW FUNCTION STATUS, displays information about stored functions (see\nSection 15.7.7.21, “SHOW FUNCTION STATUS Statement”).\nTo use either statement, you must be the user named as the routine DEFINER, have the\nSHOW_ROUTINE privilege, have the SELECT privilege at the global level, or have the CREATE\nROUTINE, ALTER ROUTINE, or EXECUTE privilege granted at a scope that includes the routine.\nThe LIKE clause, if present, indicates which procedure or function names to match. The WHERE clause\ncan be given to select rows using more general conditions, as discussed in Section 28.8, “Extensions\nto SHOW Statements”.\nmysql> SHOW PROCEDURE STATUS LIKE 'sp1'\\G\n*************************** 1. row ***************************\n                  Db: test\n                Name: sp1\n                Type: PROCEDURE\n             Definer: testuser@localhost\n            Modified: 2018-08-08 13:54:11\n             Created: 2018-08-08 13:54:11\n       Security_type: DEFINER\n             Comment:\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\nmysql> SHOW FUNCTION STATUS LIKE 'hello'\\G\n*************************** 1. row ***************************\n                  Db: test\n                Name: hello\n                Type: FUNCTION\n             Definer: testuser@localhost\n            Modified: 2020-03-10 11:10:03\n             Created: 2020-03-10 11:10:03\n       Security_type: DEFINER\n             Comment:\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\ncharacter_set_client is the session value of the character_set_client system\nvariable when the routine was created. collation_connection is the session value of the\ncollation_connection system variable when the routine was created. Database Collation is\nthe collation of the database with which the routine is associated.\nStored routine information is also available from the INFORMATION_SCHEMA PARAMETERS and\nROUTINES tables. See Section 28.3.20, “The INFORMATION_SCHEMA PARAMETERS Table”, and\nSection 28.3.30, “The INFORMATION_SCHEMA ROUTINES Table”.\n15.7.7.30 SHOW PROCESSLIST Statement\nSHOW [FULL] PROCESSLIST\nImportant\nThe INFORMATION SCHEMA implementation of SHOW PROCESSLIST\nis deprecated and subject to removal in a future MySQL release. It is\nrecommended to use the Performance Schema implementation of SHOW\nPROCESSLIST instead.\nThe MySQL process list indicates the operations currently being performed by the set of threads\nexecuting within the server. The SHOW PROCESSLIST statement is one source of process information.\nFor a comparison of this statement with other sources, see Sources of Process Information.\nNote\nAn alternative implementation for SHOW PROCESSLIST is available based\non the Performance Schema processlist table, which, unlike the default\nSHOW PROCESSLIST implementation, does not require a mutex and has\nbetter performance characteristics. For details, see Section 29.12.22.8, “The\nprocesslist Table”.\nIf you have the PROCESS privilege, you can see all threads, even those belonging to other users.\nOtherwise (without the PROCESS privilege), nonanonymous users have access to information about\ntheir own threads but not threads for other users, and anonymous users have no access to thread\ninformation.\nWithout the FULL keyword, SHOW PROCESSLIST displays only the first 100 characters of each\nstatement in the Info field.\nThe SHOW PROCESSLIST statement is very useful if you get the “too many connections” error\nmessage and want to find out what is going on. MySQL reserves one extra connection to be used by\naccounts that have the CONNECTION_ADMIN privilege (or the deprecated SUPER privilege), to ensure\nthat administrators should always be able to connect and check the system (assuming that you are not\ngiving this privilege to all your users).\nThreads can be killed with the KILL statement. See Section 15.7.8.4, “KILL Statement”.\nExample of SHOW PROCESSLIST output:\nmysql> SHOW FULL PROCESSLIST\\G\n*************************** 1. row ***************************\n     Id: 1\n   User: system user\n   Host:\n     db: NULL\nCommand: Connect\n   Time: 1030455\n  State: Waiting for source to send event\n   Info: NULL\n*************************** 2. row ***************************\n     Id: 2\n   User: system user\n   Host:\n     db: NULL\nCommand: Connect\n   Time: 1004\n  State: Has read all relay log; waiting for the replica\n         I/O thread to update it\n   Info: NULL\n*************************** 3. row ***************************\n     Id: 3112\n   User: replikator\n   Host: artemis:2204\n     db: NULL\nCommand: Binlog Dump\n   Time: 2144\n  State: Has sent all binlog to replica; waiting for binlog to be updated\n   Info: NULL\n*************************** 4. row ***************************\n     Id: 3113\n   User: replikator\n   Host: iconnect2:45781\n     db: NULL\nCommand: Binlog Dump\n   Time: 2086\n  State: Has sent all binlog to replica; waiting for binlog to be updated\n   Info: NULL\n*************************** 5. row ***************************\n     Id: 3123\n   User: stefan\n   Host: localhost\n     db: apollon\nCommand: Query\n   Time: 0\n  State: NULL\n   Info: SHOW FULL PROCESSLIST\nSHOW PROCESSLIST output has these columns:\n• Id\nThe connection identifier. This is the same value displayed in the ID column of the\nINFORMATION_SCHEMA PROCESSLIST table, displayed in the PROCESSLIST_ID column of the\nPerformance Schema threads table, and returned by the CONNECTION_ID() function within the\nthread.\n• User\nThe MySQL user who issued the statement. A value of system user refers to a nonclient thread\nspawned by the server to handle tasks internally, for example, a delayed-row handler thread or\nan I/O (receiver) or SQL (applier) thread used on replica hosts. For system user, there is no\nhost specified in the Host column. unauthenticated user refers to a thread that has become\nassociated with a client connection but for which authentication of the client user has not yet\noccurred. event_scheduler refers to the thread that monitors scheduled events (see Section 27.5,\n“Using the Event Scheduler”).\nNote\nA User value of system user is distinct from the SYSTEM_USER privilege.\nThe former designates internal threads. The latter distinguishes the system\nuser and regular user account categories (see Section 8.2.11, “Account\nCategories”).\n• Host\nThe host name of the client issuing the statement (except for system user, for which there is no\nhost). The host name for TCP/IP connections is reported in host_name:client_port format to\nmake it easier to determine which client is doing what.\n• db\nThe default database for the thread, or NULL if none has been selected.\n• Command\nThe type of command the thread is executing on behalf of the client, or Sleep if the session is idle.\nFor descriptions of thread commands, see Section 10.14, “Examining Server Thread (Process)\nInformation”. The value of this column corresponds to the COM_xxx commands of the client/server\nprotocol and Com_xxx status variables. See Section 7.1.10, “Server Status Variables”.\n• Time\nThe time in seconds that the thread has been in its current state. For a replica SQL thread, the value\nis the number of seconds between the timestamp of the last replicated event and the real time of the\nreplica host. See Section 19.2.3, “Replication Threads”.\n• State\nAn action, event, or state that indicates what the thread is doing. For descriptions of State values,\nsee Section 10.14, “Examining Server Thread (Process) Information”.\nMost states correspond to very quick operations. If a thread stays in a given state for many seconds,\nthere might be a problem that needs to be investigated.\n• Info\nThe statement the thread is executing, or NULL if it is executing no statement. The statement\nmight be the one sent to the server, or an innermost statement if the statement executes other\nstatements. For example, if a CALL statement executes a stored procedure that is executing a\nSELECT statement, the Info value shows the SELECT statement.\n15.7.7.31 SHOW PROFILE Statement\nSHOW PROFILE [type [, type] ... ]\n    [FOR QUERY n]\n    [LIMIT row_count [OFFSET offset]]\ntype: {\n    ALL\n  | BLOCK IO\n  | CONTEXT SWITCHES\n  | CPU\n  | IPC\n  | MEMORY\n  | PAGE FAULTS\n  | SOURCE\n  | SWAPS\n}\nThe SHOW PROFILE and SHOW PROFILES statements display profiling information that indicates\nresource usage for statements executed during the course of the current session.\nNote\nThe SHOW PROFILE and SHOW PROFILES statements are deprecated; expect\nthem to be removed in a future MySQL release. Use the Performance Schema\ninstead; see Section 29.19.1, “Query Profiling Using Performance Schema”.\nTo control profiling, use the profiling session variable, which has a default value of 0 (OFF). Enable\nprofiling by setting profiling to 1 or ON:\nmysql> SET profiling = 1;\nSHOW PROFILES displays a list of the most recent statements sent to the server. The size of the list is\ncontrolled by the profiling_history_size session variable, which has a default value of 15. The\nmaximum value is 100. Setting the value to 0 has the practical effect of disabling profiling.\nAll statements are profiled except SHOW PROFILE and SHOW PROFILES, so neither of those\nstatements appears in the profile list. Malformed statements are profiled. For example, SHOW\nPROFILING is an illegal statement, and a syntax error occurs if you try to execute it, but it shows up in\nthe profiling list.\nSHOW PROFILE displays detailed information about a single statement. Without the FOR QUERY n\nclause, the output pertains to the most recently executed statement. If FOR QUERY n is included, SHOW\nPROFILE displays information for statement n. The values of n correspond to the Query_ID values\ndisplayed by SHOW PROFILES.\nThe LIMIT row_count clause may be given to limit the output to row_count rows. If LIMIT is\ngiven, OFFSET offset may be added to begin the output offset rows into the full set of rows.\nBy default, SHOW PROFILE displays Status and Duration columns. The Status values are like\nthe State values displayed by SHOW PROCESSLIST, although there might be some minor differences\nin interpretation for the two statements for some status values (see Section 10.14, “Examining Server\nThread (Process) Information”).\nOptional type values may be specified to display specific additional types of information:\n• ALL displays all information\n• BLOCK IO displays counts for block input and output operations\n• CONTEXT SWITCHES displays counts for voluntary and involuntary context switches\n• CPU displays user and system CPU usage times\n• IPC displays counts for messages sent and received\n• MEMORY is not currently implemented\n• PAGE FAULTS displays counts for major and minor page faults\n• SOURCE displays the names of functions from the source code, together with the name and line\nnumber of the file in which the function occurs\n• SWAPS displays swap counts\nProfiling is enabled per session. When a session ends, its profiling information is lost.\nmysql> SELECT @@profiling;\n+-------------+\n| @@profiling |\n+-------------+\n|           0 |\n+-------------+\n1 row in set (0.00 sec)\nmysql> SET profiling = 1;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> DROP TABLE IF EXISTS t1;\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\nmysql> CREATE TABLE T1 (id INT);\nQuery OK, 0 rows affected (0.01 sec)\nmysql> SHOW PROFILES;\n+----------+----------+--------------------------+\n| Query_ID | Duration | Query                    |\n+----------+----------+--------------------------+\n|        0 | 0.000088 | SET PROFILING = 1        |\n|        1 | 0.000136 | DROP TABLE IF EXISTS t1  |\n|        2 | 0.011947 | CREATE TABLE t1 (id INT) |\n+----------+----------+--------------------------+\n3 rows in set (0.00 sec)\nmysql> SHOW PROFILE;\n+----------------------+----------+\n| Status               | Duration |\n+----------------------+----------+\n| checking permissions | 0.000040 |\n| creating table       | 0.000056 |\n| After create         | 0.011363 |\n| query end            | 0.000375 |\n| freeing items        | 0.000089 |\n| logging slow query   | 0.000019 |\n| cleaning up          | 0.000005 |\n+----------------------+----------+\n7 rows in set (0.00 sec)\nmysql> SHOW PROFILE FOR QUERY 1;\n+--------------------+----------+\n| Status             | Duration |\n+--------------------+----------+\n| query end          | 0.000107 |\n| freeing items      | 0.000008 |\n| logging slow query | 0.000015 |\n| cleaning up        | 0.000006 |\n+--------------------+----------+\n4 rows in set (0.00 sec)\nmysql> SHOW PROFILE CPU FOR QUERY 2;\n+----------------------+----------+----------+------------+\n| Status               | Duration | CPU_user | CPU_system |\n+----------------------+----------+----------+------------+\n| checking permissions | 0.000040 | 0.000038 |   0.000002 |\n| creating table       | 0.000056 | 0.000028 |   0.000028 |\n| After create         | 0.011363 | 0.000217 |   0.001571 |\n| query end            | 0.000375 | 0.000013 |   0.000028 |\n| freeing items        | 0.000089 | 0.000010 |   0.000014 |\n| logging slow query   | 0.000019 | 0.000009 |   0.000010 |\n| cleaning up          | 0.000005 | 0.000003 |   0.000002 |\n+----------------------+----------+----------+------------+\n7 rows in set (0.00 sec)\nNote\nProfiling is only partially functional on some architectures. For values that\ndepend on the getrusage() system call, NULL is returned on systems such\nas Windows that do not support the call. In addition, profiling is per process and\nnot per thread. This means that activity on threads within the server other than\nyour own may affect the timing information that you see.\nProfiling information is also available from the INFORMATION_SCHEMA PROFILING table. See\nSection 28.3.24, “The INFORMATION_SCHEMA PROFILING Table”. For example, the following\nqueries are equivalent:\nSHOW PROFILE FOR QUERY 2;\nSELECT STATE, FORMAT(DURATION, 6) AS DURATION\nFROM INFORMATION_SCHEMA.PROFILING\nWHERE QUERY_ID = 2 ORDER BY SEQ;\n15.7.7.32 SHOW PROFILES Statement\nSHOW PROFILES\nThe SHOW PROFILES statement, together with SHOW PROFILE, displays profiling information that\nindicates resource usage for statements executed during the course of the current session. For more\ninformation, see Section 15.7.7.31, “SHOW PROFILE Statement”.\nNote\nThe SHOW PROFILE and SHOW PROFILES statements are deprecated; expect\nit to be removed in a future MySQL release. Use the Performance Schema\ninstead; see Section 29.19.1, “Query Profiling Using Performance Schema”.\n15.7.7.33 SHOW RELAYLOG EVENTS Statement\nSHOW RELAYLOG EVENTS\n    [IN 'log_name']\n    [FROM pos]\n    [LIMIT [offset,] row_count]\n    [channel_option]\nchannel_option:\n    FOR CHANNEL channel\nShows the events in the relay log of a replica. If you do not specify 'log_name', the first relay log\nis displayed. This statement has no effect on the source. SHOW RELAYLOG EVENTS requires the\nREPLICATION SLAVE privilege.\nThe LIMIT clause has the same syntax as for the SELECT statement. See Section 15.2.13, “SELECT\nStatement”.\nNote\nIssuing a SHOW RELAYLOG EVENTS with no LIMIT clause could start a very\ntime- and resource-consuming process because the server returns to the client\nthe complete contents of the relay log (including all statements modifying data\nthat have been received by the replica).\nThe optional FOR CHANNEL channel clause enables you to name which replication channel the\nstatement applies to. Providing a FOR CHANNEL channel clause applies the statement to a specific\nreplication channel. If no channel is named and no extra channels exist, the statement applies to the\ndefault channel.\nWhen using multiple replication channels, if a SHOW RELAYLOG EVENTS statement does not have a\nchannel defined using a FOR CHANNEL channel clause an error is generated. See Section 19.2.2,\n“Replication Channels” for more information.\nSHOW RELAYLOG EVENTS displays the following fields for each event in the relay log:\n• Log_name\nThe name of the file that is being listed.\n• Pos\nThe position at which the event occurs.\n• Event_type\nAn identifier that describes the event type.\n• Server_id\nThe server ID of the server on which the event originated.\n• End_log_pos\nThe value of End_log_pos for this event in the source's binary log.\n• Info\nMore detailed information about the event type. The format of this information depends on the event\ntype.\nFor compressed transaction payloads, the Transaction_payload_event is first printed as a single\nunit, then it is unpacked and each event inside it is printed.\nSome events relating to the setting of user and system variables are not included in the output from\nSHOW RELAYLOG EVENTS. To get complete coverage of events within a relay log, use mysqlbinlog.\n15.7.7.34 SHOW REPLICA STATUS Statement\nSHOW REPLICA STATUS [FOR CHANNEL channel]\nThis statement provides status information on essential parameters of the replica threads. The\nstatement requires the REPLICATION CLIENT privilege (or the deprecated SUPER privilege).\nSHOW REPLICA STATUS is nonblocking. When run concurrently with STOP REPLICA, SHOW\nREPLICA STATUS returns without waiting for STOP REPLICA to finish shutting down the replication\nSQL (applier) thread or replication I/O (receiver) thread (or both). This permits use in monitoring and\nother applications where getting an immediate response from SHOW REPLICA STATUS is more\nimportant than ensuring that it returned the latest data.\nIf you issue this statement using the mysql client, you can use a \\G statement terminator rather than a\nsemicolon to obtain a more readable vertical layout:\nmysql> SHOW REPLICA STATUS\\G\n*************************** 1. row ***************************\n             Replica_IO_State: Waiting for source to send event\n                  Source_Host: 127.0.0.1\n                  Source_User: root\n                  Source_Port: 13000\n                Connect_Retry: 1\n              Source_Log_File: master-bin.000001\n          Read_Source_Log_Pos: 927\n               Relay_Log_File: slave-relay-bin.000002\n                Relay_Log_Pos: 1145\n        Relay_Source_Log_File: master-bin.000001\n           Replica_IO_Running: Yes\n          Replica_SQL_Running: Yes\n              Replicate_Do_DB:\n          Replicate_Ignore_DB:\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table:\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Source_Log_Pos: 927\n              Relay_Log_Space: 1355\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Source_SSL_Allowed: No\n           Source_SSL_CA_File:\n           Source_SSL_CA_Path:\n              Source_SSL_Cert:\n            Source_SSL_Cipher:\n               Source_SSL_Key:\n        Seconds_Behind_Source: 0\nSource_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Source_Server_Id: 1\n                  Source_UUID: 73f86016-978b-11ee-ade5-8d2a2a562feb\n             Source_Info_File: mysql.slave_master_info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n    Replica_SQL_Running_State: Replica has read all relay log; waiting for more updates\n           Source_Retry_Count: 10\n                  Source_Bind:\n      Last_IO_Error_Timestamp:\n     Last_SQL_Error_Timestamp:\n               Source_SSL_Crl:\n           Source_SSL_Crlpath:\n           Retrieved_Gtid_Set: 73f86016-978b-11ee-ade5-8d2a2a562feb:1-3\n            Executed_Gtid_Set: 73f86016-978b-11ee-ade5-8d2a2a562feb:1-3\n                Auto_Position: 1\n         Replicate_Rewrite_DB:\n                 Channel_Name:\n           Source_TLS_Version:\n       Source_public_key_path:\n        Get_Source_public_key: 0\n            Network_Namespace:\nThe Performance Schema provides tables that expose replication information. This is similar to the\ninformation available from the SHOW REPLICA STATUS statement, but represented in table form. For\ndetails, see Section 29.12.11, “Performance Schema Replication Tables”.\nYou can set the GTID_ONLY option for the CHANGE REPLICATION SOURCE TO statement to stop a\nreplication channel from persisting file names and file positions in the replication metadata repositories.\nWith this setting, file positions for the source binary log file and the relay log file are tracked in memory.\nThe SHOW REPLICA STATUS statement still displays file positions in normal use. However, because\nthe file positions are not being regularly updated in the connection metadata repository and the applier\nmetadata repository except in a few situations, they are likely to be out of date if the server is restarted.\nFor a replication channel with the GTID_ONLY setting after a server start, the read and applied file\npositions for the source binary log file (Read_Source_Log_Pos and Exec_Source_Log_Pos) are\nset to zero, and the file names (Source_Log_File and Relay_Source_Log_File) are set to\nINVALID. The relay log file name (Relay_Log_File) is set according to the relay_log_recovery\nsetting, either a new file that was created at server start or the first relay log file present. The file\nposition (Relay_Log_Pos) is set to position 4, and GTID auto-skip is used to skip any transactions in\nthe file that were already applied.\nWhen the receiver thread contacts the source and gets valid position information, the read position\n(Read_Source_Log_Pos) and file name (Source_Log_File) are updated with the correct\ndata and become valid. When the applier thread applies a transaction from the source, or skips\nan already executed transaction, the executed position (Exec_Source_Log_Pos) and file name\n(Relay_Source_Log_File) are updated with the correct data and become valid. The relay log file\nposition (Relay_Log_Pos) is also updated at that time.\nThe following list describes the fields returned by SHOW REPLICA STATUS. For additional information\nabout interpreting their meanings, see Section 19.1.7.1, “Checking Replication Status”.\n• Replica_IO_State\nA copy of the State field of the SHOW PROCESSLIST output for the replica I/O (receiver) thread.\nThis tells you what the thread is doing: trying to connect to the source, waiting for events from the\nsource, reconnecting to the source, and so on. For a listing of possible states, see Section 10.14.5,\n“Replication I/O (Receiver) Thread States”.\n• Source_Host\nThe source host that the replica is connected to.\n• Source_User\nThe user name of the account used to connect to the source.\n• Source_Port\nThe port used to connect to the source.\n• Connect_Retry\nThe number of seconds between connect retries (default 60). This can be set with a CHANGE\nREPLICATION SOURCE TO statement.\n• Source_Log_File\nThe name of the source binary log file from which the I/O (receiver) thread is currently reading. This\nis set to INVALID for a replication channel with the GTID_ONLY setting after a server start. It will be\nupdated when the replica contacts the source.\n• Read_Source_Log_Pos\nThe position in the current source binary log file up to which the I/O (receiver) thread has read. This\nis set to zero for a replication channel with the GTID_ONLY setting after a server start. It will be\nupdated when the replica contacts the source.\n• Relay_Log_File\nThe name of the relay log file from which the SQL (applier) thread is currently reading and executing.\n• Relay_Log_Pos\nThe position in the current relay log file up to which the SQL (applier) thread has read and executed.\n• Relay_Source_Log_File\nThe name of the source binary log file containing the most recent event executed by the SQL\n(applier) thread. This is set to INVALID for a replication channel with the GTID_ONLY setting after a\nserver start. It will be updated when a transaction is executed or skipped.\n• Replica_IO_Running\nWhether the replication I/O (receiver) thread is started and has connected successfully to the source.\nInternally, the state of this thread is represented by one of the following three values:\n• MYSQL_REPLICA_NOT_RUN. \n The replication I/O (receiver) thread is not running. For this\nstate, Replica_IO_Running is No.\n• MYSQL_REPLICA_RUN_NOT_CONNECT. \n The replication I/O (receiver) thread is running, but\nis not connected to a replication source. For this state, Replica_IO_Running is Connecting.\n• MYSQL_REPLICA_RUN_CONNECT. \n The replication I/O (receiver) thread is running, and is\nconnected to a replication source. For this state, Replica_IO_Running is Yes.\n• Replica_SQL_Running\nWhether the replication SQL (applier) thread is started.\n• Replicate_Do_DB, Replicate_Ignore_DB\nThe names of any databases that were specified with the --replicate-do-db and --\nreplicate-ignore-db options, or the CHANGE REPLICATION FILTER statement. If the\nFOR CHANNEL clause was used, the channel specific replication filters are shown. Otherwise, the\nreplication filters for every replication channel are shown.\n• Replicate_Do_Table, Replicate_Ignore_Table, Replicate_Wild_Do_Table,\nReplicate_Wild_Ignore_Table\nThe names of any tables that were specified with the --replicate-do-table, --replicate-\nignore-table, --replicate-wild-do-table, and --replicate-wild-ignore-table\noptions, or the CHANGE REPLICATION FILTER statement. If the FOR CHANNEL clause was used,\nthe channel specific replication filters are shown. Otherwise, the replication filters for every replication\nchannel are shown.\n• Last_Errno, Last_Error\nThese columns are aliases for Last_SQL_Errno and Last_SQL_Error.\nIssuing RESET BINARY LOGS AND GTIDS or RESET REPLICA resets the values shown in these\ncolumns.\nNote\nWhen the replication SQL thread receives an error, it reports the error first,\nthen stops the SQL thread. This means that there is a small window of\ntime during which SHOW REPLICA STATUS shows a nonzero value for\nLast_SQL_Errno even though Replica_SQL_Running still displays Yes.\n• Skip_Counter\nThe current value of the sql_replica_skip_counter system variable.\n• Exec_Source_Log_Pos\nThe position in the current source binary log file to which the replication SQL thread has read and\nexecuted, marking the start of the next transaction or event to be processed. This is set to zero\nfor a replication channel with the GTID_ONLY setting after a server start. It will be updated when a\ntransaction is executed or skipped.\nYou can use this value with the CHANGE REPLICATION SOURCE TO statement's\nSOURCE_LOG_POS option when starting a new replica from an existing replica, so that the\nnew replica reads from this point. The coordinates given by (Relay_Source_Log_File,\nExec_Source_Log_Pos) in the source's binary log correspond to the coordinates given by\n(Relay_Log_File, Relay_Log_Pos) in the relay log.\nInconsistencies in the sequence of transactions from the relay log which have been executed can\ncause this value to be a “low-water mark”. In other words, transactions appearing before the position\nare guaranteed to have committed, but transactions after the position may have committed or not.\nIf these gaps need to be corrected, use START REPLICA UNTIL SQL_AFTER_MTS_GAPS. See\nSection 19.5.1.35, “Replication and Transaction Inconsistencies” for more information.\n• Relay_Log_Space\nThe total combined size of all existing relay log files.\n• Until_Condition, Until_Log_File, Until_Log_Pos\nThe values specified in the UNTIL clause of the START REPLICA statement.\nUntil_Condition has these values:\n• None if no UNTIL clause was specified.\n• Source if the replica is reading until a given position in the source's binary log.\n• Relay if the replica is reading until a given position in its relay log.\n• SQL_BEFORE_GTIDS if the replication SQL thread is processing transactions until it has reached\nthe first transaction whose GTID is listed in the gtid_set.\n• SQL_AFTER_GTIDS if the replication threads are processing all transactions until the last\ntransaction in the gtid_set has been processed by both threads.\n• SQL_AFTER_MTS_GAPS if a multithreaded replica's SQL threads are running until no more gaps\nare found in the relay log.\nUntil_Log_File and Until_Log_Pos indicate the log file name and position that define the\ncoordinates at which the replication SQL thread stops executing.\nFor more information on UNTIL clauses, see Section 15.4.2.4, “START REPLICA Statement”.\n• Source_SSL_Allowed, Source_SSL_CA_File, Source_SSL_CA_Path, Source_SSL_Cert,\nSource_SSL_Cipher, Source_SSL_CRL_File, Source_SSL_CRL_Path, Source_SSL_Key,\nSource_SSL_Verify_Server_Cert\nThese fields show the SSL parameters used by the replica to connect to the source, if any.\nSource_SSL_Allowed has these values:\n• Yes if an SSL connection to the source is permitted.\n• No if an SSL connection to the source is not permitted.\n• Ignored if an SSL connection is permitted but the replica server does not have SSL support\nenabled.\nThe values of the other SSL-related fields correspond to the values of the SOURCE_SSL_* options of\nthe CHANGE REPLICATION SOURCE TO statement.\n• Seconds_Behind_Source\nThis field is an indication of how “late” the replica is:\n• When the replica is actively processing updates, this field shows the difference between the\ncurrent timestamp on the replica and the original timestamp logged on the source for the event\ncurrently being processed on the replica.\n• When no event is currently being processed on the replica, this value is 0.\nIn essence, this field measures the time difference in seconds between the replication SQL (applier)\nthread and the replication I/O (receiver) thread. If the network connection between source and replica\nis fast, the replication receiver thread is very close to the source, so this field is a good approximation\nof how late the replication applier thread is compared to the source. If the network is slow, this is\nnot a good approximation; the replication applier thread may quite often be caught up with the slow-\nreading replication receiver thread, so Seconds_Behind_Source often shows a value of 0, even\nif the replication receiver thread is late compared to the source. In other words, this column is useful\nonly for fast networks.\nThis time difference computation works even if the source and replica do not have identical clock\ntimes, provided that the difference, computed when the replica receiver thread starts, remains\nconstant from then on. Any changes, including NTP updates, can lead to clock skews that can make\ncalculation of Seconds_Behind_Source less reliable.\nIn MySQL 9.1, this field is NULL (undefined or unknown) if the replication applier thread is not\nrunning, or if the applier thread has consumed all of the relay log and the replication receiver thread\nis not running. (In older versions of MySQL, this field was NULL if the replication applier thread or\nthe replication receiver thread was not running or was not connected to the source.) If the replication\nreceiver thread is running but the relay log is exhausted, Seconds_Behind_Source is set to 0.\nThe value of Seconds_Behind_Source is based on the timestamps stored in events, which are\npreserved through replication. This means that if a source M1 is itself a replica of M0, any event from\nM1's binary log that originates from M0's binary log has M0's timestamp for that event. This enables\nMySQL to replicate TIMESTAMP successfully. However, the problem for Seconds_Behind_Source\nis that if M1 also receives direct updates from clients, the Seconds_Behind_Source value\nrandomly fluctuates because sometimes the last event from M1 originates from M0 and sometimes is\nthe result of a direct update on M1.\nWhen using a multithreaded replica, you should keep in mind that this value is based on\nExec_Source_Log_Pos, and so may not reflect the position of the most recently committed\ntransaction.\n• Last_IO_Errno, Last_IO_Error\nThe error number and error message of the most recent error that caused the replication I/O\n(receiver) thread to stop. An error number of 0 and message of the empty string mean “no error.” If\nthe Last_IO_Error value is not empty, the error values also appear in the replica's error log.\nI/O error information includes a timestamp showing when the most recent I/O (receiver)thread\nerror occurred. This timestamp uses the format YYMMDD hh:mm:ss, and appears in the\nLast_IO_Error_Timestamp column.\nIssuing RESET BINARY LOGS AND GTIDS or RESET REPLICA resets the values shown in these\ncolumns.\n• Last_SQL_Errno, Last_SQL_Error\nThe error number and error message of the most recent error that caused the replication SQL\n(applier) thread to stop. An error number of 0 and message of the empty string mean “no error.” If the\nLast_SQL_Error value is not empty, the error values also appear in the replica's error log.\nIf the replica is multithreaded, the replication SQL thread is the coordinator for worker threads. In\nthis case, the Last_SQL_Error field shows exactly what the Last_Error_Message column in\nthe Performance Schema replication_applier_status_by_coordinator table shows.\nThe field value is modified to suggest that there may be more failures in the other worker threads\nwhich can be seen in the replication_applier_status_by_worker table that shows each\nworker thread's status. If that table is not available, the replica error log can be used. The log or the\nreplication_applier_status_by_worker table should also be used to learn more about the\nfailure shown by SHOW REPLICA STATUS or the coordinator table.\nSQL error information includes a timestamp showing when the most recent SQL (applier)\nthread error occurred. This timestamp uses the format YYMMDD hh:mm:ss, and appears in the\nLast_SQL_Error_Timestamp column.\nIssuing RESET BINARY LOGS AND GTIDS or RESET REPLICA resets the values shown in these\ncolumns.\nIn MySQL 9.1, all error codes and messages displayed in the Last_SQL_Errno and\nLast_SQL_Error columns correspond to error values listed in Server Error Message Reference.\nThis was not always true in previous versions. (Bug #11760365, Bug #52768)\n• Replicate_Ignore_Server_Ids\nAny server IDs that have been specified using the IGNORE_SERVER_IDS option of the CHANGE\nREPLICATION SOURCE TO statement, so that the replica ignores events from these servers.\nThis option is used in a circular or other multi-source replication setup when one of the servers is\nremoved. If any server IDs have been set in this way, a comma-delimited list of one or more numbers\nis shown. If no server IDs have been set, the field is blank.\nNote\nThe Ignored_server_ids value in the slave_master_info table also\nshows the server IDs to be ignored, but as a space-delimited list, preceded\nby the total number of server IDs to be ignored. For example, if a CHANGE\nREPLICATION SOURCE TO statement containing the IGNORE_SERVER_IDS\n= (2,6,9) option has been issued to tell a replica to ignore sources having\nthe server ID 2, 6, or 9, that information appears as shown here:\n Replicate_Ignore_Server_Ids: 2, 6, 9\n Ignored_server_ids: 3, 2, 6, 9\nReplicate_Ignore_Server_Ids filtering is performed by the I/O (receiver) thread, rather than by\nthe SQL (applier) thread, which means that events which are filtered out are not written to the relay\nlog. This differs from the filtering actions taken by server options such --replicate-do-table,\nwhich apply to the applier thread.\nIf SET gtid_mode=ON is issued when any channel has existing server IDs set with\nIGNORE_SERVER_IDS, the statement is rejected with an error. Before starting GTID-based\nreplication, use SHOW REPLICA STATUS to check for and clear all ignored server ID lists on the\nservers involved. You can clear a list by issuing a CHANGE REPLICATION SOURCE TO statement\nusing IGNORE_SERVER_IDS=()—that is, with an empty list of server IDs.\n• Source_Server_Id\nThe server_id value from the source.\n• Source_UUID\nThe server_uuid value from the source.\n• Source_Info_File\nThe location of the master.info file, the use of which is now deprecated. By default, a table is\nused instead for the replica's connection metadata repository.\n• SQL_Delay\nThe number of seconds that the replica must lag the source.\n• SQL_Remaining_Delay\nWhen Replica_SQL_Running_State is Waiting until SOURCE_DELAY seconds after\nsource executed event, this field contains the number of delay seconds remaining. At other\ntimes, this field is NULL.\n• Replica_SQL_Running_State\nThe state of the SQL thread (analogous to Replica_IO_State). The value is identical to the\nState value of the SQL thread as displayed by SHOW PROCESSLIST. Section 10.14.6, “Replication\nSQL Thread States”, provides a listing of possible states.\n• Source_Retry_Count\nThe number of times the replica can attempt to reconnect to the source in the event of a lost\nconnection. This value can be set using the SOURCE_RETRY_COUNT option of the CHANGE\nREPLICATION SOURCE TO statement.\n• Source_Bind\nThe network interface that the replica is bound to, if any. This is set using the SOURCE_BIND option\nfor the CHANGE REPLICATION SOURCE TO statement.\n• Last_IO_Error_Timestamp\nA timestamp in YYMMDD hh:mm:ss format that shows when the most recent I/O error took place.\n• Last_SQL_Error_Timestamp\nA timestamp in YYMMDD hh:mm:ss format that shows when the most recent SQL error occurred.\n• Retrieved_Gtid_Set\nThe set of global transaction IDs corresponding to all transactions received by this replica. Empty if\nGTIDs are not in use. See GTID Sets for more information.\nThis is the set of all GTIDs that exist or have existed in the relay logs. Each GTID is added as soon\nas the Gtid_log_event is received. This can cause partially transmitted transactions to have their\nGTIDs included in the set.\nWhen all relay logs are lost due to executing RESET REPLICA or CHANGE REPLICATION\nSOURCE TO, or due to the effects of the --relay-log-recovery option, the set is cleared. When\nrelay_log_purge = 1, the newest relay log is always kept, and the set is not cleared.\n• Executed_Gtid_Set\nThe set of global transaction IDs written in the binary log. This is the same as the value for the global\ngtid_executed system variable on this server, as well as the value for Executed_Gtid_Set in\nthe output of SHOW BINARY LOG STATUS on this server. Empty if GTIDs are not in use. See GTID\nSets for more information.\n• Auto_Position\n1 if GTID auto-positioning is in use for the channel, otherwise 0.\n• Replicate_Rewrite_DB\nThe Replicate_Rewrite_DB value displays any replication filtering rules that were specified. For\nexample, if the following replication filter rule was set:\nCHANGE REPLICATION FILTER REPLICATE_REWRITE_DB=((db1,db2), (db3,db4));\nthe Replicate_Rewrite_DB value displays:\nReplicate_Rewrite_DB: (db1,db2),(db3,db4)\nFor more information, see Section 15.4.2.1, “CHANGE REPLICATION FILTER Statement”.\n• Channel_name\nThe replication channel which is being displayed. There is always a default replication channel,\nand more replication channels can be added. See Section 19.2.2, “Replication Channels” for more\ninformation.\n• Master_TLS_Version\nThe TLS version used on the source. For TLS version information, see Section 8.3.2, “Encrypted\nConnection TLS Protocols and Ciphers”.\n• Source_public_key_path\nThe path name to a file containing a replica-side copy of the public key required by the source for\nRSA key pair-based password exchange. The file must be in PEM format. This column applies to\nreplicas that authenticate with the sha256_password or caching_sha2_password authentication\nplugin.\nIf Source_public_key_path is given and specifies a valid public key file, it takes precedence over\nGet_source_public_key.\n• Get_source_public_key\nWhether to request from the source the public key required for RSA key pair-based password\nexchange. This column applies to replicas that authenticate with the caching_sha2_password\nauthentication plugin. For that plugin, the source does not send the public key unless requested.\nIf Source_public_key_path is given and specifies a valid public key file, it takes precedence over\nGet_source_public_key.\n• Network_Namespace\nThe network namespace name; empty if the connection uses the default (global) namespace. For\ninformation about network namespaces, see Section 7.1.14, “Network Namespace Support”.\n15.7.7.35 SHOW REPLICAS Statement\nSHOW REPLICAS\nDisplays a list of replicas currently registered with the source. SHOW REPLICAS requires the\nREPLICATION SLAVE privilege.\nSHOW REPLICAS should be executed on a server that acts as a replication source. The statement\ndisplays information about servers that are or have been connected as replicas, with each row of the\nresult corresponding to one replica server, as shown here:\nmysql> SHOW REPLICAS;\n+------------+-----------+------+-----------+--------------------------------------+\n| Server_id  | Host      | Port | Source_id | Replica_UUID                         |\n+------------+-----------+------+-----------+--------------------------------------+\n|         10 | iconnect2 | 3306 |         3 | 14cb6624-7f93-11e0-b2c0-c80aa9429562 |\n|         21 | athena    | 3306 |         3 | 07af4990-f41f-11df-a566-7ac56fdaf645 |\n+------------+-----------+------+-----------+--------------------------------------+\n• Server_id: The unique server ID of the replica server, as configured in the replica server's option\nfile, or on the command line with --server-id=value.\n• Host: The host name of the replica server, as specified on the replica with the --report-host\noption. This can differ from the machine name as configured in the operating system.\n• User: The replica server user name, as specified on the replica with the --report-user option.\nStatement output includes this column only if the source server is started with the --show-\nreplica-auth-info option.\n• Password: The replica server password, as specified on the replica with the --report-password\noption. Statement output includes this column only if the source server is started with the --show-\nreplica-auth-info option.\n• Port: The port on the source to which the replica server is listening, as specified on the replica with\nthe --report-port option.\nA zero in this column means that the replica port (--report-port) was not set.\n• Source_id: The unique server ID of the source server that the replica server is replicating from.\nThis is the server ID of the server on which SHOW REPLICAS is executed, so this same value is\nlisted for each row in the result.\n•  Replica_UUID: The globally unique ID of this replica, as generated on the replica and found in the\nreplica's auto.cnf file.\n15.7.7.36 SHOW STATUS Statement\nSHOW [GLOBAL | SESSION] STATUS\n    [LIKE 'pattern' | WHERE expr]\nSHOW STATUS provides server status information (see Section 7.1.10, “Server Status Variables”). This\nstatement does not require any privilege. It requires only the ability to connect to the server.\nStatus variable information is also available from these sources:\n• Performance Schema tables. See Section 29.12.15, “Performance Schema Status Variable Tables”.\n• The mysqladmin extended-status command. See Section 6.5.2, “mysqladmin — A MySQL\nServer Administration Program”.\nFor SHOW STATUS, a LIKE clause, if present, indicates which variable names to match. A WHERE\nclause can be given to select rows using more general conditions, as discussed in Section 28.8,\n“Extensions to SHOW Statements”.\nSHOW STATUS accepts an optional GLOBAL or SESSION variable scope modifier:\n• With a GLOBAL modifier, the statement displays the global status values. A global status variable\nmay represent status for some aspect of the server itself (for example, Aborted_connects),\nor the aggregated status over all connections to MySQL (for example, Bytes_received and\nBytes_sent). If a variable has no global value, the session value is displayed.\n• With a SESSION modifier, the statement displays the status variable values for the current\nconnection. If a variable has no session value, the global value is displayed. LOCAL is a synonym for\nSESSION.\n• If no modifier is present, the default is SESSION.\nThe scope for each status variable is listed at Section 7.1.10, “Server Status Variables”.\nEach invocation of the SHOW STATUS statement uses an internal temporary table and increments the\nglobal Created_tmp_tables value.\nPartial output is shown here. The list of names and values may differ for your server. The meaning of\neach variable is given in Section 7.1.10, “Server Status Variables”.\nmysql> SHOW STATUS;\n+--------------------------+------------+\n| Variable_name            | Value      |\n+--------------------------+------------+\n| Aborted_clients          | 0          |\n| Aborted_connects         | 0          |\n| Bytes_received           | 155372598  |\n| Bytes_sent               | 1176560426 |\n| Connections              | 30023      |\n| Created_tmp_disk_tables  | 0          |\n| Created_tmp_tables       | 8340       |\n| Created_tmp_files        | 60         |\n...\n| Open_tables              | 1          |\n| Open_files               | 2          |\n| Open_streams             | 0          |\n| Opened_tables            | 44600      |\n| Questions                | 2026873    |\n...\n| Table_locks_immediate    | 1920382    |\n| Table_locks_waited       | 0          |\n| Threads_cached           | 0          |\n| Threads_created          | 30022      |\n| Threads_connected        | 1          |\n| Threads_running          | 1          |\n| Uptime                   | 80380      |\n+--------------------------+------------+\nWith a LIKE clause, the statement displays only rows for those variables with names that match the\npattern:\nmysql> SHOW STATUS LIKE 'Key%';\n+--------------------+----------+\n| Variable_name      | Value    |\n+--------------------+----------+\n| Key_blocks_used    | 14955    |\n| Key_read_requests  | 96854827 |\n| Key_reads          | 162040   |\n| Key_write_requests | 7589728  |\n| Key_writes         | 3813196  |\n+--------------------+----------+\n15.7.7.37 SHOW TABLE STATUS Statement\nSHOW TABLE STATUS\n    [{FROM | IN} db_name]\n    [LIKE 'pattern' | WHERE expr]\nSHOW TABLE STATUS works like SHOW TABLES, but provides a lot of information about each\nnon-TEMPORARY table. You can also get this list using the mysqlshow --status db_name\ncommand. The LIKE clause, if present, indicates which table names to match. The WHERE clause can\nbe given to select rows using more general conditions, as discussed in Section 28.8, “Extensions to\nSHOW Statements”.\nThis statement also displays information about views.\nSHOW TABLE STATUS output has these columns:\n• Name\nThe name of the table.\n• Engine\nThe storage engine for the table. See Chapter 17, The InnoDB Storage Engine, and Chapter 18,\nAlternative Storage Engines.\nFor partitioned tables, Engine shows the name of the storage engine used by all partitions.\n• Version\nThis column is unused. With the removal of .frm files in MySQL 8.0, this column now reports a\nhardcoded value of 10, which was the last .frm file version used in MySQL 5.7.\n• Row_format\nThe row-storage format (Fixed, Dynamic, Compressed, Redundant, Compact). For MyISAM\ntables, Dynamic corresponds to what myisamchk -dvv reports as Packed.\n• Rows\nThe number of rows. Some storage engines, such as MyISAM, store the exact count. For other\nstorage engines, such as InnoDB, this value is an approximation, and may vary from the actual\nvalue by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate\ncount.\nThe Rows value is NULL for INFORMATION_SCHEMA tables.\nFor InnoDB tables, the row count is only a rough estimate used in SQL optimization. (This is also\ntrue if the InnoDB table is partitioned.)\n• Avg_row_length\nThe average row length.\n• Data_length\nFor MyISAM, Data_length is the length of the data file, in bytes.\nFor InnoDB, Data_length is the approximate amount of space allocated for the clustered index, in\nbytes. Specifically, it is the clustered index size, in pages, multiplied by the InnoDB page size.\nRefer to the notes at the end of this section for information regarding other storage engines.\n• Max_data_length\nFor MyISAM, Max_data_length is maximum length of the data file. This is the total number of\nbytes of data that can be stored in the table, given the data pointer size used.\nUnused for InnoDB.\nRefer to the notes at the end of this section for information regarding other storage engines.\n• Index_length\nFor MyISAM, Index_length is the length of the index file, in bytes.\nFor InnoDB, Index_length is the approximate amount of space allocated for non-clustered\nindexes, in bytes. Specifically, it is the sum of non-clustered index sizes, in pages, multiplied by the\nInnoDB page size.\nRefer to the notes at the end of this section for information regarding other storage engines.\n• Data_free\nThe number of allocated but unused bytes.\nInnoDB tables report the free space of the tablespace to which the table belongs. For a table located\nin the shared tablespace, this is the free space of the shared tablespace. If you are using multiple\ntablespaces and the table has its own tablespace, the free space is for only that table. Free space\nmeans the number of bytes in completely free extents minus a safety margin. Even if free space\ndisplays as 0, it may be possible to insert rows as long as new extents need not be allocated.\nFor NDB Cluster, Data_free shows the space allocated on disk for, but not used by, a Disk Data\ntable or fragment on disk. (In-memory data resource usage is reported by the Data_length\ncolumn.)\nFor partitioned tables, this value is only an estimate and may not be absolutely correct. A more\naccurate method of obtaining this information in such cases is to query the INFORMATION_SCHEMA\nPARTITIONS table, as shown in this example:\nSELECT SUM(DATA_FREE)\n    FROM  INFORMATION_SCHEMA.PARTITIONS\n    WHERE TABLE_SCHEMA = 'mydb'\n    AND   TABLE_NAME   = 'mytable';\nFor more information, see Section 28.3.21, “The INFORMATION_SCHEMA PARTITIONS Table”.\n• Auto_increment\nThe next AUTO_INCREMENT value.\n• Create_time\nWhen the table was created.\n• Update_time\nWhen the data file was last updated. For some storage engines, this value is NULL. For example,\nInnoDB stores multiple tables in its system tablespace and the data file timestamp does not apply.\nEven with file-per-table mode with each InnoDB table in a separate .ibd file, change buffering can\ndelay the write to the data file, so the file modification time is different from the time of the last insert,\nupdate, or delete. For MyISAM, the data file timestamp is used; however, on Windows the timestamp\nis not updated by updates, so the value is inaccurate.\nUpdate_time displays a timestamp value for the last UPDATE, INSERT, or DELETE performed on\nInnoDB tables that are not partitioned. For MVCC, the timestamp value reflects the COMMIT time,\nwhich is considered the last update time. Timestamps are not persisted when the server is restarted\nor when the table is evicted from the InnoDB data dictionary cache.\n• Check_time\nWhen the table was last checked. Not all storage engines update this time, in which case, the value\nis always NULL.\nFor partitioned InnoDB tables, Check_time is always NULL.\n• Collation\nThe table default collation. The output does not explicitly list the table default character set, but the\ncollation name begins with the character set name.\n• Checksum\nThe live checksum value, if any.\n• Create_options\nExtra options used with CREATE TABLE.\nCreate_options shows partitioned for a partitioned table.\nCreate_options shows the ENCRYPTION clause for file-per-table tablespaces if the table is\nencrypted or if the specified encryption differs from the schema encryption. The encryption clause is\nnot shown for tables created in general tablespaces. To identify encrypted file-per-table and general\ntablespaces, query the INNODB_TABLESPACES ENCRYPTION column.\nWhen creating a table with strict mode disabled, the storage engine's default row format is used\nif the specified row format is not supported. The actual row format of the table is reported in the\nRow_format column. Create_options shows the row format that was specified in the CREATE\nTABLE statement.\nWhen altering the storage engine of a table, table options that are not applicable to the new storage\nengine are retained in the table definition to enable reverting the table with its previously defined\noptions to the original storage engine, if necessary. Create_options may show retained options.\n• Comment\nThe comment used when creating the table (or information as to why MySQL could not access the\ntable information).\nNotes\n• For InnoDB tables, SHOW TABLE STATUS does not give accurate statistics except for the physical\nsize reserved by the table. The row count is only a rough estimate used in SQL optimization.\n• For NDB tables, the output of this statement shows appropriate values for the Avg_row_length and\nData_length columns, with the exception that BLOB columns are not taken into account.\n• For NDB tables, Data_length includes data stored in main memory only; the Max_data_length\nand Data_free columns apply to Disk Data.\n• For NDB Cluster Disk Data tables, Max_data_length shows the space allocated for the disk part\nof a Disk Data table or fragment. (In-memory data resource usage is reported by the Data_length\ncolumn.)\n• For MEMORY tables, the Data_length, Max_data_length, and Index_length values\napproximate the actual amount of allocated memory. The allocation algorithm reserves memory in\nlarge amounts to reduce the number of allocation operations.\n• For views, most columns displayed by SHOW TABLE STATUS are 0 or NULL except that Name\nindicates the view name, Create_time indicates the creation time, and Comment says VIEW.\nTable information is also available from the INFORMATION_SCHEMA TABLES table. See\nSection 28.3.38, “The INFORMATION_SCHEMA TABLES Table”.\n15.7.7.38 SHOW TABLES Statement\nSHOW [EXTENDED] [FULL] TABLES\n    [{FROM | IN} db_name]\n    [LIKE 'pattern' | WHERE expr]\nSHOW TABLES lists the non-TEMPORARY tables in a given database. You can also get this list using\nthe mysqlshow db_name command. The LIKE clause, if present, indicates which table names to\nmatch. The WHERE clause can be given to select rows using more general conditions, as discussed in\nSection 28.8, “Extensions to SHOW Statements”.\nMatching performed by the LIKE clause is dependent on the setting of the\nlower_case_table_names system variable.\nThe optional EXTENDED modifier causes SHOW TABLES to list hidden tables created by failed ALTER\nTABLE statements. These temporary tables have names beginning with #sql and can be dropped\nusing DROP TABLE.\nThis statement also lists any views in the database. The optional FULL modifier causes SHOW TABLES\nto display a second output column with values of BASE TABLE for a table, VIEW for a view, or SYSTEM\nVIEW for an INFORMATION_SCHEMA table.\nIf you have no privileges for a base table or view, it does not show up in the output from SHOW TABLES\nor mysqlshow db_name.\nTable information is also available from the INFORMATION_SCHEMA TABLES table. See\nSection 28.3.38, “The INFORMATION_SCHEMA TABLES Table”.\n15.7.7.39 SHOW TRIGGERS Statement\nSHOW TRIGGERS\n    [{FROM | IN} db_name]\n    [LIKE 'pattern' | WHERE expr]\nSHOW TRIGGERS lists the triggers currently defined for tables in a database (the default database\nunless a FROM clause is given). This statement returns results only for databases and tables for which\nyou have the TRIGGER privilege. The LIKE clause, if present, indicates which table names (not trigger\nnames) to match and causes the statement to display triggers for those tables. The WHERE clause can\nbe given to select rows using more general conditions, as discussed in Section 28.8, “Extensions to\nSHOW Statements”.\nFor the ins_sum trigger defined in Section 27.4, “Using Triggers”, the output of SHOW TRIGGERS is as\nshown here:\nmysql> SHOW TRIGGERS LIKE 'acc%'\\G\n*************************** 1. row ***************************\n             Trigger: ins_sum\n               Event: INSERT\n               Table: account\n           Statement: SET @sum = @sum + NEW.amount\n              Timing: BEFORE\n             Created: 2018-08-08 10:10:12.61\n            sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,\n                      NO_ZERO_IN_DATE,NO_ZERO_DATE,\n                      ERROR_FOR_DIVISION_BY_ZERO,\n                      NO_ENGINE_SUBSTITUTION\n             Definer: me@localhost\ncharacter_set_client: utf8mb4\ncollation_connection: utf8mb4_0900_ai_ci\n  Database Collation: utf8mb4_0900_ai_ci\nSHOW TRIGGERS output has these columns:\n• Trigger\nThe name of the trigger.\n• Event\nThe trigger event. This is the type of operation on the associated table for which the trigger activates.\nThe value is INSERT (a row was inserted), DELETE (a row was deleted), or UPDATE (a row was\nmodified).\n• Table\nThe table for which the trigger is defined.\n• Statement\nThe trigger body; that is, the statement executed when the trigger activates.\n• Timing\nWhether the trigger activates before or after the triggering event. The value is BEFORE or AFTER.\n• Created\nThe date and time when the trigger was created. This is a TIMESTAMP(2) value (with a fractional\npart in hundredths of seconds) for triggers.\n• sql_mode\nThe SQL mode in effect when the trigger was created, and under which the trigger executes. For the\npermitted values, see Section 7.1.11, “Server SQL Modes”.\n• Definer\nThe account of the user who created the trigger, in 'user_name'@'host_name' format.\n• character_set_client\nThe session value of the character_set_client system variable when the trigger was created.\n• collation_connection\nThe session value of the collation_connection system variable when the trigger was created.\n• Database Collation\nThe collation of the database with which the trigger is associated.\nTrigger information is also available from the INFORMATION_SCHEMA TRIGGERS table. See\nSection 28.3.44, “The INFORMATION_SCHEMA TRIGGERS Table”.\n15.7.7.40 SHOW VARIABLES Statement\nSHOW [GLOBAL | SESSION] VARIABLES\n    [LIKE 'pattern' | WHERE expr]\nSHOW VARIABLES shows the values of MySQL system variables (see Section 7.1.8, “Server System\nVariables”). This statement does not require any privilege. It requires only the ability to connect to the\nserver.\nSystem variable information is also available from these sources:\n• Performance Schema tables. See Section 29.12.14, “Performance Schema System Variable\nTables”.\n• The mysqladmin variables command. See Section 6.5.2, “mysqladmin — A MySQL Server\nAdministration Program”.\nFor SHOW VARIABLES, a LIKE clause, if present, indicates which variable names to match. A WHERE\nclause can be given to select rows using more general conditions, as discussed in Section 28.8,\n“Extensions to SHOW Statements”.\nSHOW VARIABLES accepts an optional GLOBAL or SESSION variable scope modifier:\n• With a GLOBAL modifier, the statement displays global system variable values. These are the values\nused to initialize the corresponding session variables for new connections to MySQL. If a variable\nhas no global value, no value is displayed.\n• With a SESSION modifier, the statement displays the system variable values that are in effect for\nthe current connection. If a variable has no session value, the global value is displayed. LOCAL is a\nsynonym for SESSION.\n• If no modifier is present, the default is SESSION.\nThe scope for each system variable is listed at Section 7.1.8, “Server System Variables”.\nSHOW VARIABLES is subject to a version-dependent display-width limit. For variables with very long\nvalues that are not completely displayed, use SELECT as a workaround. For example:\nSELECT @@GLOBAL.innodb_data_file_path;\nMost system variables can be set at server startup (read-only variables such as version_comment\nare exceptions). Many can be changed at runtime with the SET statement. See Section 7.1.9, “Using\nSystem Variables”, and Section 15.7.6.1, “SET Syntax for Variable Assignment”.\nPartial output is shown here. The list of names and values may differ for your server. Section 7.1.8,\n“Server System Variables”, describes the meaning of each variable, and Section 7.1.1, “Configuring the\nServer”, provides information about tuning them.\nmysql> SHOW VARIABLES;\n+-------------------------------------------------------+-----------------------+\n| Variable_name                                         | Value                 |\n+-------------------------------------------------------+-----------------------+\n| activate_all_roles_on_login                           | OFF                   |\n| admin_address                                         |                       |\n| admin_port                                            | 33062                 |\n| admin_ssl_ca                                          |                       |\n| admin_ssl_capath                                      |                       |\n| admin_ssl_cert                                        |                       |\n| admin_ssl_cipher                                      |                       |\n| admin_ssl_crl                                         |                       |\n| admin_ssl_crlpath                                     |                       |\n| admin_ssl_key                                         |                       |\n| admin_tls_ciphersuites                                |                       |\n| admin_tls_version                                     | TLSv1.2,TLSv1.3       |\n| authentication_policy                                 | *,,                   |\n| auto_generate_certs                                   | ON                    |\n| auto_increment_increment                              | 1                     |\n| auto_increment_offset                                 | 1                     |\n| autocommit                                            | ON                    |\n| automatic_sp_privileges                               | ON                    |\n| avoid_temporal_upgrade                                | OFF                   |\n| back_log                                              | 151                   |\n| basedir                                               | /local/mysql-8.4/     |\n| big_tables                                            | OFF                   |\n| bind_address                                          | 127.0.0.1             |\n| binlog_cache_size                                     | 32768                 |\n| binlog_checksum                                       | CRC32                 |\n| binlog_direct_non_transactional_updates               | OFF                   |\n| binlog_encryption                                     | OFF                   |\n| binlog_error_action                                   | ABORT_SERVER          |\n| binlog_expire_logs_auto_purge                         | ON                    |\n| binlog_expire_logs_seconds                            | 2592000               |\n        \n...        \n        \n| max_error_count                                       | 1024                  |\n| max_execution_time                                    | 0                     |\n| max_heap_table_size                                   | 16777216              |\n| max_insert_delayed_threads                            | 20                    |\n| max_join_size                                         | 18446744073709551615  |\n| max_length_for_sort_data                              | 4096                  |\n| max_points_in_geometry                                | 65536                 |\n| max_prepared_stmt_count                               | 16382                 |\n| max_relay_log_size                                    | 0                     |\n| max_seeks_for_key                                     | 18446744073709551615  |\n| max_sort_length                                       | 1024                  |\n| max_sp_recursion_depth                                | 0                     |\n| max_user_connections                                  | 0                     |\n| max_write_lock_count                                  | 18446744073709551615  |\n...\n| time_zone                                             | SYSTEM                |\n| timestamp                                             | 1682684938.710453     |\n| tls_certificates_enforced_validation                  | OFF                   |\n| tls_ciphersuites                                      |                       |\n| tls_version                                           | TLSv1.2,TLSv1.3       |\n| tmp_table_size                                        | 16777216              |\n| tmpdir                                                | /tmp                  |\n| transaction_alloc_block_size                          | 8192                  |\n| transaction_allow_batching                            | OFF                   |\n| transaction_isolation                                 | REPEATABLE-READ       |\n| transaction_prealloc_size                             | 4096                  |\n| transaction_read_only                                 | OFF                   |\n| unique_checks                                         | ON                    |\n| updatable_views_with_limit                            | YES                   |\n| use_secondary_engine                                  | ON                    |\n| version                                               | 9.1.0                 |\n| version_comment                                       | Source distribution   |\n| version_compile_machine                               | x86_64                |\n| version_compile_os                                    | Linux                 |\n| version_compile_zlib                                  | 1.2.13                |\n| wait_timeout                                          | 28800                 |\n| warning_count                                         | 0                     |\n| windowing_use_high_precision                          | ON                    |\n| xa_detach_on_prepare                                  | ON                    |\n+-------------------------------------------------------+-----------------------+\nWith a LIKE clause, the statement displays only rows for those variables with names that match the\npattern. To obtain the row for a specific variable, use a LIKE clause as shown:\nSHOW VARIABLES LIKE 'max_join_size';\nSHOW SESSION VARIABLES LIKE 'max_join_size';\nTo get a list of variables whose name match a pattern, use the % wildcard character in a LIKE clause:\nSHOW VARIABLES LIKE '%size%';\nSHOW GLOBAL VARIABLES LIKE '%size%';\nWildcard characters can be used in any position within the pattern to be matched. Strictly speaking,\nbecause _ is a wildcard that matches any single character, you should escape it as \\_ to match it\nliterally. In practice, this is rarely necessary.\n15.7.7.41 SHOW WARNINGS Statement\nSHOW WARNINGS [LIMIT [offset,] row_count]\nSHOW COUNT(*) WARNINGS\nSHOW WARNINGS is a diagnostic statement that displays information about the conditions (errors,\nwarnings, and notes) resulting from executing a statement in the current session. Warnings are\ngenerated for DML statements such as INSERT, UPDATE, and LOAD DATA as well as DDL statements\nsuch as CREATE TABLE and ALTER TABLE.\nThe LIMIT clause has the same syntax as for the SELECT statement. See Section 15.2.13, “SELECT\nStatement”.\nSHOW WARNINGS is also used following EXPLAIN, to display the extended information generated by\nEXPLAIN. See Section 10.8.3, “Extended EXPLAIN Output Format”.\nSHOW WARNINGS displays information about the conditions resulting from execution of the most recent\nnondiagnostic statement in the current session. If the most recent statement resulted in an error during\nparsing, SHOW WARNINGS shows the resulting conditions, regardless of statement type (diagnostic or\nnondiagnostic).\nThe SHOW COUNT(*) WARNINGS diagnostic statement displays the total number of errors, warnings,\nand notes. You can also retrieve this number from the warning_count system variable:\nSHOW COUNT(*) WARNINGS;\nSELECT @@warning_count;\nA difference in these statements is that the first is a diagnostic statement that does not clear the\nmessage list. The second, because it is a SELECT statement is considered nondiagnostic and does\nclear the message list.\nA related diagnostic statement, SHOW ERRORS, shows only error conditions (it excludes warnings\nand notes), and SHOW COUNT(*) ERRORS statement displays the total number of errors. See\nSection 15.7.7.18, “SHOW ERRORS Statement”. GET DIAGNOSTICS can be used to examine\ninformation for individual conditions. See Section 15.6.7.3, “GET DIAGNOSTICS Statement”.\nHere is a simple example that shows data-conversion warnings for INSERT. The example assumes\nthat strict SQL mode is disabled. With strict mode enabled, the warnings would become errors and\nterminate the INSERT.\nmysql> CREATE TABLE t1 (a TINYINT NOT NULL, b CHAR(4));\nQuery OK, 0 rows affected (0.05 sec)\nmysql> INSERT INTO t1 VALUES(10,'mysql'), (NULL,'test'), (300,'xyz');\nQuery OK, 3 rows affected, 3 warnings (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 3\nmysql> SHOW WARNINGS\\G\n*************************** 1. row ***************************\n  Level: Warning\n   Code: 1265\nMessage: Data truncated for column 'b' at row 1\n*************************** 2. row ***************************\n  Level: Warning\n   Code: 1048\nMessage: Column 'a' cannot be null\n*************************** 3. row ***************************\n  Level: Warning\n   Code: 1264\nMessage: Out of range value for column 'a' at row 3\n3 rows in set (0.00 sec)\nThe max_error_count system variable controls the maximum number of error, warning, and note\nmessages for which the server stores information, and thus the number of messages that SHOW\nWARNINGS displays. To change the number of messages the server can store, change the value of\nmax_error_count.\nmax_error_count controls only how many messages are stored, not how many are counted. The\nvalue of warning_count is not limited by max_error_count, even if the number of messages\ngenerated exceeds max_error_count. The following example demonstrates this. The ALTER TABLE\nstatement produces three warning messages (strict SQL mode is disabled for the example to prevent\nan error from occurring after a single conversion issue). Only one message is stored and displayed\nbecause max_error_count has been set to 1, but all three are counted (as shown by the value of\nwarning_count):\nmysql> SHOW VARIABLES LIKE 'max_error_count';\n+-----------------+-------+\n| Variable_name   | Value |\n+-----------------+-------+\n| max_error_count | 1024  |\n+-----------------+-------+\n1 row in set (0.00 sec)\nmysql> SET max_error_count=1, sql_mode = '';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> ALTER TABLE t1 MODIFY b CHAR;\nQuery OK, 3 rows affected, 3 warnings (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 3\nmysql> SHOW WARNINGS;\n+---------+------+----------------------------------------+\n| Level   | Code | Message                                |\n+---------+------+----------------------------------------+\n| Warning | 1263 | Data truncated for column 'b' at row 1 |\n+---------+------+----------------------------------------+\n1 row in set (0.00 sec)\nmysql> SELECT @@warning_count;\n+-----------------+\n| @@warning_count |\n+-----------------+\n|               3 |\n+-----------------+\n1 row in set (0.01 sec)\nTo disable message storage, set max_error_count to 0. In this case, warning_count still indicates\nhow many warnings occurred, but messages are not stored and cannot be displayed.\nThe sql_notes system variable controls whether note messages increment warning_count and\nwhether the server stores them. By default, sql_notes is 1, but if set to 0, notes do not increment\nwarning_count and the server does not store them:\nmysql> SET sql_notes = 1;\nmysql> DROP TABLE IF EXISTS test.no_such_table;\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\nmysql> SHOW WARNINGS;\n+-------+------+------------------------------------+\n| Level | Code | Message                            |\n+-------+------+------------------------------------+\n| Note  | 1051 | Unknown table 'test.no_such_table' |\n+-------+------+------------------------------------+\n1 row in set (0.00 sec)\nmysql> SET sql_notes = 0;\nmysql> DROP TABLE IF EXISTS test.no_such_table;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SHOW WARNINGS;\nEmpty set (0.00 sec)\nThe MySQL server sends to each client a count indicating the total number of errors, warnings, and\nnotes resulting from the most recent statement executed by that client. From the C API, this value can\nbe obtained by calling mysql_warning_count(). See mysql_warning_count().\nIn the mysql client, you can enable and disable automatic warnings display using the warnings and\nnowarning commands, respectively, or their shortcuts, \\W and \\w (see Section 6.5.1.2, “mysql Client\nCommands”). For example:\nmysql> \\W\nShow warnings enabled.\nmysql> SELECT 1/0;\n+------+\n| 1/0  |\n+------+\n| NULL |\n+------+\n1 row in set, 1 warning (0.03 sec)\nWarning (Code 1365): Division by 0\nmysql> \\w\nShow warnings disabled.",
    "15.7.8 Other Administrative Statements": "15.7.8 Other Administrative Statements\n15.7.8.1 BINLOG Statement\nBINLOG 'str'\nBINLOG is an internal-use statement. It is generated by the mysqlbinlog program as the printable\nrepresentation of certain events in binary log files. (See Section 6.6.9, “mysqlbinlog — Utility for\nProcessing Binary Log Files”.) The 'str' value is a base 64-encoded string the that server decodes to\ndetermine the data change indicated by the corresponding event.\nTo execute BINLOG statements when applying mysqlbinlog output, a user account requires the\nBINLOG_ADMIN privilege (or the deprecated SUPER privilege), or the REPLICATION_APPLIER\nprivilege plus the appropriate privileges to execute each log event.\nThis statement can execute only format description events and row events.\n15.7.8.2 CACHE INDEX Statement\nCACHE INDEX {\n      tbl_index_list [, tbl_index_list] ...\n    | tbl_name PARTITION (partition_list)\n  }\n  IN key_cache_name\ntbl_index_list:\n  tbl_name [{INDEX|KEY} (index_name[, index_name] ...)]\npartition_list: {\n    partition_name[, partition_name] ...\n  | ALL\n}\nThe CACHE INDEX statement assigns table indexes to a specific key cache. It applies only to MyISAM\ntables, including partitioned MyISAM tables. After the indexes have been assigned, they can be\npreloaded into the cache if desired with LOAD INDEX INTO CACHE.\nThe following statement assigns indexes from the tables t1, t2, and t3 to the key cache named\nhot_cache:\nmysql> CACHE INDEX t1, t2, t3 IN hot_cache;\n+---------+--------------------+----------+----------+\n| Table   | Op                 | Msg_type | Msg_text |\n+---------+--------------------+----------+----------+\n| test.t1 | assign_to_keycache | status   | OK       |\n| test.t2 | assign_to_keycache | status   | OK       |\n| test.t3 | assign_to_keycache | status   | OK       |\n+---------+--------------------+----------+----------+\nThe syntax of CACHE INDEX enables you to specify that only particular indexes from a table should be\nassigned to the cache. However, the implementation assigns all the table's indexes to the cache, so\nthere is no reason to specify anything other than the table name.\nThe key cache referred to in a CACHE INDEX statement can be created by setting its size with a\nparameter setting statement or in the server parameter settings. For example:\nSET GLOBAL keycache1.key_buffer_size=128*1024;\nKey cache parameters are accessed as members of a structured system variable. See Section 7.1.9.5,\n“Structured System Variables”.\nA key cache must exist before you assign indexes to it, or an error occurs:\nmysql> CACHE INDEX t1 IN non_existent_cache;\nERROR 1284 (HY000): Unknown key cache 'non_existent_cache'\nBy default, table indexes are assigned to the main (default) key cache created at the server startup.\nWhen a key cache is destroyed, all indexes assigned to it are reassigned to the default key cache.\nIndex assignment affects the server globally: If one client assigns an index to a given cache, this cache\nis used for all queries involving the index, no matter which client issues the queries.\nCACHE INDEX is supported for partitioned MyISAM tables. You can assign one or more indexes for\none, several, or all partitions to a given key cache. For example, you can do the following:\nCREATE TABLE pt (c1 INT, c2 VARCHAR(50), INDEX i(c1))\n    ENGINE=MyISAM\n    PARTITION BY HASH(c1)\n    PARTITIONS 4;\nSET GLOBAL kc_fast.key_buffer_size = 128 * 1024;\nSET GLOBAL kc_slow.key_buffer_size = 128 * 1024;\nCACHE INDEX pt PARTITION (p0) IN kc_fast;\nCACHE INDEX pt PARTITION (p1, p3) IN kc_slow;\nThe previous set of statements performs the following actions:\n• Creates a partitioned table with 4 partitions; these partitions are automatically named p0, ..., p3; this\ntable has an index named i on column c1.\n• Creates 2 key caches named kc_fast and kc_slow\n• Assigns the index for partition p0 to the kc_fast key cache and the index for partitions p1 and p3\nto the kc_slow key cache; the index for the remaining partition (p2) uses the server's default key\ncache.\nIf you wish instead to assign the indexes for all partitions in table pt to a single key cache named\nkc_all, you can use either of the following two statements:\nCACHE INDEX pt PARTITION (ALL) IN kc_all;\nCACHE INDEX pt IN kc_all;\nThe two statements just shown are equivalent, and issuing either one has exactly the same effect. In\nother words, if you wish to assign indexes for all partitions of a partitioned table to the same key cache,\nthe PARTITION (ALL) clause is optional.\nWhen assigning indexes for multiple partitions to a key cache, the partitions need not be contiguous,\nand you need not list their names in any particular order. Indexes for any partitions not explicitly\nassigned to a key cache automatically use the server default key cache.\nIndex preloading is also supported for partitioned MyISAM tables. For more information, see\nSection 15.7.8.5, “LOAD INDEX INTO CACHE Statement”.\n15.7.8.3 FLUSH Statement\nFLUSH [NO_WRITE_TO_BINLOG | LOCAL] {\n    flush_option [, flush_option] ...\n  | tables_option\n}\nflush_option: {\n    BINARY LOGS\n  | ENGINE LOGS\n  | ERROR LOGS\n  | GENERAL LOGS\n  | LOGS\n  | PRIVILEGES\n  | OPTIMIZER_COSTS\n  | RELAY LOGS [FOR CHANNEL channel]\n  | SLOW LOGS\n  | STATUS\n  | USER_RESOURCES\n}\ntables_option: {\n    table_synonym\n  | table_synonym tbl_name [, tbl_name] ...\n  | table_synonym WITH READ LOCK\n  | table_synonym tbl_name [, tbl_name] ... WITH READ LOCK\n  | table_synonym tbl_name [, tbl_name] ... FOR EXPORT\n}\ntable_synonym: {\n    TABLE\n  | TABLES\n}\nThe FLUSH statement has several variant forms that clear or reload various internal caches, flush\ntables, or acquire locks. Each FLUSH operation requires the privileges indicated in its description.\nNote\nIt is not possible to issue FLUSH statements within stored functions or triggers.\nHowever, you may use FLUSH in stored procedures, so long as these are not\ncalled from stored functions or triggers. See Section 27.9, “Restrictions on\nStored Programs”.\nBy default, the server writes FLUSH statements to the binary log so that they replicate to replicas. To\nsuppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias LOCAL.\nNote\nFLUSH LOGS, FLUSH BINARY LOGS, FLUSH TABLES WITH READ LOCK\n(with or without a table list), and FLUSH TABLES tbl_name ... FOR\nEXPORT are not written to the binary log in any case because they would cause\nproblems if replicated to a replica.\nThe FLUSH statement causes an implicit commit. See Section 15.3.3, “Statements That Cause an\nImplicit Commit”.\nThe mysqladmin utility provides a command-line interface to some flush operations, using\ncommands such as flush-logs, flush-privileges, flush-status, and flush-tables. See\nSection 6.5.2, “mysqladmin — A MySQL Server Administration Program”.\nSending a SIGHUP or SIGUSR1 signal to the server causes several flush operations to occur that are\nsimilar to various forms of the FLUSH statement. Signals can be sent by the root system account or\nthe system account that owns the server process. This enables the flush operations to be performed\nwithout having to connect to the server, which requires a MySQL account that has privileges sufficient\nfor those operations. See Section 6.10, “Unix Signal Handling in MySQL”.\nThe RESET statement is similar to FLUSH. See Section 15.7.8.6, “RESET Statement”, for information\nabout using RESET with replication.\nThe following list describes the permitted FLUSH statement flush_option values. For descriptions of\nthe permitted tables_option values, see FLUSH TABLES Syntax.\n• FLUSH BINARY LOGS\nCloses and reopens any binary log file to which the server is writing. If binary logging is enabled, the\nsequence number of the binary log file is incremented by one relative to the previous file.\nThis operation requires the RELOAD privilege.\n• FLUSH ENGINE LOGS\nCloses and reopens any flushable logs for installed storage engines. This causes InnoDB to flush its\nlogs to disk.\nThis operation requires the RELOAD privilege.\n• FLUSH ERROR LOGS\nCloses and reopens any error log file to which the server is writing.\nThis operation requires the RELOAD privilege.\n• FLUSH GENERAL LOGS\nCloses and reopens any general query log file to which the server is writing.\nThis operation requires the RELOAD privilege.\nThis operation has no effect on tables used for the general query log (see Section 7.4.1, “Selecting\nGeneral Query Log and Slow Query Log Output Destinations”).\n• FLUSH LOGS\nCloses and reopens any log file to which the server is writing.\nThis operation requires the RELOAD privilege.\nThe effect of this operation is equivalent to the combined effects of these operations:\nFLUSH BINARY LOGS\nFLUSH ENGINE LOGS\nFLUSH ERROR LOGS\nFLUSH GENERAL LOGS\nFLUSH RELAY LOGS\nFLUSH SLOW LOGS\n• FLUSH OPTIMIZER_COSTS\nRe-reads the cost model tables so that the optimizer starts using the current cost estimates stored in\nthem.\nThis operation requires the FLUSH_OPTIMIZER_COSTS or RELOAD privilege.\nThe server writes a warning to the error log for any unrecognized cost model table entries. For\ninformation about these tables, see Section 10.9.5, “The Optimizer Cost Model”. This operation\naffects only sessions that begin subsequent to the flush. Existing sessions continue to use the cost\nestimates that were current when they began.\n• FLUSH PRIVILEGES\nRe-reads the privileges from the grant tables in the mysql system schema. As part of this operation,\nthe server reads the global_grants table containing dynamic privilege assignments and registers\nany unregistered privileges found there.\nReloading the grant tables is necessary to enable updates to MySQL privileges and users only if you\nmake such changes directly to the grant tables; it is not needed for account management statements\nsuch as GRANT or REVOKE, which take effect immediately. See Section 8.2.13, “When Privilege\nChanges Take Effect”, for more information.\nThis operation requires the RELOAD or FLUSH_PRIVILEGES privilege.\nIf the --skip-grant-tables option was specified at server startup to disable the MySQL privilege\nsystem, FLUSH PRIVILEGES provides a way to enable the privilege system at runtime.\nResets failed-login tracking (or enables it if the server was started with --skip-grant-tables)\nand unlocks any temporarily locked accounts. See Section 8.2.15, “Password Management”.\nFrees memory cached by the server as a result of GRANT, CREATE USER, CREATE SERVER, and\nINSTALL PLUGIN statements. This memory is not released by the corresponding REVOKE, DROP\nUSER, DROP SERVER, and UNINSTALL PLUGIN statements, so for a server that executes many\ninstances of the statements that cause caching, there is an increase in cached memory use unless it\nis freed with FLUSH PRIVILEGES.\nClears the in-memory cache used by the caching_sha2_password authentication plugin. See\nCache Operation for SHA-2 Pluggable Authentication.\n• FLUSH RELAY LOGS [FOR CHANNEL channel]\nCloses and reopens any relay log file to which the server is writing. If relay logging is enabled, the\nsequence number of the relay log file is incremented by one relative to the previous file.\nThis operation requires the RELOAD privilege.\nThe FOR CHANNEL channel clause enables you to name which replication channel the operation\napplies to. Execute FLUSH RELAY LOGS FOR CHANNEL channel to flush the relay log for a\nspecific replication channel. If no channel is named and no extra replication channels exist, the\noperation applies to the default channel. If no channel is named and multiple replication channels\nexist, the operation applies to all replication channels. For more information, see Section 19.2.2,\n“Replication Channels”.\n• FLUSH SLOW LOGS\nCloses and reopens any slow query log file to which the server is writing.\nThis operation requires the RELOAD privilege.\nThis operation has no effect on tables used for the slow query log (see Section 7.4.1, “Selecting\nGeneral Query Log and Slow Query Log Output Destinations”).\n• FLUSH STATUS\nFlushes status indicators.\nThis operation adds the current thread's session status variable values to the global values and\nresets the session values to zero. Some global variables may be reset to zero as well. It also resets\nthe counters for key caches (default and named) to zero and sets Max_used_connections to the\ncurrent number of open connections. This information may be of use when debugging a query. See\nSection 1.6, “How to Report Bugs or Problems”.\nFLUSH STATUS is unaffected by read_only or super_read_only, and is always written to the\nbinary log.\nThis operation requires the FLUSH_STATUS or RELOAD privilege.\n• FLUSH USER_RESOURCES\nResets all per-hour user resource indicators to zero.\nThis operation requires the FLUSH_USER_RESOURCES or RELOAD privilege.\nResetting resource indicators enables clients that have reached their hourly connection, query, or\nupdate limits to resume activity immediately. FLUSH USER_RESOURCES does not apply to the limit\non maximum simultaneous connections that is controlled by the max_user_connections system\nvariable. See Section 8.2.21, “Setting Account Resource Limits”.\nFLUSH TABLES Syntax\nFLUSH TABLES flushes tables, and, depending on the variant used, acquires locks. Any TABLES\nvariant used in a FLUSH statement must be the only option used. FLUSH TABLE is a synonym for\nFLUSH TABLES.\nNote\nThe descriptions here that indicate tables are flushed by closing them apply\ndifferently for InnoDB, which flushes table contents to disk but leaves them\nopen. This still permits table files to be copied while the tables are open, as long\nas other activity does not modify them.\n• FLUSH TABLES\nCloses all open tables, forces all tables in use to be closed, and flushes the prepared statement\ncache.\nThis operation requires the FLUSH_TABLES or RELOAD privilege.\nFor information about prepared statement caching, see Section 10.10.3, “Caching of Prepared\nStatements and Stored Programs”.\nFLUSH TABLES is not permitted when there is an active LOCK TABLES ... READ. To flush and\nlock tables, use FLUSH TABLES tbl_name ... WITH READ LOCK instead.\n• FLUSH TABLES tbl_name [, tbl_name] ...\nWith a list of one or more comma-separated table names, this operation is like FLUSH TABLES with\nno names except that the server flushes only the named tables. If a named table does not exist, no\nerror occurs.\nThis operation requires the FLUSH_TABLES or RELOAD privilege.\n• FLUSH TABLES WITH READ LOCK\nCloses all open tables and locks all tables for all databases with a global read lock.\nThis operation requires the FLUSH_TABLES or RELOAD privilege.\nThis operation is a very convenient way to get backups if you have a file system such as Veritas or\nZFS that can take snapshots in time. Use UNLOCK TABLES to release the lock.\nFLUSH TABLES WITH READ LOCK acquires a global read lock rather than table locks, so it is not\nsubject to the same behavior as LOCK TABLES and UNLOCK TABLES with respect to table locking\nand implicit commits:\n• UNLOCK TABLES implicitly commits any active transaction only if any tables currently have been\nlocked with LOCK TABLES. The commit does not occur for UNLOCK TABLES following FLUSH\nTABLES WITH READ LOCK because the latter statement does not acquire table locks.\n• Beginning a transaction causes table locks acquired with LOCK TABLES to be released, as though\nyou had executed UNLOCK TABLES. Beginning a transaction does not release a global read lock\nacquired with FLUSH TABLES WITH READ LOCK.\nFLUSH TABLES WITH READ LOCK does not prevent the server from inserting rows into the log\ntables (see Section 7.4.1, “Selecting General Query Log and Slow Query Log Output Destinations”).\n• FLUSH TABLES tbl_name [, tbl_name] ... WITH READ LOCK\nFlushes and acquires read locks for the named tables.\nThis operation requires the FLUSH_TABLES or RELOAD privilege. Because it acquires table locks, it\nalso requires the LOCK TABLES privilege for each table.\nThe operation first acquires exclusive metadata locks for the tables, so it waits for transactions that\nhave those tables open to complete. Then the operation flushes the tables from the table cache,\nreopens the tables, acquires table locks (like LOCK TABLES ... READ), and downgrades the\nmetadata locks from exclusive to shared. After the operation acquires locks and downgrades the\nmetadata locks, other sessions can read but not modify the tables.\nThis operation applies only to existing base (non-TEMPORARY) tables. If a name refers to a base\ntable, that table is used. If it refers to a TEMPORARY table, it is ignored. If a name applies to a view,\nan ER_WRONG_OBJECT error occurs. Otherwise, an ER_NO_SUCH_TABLE error occurs.\nUse UNLOCK TABLES to release the locks, LOCK TABLES to release the locks and acquire other\nlocks, or START TRANSACTION to release the locks and begin a new transaction.\nThis FLUSH TABLES variant enables tables to be flushed and locked in a single operation. It\nprovides a workaround for the restriction that FLUSH TABLES is not permitted when there is an\nactive LOCK TABLES ... READ.\nThis operation does not perform an implicit UNLOCK TABLES, so an error results if you perform the\noperation while there is any active LOCK TABLES or use it a second time without first releasing the\nlocks acquired.\nIf a flushed table was opened with HANDLER, the handler is implicitly flushed and loses its position.\n• FLUSH TABLES tbl_name [, tbl_name] ... FOR EXPORT\nThis FLUSH TABLES variant applies to InnoDB tables. It ensures that changes to the named tables\nhave been flushed to disk so that binary table copies can be made while the server is running.\nThis operation requires the FLUSH_TABLES or RELOAD privilege. Because it acquires locks on tables\nin preparation for exporting them, it also requires the LOCK TABLES and SELECT privileges for each\ntable.\nThe operation works like this:\n1. It acquires shared metadata locks for the named tables. The operation blocks as long as other\nsessions have active transactions that have modified those tables or hold table locks for them.\nWhen the locks have been acquired, the operation blocks transactions that attempt to update the\ntables, while permitting read-only operations to continue.\n2. It checks whether all storage engines for the tables support FOR EXPORT. If any do not, an\nER_ILLEGAL_HA error occurs and the operation fails.\n3. The operation notifies the storage engine for each table to make the table ready for export. The\nstorage engine must ensure that any pending changes are written to disk.\n4. The operation puts the session in lock-tables mode so that the metadata locks acquired earlier\nare not released when the FOR EXPORT operation completes.\nThis operation applies only to existing base (non-TEMPORARY) tables. If a name refers to a base\ntable, that table is used. If it refers to a TEMPORARY table, it is ignored. If a name applies to a view,\nan ER_WRONG_OBJECT error occurs. Otherwise, an ER_NO_SUCH_TABLE error occurs.\nInnoDB supports FOR EXPORT for tables that have their own .ibd file file (that is, tables created\nwith the innodb_file_per_table setting enabled). InnoDB ensures when notified by the FOR\nEXPORT operation that any changes have been flushed to disk. This permits a binary copy of\ntable contents to be made while the FOR EXPORT operation is in effect because the .ibd file is\ntransaction consistent and can be copied while the server is running. FOR EXPORT does not apply to\nInnoDB system tablespace files, or to InnoDB tables that have FULLTEXT indexes.\nFLUSH TABLES ...FOR EXPORT is supported for partitioned InnoDB tables.\nWhen notified by FOR EXPORT, InnoDB writes to disk certain kinds of data that is normally held\nin memory or in separate disk buffers outside the tablespace files. For each table, InnoDB also\nproduces a file named table_name.cfg in the same database directory as the table. The .cfg file\ncontains metadata needed to reimport the tablespace files later, into the same or different server.\nWhen the FOR EXPORT operation completes, InnoDB has flushed all dirty pages to the table data\nfiles. Any change buffer entries are merged prior to flushing. At this point, the tables are locked and\nquiescent: The tables are in a transactionally consistent state on disk and you can copy the .ibd\ntablespace files along with the corresponding .cfg files to get a consistent snapshot of those tables.\nFor the procedure to reimport the copied table data into a MySQL instance, see Section 17.6.1.3,\n“Importing InnoDB Tables”.\nAfter you are done with the tables, use UNLOCK TABLES to release the locks, LOCK TABLES to\nrelease the locks and acquire other locks, or START TRANSACTION to release the locks and begin a\nnew transaction.\nWhile any of these statements is in effect within the session, attempts to use FLUSH TABLES ...\nFOR EXPORT produce an error:\nFLUSH TABLES ... WITH READ LOCK\nFLUSH TABLES ... FOR EXPORT\nLOCK TABLES ... READ\nLOCK TABLES ... WRITE\nWhile FLUSH TABLES ... FOR EXPORT is in effect within the session, attempts to use any of\nthese statements produce an error:\nFLUSH TABLES WITH READ LOCK\nFLUSH TABLES ... WITH READ LOCK\nFLUSH TABLES ... FOR EXPORT\n15.7.8.4 KILL Statement\nKILL [CONNECTION | QUERY] processlist_id\nEach connection to mysqld runs in a separate thread. You can kill a thread with the KILL\nprocesslist_id statement.\nThread processlist identifiers can be determined from the ID column of the INFORMATION_SCHEMA\nPROCESSLIST table, the Id column of SHOW PROCESSLIST output, and the PROCESSLIST_ID\ncolumn of the Performance Schema threads table. The value for the current thread is returned by the\nCONNECTION_ID() function.\nKILL permits an optional CONNECTION or QUERY modifier:\n• KILL CONNECTION is the same as KILL with no modifier: It terminates the connection associated\nwith the given processlist_id, after terminating any statement the connection is executing.\n• KILL QUERY terminates the statement the connection is currently executing, but leaves the\nconnection itself intact.\nThe ability to see which threads are available to be killed depends on the PROCESS privilege:\n• Without PROCESS, you can see only your own threads.\n• With PROCESS, you can see all threads.\nThe ability to kill threads and statements depends on the CONNECTION_ADMIN privilege and the\ndeprecated SUPER privilege:\n• Without CONNECTION_ADMIN or SUPER, you can kill only your own threads and statements.\n• With CONNECTION_ADMIN or SUPER, you can kill all threads and statements, except that to affect\na thread or statement that is executing with the SYSTEM_USER privilege, your own session must\nadditionally have the SYSTEM_USER privilege.\nYou can also use the mysqladmin processlist and mysqladmin kill commands to examine\nand kill threads.\nWhen you use KILL, a thread-specific kill flag is set for the thread. In most cases, it might take some\ntime for the thread to die because the kill flag is checked only at specific intervals:\n• During SELECT operations, for ORDER BY and GROUP BY loops, the flag is checked after reading a\nblock of rows. If the kill flag is set, the statement is aborted.\n• ALTER TABLE operations that make a table copy check the kill flag periodically for each few copied\nrows read from the original table. If the kill flag was set, the statement is aborted and the temporary\ntable is deleted.\nThe KILL statement returns without waiting for confirmation, but the kill flag check aborts the\noperation within a reasonably small amount of time. Aborting the operation to perform any necessary\ncleanup also takes some time.\n• During UPDATE or DELETE operations, the kill flag is checked after each block read and after\neach updated or deleted row. If the kill flag is set, the statement is aborted. If you are not using\ntransactions, the changes are not rolled back.\n• GET_LOCK() aborts and returns NULL.\n• If the thread is in the table lock handler (state: Locked), the table lock is quickly aborted.\n• If the thread is waiting for free disk space in a write call, the write is aborted with a “disk full” error\nmessage.\n• EXPLAIN ANALYZE aborts and prints the first row of output.\nWarning\nKilling a REPAIR TABLE or OPTIMIZE TABLE operation on a MyISAM table\nresults in a table that is corrupted and unusable. Any reads or writes to such a\ntable fail until you optimize or repair it again (without interruption).\n15.7.8.5 LOAD INDEX INTO CACHE Statement\nLOAD INDEX INTO CACHE\n  tbl_index_list [, tbl_index_list] ...\ntbl_index_list:\n  tbl_name\n    [PARTITION (partition_list)]\n    [{INDEX|KEY} (index_name[, index_name] ...)]\n    [IGNORE LEAVES]\npartition_list: {\n    partition_name[, partition_name] ...\n  | ALL\n}\nThe LOAD INDEX INTO CACHE statement preloads a table index into the key cache to which it has\nbeen assigned by an explicit CACHE INDEX statement, or into the default key cache otherwise.\nLOAD INDEX INTO CACHE applies only to MyISAM tables, including partitioned MyISAM tables. In\naddition, indexes on partitioned tables can be preloaded for one, several, or all partitions.\nThe IGNORE LEAVES modifier causes only blocks for the nonleaf nodes of the index to be preloaded.\nIGNORE LEAVES is also supported for partitioned MyISAM tables.\nThe following statement preloads nodes (index blocks) of indexes for the tables t1 and t2:\nmysql> LOAD INDEX INTO CACHE t1, t2 IGNORE LEAVES;\n+---------+--------------+----------+----------+\n| Table   | Op           | Msg_type | Msg_text |\n+---------+--------------+----------+----------+\n| test.t1 | preload_keys | status   | OK       |\n| test.t2 | preload_keys | status   | OK       |\n+---------+--------------+----------+----------+\nThis statement preloads all index blocks from t1. It preloads only blocks for the nonleaf nodes from t2.\nThe syntax of LOAD INDEX INTO CACHE enables you to specify that only particular indexes from a\ntable should be preloaded. However, the implementation preloads all the table's indexes into the cache,\nso there is no reason to specify anything other than the table name.\nIt is possible to preload indexes on specific partitions of partitioned MyISAM tables. For example, of\nthe following 2 statements, the first preloads indexes for partition p0 of a partitioned table pt, while the\nsecond preloads the indexes for partitions p1 and p3 of the same table:\nLOAD INDEX INTO CACHE pt PARTITION (p0);\nLOAD INDEX INTO CACHE pt PARTITION (p1, p3);\nTo preload the indexes for all partitions in table pt, you can use either of the following two statements:\nLOAD INDEX INTO CACHE pt PARTITION (ALL);\nLOAD INDEX INTO CACHE pt;\nThe two statements just shown are equivalent, and issuing either one has exactly the same effect.\nIn other words, if you wish to preload indexes for all partitions of a partitioned table, the PARTITION\n(ALL) clause is optional.\nWhen preloading indexes for multiple partitions, the partitions need not be contiguous, and you need\nnot list their names in any particular order.\nLOAD INDEX INTO CACHE ... IGNORE LEAVES fails unless all indexes in a table have the\nsame block size. To determine index block sizes for a table, use myisamchk -dv and check the\nBlocksize column.\n15.7.8.6 RESET Statement\nRESET reset_option [, reset_option] ...\nreset_option: {\n    BINARY LOGS AND GTIDS\n  | REPLICA\n}\nThe RESET statement is used to clear the state of various server operations. You must have the\nRELOAD privilege to execute RESET.\nFor information about the RESET PERSIST statement that removes persisted global system variables,\nsee Section 15.7.8.7, “RESET PERSIST Statement”.\nRESET acts as a stronger version of the FLUSH statement. See Section 15.7.8.3, “FLUSH Statement”.\nThe RESET statement causes an implicit commit. See Section 15.3.3, “Statements That Cause an\nImplicit Commit”.\nThe following list describes the permitted RESET statement reset_option values:\n• RESET BINARY LOGS AND GTIDS\nDeletes all binary logs listed in the index file, resets the binary log index file to be empty, and creates\na new binary log file.\n• RESET REPLICA\nMakes the replica forget its replication position in the source binary logs. Also resets the relay log by\ndeleting any existing relay log files and beginning a new one.\n15.7.8.7 RESET PERSIST Statement\nRESET PERSIST [[IF EXISTS] system_var_name]\nRESET PERSIST removes persisted global system variable settings from the mysqld-auto.cnf\noption file in the data directory. Removing a persisted system variable causes the variable no longer to\nbe initialized from mysqld-auto.cnf at server startup. For more information about persisting system\nvariables and the mysqld-auto.cnf file, see Section 7.1.9.3, “Persisted System Variables”.\nThe privileges required for RESET PERSIST depend on the type of system variable to be removed:\n• For dynamic system variables, this statement requires the SYSTEM_VARIABLES_ADMIN privilege (or\nthe deprecated SUPER privilege).\n• For read-only system variables, this statement requires the SYSTEM_VARIABLES_ADMIN and\nPERSIST_RO_VARIABLES_ADMIN privileges.\nSee Section 7.1.9.1, “System Variable Privileges”.\nDepending on whether the variable name and IF EXISTS clauses are present, the RESET PERSIST\nstatement has these forms:\n• To remove all persisted variables from mysqld-auto.cnf, use RESET PERSIST without naming\nany system variable:\nRESET PERSIST;\nYou must have privileges for removing both dynamic and read-only system variables if mysqld-\nauto.cnf contains both kinds of variables.\n• To remove a specific persisted variable from mysqld-auto.cnf, name it in the statement:\nRESET PERSIST system_var_name;\nThis includes plugin system variables, even if the plugin is not currently installed. If the variable is not\npresent in the file, an error occurs.\n• To remove a specific persisted variable from mysqld-auto.cnf, but produce a warning rather than\nan error if the variable is not present in the file, add an IF EXISTS clause to the previous syntax:\nRESET PERSIST IF EXISTS system_var_name;\nRESET PERSIST is not affected by the value of the persisted_globals_load system variable.\nRESET PERSIST affects the contents of the Performance Schema persisted_variables table\nbecause the table contents correspond to the contents of the mysqld-auto.cnf file. On the other\nhand, because RESET PERSIST does not change variable values, it has no effect on the contents of\nthe Performance Schema variables_info table until the server is restarted.\nFor information about RESET statement variants that clear the state of other server operations, see\nSection 15.7.8.6, “RESET Statement”.\n15.7.8.8 RESTART Statement\nRESTART\nThis statement stops and restarts the MySQL server. It requires the SHUTDOWN privilege.\nOne use for RESTART is when it is not possible or convenient to gain command-line access to the\nMySQL server on the server host to restart it. For example, SET PERSIST_ONLY can be used at\nruntime to make configuration changes to system variables that can be set only at server startup, but\nthe server must still be restarted for those changes to take effect. The RESTART statement provides a\nway to do so from within client sessions, without requiring command-line access on the server host.\nNote\nAfter executing a RESTART statement, the client can expect the current\nconnection to be lost. If auto-reconnect is enabled, the connection is\nreestablished after the server restarts. Otherwise, the connection must be\nreestablished manually.\nA successful RESTART operation requires mysqld to be running in an environment that has a\nmonitoring process available to detect a server shutdown performed for restart purposes:\n• In the presence of a monitoring process, RESTART causes mysqld to terminate such that the\nmonitoring process can determine that it should start a new mysqld instance.\n• If no monitoring process is present, RESTART fails with an error.\nThese platforms provide the necessary monitoring support for the RESTART statement:\n• Windows, when mysqld is started as a Windows service or standalone. (mysqld forks, and one\nprocess acts as a monitor to the other, which acts as the server.)\n• Unix and Unix-like systems that use systemd or mysqld_safe to manage mysqld.\nTo configure a monitoring environment such that mysqld enables the RESTART statement:\n1. Set the MYSQLD_PARENT_PID environment variable to the value of the process ID of the process\nthat starts mysqld, before starting mysqld.\n2. When mysqld performs a shutdown due to use of the RESTART statement, it returns exit code 16.\n3. When the monitoring process detects an exit code of 16, it starts mysqld again. Otherwise, it exits.\nHere is a minimal example as implemented in the bash shell:\n#!/bin/bash\nexport MYSQLD_PARENT_PID=$$\nexport MYSQLD_RESTART_EXIT=16\nwhile true ; do\n  bin/mysqld mysqld options here\n  if [ $? -ne $MYSQLD_RESTART_EXIT ]; then\n    break\n  fi\ndone\nOn Windows, the forking used to implement RESTART makes determining the server process to attach\nto for debugging more difficult. To alleviate this, starting the server with --gdb suppresses forking, in\naddition to its other actions done to set up a debugging environment. In non-debug settings, --no-\nmonitor may be used for the sole purpose of suppressing forking the monitor process. For a server\nstarted with either --gdb or --no-monitor, executing RESTART causes the server to simply exit\nwithout restarting.\nThe Com_restart status variable tracks the number of RESTART statements. Because status\nvariables are initialized for each server startup and do not persist across restarts, Com_restart\nnormally has a value of zero, but can be nonzero if RESTART statements were executed but failed.\n15.7.8.9 SHUTDOWN Statement\nSHUTDOWN\nThis statement stops the MySQL server. It requires the SHUTDOWN privilege.\nSHUTDOWN provides an SQL-level interface to the same functionality available using the mysqladmin\nshutdown command. A successful SHUTDOWN sequence consists of checking the privileges, validating\nthe arguments, and sending an OK packet to the client. Then the server is shut down.\nThe Com_shutdown status variable tracks the number of SHUTDOWN statements. Because status\nvariables are initialized for each server startup and do not persist across restarts, Com_shutdown\nnormally has a value of zero, but can be nonzero if SHUTDOWN statements were executed but failed.\nAnother way to stop the server is to send it a SIGTERM signal, which can be done by root or the\naccount that owns the server process. SIGTERM enables server shutdown to be performed without\nhaving to connect to the server. See Section 6.10, “Unix Signal Handling in MySQL”.",
    "15.8 Utility Statements": "15.8 Utility Statements",
    "15.8.1 DESCRIBE Statement": "15.8.1 DESCRIBE Statement\nThe DESCRIBE and EXPLAIN statements are synonyms, used either to obtain information about table\nstructure or query execution plans. For more information, see Section 15.7.7.6, “SHOW COLUMNS\nStatement”, and Section 15.8.2, “EXPLAIN Statement”.",
    "15.8.2 EXPLAIN Statement": "15.8.2 EXPLAIN Statement\n{EXPLAIN | DESCRIBE | DESC}\n    tbl_name [col_name | wild]\n{EXPLAIN | DESCRIBE | DESC}\n    [explain_type] [INTO variable]\n    {[schema_spec] explainable_stmt | FOR CONNECTION connection_id}\n{EXPLAIN | DESCRIBE | DESC} ANALYZE [FORMAT = TREE] [schema_spec] select_statement\n{EXPLAIN | DESCRIBE | DESC} ANALYZE FORMAT = JSON INTO variable [schema_spec] select_statement\nexplain_type: {\n    FORMAT = format_name\n}\nformat_name: {\n    TRADITIONAL\n  | JSON\n  | TREE\n}\nexplainable_stmt: {\n    SELECT statement\n  | TABLE statement\n  | DELETE statement\n  | INSERT statement\n  | REPLACE statement\n  | UPDATE statement\n}\nschema_spec:\nFOR {SCHEMA | DATABASE} schema_name\nThe DESCRIBE and EXPLAIN statements are synonyms. In practice, the DESCRIBE keyword is more\noften used to obtain information about table structure, whereas EXPLAIN is used to obtain a query\nexecution plan (that is, an explanation of how MySQL would execute a query).\nThe following discussion uses the DESCRIBE and EXPLAIN keywords in accordance with those uses,\nbut the MySQL parser treats them as completely synonymous.\n• Obtaining Table Structure Information\n• Obtaining Execution Plan Information\n• Obtaining Information with EXPLAIN ANALYZE\nObtaining Table Structure Information\nDESCRIBE provides information about the columns in a table:\nmysql> DESCRIBE City;\n+------------+----------+------+-----+---------+----------------+\n| Field      | Type     | Null | Key | Default | Extra          |\n+------------+----------+------+-----+---------+----------------+\n| Id         | int(11)  | NO   | PRI | NULL    | auto_increment |\n| Name       | char(35) | NO   |     |         |                |\n| Country    | char(3)  | NO   | UNI |         |                |\n| District   | char(20) | YES  | MUL |         |                |\n| Population | int(11)  | NO   |     | 0       |                |\n+------------+----------+------+-----+---------+----------------+\nDESCRIBE is a shortcut for SHOW COLUMNS. These statements also display information for views.\nThe description for SHOW COLUMNS provides more information about the output columns. See\nSection 15.7.7.6, “SHOW COLUMNS Statement”.\nBy default, DESCRIBE displays information about all columns in the table. col_name, if given, is the\nname of a column in the table. In this case, the statement displays information only for the named\ncolumn. wild, if given, is a pattern string. It can contain the SQL % and _ wildcard characters. In this\ncase, the statement displays output only for the columns with names matching the string. There is no\nneed to enclose the string within quotation marks unless it contains spaces or other special characters.\nThe DESCRIBE statement is provided for compatibility with Oracle.\nThe SHOW CREATE TABLE, SHOW TABLE STATUS, and SHOW INDEX statements also provide\ninformation about tables. See Section 15.7.7, “SHOW Statements”.\nThe explain_format system variable has no effect on the output of EXPLAIN when used to obtain\ninformation about table columns.\nObtaining Execution Plan Information\nThe EXPLAIN statement provides information about how MySQL executes statements:\n• EXPLAIN works with SELECT, DELETE, INSERT, REPLACE, UPDATE, and TABLE statements.\n• When EXPLAIN is used with an explainable statement, MySQL displays information from the\noptimizer about the statement execution plan. That is, MySQL explains how it would process the\nstatement, including information about how tables are joined and in which order. For information\nabout using EXPLAIN to obtain execution plan information, see Section 10.8.2, “EXPLAIN Output\nFormat”.\n• When EXPLAIN is used with FOR CONNECTION connection_id rather than an explainable\nstatement, it displays the execution plan for the statement executing in the named connection. See\nSection 10.8.4, “Obtaining Execution Plan Information for a Named Connection”.\n• For explainable statements, EXPLAIN produces additional execution plan information that can be\ndisplayed using SHOW WARNINGS. See Section 10.8.3, “Extended EXPLAIN Output Format”.\n• EXPLAIN is useful for examining queries involving partitioned tables. See Section 26.3.5, “Obtaining\nInformation About Partitions”.\n• The FORMAT option can be used to select the output format. TRADITIONAL presents the output\nin tabular format. This is the default if no FORMAT option is present. JSON format displays the\ninformation in JSON format. TREE provides tree-like output with more precise descriptions of query\nhandling than the TRADITIONAL format; it is the only format which shows hash join usage (see\nSection 10.2.1.4, “Hash Join Optimization”) and is always used for EXPLAIN ANALYZE.\nIn MySQL 9.1, the default output format used by EXPLAIN (that is, when it has no FORMAT option)\nis determined by the value of the explain_format system variable. The precise effects of this\nvariable are described later in this section.\nMySQL 9.1 supports an additional INTO option with EXPLAIN FORMAT=JSON, which enables saving\nthe JSON formatted output into a user variable, like this:\nmysql> EXPLAIN FORMAT=JSON INTO @myselect \n    ->     SELECT name FROM a WHERE id = 2;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @myselect\\G\n*************************** 1. row ***************************\n@myex: {\n  \"query_block\": {\n    \"select_id\": 1,\n    \"cost_info\": {\n      \"query_cost\": \"1.00\"\n    },\n    \"table\": {\n      \"table_name\": \"a\",\n      \"access_type\": \"const\",\n      \"possible_keys\": [\n        \"PRIMARY\"\n      ],\n      \"key\": \"PRIMARY\",\n      \"used_key_parts\": [\n        \"id\"\n      ],\n      \"key_length\": \"4\",\n      \"ref\": [\n        \"const\"\n      ],\n      \"rows_examined_per_scan\": 1,\n      \"rows_produced_per_join\": 1,\n      \"filtered\": \"100.00\",\n      \"cost_info\": {\n        \"read_cost\": \"0.00\",\n        \"eval_cost\": \"0.10\",\n        \"prefix_cost\": \"0.00\",\n        \"data_read_per_join\": \"408\"\n      },\n      \"used_columns\": [\n        \"id\",\n        \"name\"\n      ]\n    }\n  }\n}\n1 row in set (0.00 sec)\nThis works with any explainable statement (SELECT, TABLE, INSERT, UPDATE, REPLACE, or\nDELETE). Examples using UPDATE and DELETE statements are shown here:\nmysql> EXPLAIN FORMAT=JSON INTO @myupdate \n    ->   UPDATE a SET name2 = \"garcia\" WHERE id = 3;              \nQuery OK, 0 rows affected (0.00 sec)\nmysql> EXPLAIN FORMAT=JSON INTO @mydelete \n    ->     DELETE FROM a WHERE name1 LIKE '%e%';\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @myupdate, @mydelete\\G\n*************************** 1. row ***************************\n@myupdate: {\n  \"query_block\": {\n    \"select_id\": 1,\n    \"table\": {\n      \"update\": true,\n      \"table_name\": \"a\",\n      \"access_type\": \"range\",\n      \"possible_keys\": [\n        \"PRIMARY\"\n      ],\n      \"key\": \"PRIMARY\",\n      \"used_key_parts\": [\n        \"id\"\n      ],\n      \"key_length\": \"4\",\n      \"ref\": [\n        \"const\"\n      ],\n      \"rows_examined_per_scan\": 1,\n      \"filtered\": \"100.00\",\n      \"attached_condition\": \"(`db`.`a`.`id` = 3)\"\n    }\n  }\n}\n@mydelete: {\n  \"query_block\": {\n    \"select_id\": 1,\n    \"table\": {\n      \"delete\": true,\n      \"table_name\": \"a\",\n      \"access_type\": \"ALL\",\n      \"rows_examined_per_scan\": 2,\n      \"filtered\": \"100.00\",\n      \"attached_condition\": \"(`db`.`a`.`name1` like '%e%')\"\n    }\n  }\n}\n1 row in set (0.00 sec)\nYou can work with this value using MySQL JSON functions as you would with any other JSON value,\nas in these examples using JSON_EXTRACT():\nmysql> SELECT JSON_EXTRACT(@myselect, \"$.query_block.table.key\");\n+----------------------------------------------------+\n| JSON_EXTRACT(@myselect, \"$.query_block.table.key\") |\n+----------------------------------------------------+\n| \"PRIMARY\"                                          |\n+----------------------------------------------------+\n1 row in set (0.01 sec)\nmysql> SELECT JSON_EXTRACT(@myupdate, \"$.query_block.table.access_type\") AS U_acc,\n    ->        JSON_EXTRACT(@mydelete, \"$.query_block.table.access_type\") AS D_acc;\n+---------+-------+\n| U_acc   | D_acc |\n+---------+-------+\n| \"range\" | \"ALL\" |\n+---------+-------+\n1 row in set (0.00 sec)\nFor complex statements, the JSON output can be quite large; in particular, it can be difficult when\nreading it to pair the closing bracket and opening brackets; to cause the JSON structure's key, if it\nhas one, to be repeated near the closing bracket, set end_markers_in_json=ON. You should\nbe aware that while this makes the output easier to read, it also renders the JSON invalid, causing\nJSON functions to raise an error.\nSee also Section 14.17, “JSON Functions”.\nTrying to use an INTO clause without explicitly including FORMAT=JSON causes EXPLAIN to be\nrejected with ER_EXPLAIN_INTO_IMPLICIT_FORMAT_NOT_SUPPORTED. This is true regardless of\nthe current value of the explain_format system variable.\nThe INTO clause is not supported with FOR CONNECTION.\nINTO is also not supported with EXPLAIN ANALYZE when explain_json_format_version=1.\nImportant\nIf, for any reason, the statement to be analyzed is rejected, the user variable\nis not updated.\n• MySQL 9.1 supports a FOR SCHEMA clause, which causes EXPLAIN to behave as if the statement\nto be analyzed had been executed in the named database; FOR DATABASE is supported as a\nsynonym. A simple example of use is shown here:\nmysql> USE b;\nDatabase changed\nmysql> CREATE SCHEMA s1;\nQuery OK, 1 row affected (0.01 sec)\nmysql> CREATE SCHEMA s2;\nQuery OK, 1 row affected (0.01 sec)\nmysql> USE s1;\nDatabase changed\nmysql> CREATE TABLE t (c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY, c2 INT NOT NULL);\nQuery OK, 0 rows affected (0.04 sec)\nmysql> USE s2;\nDatabase changed\nmysql> CREATE TABLE t (c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY, c2 INT NOT NULL, KEY i1 (c2));\nQuery OK, 0 rows affected (0.04 sec)\nmysql> USE b;\nDatabase changed\nmysql> EXPLAIN FORMAT=TREE FOR SCHEMA s1 SELECT * FROM t WHERE c2 > 50\\G\n*************************** 1. row ***************************\nEXPLAIN: -> Filter: (t.c2 > 50)  (cost=0.35 rows=1)\n    -> Table scan on t  (cost=0.35 rows=1)\n1 row in set (0.00 sec)\nmysql> EXPLAIN FORMAT=TREE FOR SCHEMA s2 SELECT * FROM t WHERE c2 > 50\\G\n*************************** 1. row ***************************\nEXPLAIN: -> Filter: (t.c2 > 50)  (cost=0.35 rows=1)\n    -> Covering index scan on t using i1  (cost=0.35 rows=1)\n1 row in set (0.00 sec)\nIf the database does not exist, the statement is rejected with ER_BAD_DB_ERROR. If\nthe user does not have the necessary privileges to run the statement, it is rejected with\nER_DBACCESS_DENIED_ERROR.\nFOR SCHEMA is not compatible with FOR CONNECTION.\nEXPLAIN requires the same privileges required to execute the explained statement. Additionally,\nEXPLAIN also requires the SHOW VIEW privilege for any explained view. EXPLAIN ... FOR\nCONNECTION also requires the PROCESS privilege if the specified connection belongs to a different\nuser.\nThe explain_format system variable determines the format of the output from EXPLAIN when\nused to display a query execution plan. This variable can take any of the values used with the FORMAT\noption, with the addition of DEFAULT as a synonym for TRADITIONAL. The following example uses the\ncountry table from the world database which can be obtained from MySQL: Other Downloads:\nmysql> USE world; # Make world the current database\nDatabase changed\nChecking the value of explain_format, we see that it has the default value, and that EXPLAIN (with\nno FORMAT option) therefore uses the traditional tabular output:\nmysql> SELECT @@explain_format;\n+------------------+\n| @@explain_format |\n+------------------+\n| TRADITIONAL      |\n+------------------+\n1 row in set (0.00 sec)\nmysql> EXPLAIN SELECT Name FROM country WHERE Code Like 'A%';\n+----+-------------+---------+------------+-------+---------------+---------+---------+------+------+------\n| id | select_type | table   | partitions | type  | possible_keys | key     | key_len | ref  | rows | filte\n+----+-------------+---------+------------+-------+---------------+---------+---------+------+------+------\n|  1 | SIMPLE      | country | NULL       | range | PRIMARY       | PRIMARY | 12      | NULL |   17 |   100\n+----+-------------+---------+------------+-------+---------------+---------+---------+------+------+------\n1 row in set, 1 warning (0.00 sec)\nIf we set the value of explain_format to TREE, then rerun the same EXPLAIN statement, the output\nuses the tree-like format:\nmysql> SET @@explain_format=TREE;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @@explain_format;\n+------------------+\n| @@explain_format |\n+------------------+\n| TREE             |\n+------------------+\n1 row in set (0.00 sec)\nmysql> EXPLAIN SELECT Name FROM country WHERE Code LIKE 'A%';\n+----------------------------------------------------------------------------------------------------------\n| EXPLAIN                                                                                                  \n+----------------------------------------------------------------------------------------------------------\n| -> Filter: (country.`Code` like 'A%')  (cost=3.67 rows=17)\n    -> Index range scan on country using PRIMARY over ('A' <= Code <= 'A????????')  (cost=3.67 rows=17)  |\n+----------------------------------------------------------------------------------------------------------\n1 row in set, 1 warning (0.00 sec)\nAs stated previously, the FORMAT option overrides this setting. Executing the same EXPLAIN statement\nusing FORMAT=JSON instead of FORMAT=TREE shows that this is the case:\nmysql> EXPLAIN FORMAT=JSON SELECT Name FROM country WHERE Code LIKE 'A%';\n+------------------------------------------------------------------------------+\n| EXPLAIN                                                                      |\n+------------------------------------------------------------------------------+\n| {\n  \"query_block\": {\n    \"select_id\": 1,\n    \"cost_info\": {\n      \"query_cost\": \"3.67\"\n    },\n    \"table\": {\n      \"table_name\": \"country\",\n      \"access_type\": \"range\",\n      \"possible_keys\": [\n        \"PRIMARY\"\n      ],\n      \"key\": \"PRIMARY\",\n      \"used_key_parts\": [\n        \"Code\"\n      ],\n      \"key_length\": \"12\",\n      \"rows_examined_per_scan\": 17,\n      \"rows_produced_per_join\": 17,\n      \"filtered\": \"100.00\",\n      \"cost_info\": {\n        \"read_cost\": \"1.97\",\n        \"eval_cost\": \"1.70\",\n        \"prefix_cost\": \"3.67\",\n        \"data_read_per_join\": \"16K\"\n      },\n      \"used_columns\": [\n        \"Code\",\n        \"Name\"\n      ],\n      \"attached_condition\": \"(`world`.`country`.`Code` like 'A%')\"\n    }\n  }\n}                                                                              |\n+------------------------------------------------------------------------------+\n1 row in set, 1 warning (0.00 sec)\nTo return the default output of EXPLAIN to the tabular format, set explain_format to TRADITIONAL.\nAlternatively, you can set it to DEFAULT, which has the same effect, as shown here:\nmysql> SET @@explain_format=DEFAULT;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @@explain_format;\n+------------------+\n| @@explain_format |\n+------------------+\n| TRADITIONAL      |\n+------------------+\n1 row in set (0.00 sec)\nMySQL 9.1 supports two versions of the JSON output format. Version 1 is the linear format always\nused in MySQL 8.2 and earlier; this remains the default in MySQL 9.1, and is used in the examples\nalready shown in this section. Version 2 of the JSON output format is based on access paths, and\nis intended to provide compatibility with future versions of the MySQL Optimizer. You can switch to\nthe Version 2 format by setting the value of the explain_json_format_version server system\nvariable to 2, as shown here for the same EXPLAIN statement used in the previous example:\nmysql> SELECT @@explain_json_format_version;\n+-------------------------------+\n| @@explain_json_format_version |\n+-------------------------------+\n|                             1 |\n+-------------------------------+\n1 row in set (0.00 sec)\nmysql> SET @@explain_json_format_version = 2;\nQuery OK, 0 rows affected (0.00 sec)\nmysql> SELECT @@explain_json_format_version;\n+-------------------------------+\n| @@explain_json_format_version |\n+-------------------------------+\n|                             2 |\n+-------------------------------+\n1 row in set (0.00 sec)\nmysql> EXPLAIN FORMAT=JSON SELECT Name FROM country WHERE Code LIKE 'A%';\n+------------------------------------------------------------------------------+\n| EXPLAIN                                                                      |\n+------------------------------------------------------------------------------+\n| {\n  \"query\": \"/* select#1 */ select `world`.`country`.`Name` AS `Name` from `world`.`country` where (`wor\n  \"inputs\": [\n    {\n      \"ranges\": [\n        \"('A' <= Code <= 'A????????')\"\n      ],\n      \"covering\": false,\n      \"operation\": \"Index range scan on country using PRIMARY over ('A' <= Code < 'A????????')\",\n      \"index_name\": \"PRIMARY\",\n      \"table_name\": \"country\",\n      \"access_type\": \"index\",\n      \"estimated_rows\": 17.0,\n      \"index_access_type\": \"index_range_scan\",\n      \"estimated_total_cost\": 3.668778400708174\n    }\n  ],\n  \"condition\": \"(country.`Code` like 'A%')\",\n  \"operation\": \"Filter: (country.`Code` like 'A%')\",\n  \"access_type\": \"filter\",\n  \"estimated_rows\": 17.0,\n  \"estimated_total_cost\": 3.668778400708174\n}                                                                              |\n+------------------------------------------------------------------------------+\nSetting explain_json_format_version = 2 also enables support for an INTO clause with\nEXPLAIN ANALYZE FORMAT=JSON, which enables you to store the JSON output in a user variable,\nas shown here:\nmysql> EXPLAIN ANALYZE FORMAT=JSON INTO @v1\n    ->   SELECT Name FROM country WHERE Code LIKE 'A%'\\G\n*************************** 1. row ***************************\n@v1: {\n  \"query\": \"/* select#1 */ select `world`.`country`.`Name` AS `Name` from `world`.`country` where (`world`.\n  \"inputs\": [\n    {\n      \"ranges\": [\n        \"('A' <= Code <= 'A????????')\"\n      ],\n      \"covering\": false,\n      \"operation\": \"Index range scan on country using PRIMARY over ('A' <= Code <= 'A????????')\",\n      \"index_name\": \"PRIMARY\",\n      \"table_name\": \"country\",\n      \"access_type\": \"index\",\n      \"actual_rows\": 17.0,\n      \"key_columns\": [\n        \"Code\"\n      ],\n      \"schema_name\": \"world\",\n      \"actual_loops\": 1,\n      \"used_columns\": [\n        \"Code\",\n        \"Name\"\n      ],\n      \"estimated_rows\": 17.0,\n      \"index_access_type\": \"index_range_scan\",\n      \"actual_last_row_ms\": 0.097402,\n      \"actual_first_row_ms\": 0.08752700000000001,\n      \"estimated_total_cost\": 3.668778400708174\n    }\n  ],\n  \"condition\": \"(country.`Code` like 'A%')\",\n  \"operation\": \"Filter: (country.`Code` like 'A%')\",\n  \"query_type\": \"select\",\n  \"access_type\": \"filter\",\n  \"actual_rows\": 17.0,\n  \"actual_loops\": 1,\n  \"estimated_rows\": 17.0,\n  \"filter_columns\": [\n    \"world.country.`Code`\"\n  ],\n  \"actual_last_row_ms\": 0.10903299999999999,\n  \"actual_first_row_ms\": 0.09328499999999999,\n  \"estimated_total_cost\": 3.668778400708174\n}\nYou can use the variable as an argument to JSON functions to obtain specific items of information from\nthe value, like this:\nmysql> SELECT JSON_EXTRACT(@v1,'$.index_name') AS iname,\n    ->        JSON_EXTRACT(@v1, '$.table_name') AS tname\\G\n*************************** 1. row ***************************\niname: \"PRIMARY\"\ntname: \"country\"\n1 row in set (0.00 sec)\nThis form of EXPLAIN ANALYZE requires an explicit FORMAT=JSON clause, and is supported only\nwith SELECT statements. An optional FOR SCHEMA option is also supported, but not required. (FOR\nDATABASE can also be used, instead.) The INTO clause is supported with FORMAT=JSON only\nwhen explain_json_format_version is equal to 2; otherwise the statement fails with EXPLAIN\nANALYZE does not support FORMAT=JSON with explain_json_format_version=1.\nAfter using the Version 2 format, you can cause the JSON output from all subsequent\nEXPLAIN FORMAT=JSON statements to revert to the Version 1 format by setting\nexplain_json_format_version back to 1 (the default).\nThe value of explain_json_format_version determines the version of the JSON output format\nemployed by all EXPLAIN statements which use it, whether the JSON format is used because a given\nEXPLAIN statement includes an explicit FORMAT=JSON option, or because the JSON format is used\nautomatically due to the explain_format system variable being set to JSON.\nWith the help of EXPLAIN, you can see where you should add indexes to tables so that the statement\nexecutes faster by using indexes to find rows. You can also use EXPLAIN to check whether the\noptimizer joins the tables in an optimal order. To give a hint to the optimizer to use a join order\ncorresponding to the order in which the tables are named in a SELECT statement, begin the statement\nwith SELECT STRAIGHT_JOIN rather than just SELECT. (See Section 15.2.13, “SELECT Statement”.)\nThe optimizer trace may sometimes provide information complementary to that of EXPLAIN. However,\nthe optimizer trace format and content are subject to change between versions. For details, see\nSection 10.15, “Tracing the Optimizer”.\nIf you have a problem with indexes not being used when you believe that they should be, run ANALYZE\nTABLE to update table statistics, such as cardinality of keys, that can affect the choices the optimizer\nmakes. See Section 15.7.3.1, “ANALYZE TABLE Statement”.\nNote\nMySQL Workbench has a Visual Explain capability that provides a visual\nrepresentation of EXPLAIN output. See Tutorial: Using Explain to Improve\nQuery Performance.\nObtaining Information with EXPLAIN ANALYZE\nEXPLAIN ANALYZE runs a statement and produces EXPLAIN output along with timing and additional,\niterator-based, information about how the optimizer's expectations matched the actual execution. For\neach iterator, the following information is provided:\n• Estimated execution cost\n(Some iterators are not accounted for by the cost model, and so are not included in the estimate.)\n• Estimated number of returned rows\n• Time to return first row\n• Time spent executing this iterator (including child iterators, but not parent iterators), in milliseconds.\n(When there are multiple loops, this figure shows the average time per loop.)\n• Number of rows returned by the iterator\n• Number of loops\nThe query execution information is displayed using the TREE output format, in which nodes represent\niterators. EXPLAIN ANALYZE uses an output format which can optionally be specified explicitly\nusing FORMAT=TREE or FORMAT=JSON; the default is TREE. FORMAT=JSON can be used only if\nexplain_json_format_version is set to 2.\nEXPLAIN ANALYZE can be used with SELECT statements, multi-table UPDATE and DELETE\nstatements, and TABLE statements.\nYou can terminate this statement using KILL QUERY or CTRL-C.\nEXPLAIN ANALYZE cannot be used with FOR CONNECTION.\nExample output:\nmysql> SELECT @@explain_format;\n+------------------+\n| @@explain_format |\n+------------------+\n| TRADITIONAL      |\n+------------------+\nmysql> EXPLAIN ANALYZE SELECT * FROM t1 JOIN t2 ON (t1.c1 = t2.c2)\\G\n*************************** 1. row ***************************\nEXPLAIN: -> Inner hash join (t2.c2 = t1.c1)  (cost=3.5 rows=5) \n(actual time=0.121..0.131 rows=1 loops=1) \n    -> Table scan on t2  (cost=0.07 rows=5) \n(actual time=0.0126..0.0221 rows=5 loops=1) \n    -> Hash\n        -> Table scan on t1  (cost=0.75 rows=5) \n(actual time=0.0372..0.0534 rows=5 loops=1)\nmysql> EXPLAIN ANALYZE FORMAT=TREE SELECT * FROM t3 WHERE i > 8\\G\n*************************** 1. row ***************************\nEXPLAIN: -> Filter: (t3.i > 8)  (cost=0.75 rows=1.67) \n(actual time=0.0484..0.0542 rows=1 loops=1)\n    -> Table scan on t3  (cost=0.75 rows=5) \n(actual time=0.0417..0.0494 rows=5 loops=1)\nmysql> EXPLAIN ANALYZE FORMAT=JSON SELECT * FROM t3 WHERE pk < 17\\G\n*************************** 1. row ***************************\nEXPLAIN: {\n  \"query\": \"/* select#1 */ select `a`.`t3`.`pk` AS `pk`,`a`.`t3`.`i` AS `i` from `a`.`t3` where (`a`.`t3`.`\n  \"inputs\": [\n    {\n      \"ranges\": [\n        \"(pk < 17)\"\n      ],\n      \"covering\": false,\n      \"operation\": \"Index range scan on t3 using PRIMARY over (pk < 17)\",\n      \"index_name\": \"PRIMARY\",\n      \"table_name\": \"t3\",\n      \"access_type\": \"index\",\n      \"actual_rows\": 3.0,\n      \"key_columns\": [\n        \"pk\"\n      ],\n      \"schema_name\": \"a\",\n      \"actual_loops\": 1,\n      \"used_columns\": [\n        \"pk\",\n        \"i\"\n      ],\n      \"estimated_rows\": 3.0,\n      \"index_access_type\": \"index_range_scan\",\n      \"actual_last_row_ms\": 0.034214,\n      \"actual_first_row_ms\": 0.03052,\n      \"estimated_total_cost\": 0.860618301731245\n    }\n  ],\n  \"condition\": \"(t3.pk < 17)\",\n  \"operation\": \"Filter: (t3.pk < 17)\",\n  \"query_type\": \"select\",\n  \"access_type\": \"filter\",\n  \"actual_rows\": 3.0,\n  \"actual_loops\": 1,\n  \"estimated_rows\": 3.0,\n  \"filter_columns\": [\n    \"a.t3.pk\"\n  ],\n  \"actual_last_row_ms\": 0.038189,\n  \"actual_first_row_ms\": 0.033429,\n  \"estimated_total_cost\": 0.860618301731245\n}\nThe tables used in the example output were created by the statements shown here:\nCREATE TABLE t1 (\n    c1 INTEGER DEFAULT NULL,\n    c2 INTEGER DEFAULT NULL\n);\nCREATE TABLE t2 (\n    c1 INTEGER DEFAULT NULL,\n    c2 INTEGER DEFAULT NULL\n);\nCREATE TABLE t3 (\n    pk INTEGER NOT NULL PRIMARY KEY,\n    i INTEGER DEFAULT NULL\n);\nValues shown for actual time in the output of this statement are expressed in milliseconds.\nexplain_format has the following effects on EXPLAIN ANALYZE:\n• If the value of this variable is TRADITIONAL or TREE (or the synonym DEFAULT), EXPLAIN\nANALYZE uses the TREE format unless the statement includes FORMAT=JSON.\n• If the value of explain_format is JSON, EXPLAIN ANALYZE uses the JSON format unless\nFORMAT=TREE is specified as part of the statement.\nUsing FORMAT=TRADITIONAL or FORMAT=DEFAULT with EXPLAIN ANALYZE always raises an error,\nregardless of the value of explain_format.\nIn MySQL 9.1, numbers in the output of EXPLAIN ANALYZE and EXPLAIN FORMAT=TREE are\nformatted according to the following rules:\n• Numbers in the range 0.001-999999.5 are printed as decimal numbers.\nDecimal numbers less than 1000 have three significant digits; the remainder have four, five, or six.\n• Numbers outside the range 0.001-999999.5 are printed in engineering format. Examples of such\nvalues are 1.23e+9 and 934e-6.\n• No trailing zeros are printed. For example, we print 2.3 rather than 2.30, and 1.2e+6 rather than\n1.20e+6.\n• Numbers less than 1e-12 are printed as 0.",
    "15.8.3 HELP Statement": "15.8.3 HELP Statement\nHELP 'search_string'\nThe HELP statement returns online information from the MySQL Reference Manual. Its proper\noperation requires that the help tables in the mysql database be initialized with help topic information\n(see Section 7.1.17, “Server-Side Help Support”).\nThe HELP statement searches the help tables for the given search string and displays the result of the\nsearch. The search string is not case-sensitive.\nThe search string can contain the wildcard characters % and _. These have the same meaning as for\npattern-matching operations performed with the LIKE operator. For example, HELP 'rep%' returns a\nlist of topics that begin with rep.\nThe HELP statement does not require a terminator such as ; or \\G.\nThe HELP statement understands several types of search strings:\n• At the most general level, use contents to retrieve a list of the top-level help categories:\nHELP 'contents'\n• For a list of topics in a given help category, such as Data Types, use the category name:\nHELP 'data types'\n• For help on a specific help topic, such as the ASCII() function or the CREATE TABLE statement,\nuse the associated keyword or keywords:\nHELP 'ascii'\nHELP 'create table'\nIn other words, the search string matches a category, many topics, or a single topic. The following\ndescriptions indicate the forms that the result set can take.\n• Empty result\nNo match could be found for the search string.\nExample: HELP 'fake'\nYields:\nNothing found\nPlease try to run 'help contents' for a list of all accessible topics\n• Result set containing a single row\nThis means that the search string yielded a hit for the help topic. The result includes the following\nitems:\n• name: The topic name.\n• description: Descriptive help text for the topic.\n• example: One or more usage examples. (May be empty.)\nExample: HELP 'log'\nYields:\nName: 'LOG'\nDescription:\nSyntax:\nLOG(X), LOG(B,X)\nIf called with one parameter, this function returns the natural\nlogarithm of X. If X is less than or equal to 0.0E0, the function\nreturns NULL and a warning \"Invalid argument for logarithm\" is\nreported. Returns NULL if X or B is NULL.\nThe inverse of this function (when called with a single argument) is\nthe EXP() function.\nURL: https://dev.mysql.com/doc/refman/8.4/en/mathematical-functions.html\nExamples:\nmysql> SELECT LOG(2);\n        -> 0.69314718055995\nmysql> SELECT LOG(-2);\n        -> NULL\n• List of topics.\nThis means that the search string matched multiple help topics.\nExample: HELP 'status'\nYields:\nMany help items for your request exist.\nTo make a more specific request, please type 'help <item>',\nwhere <item> is one of the following topics:\n   FLUSH\n   SHOW\n   SHOW BINARY LOG STATUS\n   SHOW ENGINE\n   SHOW FUNCTION STATUS\n   SHOW PROCEDURE STATUS\n   SHOW REPLICA STATUS\n   SHOW STATUS\n   SHOW TABLE STATUS\n• List of topics.\nA list is also displayed if the search string matches a category.\nExample: HELP 'functions'\nYields:\nYou asked for help about help category: \"Functions\"\nFor more information, type 'help <item>', where <item> is one of the following\ncategories:\n   Aggregate Functions and Modifiers\n   Bit Functions\n   Cast Functions and Operators\n   Comparison Operators\n   Date and Time Functions\n   Encryption Functions\n   Enterprise Encryption Functions\n   Flow Control Functions\n   GROUP BY Functions and Modifiers\n   GTID\n   Information Functions\n   Internal Functions\n   Locking Functions\n   Logical Operators\n   Miscellaneous Functions\n   Numeric Functions\n   Performance Schema Functions\n   Spatial Functions\n   String Functions\n   Window Functions\n   XML",
    "15.8.4 USE Statement": "15.8.4 USE Statement\nUSE db_name\nThe USE statement tells MySQL to use the named database as the default (current) database for\nsubsequent statements. This statement requires some privilege for the database or some object within\nit.\nThe named database remains the default until the end of the session or another USE statement is\nissued:\nUSE db1;\nSELECT COUNT(*) FROM mytable;   # selects from db1.mytable\nUSE db2;\nSELECT COUNT(*) FROM mytable;   # selects from db2.mytable\nThe database name must be specified on a single line. Newlines in database names are not supported.\nMaking a particular database the default by means of the USE statement does not preclude accessing\ntables in other databases. The following example accesses the author table from the db1 database\nand the editor table from the db2 database:\nUSE db1;\nSELECT author_name,editor_name FROM author,db2.editor\n  WHERE author.editor_id = db2.editor.editor_id;"
}